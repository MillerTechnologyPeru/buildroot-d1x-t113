From f46b6797597ddb299bd38ec08de17c63209db406 Mon Sep 17 00:00:00 2001
From: YuzukiTsuru <gloomyghost@gloomyghost.com>
Date: Fri, 25 Mar 2022 17:12:28 +0800
Subject: [PATCH 60/93] add sunxi riscv soc support

---
 drivers/soc/qcom/Kconfig           |   6 +-
 drivers/soc/qcom/cmd-db.c          |   5 +
 drivers/soc/qcom/rpmh-rsc.c        |   6 +
 drivers/soc/qcom/rpmhpd.c          |   5 +
 drivers/soc/sunxi/Kconfig          |  51 ++-
 drivers/soc/sunxi/Makefile         |   7 +
 drivers/soc/sunxi/gpu_domain.c     | 361 ++++++++++++++++++
 drivers/soc/sunxi/pm_domains.c     | 547 ++++++++++++++++++++++++++++
 drivers/soc/sunxi/pm_trace_nvmem.c | 147 ++++++++
 drivers/soc/sunxi/sunxi-dump.c     | 109 ++++++
 drivers/soc/sunxi/sunxi-sid.c      | 564 +++++++++++++++++++++++++++++
 drivers/soc/sunxi/sunxi_riscv_pm.c |  41 +++
 drivers/soc/sunxi/vf-test.c        | 184 ++++++++++
 drivers/soc/tegra/Kconfig          |   1 +
 14 files changed, 2030 insertions(+), 4 deletions(-)
 create mode 100644 drivers/soc/sunxi/gpu_domain.c
 create mode 100644 drivers/soc/sunxi/pm_domains.c
 create mode 100644 drivers/soc/sunxi/pm_trace_nvmem.c
 create mode 100644 drivers/soc/sunxi/sunxi-dump.c
 create mode 100644 drivers/soc/sunxi/sunxi-sid.c
 create mode 100644 drivers/soc/sunxi/sunxi_riscv_pm.c
 create mode 100644 drivers/soc/sunxi/vf-test.c

diff --git a/drivers/soc/qcom/Kconfig b/drivers/soc/qcom/Kconfig
index 661e47acc..90db45593 100644
--- a/drivers/soc/qcom/Kconfig
+++ b/drivers/soc/qcom/Kconfig
@@ -17,7 +17,7 @@ config QCOM_AOSS_QMP
 	  Subsystem (AOSS) using Qualcomm Messaging Protocol (QMP).
 
 config QCOM_COMMAND_DB
-	bool "Qualcomm Command DB"
+	tristate "Qualcomm Command DB"
 	depends on ARCH_QCOM || COMPILE_TEST
 	depends on OF_RESERVED_MEM
 	help
@@ -102,7 +102,7 @@ config QCOM_RMTFS_MEM
 	  Say y here if you intend to boot the modem remoteproc.
 
 config QCOM_RPMH
-	bool "Qualcomm RPM-Hardened (RPMH) Communication"
+	tristate "Qualcomm RPM-Hardened (RPMH) Communication"
 	depends on ARCH_QCOM && ARM64 || COMPILE_TEST
 	help
 	  Support for communication with the hardened-RPM blocks in
@@ -112,7 +112,7 @@ config QCOM_RPMH
 	  help apply the aggregated state on the resource.
 
 config QCOM_RPMHPD
-	bool "Qualcomm RPMh Power domain driver"
+	tristate "Qualcomm RPMh Power domain driver"
 	depends on QCOM_RPMH && QCOM_COMMAND_DB
 	help
 	  QCOM RPMh Power domain driver to support power-domains with
diff --git a/drivers/soc/qcom/cmd-db.c b/drivers/soc/qcom/cmd-db.c
index f6c3d17b0..1967757a2 100644
--- a/drivers/soc/qcom/cmd-db.c
+++ b/drivers/soc/qcom/cmd-db.c
@@ -2,6 +2,7 @@
 /* Copyright (c) 2016-2018, The Linux Foundation. All rights reserved. */
 
 #include <linux/kernel.h>
+#include <linux/module.h>
 #include <linux/of.h>
 #include <linux/of_address.h>
 #include <linux/of_platform.h>
@@ -266,6 +267,7 @@ static const struct of_device_id cmd_db_match_table[] = {
 	{ .compatible = "qcom,cmd-db" },
 	{ },
 };
+MODULE_DEVICE_TABLE(of, cmd_db_match_table);
 
 static struct platform_driver cmd_db_dev_driver = {
 	.probe  = cmd_db_dev_probe,
@@ -280,3 +282,6 @@ static int __init cmd_db_device_init(void)
 	return platform_driver_register(&cmd_db_dev_driver);
 }
 arch_initcall(cmd_db_device_init);
+
+MODULE_DESCRIPTION("Qualcomm Technologies, Inc. Command DB for QCOM SoCs");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/soc/qcom/rpmh-rsc.c b/drivers/soc/qcom/rpmh-rsc.c
index 8924fcd9f..f3409fe6a 100644
--- a/drivers/soc/qcom/rpmh-rsc.c
+++ b/drivers/soc/qcom/rpmh-rsc.c
@@ -11,6 +11,7 @@
 #include <linux/io.h>
 #include <linux/kernel.h>
 #include <linux/list.h>
+#include <linux/module.h>
 #include <linux/of.h>
 #include <linux/of_irq.h>
 #include <linux/of_platform.h>
@@ -709,6 +710,8 @@ static const struct of_device_id rpmh_drv_match[] = {
 	{ .compatible = "qcom,rpmh-rsc", },
 	{ }
 };
+MODULE_DEVICE_TABLE(of, rpmh_drv_match);
+
 
 static struct platform_driver rpmh_driver = {
 	.probe = rpmh_rsc_probe,
@@ -724,3 +727,6 @@ static int __init rpmh_driver_init(void)
 	return platform_driver_register(&rpmh_driver);
 }
 arch_initcall(rpmh_driver_init);
+
+MODULE_DESCRIPTION("Qualcomm Technologies, Inc. RPMh Driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/soc/qcom/rpmhpd.c b/drivers/soc/qcom/rpmhpd.c
index 51850cc68..a858a1709 100644
--- a/drivers/soc/qcom/rpmhpd.c
+++ b/drivers/soc/qcom/rpmhpd.c
@@ -4,6 +4,7 @@
 #include <linux/err.h>
 #include <linux/init.h>
 #include <linux/kernel.h>
+#include <linux/module.h>
 #include <linux/mutex.h>
 #include <linux/pm_domain.h>
 #include <linux/slab.h>
@@ -135,6 +136,7 @@ static const struct of_device_id rpmhpd_match_table[] = {
 	{ .compatible = "qcom,sdm845-rpmhpd", .data = &sdm845_desc },
 	{ }
 };
+MODULE_DEVICE_TABLE(of, rpmhpd_match_table);
 
 static int rpmhpd_send_corner(struct rpmhpd *pd, int state,
 			      unsigned int corner, bool sync)
@@ -406,3 +408,6 @@ static int __init rpmhpd_init(void)
 	return platform_driver_register(&rpmhpd_driver);
 }
 core_initcall(rpmhpd_init);
+
+MODULE_DESCRIPTION("Qualcomm Technologies, Inc. RPMh Power Domain Driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/soc/sunxi/Kconfig b/drivers/soc/sunxi/Kconfig
index f10fd6cae..3d144e2c0 100644
--- a/drivers/soc/sunxi/Kconfig
+++ b/drivers/soc/sunxi/Kconfig
@@ -3,10 +3,59 @@
 # Allwinner sunXi SoC drivers
 #
 config SUNXI_SRAM
-	bool
+	bool "Allwinner SRAM controller"
 	default ARCH_SUNXI
 	select REGMAP_MMIO
 	help
 	  Say y here to enable the SRAM controller support. This
 	  device is responsible on mapping the SRAM in the sunXi SoCs
 	  whether to the CPU/DMA, or to the devices.
+
+config GPU_PM_DOMAINS
+	tristate "Allwinner gpu power domain"
+	depends on PM
+	depends on ARCH_SUN50IW10
+	select PM_GENERIC_DOMAINS
+	select PM_GENERIC_DOMAINS_OF
+	help
+	 Say y here to enable power domain support.
+	 In order to meet high performance and low power requirements, a power
+	 management unit is designed or saving power when gpu in low power
+	 mode. The PPU is dedicated for managing the power of the GPU.
+
+	 If unsure, say N.
+
+config SUNXI_PM_DOMAINS
+	tristate "Allwinner power domain"
+	depends on PM
+	depends on ARCH_SUN50IW12 || ARCH_SUN8IW20
+	select PM_GENERIC_DOMAINS
+	select PM_GENERIC_DOMAINS_OF
+	select MFD_SYSCON
+	help
+	 Say y here to enable power domain support.
+	 In order to meet high performance and low power requirements, a power
+	 management unit is designed or saving power when domain in low power
+	 mode. The PPU is dedicated for managing the power of the domain.
+
+	 If unsure, say N.
+
+config SUNXI_SID
+	tristate "Allwinner sunxi sid support"
+	default n
+	help
+	 Say y here to enable the sunxi sid support.
+
+config SUNXI_RISCV_SUSPEND
+	tristate "Allwinner sunxi riscv suspend support"
+	default n
+	select HARDIRQS_SW_RESEND
+	select ARCH_SUSPEND_POSSIBLE
+
+config PM_TRACE_NVMEM
+	bool "trace pm suspend use nvmem"
+	default n
+	depends on ARM || ARM64
+	select PM_TRACE
+
+
diff --git a/drivers/soc/sunxi/Makefile b/drivers/soc/sunxi/Makefile
index 7816fbbec..87905d7d4 100644
--- a/drivers/soc/sunxi/Makefile
+++ b/drivers/soc/sunxi/Makefile
@@ -1,2 +1,9 @@
 # SPDX-License-Identifier: GPL-2.0-only
 obj-$(CONFIG_SUNXI_SRAM) +=	sunxi_sram.o
+obj-$(CONFIG_GPU_PM_DOMAINS) += gpu_domain.o
+obj-$(CONFIG_SUNXI_PM_DOMAINS) += pm_domains.o
+obj-$(CONFIG_SUNXI_SID) +=        sunxi-sid.o
+obj-$(CONFIG_SUNXI_DUMP) +=       sunxi-dump.o
+obj-$(CONFIG_SUNXI_RISCV_SUSPEND) += sunxi_riscv_pm.o
+obj-$(CONFIG_PM_TRACE_NVMEM) += pm_trace_nvmem.o
+obj-m += vf-test.o
diff --git a/drivers/soc/sunxi/gpu_domain.c b/drivers/soc/sunxi/gpu_domain.c
new file mode 100644
index 000000000..098aef790
--- /dev/null
+++ b/drivers/soc/sunxi/gpu_domain.c
@@ -0,0 +1,361 @@
+/*
+ * Allwinner GPU power domain support.
+ *
+ * Copyright (C) 2019 Allwinner Technology, Inc.
+ *	fanqinghua <fanqinghua@allwinnertech.com>
+ *
+ * Implementation of gpu specific power domain control which is used in
+ * conjunction with runtime-pm. Support for both device-tree and non-device-tree
+ * based power domain support is included.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include <linux/reset.h>
+#include <linux/module.h>
+#include <linux/io.h>
+#include <linux/interrupt.h>
+#include <linux/err.h>
+#include <linux/slab.h>
+#include <linux/pm_domain.h>
+#include <linux/clk.h>
+#include <linux/regmap.h>
+#include <linux/delay.h>
+#include <linux/of.h>
+#include <linux/of_irq.h>
+#include <linux/of_address.h>
+#include <linux/of_platform.h>
+#include <linux/sched.h>
+#include <linux/mfd/syscon.h>
+
+#define DRIVER_NAME	"GPU power domain driver"
+#define GPU_RSTN_REG			0x0
+#define GPU_CLK_GATE_REG		0x4
+#define GPU_POWEROFF_GATE_REG	0x8
+#define GPU_PSWON_REG			0xC
+
+#define GPU_PSWOFF_REG			0x10
+#define GPU_PDA_OFF				0xff
+#define GPU_PDB_OFF				0xff0000
+
+#define GPU_PSW_DLY_REG			0x14
+#define GPU_PDOFFCTL_DLY_REG	0x18
+#define GPU_PDONCTL_DLY_REG		0x1C
+
+#define GPU_PD_STAT_REG			0x20
+#define GPU_PD_STAT_MASK		0x3
+#define GPU_PD_STAT_3D			0x0
+#define GPU_PD_STAT_HOST		0x1
+#define GPU_PD_STAT_ALLOFF		0x2
+
+#define PPU_CFG_REG				0x24
+#define POWER_CTRL_MODE_MASK	0x3
+#define POWER_CTRL_MODE_SW		0x1
+#define POWER_CTRL_MODE_HW		0x2
+#define PPU_POWER_ON_COMPLETE	0x10
+
+#define PPU_STAT_REG			0x28
+#define GPU_POWER_REQ			0x1
+#define GPU_STAT_3D_2_HOST		0x2
+#define GPU_STAT_HOST_2_3D		0x4
+#define GPU_STAT_POWER_MASK		0x7
+
+#define PPU_IRQ_MASK_REG		0x2C
+#define PSW_OFF_DLY_REG			0x30
+
+#define to_gpu_pd(gpd) container_of(gpd, struct gpu_pm_domain, genpd)
+
+/*
+ * gpu specific wrapper around the generic power domain
+ */
+struct gpu_pm_domain {
+	struct device *dev;
+	struct regmap *regmap;
+	char const *name;
+	struct clk *clk;
+	struct reset_control *reset;
+	int irq;
+	struct generic_pm_domain genpd;
+	spinlock_t ppu_lock;
+};
+
+static inline void gpu_rstn(struct gpu_pm_domain *pd, bool on)
+{
+	udelay(1);
+	regmap_write(pd->regmap, GPU_RSTN_REG, on ? 1 : 0);
+}
+
+static inline void gpu_clk_gate(struct gpu_pm_domain *pd, bool on)
+{
+	regmap_write(pd->regmap, GPU_CLK_GATE_REG, on ? 1 : 0);
+	udelay(1);
+}
+
+static inline void gpu_iso_b(struct gpu_pm_domain *pd, bool on)
+{
+	regmap_update_bits(pd->regmap,
+		GPU_POWEROFF_GATE_REG, BIT(1), on ? -1U : 0);
+}
+
+static inline void gpu_iso_a(struct gpu_pm_domain *pd, bool on)
+{
+	regmap_update_bits(pd->regmap,
+		GPU_POWEROFF_GATE_REG, BIT(0), on ? -1U : 0);
+}
+
+static inline void gpu_pwra_on(struct gpu_pm_domain *pd)
+{
+	unsigned int i;
+
+	for (i = 0; i < 8; i++) {
+		regmap_write(pd->regmap, GPU_PSWON_REG, 1 << i);
+		udelay(1);
+	}
+}
+
+static inline void gpu_pwra_off(struct gpu_pm_domain *pd)
+{
+	regmap_write(pd->regmap, GPU_PSWOFF_REG, GPU_PDA_OFF);
+}
+
+static inline void gpu_pwrb_on(struct gpu_pm_domain *pd)
+{
+	regmap_write(pd->regmap, GPU_PSWON_REG, BIT(23));
+	udelay(10);
+	regmap_write(pd->regmap, GPU_PSWON_REG, BIT(18));
+	udelay(10);
+	regmap_write(pd->regmap, GPU_PSWON_REG, BIT(16));
+	udelay(5);
+	regmap_write(pd->regmap, GPU_PSWON_REG, BIT(19));
+	udelay(5);
+	regmap_write(pd->regmap, GPU_PSWON_REG, BIT(20));
+	udelay(5);
+	regmap_write(pd->regmap, GPU_PSWON_REG, BIT(21));
+	udelay(5);
+	regmap_write(pd->regmap, GPU_PSWON_REG, BIT(22));
+	udelay(5);
+	regmap_write(pd->regmap, GPU_PSWON_REG, BIT(17));
+	udelay(5);
+}
+
+static inline void gpu_pwrb_off(struct gpu_pm_domain *pd)
+{
+	regmap_write(pd->regmap, GPU_PSWOFF_REG, GPU_PDB_OFF);
+}
+
+static inline void domain_b_on_flow(struct gpu_pm_domain *pd)
+{
+	gpu_pwrb_on(pd);
+	gpu_iso_b(pd, false);
+	regmap_write(pd->regmap, GPU_PD_STAT_REG, GPU_PD_STAT_3D);
+}
+
+static inline void domain_b_off_flow(struct gpu_pm_domain *pd)
+{
+	gpu_iso_b(pd, true);
+	gpu_pwrb_off(pd);
+	regmap_write(pd->regmap, GPU_PD_STAT_REG, GPU_PD_STAT_HOST);
+}
+
+static irqreturn_t ppu_irq_handler(int irq, void *dev_id)
+{
+	struct gpu_pm_domain *pd = dev_id;
+	unsigned int rdata;
+
+	regmap_read(pd->regmap, PPU_STAT_REG, &rdata);
+
+
+	/* gpu power req */
+	if (rdata & GPU_POWER_REQ) {
+		spin_lock(&(pd->ppu_lock));
+		if (((rdata >> 16) & GPU_STAT_POWER_MASK)
+			== GPU_STAT_3D_2_HOST)
+			domain_b_off_flow(pd);
+		else if (((rdata >> 16) & GPU_STAT_POWER_MASK)
+			== GPU_STAT_HOST_2_3D)
+			domain_b_on_flow(pd);
+
+		/* clear gpu power req pending */
+		regmap_write(pd->regmap, PPU_STAT_REG, 0x1);
+		/* send complete signal to gpu*/
+		regmap_read(pd->regmap, PPU_CFG_REG, &rdata);
+		regmap_write(pd->regmap, PPU_CFG_REG,
+			rdata | PPU_POWER_ON_COMPLETE);
+		spin_unlock(&(pd->ppu_lock));
+	}
+
+	return IRQ_HANDLED;
+}
+
+static int gpu_pd_power_on(struct generic_pm_domain *domain)
+{
+	struct gpu_pm_domain *pd = to_gpu_pd(domain);
+	unsigned int rdata;
+	unsigned long irqflags;
+
+	regmap_read(pd->regmap, GPU_PD_STAT_REG, &rdata);
+	WARN_ON((rdata & GPU_PD_STAT_MASK) != GPU_PD_STAT_ALLOFF);
+
+	spin_lock_irqsave(&(pd->ppu_lock), irqflags);
+
+	gpu_pwra_on(pd);
+	gpu_clk_gate(pd, true);
+	gpu_iso_a(pd, false);
+	gpu_pwrb_on(pd);
+	gpu_iso_b(pd, false);
+	gpu_rstn(pd, true);
+	udelay(10);
+	regmap_write(pd->regmap, GPU_PD_STAT_REG, GPU_PD_STAT_3D);
+	regmap_write(pd->regmap, PPU_STAT_REG, 0x1);
+	regmap_write(pd->regmap, PPU_IRQ_MASK_REG, 0x1);
+
+	spin_unlock_irqrestore(&(pd->ppu_lock), irqflags);
+
+	return 0;
+}
+
+static int gpu_pd_power_off(struct generic_pm_domain *domain)
+{
+	struct gpu_pm_domain *pd = to_gpu_pd(domain);
+	unsigned int rdata;
+	unsigned long irqflags;
+
+	regmap_read(pd->regmap, GPU_PD_STAT_REG, &rdata);
+	WARN_ON((rdata & GPU_PD_STAT_MASK) == GPU_PD_STAT_ALLOFF);
+
+	spin_lock_irqsave(&(pd->ppu_lock), irqflags);
+
+	gpu_iso_b(pd, true);
+	gpu_iso_a(pd, true);
+	gpu_clk_gate(pd, false);
+	gpu_rstn(pd, false);
+	gpu_pwrb_off(pd);
+	gpu_pwra_off(pd);
+	regmap_write(pd->regmap, GPU_PD_STAT_REG, GPU_PD_STAT_ALLOFF);
+	regmap_write(pd->regmap, PPU_STAT_REG, 0x1);
+	regmap_write(pd->regmap, PPU_IRQ_MASK_REG, 0x0);
+
+	spin_unlock_irqrestore(&(pd->ppu_lock), irqflags);
+
+	return 0;
+}
+
+static const struct of_device_id gpu_pm_domain_of_match[] = {
+	{
+		.compatible = "allwinner,gpu-pd",
+	},
+	{ },
+};
+MODULE_DEVICE_TABLE(of, gpu_pm_domain_of_match);
+
+static int gpu_domain_probe(struct platform_device *pdev)
+{
+	struct device_node *np = pdev->dev.of_node;
+	struct gpu_pm_domain *pd;
+	int ret = 0;
+
+	if (!np) {
+		dev_err(&pdev->dev, "failed to match gpu power domain\n");
+		return -ENODEV;
+	}
+
+	pd = devm_kzalloc(&pdev->dev, sizeof(*pd), GFP_KERNEL);
+	if (!pd) {
+		dev_err(&pdev->dev, "failed to malloc pd space\n");
+		return -ENOMEM;
+	}
+
+	pd->dev = &pdev->dev;
+	platform_set_drvdata(pdev, pd);
+
+	pd->genpd.name = np->full_name;
+	pd->name = pd->genpd.name;
+	pd->regmap = syscon_node_to_regmap(np);
+	if (IS_ERR(pd->regmap)) {
+		dev_err(&pdev->dev, "no regmap available\n");
+		return PTR_ERR(pd->regmap);
+	}
+
+	pd->genpd.power_off = gpu_pd_power_off;
+	pd->genpd.power_on = gpu_pd_power_on;
+	pd->genpd.flags = GENPD_FLAG_PM_CLK;
+
+	pd->irq = of_irq_get(np, 0);
+	if (pd->irq == -EPROBE_DEFER) {
+		dev_err(&pdev->dev, "failed to find gpu domain IRQ number\n");
+		return -EPROBE_DEFER;
+	}
+
+	ret = devm_request_irq(&pdev->dev, pd->irq, ppu_irq_handler,
+				0, "ppu_interrupt", (void *)pd);
+	if (ret) {
+		dev_err(&pdev->dev, "failed to request gpu domain interrupt\n");
+		return ret;
+	}
+
+	pd->reset = devm_reset_control_get(&pdev->dev, "ppu_rst");
+	if (IS_ERR(pd->reset))
+		return PTR_ERR(pd->reset);
+
+	pd->clk = devm_clk_get(&pdev->dev, "ppu");
+	if (IS_ERR(pd->clk)) {
+		dev_err(&pdev->dev, "failed to find clock\n");
+		return -ENOMEM;
+	}
+
+	ret = reset_control_deassert(pd->reset);
+	if (ret)
+		return ret;
+
+	ret = clk_prepare_enable(pd->clk);
+	if (ret)
+		goto assert_reset;
+
+	spin_lock_init(&(pd->ppu_lock));
+
+	regmap_write(pd->regmap, PPU_CFG_REG, POWER_CTRL_MODE_SW);
+	regmap_write(pd->regmap, PPU_IRQ_MASK_REG, 0x1);
+
+	if (IS_ENABLED(CONFIG_PM_GENERIC_DOMAINS)) {
+		pm_genpd_init(&pd->genpd, NULL, true);
+		of_genpd_add_provider_simple(np, &pd->genpd);
+	}
+
+	return 0;
+
+assert_reset:
+	reset_control_assert(pd->reset);
+	return ret;
+}
+
+static int gpu_domain_remove(struct platform_device *pdev)
+{
+	struct device_node *np = pdev->dev.of_node;
+	struct gpu_pm_domain *pd = platform_get_drvdata(pdev);
+
+	if (IS_ENABLED(CONFIG_PM_GENERIC_DOMAINS)) {
+		of_genpd_del_provider(np);
+		pm_genpd_remove(&pd->genpd);
+	}
+	clk_disable_unprepare(pd->clk);
+	reset_control_assert(pd->reset);
+	return 0;
+}
+
+static struct platform_driver gpu_domain_driver = {
+	.probe   = gpu_domain_probe,
+	.remove  = gpu_domain_remove,
+	.driver  = {
+		.name  = DRIVER_NAME,
+		.of_match_table = gpu_pm_domain_of_match,
+	},
+};
+
+module_platform_driver(gpu_domain_driver);
+MODULE_LICENSE("GPL v2");
+MODULE_DESCRIPTION("Allwinner GPU power domain driver");
+MODULE_ALIAS("platform:" DRIVER_NAME);
+MODULE_AUTHOR("fanqinghua <fanqinghua@allwinnertech.com>");
+MODULE_VERSION("1.0.1");
diff --git a/drivers/soc/sunxi/pm_domains.c b/drivers/soc/sunxi/pm_domains.c
new file mode 100644
index 000000000..d01cda2b5
--- /dev/null
+++ b/drivers/soc/sunxi/pm_domains.c
@@ -0,0 +1,547 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Allwinner power domain support.
+ *
+ * Copyright (c) 2021 ALLWINNER, Co. Ltd.
+ */
+
+#include <linux/reset.h>
+#include <linux/module.h>
+#include <linux/io.h>
+#include <linux/iopoll.h>
+#include <linux/err.h>
+#include <linux/pm_clock.h>
+#include <linux/pm_domain.h>
+#include <linux/of_address.h>
+#include <linux/of_clk.h>
+#include <linux/of_platform.h>
+#include <linux/clk.h>
+#include <linux/regmap.h>
+#include <linux/mfd/syscon.h>
+#include <dt-bindings/power/tv303-power.h>
+#include <dt-bindings/power/r528-power.h>
+
+struct sunxi_domain_info {
+	u32 domain_id;
+	u32 wait_mode;
+	u32 pwr_on_delay;
+	u32 pwr_off_delay;
+	u32 idle_mask;
+	u32 status_mask;
+	u32 trans_complete_mask;
+};
+
+struct sunxi_pmu_info {
+	u32 wait_mode_offset;
+	u32 pwr_off_delay_offset;
+	u32 pwr_on_delay_offset;
+	u32 pwr_offset;
+	u32 status_offset;
+	u32 num_domains;
+	const struct sunxi_domain_info *domain_info;
+};
+
+struct sunxi_pm_domain {
+	struct generic_pm_domain genpd;
+	const struct sunxi_domain_info *info;
+	struct sunxi_pmu *pmu;
+};
+
+struct sunxi_pmu {
+	struct device *dev;
+	struct clk *clk;
+	struct reset_control *reset;
+	struct regmap *regmap;
+	const struct sunxi_pmu_info *info;
+	struct mutex mutex; /* mutex lock for pmu */
+	struct genpd_onecell_data genpd_data;
+	struct generic_pm_domain *domains[];
+};
+
+#define DRIVER_NAME	"power domain driver"
+
+#define to_sunxi_pd(gpd) container_of(gpd, struct sunxi_pm_domain, genpd)
+
+#define DOMAIN_TV303(id, wait, pwr_on, pwr_off, imask, smask, trans_mask)	\
+{							\
+	.domain_id = (id),			\
+	.wait_mode = (wait),			\
+	.pwr_on_delay = (pwr_on),				\
+	.pwr_off_delay = (pwr_off),			\
+	.idle_mask = (imask),			\
+	.status_mask = (smask),				\
+	.trans_complete_mask = (trans_mask),			\
+}
+
+#define COMMAND_ON	0x1
+#define COMMAND_OFF	0x2
+#define STATUS_ON	0x10000
+#define STATUS_OFF	0x20000
+#define COMPLETE	BIT(1)
+#define BASE(id)	((id) << 7)
+
+static bool sunxi_pmu_domain_is_idle(struct sunxi_pm_domain *pd)
+{
+	struct sunxi_pmu *pmu = pd->pmu;
+	const struct sunxi_domain_info *pd_info = pd->info;
+	unsigned int val;
+
+	regmap_read(pmu->regmap, BASE(pd_info->domain_id) + pmu->info->status_offset, &val);
+	return (val & pd_info->idle_mask) == 0;
+}
+
+static bool sunxi_pmu_domain_is_on(struct sunxi_pm_domain *pd)
+{
+	struct sunxi_pmu *pmu = pd->pmu;
+	const struct sunxi_domain_info *pd_info = pd->info;
+	unsigned int val;
+
+	regmap_read(pmu->regmap, BASE(pd_info->domain_id) + pmu->info->status_offset, &val);
+
+	return (val & pd->info->status_mask) == STATUS_ON;
+}
+
+static bool sunxi_pmu_domain_is_complete(struct sunxi_pm_domain *pd)
+{
+	struct sunxi_pmu *pmu = pd->pmu;
+	const struct sunxi_domain_info *pd_info = pd->info;
+	unsigned int val;
+
+	regmap_read(pmu->regmap, BASE(pd_info->domain_id) + pmu->info->status_offset, &val);
+
+	return (val & pd->info->trans_complete_mask) == COMPLETE;
+}
+
+static void sunxi_do_pmu_set_power_domain(struct sunxi_pm_domain *pd,
+					     bool on)
+{
+	struct sunxi_pmu *pmu = pd->pmu;
+	const struct sunxi_domain_info *pd_info = pd->info;
+	struct generic_pm_domain *genpd = &pd->genpd;
+	bool is_on, is_complete;
+	unsigned int val;
+
+	regmap_write(pmu->regmap, BASE(pd_info->domain_id) + pmu->info->pwr_offset,
+			     on ? COMMAND_ON : COMMAND_OFF);
+
+	dsb(sy);
+
+	if (readx_poll_timeout_atomic(sunxi_pmu_domain_is_complete, pd, is_complete,
+				      is_complete == true, 0, 10000)) {
+		dev_err(pmu->dev,
+			"failed to set domain '%s', val=%d\n",
+			genpd->name, is_on);
+		return;
+	}
+
+	/* clear the complete bit */
+	regmap_read(pmu->regmap, BASE(pd_info->domain_id) + pmu->info->status_offset, &val);
+	regmap_write(pmu->regmap, BASE(pd_info->domain_id) + pmu->info->status_offset, val);
+
+	if (readx_poll_timeout_atomic(sunxi_pmu_domain_is_on, pd, is_on,
+				      is_on == on, 0, 10000)) {
+		dev_err(pmu->dev,
+			"failed to set domain '%s', val=%d\n",
+			genpd->name, is_on);
+		return;
+	}
+}
+
+static int sunxi_pd_init(struct sunxi_pm_domain *pd)
+{
+	struct sunxi_pmu *pmu = pd->pmu;
+	const struct sunxi_domain_info *pd_info = pd->info;
+
+	regmap_write(pmu->regmap, BASE(pd_info->domain_id) + pmu->info->wait_mode_offset,
+			     pd_info->wait_mode);
+	regmap_write(pmu->regmap, BASE(pd_info->domain_id) + pmu->info->pwr_on_delay_offset,
+			     pd_info->pwr_on_delay);
+	regmap_write(pmu->regmap, BASE(pd_info->domain_id) + pmu->info->pwr_off_delay_offset,
+			     pd_info->pwr_off_delay);
+	return 0;
+}
+
+static int sunxi_pd_power(struct sunxi_pm_domain *pd, bool power_on)
+{
+	struct sunxi_pmu *pmu = pd->pmu;
+	struct generic_pm_domain *genpd = &pd->genpd;
+	bool is_idle;
+	int ret;
+
+	ret = readx_poll_timeout_atomic(sunxi_pmu_domain_is_idle, pd,
+						is_idle, is_idle == true, 0, 10000);
+	if (ret) {
+		dev_err(pmu->dev,
+			"failed to set idle on domain '%s', val=%d\n",
+			genpd->name, is_idle);
+		return ret;
+	}
+
+	mutex_lock(&pmu->mutex);
+
+	if (sunxi_pmu_domain_is_on(pd) != power_on)
+		sunxi_do_pmu_set_power_domain(pd, power_on);
+
+	mutex_unlock(&pmu->mutex);
+	return 0;
+}
+
+static int sunxi_pd_power_on(struct generic_pm_domain *domain)
+{
+	struct sunxi_pm_domain *pd = to_sunxi_pd(domain);
+
+	return sunxi_pd_power(pd, true);
+}
+
+static int sunxi_pd_power_off(struct generic_pm_domain *domain)
+{
+	struct sunxi_pm_domain *pd = to_sunxi_pd(domain);
+
+	return sunxi_pd_power(pd, false);
+}
+
+static int sunxi_pm_add_one_domain(struct sunxi_pmu *pmu,
+				      struct device_node *node)
+{
+	const struct sunxi_domain_info *pd_info;
+	struct sunxi_pm_domain *pd;
+	u32 id;
+	int error;
+
+	error = of_property_read_u32(node, "reg", &id);
+	if (error) {
+		dev_err(pmu->dev,
+			"%pOFn: failed to retrieve domain id (reg): %d\n",
+			node, error);
+		return -EINVAL;
+	}
+
+	if (id >= pmu->info->num_domains) {
+		dev_err(pmu->dev, "%pOFn: invalid domain id %d\n",
+			node, id);
+		return -EINVAL;
+	}
+
+	pd_info = &pmu->info->domain_info[id];
+	if (!pd_info) {
+		dev_err(pmu->dev, "%pOFn: undefined domain id %d\n",
+			node, id);
+		return -EINVAL;
+	}
+
+	pd = devm_kzalloc(pmu->dev, sizeof(*pd), GFP_KERNEL);
+	if (!pd)
+		return -ENOMEM;
+
+	pd->info = pd_info;
+	pd->pmu = pmu;
+
+	error = sunxi_pd_init(pd);
+	if (error) {
+		dev_err(pmu->dev,
+			"failed to power on domain '%pOFn': %d\n",
+			node, error);
+		goto err;
+	}
+
+	pd->genpd.name = node->name;
+	pd->genpd.power_off = sunxi_pd_power_off;
+	pd->genpd.power_on = sunxi_pd_power_on;
+	pd->genpd.flags = GENPD_FLAG_PM_CLK;
+	pm_genpd_init(&pd->genpd, NULL, false);
+
+	pmu->genpd_data.domains[id] = &pd->genpd;
+	return 0;
+
+err:
+	return error;
+}
+
+static void sunxi_pm_remove_one_domain(struct sunxi_pm_domain *pd)
+{
+	int ret;
+
+	/*
+	 * We're in the error cleanup already, so we only complain,
+	 * but won't emit another error on top of the original one.
+	 */
+	ret = pm_genpd_remove(&pd->genpd);
+	if (ret < 0)
+		dev_err(pd->pmu->dev, "failed to remove domain '%s' : %d - state may be inconsistent\n",
+			pd->genpd.name, ret);
+}
+
+static void sunxi_pm_domain_cleanup(struct sunxi_pmu *pmu)
+{
+	struct generic_pm_domain *genpd;
+	struct sunxi_pm_domain *pd;
+	int i;
+
+	for (i = 0; i < pmu->genpd_data.num_domains; i++) {
+		genpd = pmu->genpd_data.domains[i];
+		if (genpd) {
+			pd = to_sunxi_pd(genpd);
+			sunxi_pm_remove_one_domain(pd);
+		}
+	}
+
+	/* devm will free our memory */
+}
+
+static int sunxi_pm_add_subdomain(struct sunxi_pmu *pmu,
+				     struct device_node *parent)
+{
+	struct device_node *np;
+	struct generic_pm_domain *child_domain, *parent_domain;
+	int error;
+
+	for_each_child_of_node(parent, np) {
+		u32 idx;
+
+		error = of_property_read_u32(parent, "reg", &idx);
+		if (error) {
+			dev_err(pmu->dev,
+				"%pOFn: failed to retrieve domain id (reg): %d\n",
+				parent, error);
+			goto err_out;
+		}
+		parent_domain = pmu->genpd_data.domains[idx];
+
+		error = sunxi_pm_add_one_domain(pmu, np);
+		if (error) {
+			dev_err(pmu->dev, "failed to handle node %pOFn: %d\n",
+				np, error);
+			goto err_out;
+		}
+
+		error = of_property_read_u32(np, "reg", &idx);
+		if (error) {
+			dev_err(pmu->dev,
+				"%pOFn: failed to retrieve domain id (reg): %d\n",
+				np, error);
+			goto err_out;
+		}
+		child_domain = pmu->genpd_data.domains[idx];
+
+		error = pm_genpd_add_subdomain(parent_domain, child_domain);
+		if (error) {
+			dev_err(pmu->dev, "%s failed to add subdomain %s: %d\n",
+				parent_domain->name, child_domain->name, error);
+			goto err_out;
+		} else {
+			dev_dbg(pmu->dev, "%s add subdomain: %s\n",
+				parent_domain->name, child_domain->name);
+		}
+
+		sunxi_pm_add_subdomain(pmu, np);
+	}
+
+	return 0;
+
+err_out:
+	of_node_put(np);
+	return error;
+}
+
+static int sunxi_pm_domain_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct device_node *np = dev->of_node;
+	struct device_node *node;
+	struct device *parent;
+	struct sunxi_pmu *pmu;
+	const struct of_device_id *match;
+	const struct sunxi_pmu_info *pmu_info;
+	int error;
+
+	if (!np) {
+		dev_err(dev, "device tree node not found\n");
+		return -ENODEV;
+	}
+
+	match = of_match_device(dev->driver->of_match_table, dev);
+	if (!match || !match->data) {
+		dev_err(dev, "missing pmu data\n");
+		return -EINVAL;
+	}
+
+	pmu_info = match->data;
+
+	pmu = devm_kzalloc(dev,
+			   struct_size(pmu, domains, pmu_info->num_domains),
+			   GFP_KERNEL);
+	if (!pmu)
+		return -ENOMEM;
+
+	pmu->dev = &pdev->dev;
+	platform_set_drvdata(pdev, pmu);
+
+	mutex_init(&pmu->mutex);
+
+	pmu->info = pmu_info;
+
+	pmu->genpd_data.domains = pmu->domains;
+	pmu->genpd_data.num_domains = pmu_info->num_domains;
+
+	parent = dev->parent;
+	if (!parent) {
+		dev_err(dev, "no parent for syscon devices\n");
+		return -ENODEV;
+	}
+
+	pmu->regmap = syscon_node_to_regmap(parent->of_node);
+	if (IS_ERR(pmu->regmap)) {
+		dev_err(dev, "no regmap available\n");
+		return PTR_ERR(pmu->regmap);
+	}
+
+	error = -ENODEV;
+
+	for_each_available_child_of_node(np, node) {
+		error = sunxi_pm_add_one_domain(pmu, node);
+		if (error) {
+			dev_err(dev, "failed to handle node %pOFn: %d\n",
+				node, error);
+			of_node_put(node);
+			goto err_out;
+		}
+
+		error = sunxi_pm_add_subdomain(pmu, node);
+		if (error < 0) {
+			dev_err(dev, "failed to handle subdomain node %pOFn: %d\n",
+				node, error);
+			of_node_put(node);
+			goto err_out;
+		}
+	}
+
+	if (error) {
+		dev_dbg(dev, "no power domains defined\n");
+		goto err_out;
+	}
+
+	pmu->reset = devm_reset_control_get(dev, "ppu_rst");
+	if (IS_ERR(pmu->reset)) {
+		dev_err(dev, "failed to get reset control: %d\n", IS_ERR(pmu->reset));
+		goto err_out;
+	}
+
+	pmu->clk = devm_clk_get(dev, "ppu");
+	if (IS_ERR(pmu->clk)) {
+		dev_err(&pdev->dev, "failed to get clock\n");
+		goto err_out;
+	}
+
+	error = reset_control_deassert(pmu->reset);
+	if (error) {
+		dev_err(dev, "reset control deassert failed!\n");
+		goto err_out;
+	}
+
+	error = clk_prepare_enable(pmu->clk);
+	if (error) {
+		dev_err(dev, "clk prepare enable failed!\n");
+		goto assert_reset;
+	}
+
+	error = of_genpd_add_provider_onecell(np, &pmu->genpd_data);
+	if (error) {
+		dev_err(dev, "failed to add provider: %d\n", error);
+		goto clk_disable;
+	}
+
+	return 0;
+
+clk_disable:
+	clk_disable_unprepare(pmu->clk);
+
+assert_reset:
+	reset_control_assert(pmu->reset);
+
+err_out:
+	sunxi_pm_domain_cleanup(pmu);
+	return error;
+}
+
+static int sunxi_pm_domain_remove(struct platform_device *pdev)
+{
+	struct device_node *np = pdev->dev.of_node;
+	struct sunxi_pmu *pmu = platform_get_drvdata(pdev);
+
+	if (IS_ENABLED(CONFIG_PM_GENERIC_DOMAINS)) {
+		of_genpd_del_provider(np);
+		sunxi_pm_domain_cleanup(pmu);
+	}
+
+	clk_disable_unprepare(pmu->clk);
+	reset_control_assert(pmu->reset);
+	return 0;
+}
+
+static const struct sunxi_domain_info tv303_pm_domains[] = {
+	[TV303_PD_GPU] = DOMAIN_TV303(TV303_PD_GPU,  0x8, 0x080808,  0x080808,  BIT(3),  0x30000,  BIT(1)),
+	[TV303_PD_TVFE] = DOMAIN_TV303(TV303_PD_TVFE,  0x8, 0x080808,  0x080808,  BIT(3),  0x30000,  BIT(1)),
+	[TV303_PD_TVCAP] = DOMAIN_TV303(TV303_PD_TVCAP, 0x8, 0x080808, 0x080808,  BIT(3),  0x30000,  BIT(1)),
+	[TV303_PD_VE] = DOMAIN_TV303(TV303_PD_VE, 0x8, 0x080808, 0x080808,  BIT(3),  0x30000,  BIT(1)),
+	[TV303_PD_AV1] = DOMAIN_TV303(TV303_PD_AV1, 0x8, 0x080808, 0x080808,  BIT(3),  0x30000,  BIT(1)),
+};
+
+static const struct sunxi_pmu_info tv303_pmu = {
+	.wait_mode_offset = 0x14,
+	.pwr_off_delay_offset = 0x18,
+	.pwr_on_delay_offset = 0x1c,
+	.pwr_offset = 0x20,
+	.status_offset = 0x24,
+	.num_domains = ARRAY_SIZE(tv303_pm_domains),
+	.domain_info = tv303_pm_domains,
+};
+
+static const struct sunxi_domain_info r528_pm_domains[] = {
+	[R528_PD_CPU] = DOMAIN_TV303(R528_PD_CPU,  0x8, 0x080808,  0x080808,  BIT(3),  0x30000,  BIT(1)),
+	[R528_PD_VE] = DOMAIN_TV303(R528_PD_VE,  0x8, 0x080808,  0x080808,  BIT(3),  0x30000,  BIT(1)),
+	[R528_PD_DSP] = DOMAIN_TV303(R528_PD_DSP, 0x8, 0x080808, 0x080808,  BIT(3),  0x30000,  BIT(1)),
+};
+
+static const struct sunxi_pmu_info r528_pmu = {
+	.wait_mode_offset = 0x14,
+	.pwr_off_delay_offset = 0x18,
+	.pwr_on_delay_offset = 0x1c,
+	.pwr_offset = 0x20,
+	.status_offset = 0x24,
+	.num_domains = ARRAY_SIZE(r528_pm_domains),
+	.domain_info = r528_pm_domains,
+};
+
+static const struct of_device_id sunxi_pm_domain_dt_match[] = {
+	{
+		.compatible = "allwinner,tv303-power-controller",
+		.data = (void *)&tv303_pmu,
+	},
+	{
+		.compatible = "allwinner,r528-power-controller",
+		.data = (void *)&r528_pmu,
+	},
+	{ /* sentinel */ },
+};
+
+static struct platform_driver power_domain_driver = {
+	.probe = sunxi_pm_domain_probe,
+	.remove  = sunxi_pm_domain_remove,
+	.driver = {
+		.name   = "sunxi-pm-domain",
+		.of_match_table = sunxi_pm_domain_dt_match,
+		/*
+		 * We can't forcibly eject devices form power domain,
+		 * so we can't really remove power domains once they
+		 * were added.
+		 */
+		.suppress_bind_attrs = true,
+	},
+};
+
+module_platform_driver(power_domain_driver);
+MODULE_LICENSE("GPL v2");
+MODULE_DESCRIPTION("Allwinner power domain driver");
+MODULE_ALIAS("platform:" DRIVER_NAME);
+MODULE_AUTHOR("fanqinghua <fanqinghua@allwinnertech.com>");
+MODULE_VERSION("1.0.0");
diff --git a/drivers/soc/sunxi/pm_trace_nvmem.c b/drivers/soc/sunxi/pm_trace_nvmem.c
new file mode 100644
index 000000000..a72788869
--- /dev/null
+++ b/drivers/soc/sunxi/pm_trace_nvmem.c
@@ -0,0 +1,147 @@
+#define pr_fmt(fmt) "pm_trace: " fmt
+
+#include <linux/pm-trace.h>
+#include <linux/pm.h>
+#include <asm/pm-trace.h>
+#include <linux/export.h>
+#include <linux/suspend.h>
+#include <linux/rtc.h>
+#include <linux/of.h>
+#include <linux/nvmem-consumer.h>
+#include <linux/platform_device.h>
+#include "../drivers/base/power/power.h"
+
+#define USERHASH (16)
+#define FILEHASH (997)
+#define DEVHASH (1009)
+
+#define DEVSEED (7919)
+
+static uint32_t hash_value_early_read;
+static uint32_t dev_hash_value;
+static struct nvmem_cell *nc;
+
+static unsigned int hash_string(unsigned int seed, const char *data,
+				unsigned int mod)
+{
+	unsigned char c;
+
+	while ((c = *data++) != 0) {
+		seed = (seed << 16) + (seed << 6) - seed + c;
+	}
+
+	return seed % mod;
+}
+
+void generate_pm_trace(const void *tracedata, unsigned int user)
+{
+	if (!IS_ERR_OR_NULL(nc))
+		nvmem_cell_write(nc, &dev_hash_value, sizeof(uint32_t));
+}
+EXPORT_SYMBOL(generate_pm_trace);
+
+int show_trace_dev_match(char *buf, size_t size)
+{
+	unsigned int value = hash_value_early_read;
+	int ret = 0;
+	struct list_head *entry;
+
+	/*
+	 * It's possible that multiple devices will match the hash and we can't
+	 * tell which is the culprit, so it's best to output them all.
+	 */
+	device_pm_lock();
+	entry = dpm_list.prev;
+	while (size && entry != &dpm_list) {
+		struct device *dev = to_device(entry);
+		unsigned int hash = hash_string(DEVSEED, dev_name(dev),
+						DEVHASH);
+		if (hash == value) {
+			int len = snprintf(buf, size, "%s\n",
+					    dev_driver_string(dev));
+			if (len > size)
+				len = size;
+			buf += len;
+			ret += len;
+			size -= len;
+		}
+		entry = entry->prev;
+	}
+	device_pm_unlock();
+	return ret;
+}
+EXPORT_SYMBOL(show_trace_dev_match);
+
+void set_trace_device(struct device *dev)
+{
+	dev_hash_value = hash_string(DEVSEED, dev_name(dev), DEVHASH);
+}
+EXPORT_SYMBOL(set_trace_device);
+
+static int sunxi_pm_trace_probe(struct platform_device *pdev)
+{
+	struct device_node *nd;
+	size_t size;
+	int rst = 0;
+	unsigned int *v;
+
+	nd = of_find_node_with_property(NULL, "pm-trace");
+	if (!nd) {
+		pr_err("can not find pm-trace node\n");
+		rst = -ENODEV;
+		goto nodev;
+	}
+
+	nc = of_nvmem_cell_get(nd, NULL);
+	if (IS_ERR_OR_NULL(nc)) {
+		pr_err("can not get nvmem cell\n");
+		rst = PTR_ERR(nc);
+		goto nocell;
+	}
+
+	v = nvmem_cell_read(nc, &size);
+	if (IS_ERR(v)) {
+		pr_err("can not read nvmem cell\n");
+		rst = -EIO;
+		goto err_cell_read;
+	}
+	if (sizeof(uint32_t) >= size)
+		memcpy(&hash_value_early_read, v, size);
+
+	kfree(v);
+
+	return 0;
+
+err_cell_read:
+	nvmem_cell_put(nc);
+nocell:
+	of_node_put(nd);
+nodev:
+	return rst;
+}
+
+static int sunxi_pm_trace_remove(struct platform_device *pdev)
+{
+	return 0;
+}
+
+static struct platform_driver pm_trace_drv = {
+	.probe = sunxi_pm_trace_probe,
+	.remove = sunxi_pm_trace_remove,
+	.driver = {
+		.name = "pm-trace",
+		.owner = THIS_MODULE,
+	},
+};
+
+static int pm_trace_init(void)
+{
+	platform_device_register_simple("pm-trace", PLATFORM_DEVID_NONE, 0, 0);
+	platform_driver_register(&pm_trace_drv);
+
+	return 0;
+}
+
+late_initcall(pm_trace_init);
+
+
diff --git a/drivers/soc/sunxi/sunxi-dump.c b/drivers/soc/sunxi/sunxi-dump.c
new file mode 100644
index 000000000..7674e6adb
--- /dev/null
+++ b/drivers/soc/sunxi/sunxi-dump.c
@@ -0,0 +1,109 @@
+/*
+ * drivers/soc/sunxi-dump.c
+ *
+ * Copyright(c) 2019-2020 Allwinnertech Co., Ltd.
+ *         http://www.allwinnertech.com
+ *
+ * Allwinner sunxi crash dump debug
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ */
+
+#include <linux/io.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/err.h>
+#include <linux/slab.h>
+#include <soc/allwinner/sunxi_sip.h>
+#define SUNXI_DUMP_COMPATIBLE "sunxi-dump"
+static LIST_HEAD(dump_group_list);
+
+struct sunxi_dump_group {
+	char name[10];
+	u32 *reg_buf;
+	void __iomem *vir_base;
+	phys_addr_t phy_base;
+	u32 len;
+	struct list_head list;
+};
+
+int sunxi_dump_group_reg(struct sunxi_dump_group *group)
+{
+	u32 *buf = group->reg_buf;
+	void __iomem *membase = group->vir_base;
+	u32 len = ALIGN(group->len, 4);
+	int i;
+
+	for (i = 0; i < len; i += 4)
+		*(buf++) = readl(membase + i);
+
+	return 0;
+}
+
+int sunxi_dump_group_dump(void)
+{
+	struct sunxi_dump_group *dump_group;
+
+	list_for_each_entry(dump_group, &dump_group_list, list) {
+		sunxi_dump_group_reg(dump_group);
+	}
+	return 0;
+}
+EXPORT_SYMBOL(sunxi_dump_group_dump);
+
+int sunxi_dump_group_register(const char *name, phys_addr_t start, u32 len)
+{
+	struct sunxi_dump_group *dump_group = NULL;
+
+	dump_group = kmalloc(sizeof(struct sunxi_dump_group), GFP_KERNEL);
+	if (!dump_group)
+		return -ENOMEM;
+
+	memcpy(dump_group->name, name, sizeof(dump_group->name));
+	dump_group->phy_base = start;
+	dump_group->len = len;
+	dump_group->vir_base = ioremap(dump_group->phy_base, dump_group->len);
+	if (!dump_group->vir_base) {
+		pr_err("%s can't iomap\n", dump_group->name);
+		return -EINVAL;
+	}
+	dump_group->reg_buf = kmalloc(dump_group->len, GFP_KERNEL);
+	if (!dump_group->reg_buf)
+		return -ENOMEM;
+
+	list_add_tail(&dump_group->list, &dump_group_list);
+	return 0;
+}
+
+static int __init sunxi_dump_init(void)
+{
+	struct device_node *node;
+	int i = 0;
+	const char *name = NULL;
+	struct resource res;
+
+	node = of_find_compatible_node(NULL, NULL, SUNXI_DUMP_COMPATIBLE);
+
+	for (i = 0; ; i++) {
+		if (of_address_to_resource(node, i, &res))
+			break;
+		if (of_property_read_string_index(node, "group-names",
+						i, &name))
+			break;
+		sunxi_dump_group_register(name, res.start, resource_size(&res));
+	}
+
+	return 0;
+
+}
+
+int sunxi_set_crashdump_mode(void)
+{
+	invoke_scp_fn_smc(ARM_SVC_SUNXI_CRASHDUMP_START, 0, 0, 0);
+	while (1)
+		cpu_relax();
+}
+late_initcall(sunxi_dump_init);
diff --git a/drivers/soc/sunxi/sunxi-sid.c b/drivers/soc/sunxi/sunxi-sid.c
new file mode 100644
index 000000000..cda55c1a7
--- /dev/null
+++ b/drivers/soc/sunxi/sunxi-sid.c
@@ -0,0 +1,564 @@
+/*
+ * drivers/soc/sunxi-sid.c
+ *
+ * Copyright(c) 2014-2016 Allwinnertech Co., Ltd.
+ *         http://www.allwinnertech.com
+ *
+ * Author: sunny <sunny@allwinnertech.com>
+ * Author: superm <superm@allwinnertech.com>
+ * Author: Matteo <duanmintao@allwinnertech.com>
+ *
+ * Allwinner sunxi soc chip version and chip id manager.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ */
+
+#include <linux/io.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/err.h>
+#include <linux/sunxi-smc.h>
+
+#include <linux/module.h>
+#include <linux/printk.h>
+#include <linux/kernel.h>
+#include <linux/device.h>
+#include <linux/vmalloc.h>
+#include <linux/uaccess.h>
+#include <linux/fs.h>
+#include <linux/miscdevice.h>
+
+#include <linux/sunxi-sid.h>
+
+#define SID_DBG(fmt, arg...) pr_debug("%s()%d - "fmt, __func__, __LINE__, ##arg)
+#define SID_WARN(fmt, arg...) pr_warn("%s()%d - "fmt, __func__, __LINE__, ##arg)
+#define SID_ERR(fmt, arg...) pr_err("%s()%d - "fmt, __func__, __LINE__, ##arg)
+
+#if defined(CONFIG_ARCH_SUN50I) || defined(CONFIG_ARCH_SUN8IW6)
+#define SUNXI_SECURITY_SUPPORT	1
+#endif
+
+#define SUNXI_VER_MAX_NUM	8
+struct soc_ver_map {
+	u32 id;
+	u32 rev[SUNXI_VER_MAX_NUM];
+};
+
+#define SUNXI_SOC_ID_INDEX		1
+#define SUNXI_SECURITY_ENABLE_INDEX	2
+struct soc_ver_reg {
+	s8 compatile[48];
+	u32 offset;
+	u32 mask;
+	u32 shift;
+	struct soc_ver_map ver_map;
+};
+
+#define SUNXI_SOC_ID_IN_SID
+
+#if defined(CONFIG_ARCH_SUN50IW6)
+#define TYPE_SB (0b001)
+#define TYPE_NB (0b010)
+#define TYPE_FB (0b011)
+#else
+#define TYPE_SB (0b001)
+#define TYPE_NB (0b011)
+#define TYPE_FB (0b111)
+#endif
+
+static unsigned int sunxi_soc_chipid[4];
+static unsigned int sunxi_soc_ftzone[4];
+static unsigned int sunxi_serial[4];
+static int sunxi_soc_secure;
+static unsigned int sunxi_soc_bin;
+static unsigned int sunxi_soc_ver;
+static unsigned int sunxi_soc_rotpk_status;
+
+#ifndef CONFIG_SUNXI_SMC
+u32 sunxi_smc_readl(phys_addr_t addr)
+{
+	void __iomem *vaddr = ioremap(addr, 4);
+	u32 val;
+
+	val = readl(vaddr);
+	iounmap(vaddr);
+	return val;
+}
+#endif
+
+static s32 sid_get_vir_base(struct device_node **pnode, void __iomem **base,
+		s8 *compatible)
+{
+	*pnode = of_find_compatible_node(NULL, NULL, compatible);
+	if (IS_ERR_OR_NULL(*pnode)) {
+		SID_ERR("Failed to find \"%s\" in dts.\n", compatible);
+		return -ENXIO;
+	}
+
+	*base = of_iomap(*pnode, 0); /* reg[0] must be accessible. */
+	if (*base == NULL) {
+		SID_ERR("Unable to remap IO\n");
+		return -ENXIO;
+	}
+	SID_DBG("Base addr of \"%s\" is %p\n", compatible, *base);
+	return 0;
+}
+
+static s32  sid_get_phy_base(struct device_node **pnode, phys_addr_t **base,
+		s8 *compatible)
+{
+	struct resource res = {0};
+	int ret;
+	*pnode = of_find_compatible_node(*pnode, NULL, compatible);
+	if (IS_ERR_OR_NULL(*pnode)) {
+		SID_ERR("Failed to find \"%s\" in dts.\n", compatible);
+		return -ENXIO;
+	}
+
+	ret = of_address_to_resource(*pnode, 0, &res);
+	if (ret) {
+		SID_ERR("ret:%d Failed to get \"%s\"  base address\n", ret, compatible);
+		return -ENXIO;
+	}
+	*base = (phys_addr_t *)res.start;
+	SID_DBG("Base addr of \"%s\" is %p\n", compatible, (void *)*base);
+	return 0;
+}
+
+static s32 sid_get_base(struct device_node **pnode,
+		void __iomem **base, s8 *compatible, u32 sec)
+{
+	if (sec == 1)
+		return sid_get_phy_base(pnode,
+			(phys_addr_t **)base, compatible);
+	else
+		return sid_get_vir_base(pnode, base, compatible);
+}
+
+static void sid_put_base(struct device_node *pnode, void __iomem *base, u32 sec)
+{
+	SID_DBG("base = %p, Sec = %d\n", base, sec);
+	if ((sec == 0) && (base != NULL))
+		iounmap(base);
+	if (pnode)
+		of_node_put(pnode);
+}
+
+static u32 sid_readl(void __iomem *base, u32 sec)
+{
+	if (sec == 0)
+		return readl(base);
+	else
+		return sunxi_smc_readl((phys_addr_t)base);
+}
+
+int get_key_map_info(s8 *name, u8 *compatile, u32 *offset, u32 *max_size)
+{
+	struct device_node *child_pnode;
+	struct device_node *pnode = of_find_compatible_node(NULL, NULL, compatile);
+	if (IS_ERR_OR_NULL(pnode)) {
+		SID_ERR("Failed to find \"%s\" in dts.\n", compatile);
+		return -ENXIO;
+	}
+	child_pnode = of_get_child_by_name(pnode, name);
+	if (IS_ERR_OR_NULL(child_pnode)) {
+		SID_ERR("Failed to find \"%s\" in dts.\n", name);
+		return -ENXIO;
+	}
+	of_property_read_u32(child_pnode, "offset", offset);
+	of_property_read_u32(child_pnode, "size", max_size);
+	return 0;
+}
+
+
+static u32 sid_read_key(s8 *key_name, u32 *key_buf, u32 key_size, u32 sec)
+{
+	u32 i, offset = 0, max_size = 0;
+	void __iomem *baseaddr = NULL;
+	struct device_node *dev_node = NULL;
+
+	if (sid_get_base(&dev_node, &baseaddr, EFUSE_SID_BASE, sec))
+		return 0;
+
+	get_key_map_info(key_name, EFUSE_SID_BASE, &offset, &max_size);
+	SID_DBG("key_name:%s offset:0x%x max_size:0x%x\n", key_name, offset, max_size);
+	if (key_size > max_size) {
+		key_size = max_size;
+	}
+	for (i = 0; i < key_size; i += 4) {
+		key_buf[i/4] = sid_readl(baseaddr + offset + i, sec);
+	}
+
+	sid_put_base(dev_node, baseaddr, sec);
+	return 0;
+}
+
+
+static u32 sid_rd_bits(s8 *name, u32 offset, u32 shift, u32 mask, u32 sec)
+{
+	u32 value = 0;
+	void __iomem *baseaddr = NULL;
+	struct device_node *dev_node = NULL;
+
+#ifdef SID_REG_READ
+	return __sid_reg_read_key(offset);
+#else
+	if (sid_get_base(&dev_node, &baseaddr, name, sec))
+		return 0;
+
+	value = sid_readl(baseaddr + offset, sec);
+
+	value = (value >> shift) & mask;
+	SID_DBG("Read \"%s\" + %#x, shift %#x, mask %#x, return %#x, Sec %d\n",
+			name, offset, shift, mask, value, sec);
+
+	sid_put_base(dev_node, baseaddr, sec);
+	return value;
+#endif
+}
+
+int get_soc_ver_regs(u8 *name, u8 *compatile, struct soc_ver_reg *reg)
+{
+	struct device_node *child_pnode;
+	struct device_node *pnode = of_find_compatible_node(NULL, NULL, compatile);
+	if (IS_ERR_OR_NULL(pnode)) {
+		SID_ERR("Failed to find \"%s\" in dts.\n", SRAM_CTRL_BASE);
+		return -ENXIO;
+	}
+	child_pnode = of_get_child_by_name(pnode, name);
+	if (IS_ERR_OR_NULL(child_pnode)) {
+		SID_ERR("Failed to find \"%s\" in dts.\n", name);
+		return -ENXIO;
+	}
+
+	of_property_read_u32(child_pnode, "offset", &reg->offset);
+	of_property_read_u32(child_pnode, "shift", &reg->shift);
+	of_property_read_u32(child_pnode, "mask", &reg->mask);
+	of_property_read_u32(child_pnode, "ver_a", &reg->ver_map.rev[0]);
+	of_property_read_u32(child_pnode, "ver_b", &reg->ver_map.rev[1]);
+	return 0;
+}
+
+void sid_rd_ver_reg(u32 id)
+{
+	s32 i = 0;
+	u32 ver = 0;
+	static struct soc_ver_reg reg = {0};
+	get_soc_ver_regs("soc_ver", SRAM_CTRL_BASE, &reg);
+	ver = sid_rd_bits(SRAM_CTRL_BASE, reg.offset,
+		reg.shift, reg.mask, 0);
+	if (ver >= SUNXI_VER_MAX_NUM/2)
+		SID_WARN("ver >= %d, soc ver:%d\n", SUNXI_VER_MAX_NUM/2, ver);
+
+	sunxi_soc_ver = reg.ver_map.rev[0] + ver;
+
+	SID_DBG("%d-%d: soc_ver %#x\n", i, ver, sunxi_soc_ver);
+}
+
+static s32 sid_rd_soc_ver_from_sid(void)
+{
+	u32 id = 0;
+	static struct soc_ver_reg reg = {0};
+	get_soc_ver_regs("soc_id", SRAM_CTRL_BASE, &reg);
+	id = sid_rd_bits(EFUSE_SID_BASE, reg.offset, reg.shift, reg.mask, 0);
+	sid_rd_ver_reg(id);
+
+	return 0;
+}
+
+static void sid_soc_ver_init(void)
+{
+	static s32 init_flag;
+
+	if (init_flag == 1) {
+		SID_DBG("It's already inited.\n");
+		return;
+	}
+
+	sid_rd_soc_ver_from_sid();
+
+	SID_DBG("The SoC version: %#x\n", sunxi_soc_ver);
+	init_flag = 1;
+}
+
+
+static void sid_chipid_init(void)
+{
+	u32 type = 0, offset = 0, max_size;
+	static s32 init_flag;
+	static struct soc_ver_reg reg = {0};
+
+	if (init_flag == 1) {
+		SID_DBG("It's already inited.\n");
+		return;
+	}
+	sid_read_key("chipid", sunxi_soc_chipid, 16, sunxi_soc_is_secure());
+
+	sunxi_serial[0] = sunxi_soc_chipid[3];
+	sunxi_serial[1] = sunxi_soc_chipid[2];
+	sunxi_serial[2] = (sunxi_soc_chipid[1] >> 16) & 0x0FFFF;
+
+	get_key_map_info("chipid", EFUSE_SID_BASE, &offset, &max_size);
+	get_soc_ver_regs("soc_bin", SRAM_CTRL_BASE, &reg);
+
+	type = sid_rd_bits(EFUSE_SID_BASE, reg.offset + offset, reg.shift,
+		reg.mask, sunxi_soc_is_secure());
+
+	switch (type) {
+	case 0b000001:
+		sunxi_soc_bin = 1;
+		break;
+	case 0b000011:
+		sunxi_soc_bin = 2;
+		break;
+	case 0b000111:
+		sunxi_soc_bin = 3;
+		break;
+	default:
+		break;
+	}
+	SID_DBG("soc bin: %d\n", sunxi_soc_bin);
+
+	init_flag = 1;
+}
+
+void sid_ft_zone_init(void)
+{
+	static s32 init_flag;
+	if (init_flag == 1) {
+		SID_DBG("It's already inited.\n");
+		return;
+	}
+	sid_read_key(EFUSE_FT_ZONE_NAME, sunxi_soc_ftzone, 0x10, sunxi_soc_is_secure());
+
+	init_flag = 1;
+
+}
+
+void sid_rd_soc_secure_status(void)
+{
+#if defined(CONFIG_TEE) && \
+	(defined(CONFIG_ARCH_SUN8IW7) || defined(CONFIG_ARCH_SUN8IW6))
+	sunxi_soc_secure = 1;
+#else
+	static s32 init_flag;
+	void __iomem *base = NULL;
+	struct device_node *node = NULL;
+	u32 offset = 0, max_size;
+
+	if (init_flag == 1) {
+		SID_DBG("It's already inited.\n");
+		return;
+	}
+
+	if (sid_get_base(&node, &base, EFUSE_SID_BASE, 1))
+		return;
+
+	get_key_map_info("secure_status", EFUSE_SID_BASE, &offset, &max_size);
+
+#ifdef CONFIG_ARCH_SUN20IW1
+	sunxi_soc_secure = (((sunxi_smc_readl((phys_addr_t)(base + offset))) >> 31) & 0x1);
+#else
+	sunxi_soc_secure = ((sunxi_smc_readl((phys_addr_t)(base + offset))) & 0x1);
+#endif
+
+	sid_put_base(node, base, 1);
+	init_flag = 1;
+#endif
+}
+
+void sid_rotpk_status_init(void)
+{
+	static s32 init_flag;
+	if (init_flag == 1) {
+		SID_DBG("It's already inited.\n");
+		return;
+	}
+	sid_read_key(EFUSE_ROTPK_NAME, &sunxi_soc_rotpk_status, 4, sunxi_soc_is_secure());
+
+	init_flag = 1;
+
+}
+
+s32 sunxi_get_platform(s8 *buf, s32 size)
+{
+	return snprintf(buf, size, "%s", CONFIG_SUNXI_SOC_NAME);
+}
+EXPORT_SYMBOL(sunxi_get_platform);
+
+/**
+ * soc chipid:
+ */
+int sunxi_get_soc_chipid(u8 *chipid)
+{
+	sid_chipid_init();
+	memcpy(chipid, sunxi_soc_chipid, 16);
+	return 0;
+}
+EXPORT_SYMBOL(sunxi_get_soc_chipid);
+
+/**
+ * soc chipid serial:
+ */
+int sunxi_get_serial(u8 *serial)
+{
+	sid_chipid_init();
+	memcpy(serial, sunxi_serial, 16);
+	return 0;
+}
+EXPORT_SYMBOL(sunxi_get_serial);
+
+/**
+ * get module_param:
+ * argc[0]---dst buf
+ * argc[1]---the sid offset
+ * argc[2]---len(btye)
+ */
+int sunxi_get_module_param_from_sid(u32 *dst, u32 offset, u32 len)
+{
+	void __iomem *baseaddr = NULL;
+	struct device_node *dev_node = NULL;
+	int i;
+
+	if (dst == NULL) {
+		pr_err("the dst buf is NULL\n");
+		return -1;
+	}
+
+	if (len & 0x3) {
+		pr_err("the len must be word algin\n");
+		return -2;
+	}
+
+	if (sid_get_base(&dev_node, &baseaddr, EFUSE_SID_BASE, 0)) {
+		pr_err("sid_get_base fail \n");
+		return 0;
+	}
+
+	SID_DBG("baseaddr: 0x%p offset:0x%x len(word):0x%x\n", baseaddr, offset, len);
+
+	for (i = 0; i < len; i += 4) {
+		dst[i] = sid_readl(baseaddr + 0x200 + offset + i, 0);
+	}
+
+	sid_put_base(dev_node, baseaddr, 0);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(sunxi_get_module_param_from_sid);
+
+
+
+/**
+ * soc chipid str:
+ */
+int sunxi_get_soc_chipid_str(char *serial)
+{
+	size_t size;
+
+	sid_chipid_init();
+#if defined(CONFIG_ARCH_SUN50IW9) || defined(CONFIG_ARCH_SUN50IW10)
+	size = sprintf(serial, "%08x", sunxi_soc_chipid[0] & 0xffff);
+#else
+	size = sprintf(serial, "%08x", sunxi_soc_chipid[0] & 0x0ff);
+#endif
+	return size;
+}
+EXPORT_SYMBOL(sunxi_get_soc_chipid_str);
+
+/**
+ * soc ft zone str:
+ */
+int sunxi_get_soc_ft_zone_str(char *serial)
+{
+	size_t size;
+
+	sid_ft_zone_init();
+	size = sprintf(serial, "%08x", (sunxi_soc_ftzone[0] & 0xff000000) >> 24);
+	return size;
+}
+EXPORT_SYMBOL(sunxi_get_soc_ft_zone_str);
+
+/**
+ * soc rotpk status str:
+ */
+int sunxi_get_soc_rotpk_status_str(char *status)
+{
+	size_t size;
+
+	sid_rotpk_status_init();
+	size = sprintf(status, "%d", (sunxi_soc_rotpk_status & 0x3) >> 1);
+	return size;
+}
+EXPORT_SYMBOL(sunxi_get_soc_rotpk_status_str);
+
+/**
+ * soc chipid:
+ */
+int sunxi_soc_is_secure(void)
+{
+	sid_rd_soc_secure_status();
+	return sunxi_soc_secure;
+}
+EXPORT_SYMBOL(sunxi_soc_is_secure);
+
+/**
+ * get sunxi soc bin
+ *
+ * return: the bin of sunxi soc, like that:
+ * 0 : fail
+ * 1 : slow
+ * 2 : normal
+ * 3 : fast
+ */
+unsigned int sunxi_get_soc_bin(void)
+{
+	sid_chipid_init();
+	return sunxi_soc_bin;
+}
+EXPORT_SYMBOL(sunxi_get_soc_bin);
+
+unsigned int sunxi_get_soc_ver(void)
+{
+	sid_soc_ver_init();
+	return sunxi_soc_ver;
+}
+EXPORT_SYMBOL(sunxi_get_soc_ver);
+
+s32 sunxi_efuse_readn(s8 *key_name, void *buf, u32 n)
+{
+	char name[32] = {0};
+
+	if ((key_name == NULL) || (*(s8 *)key_name == 0)
+			|| (n == 0) || (buf == NULL)) {
+		SID_ERR("Invalid parameter. name: %p, read_buf: %p, size: %d\n",
+		key_name, buf, n);
+		return -EINVAL;
+	}
+	WARN_ON(n < 4);
+
+	strncpy(name, key_name, strlen(key_name) - 1);
+	sid_read_key(name, buf, n, sunxi_soc_is_secure());
+	return 0;
+}
+EXPORT_SYMBOL(sunxi_efuse_readn);
+
+static int __init sunxi_sid_init(void)
+{
+	SID_WARN("insmod ok\n");
+	return 0;
+}
+
+static void __exit sunxi_sid_exit(void)
+{
+	SID_WARN("rmmod ok\n");
+}
+
+module_init(sunxi_sid_init);
+module_exit(sunxi_sid_exit);
+MODULE_LICENSE("GPL v2");
+MODULE_AUTHOR("weidonghui<weidonghui@allwinnertech.com>");
+MODULE_DESCRIPTION("sunxi sid.");
diff --git a/drivers/soc/sunxi/sunxi_riscv_pm.c b/drivers/soc/sunxi/sunxi_riscv_pm.c
new file mode 100644
index 000000000..0aaf33a00
--- /dev/null
+++ b/drivers/soc/sunxi/sunxi_riscv_pm.c
@@ -0,0 +1,41 @@
+/*
+ * drivers/soc/sunxi_riscv_pm.c
+ *
+ * Copyright(c) 2019-2020 Allwinnertech Co., Ltd.
+ *         http://www.allwinnertech.com
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ */
+
+#include <linux/module.h>
+#include <linux/suspend.h>
+#include <asm/sbi.h>
+
+static int sunxi_riscv_enter(suspend_state_t state)
+{
+	sbi_suspend(0);
+
+	return 0;
+}
+
+static struct platform_suspend_ops sunxi_riscv_pm = {
+	.valid = suspend_valid_only_mem,
+	.enter = sunxi_riscv_enter,
+};
+
+int sunxi_riscv_pm_register(void)
+{
+	suspend_set_ops(&sunxi_riscv_pm);
+
+	return 0;
+}
+
+void sunxi_riscv_pm_unregister(void)
+{
+}
+
+module_init(sunxi_riscv_pm_register);
+module_exit(sunxi_riscv_pm_unregister);
diff --git a/drivers/soc/sunxi/vf-test.c b/drivers/soc/sunxi/vf-test.c
new file mode 100644
index 000000000..84ca2863f
--- /dev/null
+++ b/drivers/soc/sunxi/vf-test.c
@@ -0,0 +1,184 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * cpu vf test module
+ * Copyright (C) 2019 frank@allwinnertech.com
+ */
+
+#include <linux/device.h>
+#include <linux/clk.h>
+#include <linux/cpu.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/regulator/consumer.h>
+
+struct vf_dev {
+	struct regulator *cpu_reg;
+	struct clk *cpu_clk;
+} vf_dev;
+
+static ssize_t volt_show(struct class *class, struct class_attribute *attr,
+			 char *buf)
+{
+	return sprintf(buf, "%d\n", regulator_get_voltage(vf_dev.cpu_reg));
+}
+
+static ssize_t volt_store(struct class *class, struct class_attribute *attr,
+			  const char *buf, size_t count)
+{
+	int volt;
+	int ret;
+
+	ret = kstrtoint(buf, 10, &volt);
+	if (ret)
+		return -EINVAL;
+
+	regulator_set_voltage(vf_dev.cpu_reg, volt, volt);
+
+	return count;
+}
+static CLASS_ATTR_RW(volt);
+
+static ssize_t freq_show(struct class *class, struct class_attribute *attr,
+			 char *buf)
+{
+	return sprintf(buf, "%lu\n", clk_get_rate(vf_dev.cpu_clk));
+}
+
+static ssize_t freq_store(struct class *class, struct class_attribute *attr,
+			  const char *buf, size_t count)
+{
+	int freq;
+	int ret;
+
+	ret = kstrtoint(buf, 10, &freq);
+	if (ret)
+		return -EINVAL;
+
+	clk_set_rate(vf_dev.cpu_clk, freq);
+
+	return count;
+}
+static CLASS_ATTR_RW(freq);
+
+/*
+static struct class_attribute vf_class_attrs[] = {
+	__ATTR(cpu_volt, S_IWUSR | S_IRUGO, volt_show, volt_store),
+	__ATTR(cpu_freq, S_IWUSR | S_IRUGO, freq_show, freq_store),
+	__ATTR_NULL,
+};
+*/
+
+static struct attribute *vf_class_attrs[] = {
+	&class_attr_volt.attr,
+	&class_attr_freq.attr,
+	NULL,
+};
+ATTRIBUTE_GROUPS(vf_class);
+
+static struct class vf_class = {
+	.name		= "vf_table",
+	.class_groups	= vf_class_groups,
+};
+
+/*
+ * An earlier version of opp-v1 bindings used to name the regulator
+ * "cpu0-supply", we still need to handle that for backwards compatibility.
+ */
+static const char *find_supply_name(struct device *dev)
+{
+	struct device_node *np;
+	struct property *pp;
+	int cpu = dev->id;
+	const char *name = NULL;
+
+	np = of_node_get(dev->of_node);
+
+	/* This must be valid for sure */
+	if (WARN_ON(!np))
+		return NULL;
+
+	/* Try "cpu0" for older DTs */
+	if (!cpu) {
+		pp = of_find_property(np, "cpu0-supply", NULL);
+		if (pp) {
+			name = "cpu0";
+			goto node_put;
+		}
+	}
+
+	pp = of_find_property(np, "cpu-supply", NULL);
+	if (pp) {
+		name = "cpu";
+		goto node_put;
+	}
+
+	dev_dbg(dev, "no regulator for cpu%d\n", cpu);
+node_put:
+	of_node_put(np);
+	return name;
+}
+
+static int resources_available(void)
+{
+	struct device *cpu_dev;
+	int ret = 0;
+	const char *name;
+
+	cpu_dev = get_cpu_device(0);
+	if (!cpu_dev) {
+		pr_err("failed to get cpu0 device\n");
+		return -ENODEV;
+	}
+
+	vf_dev.cpu_clk = clk_get(cpu_dev, NULL);
+	ret = PTR_ERR_OR_ZERO(vf_dev.cpu_clk);
+	if (ret) {
+		/*
+		 * If cpu's clk node is present, but clock is not yet
+		 * registered, we should try defering probe.
+		 */
+		if (ret == -EPROBE_DEFER)
+			dev_dbg(cpu_dev, "clock not ready, retry\n");
+		else
+			dev_err(cpu_dev, "failed to get clock: %d\n", ret);
+
+		return ret;
+	}
+
+	name = find_supply_name(cpu_dev);
+	/* Platform doesn't require regulator */
+	if (!name)
+		return 0;
+
+	vf_dev.cpu_reg = regulator_get_optional(cpu_dev, name);
+	ret = PTR_ERR_OR_ZERO(vf_dev.cpu_reg);
+	if (ret) {
+		/*
+		 * If cpu's regulator supply node is present, but regulator is
+		 * not yet registered, we should try defering probe.
+		 */
+		if (ret == -EPROBE_DEFER)
+			dev_dbg(cpu_dev, "cpu0 regulator not ready, retry\n");
+		else
+			dev_dbg(cpu_dev, "no regulator for cpu0: %d\n", ret);
+
+		return ret;
+	}
+
+	return 0;
+}
+
+static int __init vf_init(void)
+{
+	int ret;
+
+	ret = resources_available();
+	if (ret)
+		return ret;
+
+	return class_register(&vf_class);
+}
+
+late_initcall_sync(vf_init);
+MODULE_LICENSE("GPL");
diff --git a/drivers/soc/tegra/Kconfig b/drivers/soc/tegra/Kconfig
index 25df4406c..ce3f127cb 100644
--- a/drivers/soc/tegra/Kconfig
+++ b/drivers/soc/tegra/Kconfig
@@ -78,6 +78,7 @@ config ARCH_TEGRA_210_SOC
 	select SOC_TEGRA_FLOWCTRL
 	select SOC_TEGRA_PMC
 	select TEGRA_TIMER
+	depends on !LTO_CLANG
 	help
 	  Enable support for the NVIDIA Tegra210 SoC. Also known as Tegra X1,
 	  the Tegra210 has four Cortex-A57 cores paired with four Cortex-A53
-- 
2.17.1

