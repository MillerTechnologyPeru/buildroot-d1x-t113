From b1c46b86141b794f753d47ee59acac9212dcd3c2 Mon Sep 17 00:00:00 2001
From: YuzukiTsuru <gloomyghost@gloomyghost.com>
Date: Fri, 25 Mar 2022 17:04:04 +0800
Subject: [PATCH 46/93] add sunxi mmc and sdhc support

---
 drivers/mmc/core/Kconfig                  |    8 +
 drivers/mmc/core/Makefile                 |    1 +
 drivers/mmc/core/block.c                  |   64 +
 drivers/mmc/core/crypto.c                 |   40 +
 drivers/mmc/core/crypto.h                 |   33 +
 drivers/mmc/core/host.c                   |    8 +-
 drivers/mmc/core/mmc.c                    |   18 +-
 drivers/mmc/core/queue.c                  |   25 +-
 drivers/mmc/core/sd.c                     |   10 +
 drivers/mmc/host/Kconfig                  |   50 +-
 drivers/mmc/host/Makefile                 |   12 +-
 drivers/mmc/host/cqhci.c                  |    8 +-
 drivers/mmc/host/mmc_hsq.c                |  375 +++
 drivers/mmc/host/mmc_hsq.h                |   31 +
 drivers/mmc/host/sdhci-sprd.c             |   50 +-
 drivers/mmc/host/sdhci.c                  |  238 +-
 drivers/mmc/host/sdhci.h                  |    6 +-
 drivers/mmc/host/sunxi-mmc-base.c         | 1525 +++++++++
 drivers/mmc/host/sunxi-mmc-debug.c        |  800 +++++
 drivers/mmc/host/sunxi-mmc-debug.h        |   49 +
 drivers/mmc/host/sunxi-mmc-export.c       |   98 +
 drivers/mmc/host/sunxi-mmc-export.h       |   23 +
 drivers/mmc/host/sunxi-mmc-panic.c        | 1087 ++++++
 drivers/mmc/host/sunxi-mmc-panic.h        |   25 +
 drivers/mmc/host/sunxi-mmc-sun50iw1p1-0.c |  586 ++++
 drivers/mmc/host/sunxi-mmc-sun50iw1p1-0.h |   40 +
 drivers/mmc/host/sunxi-mmc-sun50iw1p1-1.c |  580 ++++
 drivers/mmc/host/sunxi-mmc-sun50iw1p1-1.h |   40 +
 drivers/mmc/host/sunxi-mmc-sun50iw1p1-2.c |  629 ++++
 drivers/mmc/host/sunxi-mmc-sun50iw1p1-2.h |   47 +
 drivers/mmc/host/sunxi-mmc-v4p00x.c       |  465 +++
 drivers/mmc/host/sunxi-mmc-v4p00x.h       |   23 +
 drivers/mmc/host/sunxi-mmc-v4p10x.c       |  579 ++++
 drivers/mmc/host/sunxi-mmc-v4p10x.h       |   23 +
 drivers/mmc/host/sunxi-mmc-v4p1x.c        |  725 ++++
 drivers/mmc/host/sunxi-mmc-v4p1x.h        |   22 +
 drivers/mmc/host/sunxi-mmc-v4p5x.c        | 1075 ++++++
 drivers/mmc/host/sunxi-mmc-v4p5x.h        |   24 +
 drivers/mmc/host/sunxi-mmc-v5p3x.c        |  803 +++++
 drivers/mmc/host/sunxi-mmc-v5p3x.h        |   22 +
 drivers/mmc/host/sunxi-mmc-v5px.c         |  608 ++++
 drivers/mmc/host/sunxi-mmc-v5px.h         |   33 +
 drivers/mmc/host/sunxi-mmc.c              | 3681 +++++++++++++++------
 drivers/mmc/host/sunxi-mmc.h              |  507 +++
 drivers/mmc/host/sunxi-smhc.c             | 1794 ++++++++++
 drivers/mmc/host/sunxi-smhc.h             |  362 ++
 46 files changed, 16211 insertions(+), 1041 deletions(-)
 create mode 100644 drivers/mmc/core/crypto.c
 create mode 100644 drivers/mmc/core/crypto.h
 create mode 100644 drivers/mmc/host/mmc_hsq.c
 create mode 100644 drivers/mmc/host/mmc_hsq.h
 create mode 100644 drivers/mmc/host/sunxi-mmc-base.c
 create mode 100644 drivers/mmc/host/sunxi-mmc-debug.c
 create mode 100644 drivers/mmc/host/sunxi-mmc-debug.h
 create mode 100644 drivers/mmc/host/sunxi-mmc-export.c
 create mode 100644 drivers/mmc/host/sunxi-mmc-export.h
 create mode 100644 drivers/mmc/host/sunxi-mmc-panic.c
 create mode 100644 drivers/mmc/host/sunxi-mmc-panic.h
 create mode 100644 drivers/mmc/host/sunxi-mmc-sun50iw1p1-0.c
 create mode 100644 drivers/mmc/host/sunxi-mmc-sun50iw1p1-0.h
 create mode 100644 drivers/mmc/host/sunxi-mmc-sun50iw1p1-1.c
 create mode 100644 drivers/mmc/host/sunxi-mmc-sun50iw1p1-1.h
 create mode 100644 drivers/mmc/host/sunxi-mmc-sun50iw1p1-2.c
 create mode 100644 drivers/mmc/host/sunxi-mmc-sun50iw1p1-2.h
 create mode 100644 drivers/mmc/host/sunxi-mmc-v4p00x.c
 create mode 100644 drivers/mmc/host/sunxi-mmc-v4p00x.h
 create mode 100644 drivers/mmc/host/sunxi-mmc-v4p10x.c
 create mode 100644 drivers/mmc/host/sunxi-mmc-v4p10x.h
 create mode 100644 drivers/mmc/host/sunxi-mmc-v4p1x.c
 create mode 100644 drivers/mmc/host/sunxi-mmc-v4p1x.h
 create mode 100644 drivers/mmc/host/sunxi-mmc-v4p5x.c
 create mode 100644 drivers/mmc/host/sunxi-mmc-v4p5x.h
 create mode 100644 drivers/mmc/host/sunxi-mmc-v5p3x.c
 create mode 100644 drivers/mmc/host/sunxi-mmc-v5p3x.h
 create mode 100644 drivers/mmc/host/sunxi-mmc-v5px.c
 create mode 100644 drivers/mmc/host/sunxi-mmc-v5px.h
 create mode 100644 drivers/mmc/host/sunxi-mmc.h
 create mode 100644 drivers/mmc/host/sunxi-smhc.c
 create mode 100644 drivers/mmc/host/sunxi-smhc.h

diff --git a/drivers/mmc/core/Kconfig b/drivers/mmc/core/Kconfig
index c12fe13e4..ae8b69aee 100644
--- a/drivers/mmc/core/Kconfig
+++ b/drivers/mmc/core/Kconfig
@@ -81,3 +81,11 @@ config MMC_TEST
 	  This driver is only of interest to those developing or
 	  testing a host driver. Most people should say N here.
 
+config MMC_CRYPTO
+	bool "MMC Crypto Engine Support"
+	depends on BLK_INLINE_ENCRYPTION
+	help
+	  Enable Crypto Engine Support in MMC.
+	  Enabling this makes it possible for the kernel to use the crypto
+	  capabilities of the MMC device (if present) to perform crypto
+	  operations on data being transferred to/from the device.
diff --git a/drivers/mmc/core/Makefile b/drivers/mmc/core/Makefile
index 95ffe008e..6a907736c 100644
--- a/drivers/mmc/core/Makefile
+++ b/drivers/mmc/core/Makefile
@@ -18,3 +18,4 @@ obj-$(CONFIG_MMC_BLOCK)		+= mmc_block.o
 mmc_block-objs			:= block.o queue.o
 obj-$(CONFIG_MMC_TEST)		+= mmc_test.o
 obj-$(CONFIG_SDIO_UART)		+= sdio_uart.o
+mmc_core-$(CONFIG_MMC_CRYPTO)	+= crypto.o
diff --git a/drivers/mmc/core/block.c b/drivers/mmc/core/block.c
index 7f480c6b1..c94f79252 100644
--- a/drivers/mmc/core/block.c
+++ b/drivers/mmc/core/block.c
@@ -51,6 +51,7 @@
 #include "block.h"
 #include "core.h"
 #include "card.h"
+#include "crypto.h"
 #include "host.h"
 #include "bus.h"
 #include "mmc_ops.h"
@@ -168,6 +169,11 @@ MODULE_PARM_DESC(perdev_minors, "Minors numbers to allocate per device");
 
 static inline int mmc_blk_part_switch(struct mmc_card *card,
 				      unsigned int part_type);
+static void mmc_blk_rw_rq_prep(struct mmc_queue_req *mqrq,
+			       struct mmc_card *card,
+			       int disable_multi,
+			       struct mmc_queue *mq);
+static void mmc_blk_hsq_req_done(struct mmc_request *mrq);
 
 static struct mmc_blk_data *mmc_blk_get(struct gendisk *disk)
 {
@@ -1297,6 +1303,8 @@ static void mmc_blk_data_prep(struct mmc_queue *mq, struct mmc_queue_req *mqrq,
 
 	memset(brq, 0, sizeof(struct mmc_blk_request));
 
+	mmc_crypto_prepare_req(mqrq);
+
 	brq->mrq.data = &brq->data;
 	brq->mrq.tag = req->tag;
 
@@ -1533,9 +1541,30 @@ static int mmc_blk_cqe_issue_flush(struct mmc_queue *mq, struct request *req)
 	return mmc_blk_cqe_start_req(mq->card->host, mrq);
 }
 
+static int mmc_blk_hsq_issue_rw_rq(struct mmc_queue *mq, struct request *req)
+{
+	struct mmc_queue_req *mqrq = req_to_mmc_queue_req(req);
+	struct mmc_host *host = mq->card->host;
+	int err;
+
+	mmc_blk_rw_rq_prep(mqrq, mq->card, 0, mq);
+	mqrq->brq.mrq.done = mmc_blk_hsq_req_done;
+	mmc_pre_req(host, &mqrq->brq.mrq);
+
+	err = mmc_cqe_start_req(host, &mqrq->brq.mrq);
+	if (err)
+		mmc_post_req(host, &mqrq->brq.mrq, err);
+
+	return err;
+}
+
 static int mmc_blk_cqe_issue_rw_rq(struct mmc_queue *mq, struct request *req)
 {
 	struct mmc_queue_req *mqrq = req_to_mmc_queue_req(req);
+	struct mmc_host *host = mq->card->host;
+
+	if (host->hsq_enabled)
+		return mmc_blk_hsq_issue_rw_rq(mq, req);
 
 	mmc_blk_data_prep(mq, mqrq, 0, NULL, NULL);
 
@@ -1921,6 +1950,41 @@ static void mmc_blk_urgent_bkops(struct mmc_queue *mq,
 		mmc_run_bkops(mq->card);
 }
 
+static void mmc_blk_hsq_req_done(struct mmc_request *mrq)
+{
+	struct mmc_queue_req *mqrq =
+		container_of(mrq, struct mmc_queue_req, brq.mrq);
+	struct request *req = mmc_queue_req_to_req(mqrq);
+	struct request_queue *q = req->q;
+	struct mmc_queue *mq = q->queuedata;
+	struct mmc_host *host = mq->card->host;
+	unsigned long flags;
+
+	if (mmc_blk_rq_error(&mqrq->brq) ||
+	    mmc_blk_urgent_bkops_needed(mq, mqrq)) {
+		spin_lock_irqsave(&mq->lock, flags);
+		mq->recovery_needed = true;
+		mq->recovery_req = req;
+		spin_unlock_irqrestore(&mq->lock, flags);
+
+		host->cqe_ops->cqe_recovery_start(host);
+
+		schedule_work(&mq->recovery_work);
+		return;
+	}
+
+	mmc_blk_rw_reset_success(mq, req);
+
+	/*
+	 * Block layer timeouts race with completions which means the normal
+	 * completion path cannot be used during recovery.
+	 */
+	if (mq->in_recovery)
+		mmc_blk_cqe_complete_rq(mq, req);
+	else
+		blk_mq_complete_request(req);
+}
+
 void mmc_blk_mq_complete(struct request *req)
 {
 	struct mmc_queue *mq = req->q->queuedata;
diff --git a/drivers/mmc/core/crypto.c b/drivers/mmc/core/crypto.c
new file mode 100644
index 000000000..661e7f862
--- /dev/null
+++ b/drivers/mmc/core/crypto.c
@@ -0,0 +1,40 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright 2020 Google LLC
+ */
+
+#include <linux/blk-crypto.h>
+#include <linux/blkdev.h>
+#include <linux/keyslot-manager.h>
+#include <linux/mmc/host.h>
+
+#include "core.h"
+#include "queue.h"
+
+void mmc_crypto_setup_queue(struct mmc_host *host, struct request_queue *q)
+{
+	if (host->caps2 & MMC_CAP2_CRYPTO)
+		q->ksm = host->ksm;
+}
+EXPORT_SYMBOL_GPL(mmc_crypto_setup_queue);
+
+void mmc_crypto_free_host(struct mmc_host *host)
+{
+	keyslot_manager_destroy(host->ksm);
+}
+
+void mmc_crypto_prepare_req(struct mmc_queue_req *mqrq)
+{
+	struct request *req = mmc_queue_req_to_req(mqrq);
+	struct mmc_request *mrq = &mqrq->brq.mrq;
+	const struct bio_crypt_ctx *bc;
+
+	if (!bio_crypt_should_process(req))
+		return;
+
+	bc = req->bio->bi_crypt_context;
+	mrq->crypto_key_slot = bc->bc_keyslot;
+	mrq->data_unit_num = bc->bc_dun[0];
+	mrq->crypto_key = bc->bc_key;
+}
+EXPORT_SYMBOL_GPL(mmc_crypto_prepare_req);
diff --git a/drivers/mmc/core/crypto.h b/drivers/mmc/core/crypto.h
new file mode 100644
index 000000000..74145c362
--- /dev/null
+++ b/drivers/mmc/core/crypto.h
@@ -0,0 +1,33 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright 2020 Google LLC
+ */
+
+#ifndef _MMC_CORE_CRYPTO_H
+#define _MMC_CORE_CRYPTO_H
+
+struct mmc_host;
+struct mmc_queue_req;
+struct request;
+struct request_queue;
+
+#ifdef CONFIG_MMC_CRYPTO
+
+void mmc_crypto_setup_queue(struct mmc_host *host, struct request_queue *q);
+
+void mmc_crypto_free_host(struct mmc_host *host);
+
+void mmc_crypto_prepare_req(struct mmc_queue_req *mqrq);
+
+#else /* CONFIG_MMC_CRYPTO */
+
+static inline void mmc_crypto_setup_queue(struct mmc_host *host,
+					  struct request_queue *q) { }
+
+static inline void mmc_crypto_free_host(struct mmc_host *host) { }
+
+static inline void mmc_crypto_prepare_req(struct mmc_queue_req *mqrq) { }
+
+#endif /* CONFIG_MMC_CRYPTO */
+
+#endif /* _MMC_CORE_CRYPTO_H */
diff --git a/drivers/mmc/core/host.c b/drivers/mmc/core/host.c
index b3484def0..e27d3feb5 100644
--- a/drivers/mmc/core/host.c
+++ b/drivers/mmc/core/host.c
@@ -24,6 +24,7 @@
 #include <linux/mmc/slot-gpio.h>
 
 #include "core.h"
+#include "crypto.h"
 #include "host.h"
 #include "slot-gpio.h"
 #include "pwrseq.h"
@@ -477,7 +478,8 @@ int mmc_add_host(struct mmc_host *host)
 #endif
 
 	mmc_start_host(host);
-	mmc_register_pm_notifier(host);
+	if (!(host->pm_flags & MMC_PM_IGNORE_PM_NOTIFY))
+		mmc_register_pm_notifier(host);
 
 	return 0;
 }
@@ -494,7 +496,8 @@ EXPORT_SYMBOL(mmc_add_host);
  */
 void mmc_remove_host(struct mmc_host *host)
 {
-	mmc_unregister_pm_notifier(host);
+	if (!(host->pm_flags & MMC_PM_IGNORE_PM_NOTIFY))
+		mmc_unregister_pm_notifier(host);
 	mmc_stop_host(host);
 
 #ifdef CONFIG_DEBUG_FS
@@ -516,6 +519,7 @@ EXPORT_SYMBOL(mmc_remove_host);
  */
 void mmc_free_host(struct mmc_host *host)
 {
+	mmc_crypto_free_host(host);
 	mmc_pwrseq_free(host);
 	put_device(&host->class_dev);
 }
diff --git a/drivers/mmc/core/mmc.c b/drivers/mmc/core/mmc.c
index b7159e243..b975d6d01 100644
--- a/drivers/mmc/core/mmc.c
+++ b/drivers/mmc/core/mmc.c
@@ -1852,15 +1852,19 @@ static int mmc_init_card(struct mmc_host *host, u32 ocr,
 	 */
 	card->reenable_cmdq = card->ext_csd.cmdq_en;
 
-	if (card->ext_csd.cmdq_en && !host->cqe_enabled) {
+	if (host->cqe_ops && !host->cqe_enabled) {
 		err = host->cqe_ops->cqe_enable(host, card);
-		if (err) {
-			pr_err("%s: Failed to enable CQE, error %d\n",
-				mmc_hostname(host), err);
-		} else {
+		if (!err) {
 			host->cqe_enabled = true;
-			pr_info("%s: Command Queue Engine enabled\n",
-				mmc_hostname(host));
+
+			if (card->ext_csd.cmdq_en) {
+				pr_info("%s: Command Queue Engine enabled\n",
+					mmc_hostname(host));
+			} else {
+				host->hsq_enabled = true;
+				pr_info("%s: Host Software Queue enabled\n",
+					mmc_hostname(host));
+			}
 		}
 	}
 
diff --git a/drivers/mmc/core/queue.c b/drivers/mmc/core/queue.c
index 9c0ccb374..c1cc9b50f 100644
--- a/drivers/mmc/core/queue.c
+++ b/drivers/mmc/core/queue.c
@@ -18,6 +18,7 @@
 #include "queue.h"
 #include "block.h"
 #include "core.h"
+#include "crypto.h"
 #include "card.h"
 #include "host.h"
 
@@ -62,7 +63,7 @@ enum mmc_issue_type mmc_issue_type(struct mmc_queue *mq, struct request *req)
 {
 	struct mmc_host *host = mq->card->host;
 
-	if (mq->use_cqe)
+	if (mq->use_cqe && !host->hsq_enabled)
 		return mmc_cqe_issue_type(host, req);
 
 	if (req_op(req) == REQ_OP_READ || req_op(req) == REQ_OP_WRITE)
@@ -123,11 +124,14 @@ static enum blk_eh_timer_return mmc_mq_timed_out(struct request *req,
 {
 	struct request_queue *q = req->q;
 	struct mmc_queue *mq = q->queuedata;
+	struct mmc_card *card = mq->card;
+	struct mmc_host *host = card->host;
 	unsigned long flags;
 	bool ignore_tout;
 
 	spin_lock_irqsave(&mq->lock, flags);
-	ignore_tout = mq->recovery_needed || !mq->use_cqe;
+
+	ignore_tout = mq->recovery_needed || !mq->use_cqe || host->hsq_enabled;
 	spin_unlock_irqrestore(&mq->lock, flags);
 
 	return ignore_tout ? BLK_EH_RESET_TIMER : mmc_cqe_timed_out(req);
@@ -138,12 +142,13 @@ static void mmc_mq_recovery_handler(struct work_struct *work)
 	struct mmc_queue *mq = container_of(work, struct mmc_queue,
 					    recovery_work);
 	struct request_queue *q = mq->queue;
+	struct mmc_host *host = mq->card->host;
 
 	mmc_get_card(mq->card, &mq->ctx);
 
 	mq->in_recovery = true;
 
-	if (mq->use_cqe)
+	if (mq->use_cqe && !host->hsq_enabled)
 		mmc_blk_cqe_recovery(mq);
 	else
 		mmc_blk_mq_recovery(mq);
@@ -154,6 +159,9 @@ static void mmc_mq_recovery_handler(struct work_struct *work)
 	mq->recovery_needed = false;
 	spin_unlock_irq(&mq->lock);
 
+	if (host->hsq_enabled)
+		host->cqe_ops->cqe_recovery_finish(host);
+
 	mmc_put_card(mq->card, &mq->ctx);
 
 	blk_mq_run_hw_queues(q, true);
@@ -273,6 +281,14 @@ static blk_status_t mmc_mq_queue_rq(struct blk_mq_hw_ctx *hctx,
 		}
 		break;
 	case MMC_ISSUE_ASYNC:
+		/*
+		 * For MMC host software queue, we only allow 2 requests in
+		 * flight to avoid a long latency.
+		 */
+		if (host->hsq_enabled && mq->in_flight[issue_type] > 2) {
+			spin_unlock_irq(&mq->lock);
+			return BLK_STS_RESOURCE;
+		}
 		break;
 	default:
 		/*
@@ -424,7 +440,7 @@ int mmc_init_queue(struct mmc_queue *mq, struct mmc_card *card)
 	 * The queue depth for CQE must match the hardware because the request
 	 * tag is used to index the hardware queue.
 	 */
-	if (mq->use_cqe)
+	if (mq->use_cqe && !host->hsq_enabled)
 		mq->tag_set.queue_depth =
 			min_t(int, card->ext_csd.cmdq_depth, host->cqe_qdepth);
 	else
@@ -465,6 +481,7 @@ int mmc_init_queue(struct mmc_queue *mq, struct mmc_card *card)
 	blk_queue_rq_timeout(mq->queue, 60 * HZ);
 
 	mmc_setup_queue(mq, card);
+	mmc_crypto_setup_queue(host, mq->queue);
 	return 0;
 
 free_tag_set:
diff --git a/drivers/mmc/core/sd.c b/drivers/mmc/core/sd.c
index fe914ff5f..76c7add36 100644
--- a/drivers/mmc/core/sd.c
+++ b/drivers/mmc/core/sd.c
@@ -1082,6 +1082,16 @@ static int mmc_sd_init_card(struct mmc_host *host, u32 ocr,
 		}
 	}
 
+	if (host->cqe_ops && !host->cqe_enabled) {
+		err = host->cqe_ops->cqe_enable(host, card);
+		if (!err) {
+			host->cqe_enabled = true;
+			host->hsq_enabled = true;
+			pr_info("%s: Host Software Queue enabled\n",
+				mmc_hostname(host));
+		}
+	}
+
 	if (host->caps2 & MMC_CAP2_AVOID_3_3V &&
 	    host->ios.signal_voltage == MMC_SIGNAL_VOLTAGE_330) {
 		pr_err("%s: Host failed to negotiate down from 3.3V\n",
diff --git a/drivers/mmc/host/Kconfig b/drivers/mmc/host/Kconfig
index 49ea02c46..1c5ca8a60 100644
--- a/drivers/mmc/host/Kconfig
+++ b/drivers/mmc/host/Kconfig
@@ -632,6 +632,7 @@ config MMC_SDHCI_SPRD
 	depends on ARCH_SPRD
 	depends on MMC_SDHCI_PLTFM
 	select MMC_SDHCI_IO_ACCESSORS
+	select MMC_HSQ
 	help
 	  This selects the SDIO Host Controller in Spreadtrum
 	  SoCs, this driver supports R11(IP version: R11P0).
@@ -916,13 +917,49 @@ config MMC_REALTEK_USB
 	  Say Y here to include driver code to support SD/MMC card interface
 	  of Realtek RTS5129/39 series card reader
 
-config MMC_SUNXI
+menuconfig MMC_SUNXI
 	tristate "Allwinner sunxi SD/MMC Host Controller support"
 	depends on ARCH_SUNXI
 	help
 	  This selects support for the SD/MMC Host Controller on
 	  Allwinner sunxi SoCs.
 
+config MMC_SUNXI_V4P1X
+	bool "V4P1X sunxi SD/MMC Host Controller support"
+	depends on MMC_SUNXI
+	default y
+	help
+	  V4P1X sunxi SD/MMC Host Contrller support.
+
+config MMC_SUNXI_V4P00X
+	bool "V4P00X sunxi SD/MMC Host Controller support"
+	depends on MMC_SUNXI
+	default y
+	help
+	  V4P00X sunxi SD/MMC Host Contrller support.
+
+config MMC_SUNXI_V4P10X
+	bool "V4P10X sunxi SD/MMC Host Controller support"
+	depends on MMC_SUNXI
+	default y
+	help
+	  V4P10X sunxi SD/MMC Host Contrller support.
+
+config MMC_SUNXI_V4P5X
+	bool "V4P5X sunxi SD/MMC Host Controller support"
+	depends on MMC_SUNXI
+	default y
+	help
+	  V4P5X sunxi SD/MMC Host Contrller support.
+
+config MMC_SUNXI_V5P3X
+	bool "V5P3X sunxi SD/MMC Host Controller support"
+	depends on MMC_SUNXI
+	default y
+	help
+	  V5P3X sunxi SD/MMC Host Contrller support.
+
+
 config MMC_CQHCI
 	tristate "Command Queue Host Controller Interface support"
 	depends on HAS_DMA
@@ -936,6 +973,17 @@ config MMC_CQHCI
 
 	  If unsure, say N.
 
+config MMC_HSQ
+	tristate "MMC Host Software Queue support"
+	help
+	  This selects the MMC Host Software Queue support. This may increase
+	  performance, if the host controller and its driver supports it.
+
+	  If you have a controller/driver supporting this interface, say Y or M
+	  here.
+
+	  If unsure, say N.
+
 config MMC_TOSHIBA_PCI
 	tristate "Toshiba Type A SD/MMC Card Interface Driver"
 	depends on PCI
diff --git a/drivers/mmc/host/Makefile b/drivers/mmc/host/Makefile
index 11c4598e9..e88cba8f1 100644
--- a/drivers/mmc/host/Makefile
+++ b/drivers/mmc/host/Makefile
@@ -69,7 +69,16 @@ obj-$(CONFIG_MMC_WMT)		+= wmt-sdmmc.o
 obj-$(CONFIG_MMC_MESON_GX)	+= meson-gx-mmc.o
 obj-$(CONFIG_MMC_MESON_MX_SDIO)	+= meson-mx-sdio.o
 obj-$(CONFIG_MMC_MOXART)	+= moxart-mmc.o
-obj-$(CONFIG_MMC_SUNXI)		+= sunxi-mmc.o
+obj-$(CONFIG_MMC_SUNXI)		+= sunxi_mmc_host.o
+sunxi_mmc_host-$(CONFIG_ARCH_SUN8IW10P1)         += sunxi-smhc.o sunxi-mmc-v5px.o
+sunxi_mmc_host-$(CONFIG_ARCH_SUN50IW1P1)          += sunxi-mmc-sun50iw1p1-2.o sunxi-mmc-sun50iw1p1-1.o sunxi-mmc-sun50iw1p1-0.o
+sunxi_mmc_host-$(CONFIG_MMC_SUNXI_V4P1X)          += sunxi-mmc-v4p1x.o
+sunxi_mmc_host-$(CONFIG_MMC_SUNXI_V4P00X)          += sunxi-mmc-v4p00x.o
+sunxi_mmc_host-$(CONFIG_MMC_SUNXI_V4P10X)          += sunxi-mmc-v4p10x.o
+sunxi_mmc_host-$(CONFIG_MMC_SUNXI_V4P5X)          += sunxi-mmc-v4p5x.o
+sunxi_mmc_host-$(CONFIG_MMC_SUNXI_V5P3X)          += sunxi-mmc-v5p3x.o
+sunxi_mmc_host-y                += sunxi-mmc.o sunxi-mmc-debug.o sunxi-mmc-export.o sunxi-mmc-panic.o
+
 obj-$(CONFIG_MMC_USDHI6ROL0)	+= usdhi6rol0.o
 obj-$(CONFIG_MMC_TOSHIBA_PCI)	+= toshsd.o
 obj-$(CONFIG_MMC_BCM2835)	+= bcm2835.o
@@ -98,6 +107,7 @@ obj-$(CONFIG_MMC_SDHCI_BRCMSTB)		+= sdhci-brcmstb.o
 obj-$(CONFIG_MMC_SDHCI_OMAP)		+= sdhci-omap.o
 obj-$(CONFIG_MMC_SDHCI_SPRD)		+= sdhci-sprd.o
 obj-$(CONFIG_MMC_CQHCI)			+= cqhci.o
+obj-$(CONFIG_MMC_HSQ)			+= mmc_hsq.o
 
 ifeq ($(CONFIG_CB710_DEBUG),y)
 	CFLAGS-cb710-mmc	+= -DDEBUG
diff --git a/drivers/mmc/host/cqhci.c b/drivers/mmc/host/cqhci.c
index c19f4c3f1..6ae4ce219 100644
--- a/drivers/mmc/host/cqhci.c
+++ b/drivers/mmc/host/cqhci.c
@@ -322,14 +322,20 @@ static int cqhci_enable(struct mmc_host *mmc, struct mmc_card *card)
 	struct cqhci_host *cq_host = mmc->cqe_private;
 	int err;
 
+	if (!card->ext_csd.cmdq_en)
+		return -EINVAL;
+
 	if (cq_host->enabled)
 		return 0;
 
 	cq_host->rca = card->rca;
 
 	err = cqhci_host_alloc_tdl(cq_host);
-	if (err)
+	if (err) {
+		pr_err("%s: Failed to enable CQE, error %d\n",
+		       mmc_hostname(mmc), err);
 		return err;
+	}
 
 	__cqhci_enable(cq_host);
 
diff --git a/drivers/mmc/host/mmc_hsq.c b/drivers/mmc/host/mmc_hsq.c
new file mode 100644
index 000000000..a5e05ed0f
--- /dev/null
+++ b/drivers/mmc/host/mmc_hsq.c
@@ -0,0 +1,375 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ *
+ * MMC software queue support based on command queue interfaces
+ *
+ * Copyright (C) 2019 Linaro, Inc.
+ * Author: Baolin Wang <baolin.wang@linaro.org>
+ */
+
+#include <linux/mmc/card.h>
+#include <linux/mmc/host.h>
+#include <linux/module.h>
+
+#include "mmc_hsq.h"
+
+#define HSQ_NUM_SLOTS	64
+#define HSQ_INVALID_TAG	HSQ_NUM_SLOTS
+
+static void mmc_hsq_retry_handler(struct work_struct *work)
+{
+	struct mmc_hsq *hsq = container_of(work, struct mmc_hsq, retry_work);
+	struct mmc_host *mmc = hsq->mmc;
+
+	mmc->ops->request(mmc, hsq->mrq);
+}
+
+static void mmc_hsq_pump_requests(struct mmc_hsq *hsq)
+{
+	struct mmc_host *mmc = hsq->mmc;
+	struct hsq_slot *slot;
+	unsigned long flags;
+	int ret = 0;
+
+	spin_lock_irqsave(&hsq->lock, flags);
+
+	/* Make sure we are not already running a request now */
+	if (hsq->mrq) {
+		spin_unlock_irqrestore(&hsq->lock, flags);
+		return;
+	}
+
+	/* Make sure there are remain requests need to pump */
+	if (!hsq->qcnt || !hsq->enabled) {
+		spin_unlock_irqrestore(&hsq->lock, flags);
+		return;
+	}
+
+	slot = &hsq->slot[hsq->next_tag];
+	hsq->mrq = slot->mrq;
+	hsq->qcnt--;
+
+	spin_unlock_irqrestore(&hsq->lock, flags);
+
+	if (mmc->ops->request_atomic)
+		ret = mmc->ops->request_atomic(mmc, hsq->mrq);
+	else
+		mmc->ops->request(mmc, hsq->mrq);
+
+	/*
+	 * If returning BUSY from request_atomic(), which means the card
+	 * may be busy now, and we should change to non-atomic context to
+	 * try again for this unusual case, to avoid time-consuming operations
+	 * in the atomic context.
+	 *
+	 * Note: we just give a warning for other error cases, since the host
+	 * driver will handle them.
+	 */
+	if (ret == -EBUSY)
+		schedule_work(&hsq->retry_work);
+	else
+		WARN_ON_ONCE(ret);
+}
+
+static void mmc_hsq_update_next_tag(struct mmc_hsq *hsq, int remains)
+{
+	struct hsq_slot *slot;
+	int tag;
+
+	/*
+	 * If there are no remain requests in software queue, then set a invalid
+	 * tag.
+	 */
+	if (!remains) {
+		hsq->next_tag = HSQ_INVALID_TAG;
+		return;
+	}
+
+	/*
+	 * Increasing the next tag and check if the corresponding request is
+	 * available, if yes, then we found a candidate request.
+	 */
+	if (++hsq->next_tag != HSQ_INVALID_TAG) {
+		slot = &hsq->slot[hsq->next_tag];
+		if (slot->mrq)
+			return;
+	}
+
+	/* Othersie we should iterate all slots to find a available tag. */
+	for (tag = 0; tag < HSQ_NUM_SLOTS; tag++) {
+		slot = &hsq->slot[tag];
+		if (slot->mrq)
+			break;
+	}
+
+	if (tag == HSQ_NUM_SLOTS)
+		tag = HSQ_INVALID_TAG;
+
+	hsq->next_tag = tag;
+}
+
+static void mmc_hsq_post_request(struct mmc_hsq *hsq)
+{
+	unsigned long flags;
+	int remains;
+
+	spin_lock_irqsave(&hsq->lock, flags);
+
+	remains = hsq->qcnt;
+	hsq->mrq = NULL;
+
+	/* Update the next available tag to be queued. */
+	mmc_hsq_update_next_tag(hsq, remains);
+
+	if (hsq->waiting_for_idle && !remains) {
+		hsq->waiting_for_idle = false;
+		wake_up(&hsq->wait_queue);
+	}
+
+	/* Do not pump new request in recovery mode. */
+	if (hsq->recovery_halt) {
+		spin_unlock_irqrestore(&hsq->lock, flags);
+		return;
+	}
+
+	spin_unlock_irqrestore(&hsq->lock, flags);
+
+	 /*
+	  * Try to pump new request to host controller as fast as possible,
+	  * after completing previous request.
+	  */
+	if (remains > 0)
+		mmc_hsq_pump_requests(hsq);
+}
+
+/**
+ * mmc_hsq_finalize_request - finalize one request if the request is done
+ * @mmc: the host controller
+ * @mrq: the request need to be finalized
+ *
+ * Return true if we finalized the corresponding request in software queue,
+ * otherwise return false.
+ */
+bool mmc_hsq_finalize_request(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct mmc_hsq *hsq = mmc->cqe_private;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hsq->lock, flags);
+
+	if (!hsq->enabled || !hsq->mrq || hsq->mrq != mrq) {
+		spin_unlock_irqrestore(&hsq->lock, flags);
+		return false;
+	}
+
+	/*
+	 * Clear current completed slot request to make a room for new request.
+	 */
+	hsq->slot[hsq->next_tag].mrq = NULL;
+
+	spin_unlock_irqrestore(&hsq->lock, flags);
+
+	mmc_cqe_request_done(mmc, hsq->mrq);
+
+	mmc_hsq_post_request(hsq);
+
+	return true;
+}
+EXPORT_SYMBOL_GPL(mmc_hsq_finalize_request);
+
+static void mmc_hsq_recovery_start(struct mmc_host *mmc)
+{
+	struct mmc_hsq *hsq = mmc->cqe_private;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hsq->lock, flags);
+
+	hsq->recovery_halt = true;
+
+	spin_unlock_irqrestore(&hsq->lock, flags);
+}
+
+static void mmc_hsq_recovery_finish(struct mmc_host *mmc)
+{
+	struct mmc_hsq *hsq = mmc->cqe_private;
+	int remains;
+
+	spin_lock_irq(&hsq->lock);
+
+	hsq->recovery_halt = false;
+	remains = hsq->qcnt;
+
+	spin_unlock_irq(&hsq->lock);
+
+	/*
+	 * Try to pump new request if there are request pending in software
+	 * queue after finishing recovery.
+	 */
+	if (remains > 0)
+		mmc_hsq_pump_requests(hsq);
+}
+
+static int mmc_hsq_request(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct mmc_hsq *hsq = mmc->cqe_private;
+	int tag = mrq->tag;
+
+	spin_lock_irq(&hsq->lock);
+
+	if (!hsq->enabled) {
+		spin_unlock_irq(&hsq->lock);
+		return -ESHUTDOWN;
+	}
+
+	/* Do not queue any new requests in recovery mode. */
+	if (hsq->recovery_halt) {
+		spin_unlock_irq(&hsq->lock);
+		return -EBUSY;
+	}
+
+	hsq->slot[tag].mrq = mrq;
+
+	/*
+	 * Set the next tag as current request tag if no available
+	 * next tag.
+	 */
+	if (hsq->next_tag == HSQ_INVALID_TAG)
+		hsq->next_tag = tag;
+
+	hsq->qcnt++;
+
+	spin_unlock_irq(&hsq->lock);
+
+	mmc_hsq_pump_requests(hsq);
+
+	return 0;
+}
+
+static void mmc_hsq_post_req(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	if (mmc->ops->post_req)
+		mmc->ops->post_req(mmc, mrq, 0);
+}
+
+static bool mmc_hsq_queue_is_idle(struct mmc_hsq *hsq, int *ret)
+{
+	bool is_idle;
+
+	spin_lock_irq(&hsq->lock);
+
+	is_idle = (!hsq->mrq && !hsq->qcnt) ||
+		hsq->recovery_halt;
+
+	*ret = hsq->recovery_halt ? -EBUSY : 0;
+	hsq->waiting_for_idle = !is_idle;
+
+	spin_unlock_irq(&hsq->lock);
+
+	return is_idle;
+}
+
+static int mmc_hsq_wait_for_idle(struct mmc_host *mmc)
+{
+	struct mmc_hsq *hsq = mmc->cqe_private;
+	int ret;
+
+	wait_event(hsq->wait_queue,
+		   mmc_hsq_queue_is_idle(hsq, &ret));
+
+	return ret;
+}
+
+static void mmc_hsq_disable(struct mmc_host *mmc)
+{
+	struct mmc_hsq *hsq = mmc->cqe_private;
+	u32 timeout = 500;
+	int ret;
+
+	spin_lock_irq(&hsq->lock);
+
+	if (!hsq->enabled) {
+		spin_unlock_irq(&hsq->lock);
+		return;
+	}
+
+	spin_unlock_irq(&hsq->lock);
+
+	ret = wait_event_timeout(hsq->wait_queue,
+				 mmc_hsq_queue_is_idle(hsq, &ret),
+				 msecs_to_jiffies(timeout));
+	if (ret == 0) {
+		pr_warn("could not stop mmc software queue\n");
+		return;
+	}
+
+	spin_lock_irq(&hsq->lock);
+
+	hsq->enabled = false;
+
+	spin_unlock_irq(&hsq->lock);
+}
+
+static int mmc_hsq_enable(struct mmc_host *mmc, struct mmc_card *card)
+{
+	struct mmc_hsq *hsq = mmc->cqe_private;
+
+	spin_lock_irq(&hsq->lock);
+
+	if (hsq->enabled) {
+		spin_unlock_irq(&hsq->lock);
+		return -EBUSY;
+	}
+
+	hsq->enabled = true;
+
+	spin_unlock_irq(&hsq->lock);
+
+	return 0;
+}
+
+static const struct mmc_cqe_ops mmc_hsq_ops = {
+	.cqe_enable = mmc_hsq_enable,
+	.cqe_disable = mmc_hsq_disable,
+	.cqe_request = mmc_hsq_request,
+	.cqe_post_req = mmc_hsq_post_req,
+	.cqe_wait_for_idle = mmc_hsq_wait_for_idle,
+	.cqe_recovery_start = mmc_hsq_recovery_start,
+	.cqe_recovery_finish = mmc_hsq_recovery_finish,
+};
+
+int mmc_hsq_init(struct mmc_hsq *hsq, struct mmc_host *mmc)
+{
+	hsq->num_slots = HSQ_NUM_SLOTS;
+	hsq->next_tag = HSQ_INVALID_TAG;
+
+	hsq->slot = devm_kcalloc(mmc_dev(mmc), hsq->num_slots,
+				 sizeof(struct hsq_slot), GFP_KERNEL);
+	if (!hsq->slot)
+		return -ENOMEM;
+
+	hsq->mmc = mmc;
+	hsq->mmc->cqe_private = hsq;
+	mmc->cqe_ops = &mmc_hsq_ops;
+
+	INIT_WORK(&hsq->retry_work, mmc_hsq_retry_handler);
+	spin_lock_init(&hsq->lock);
+	init_waitqueue_head(&hsq->wait_queue);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mmc_hsq_init);
+
+void mmc_hsq_suspend(struct mmc_host *mmc)
+{
+	mmc_hsq_disable(mmc);
+}
+EXPORT_SYMBOL_GPL(mmc_hsq_suspend);
+
+int mmc_hsq_resume(struct mmc_host *mmc)
+{
+	return mmc_hsq_enable(mmc, NULL);
+}
+EXPORT_SYMBOL_GPL(mmc_hsq_resume);
+
+MODULE_DESCRIPTION("MMC Host Software Queue support");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/mmc/host/mmc_hsq.h b/drivers/mmc/host/mmc_hsq.h
new file mode 100644
index 000000000..ffdd9cd17
--- /dev/null
+++ b/drivers/mmc/host/mmc_hsq.h
@@ -0,0 +1,31 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+#ifndef LINUX_MMC_HSQ_H
+#define LINUX_MMC_HSQ_H
+
+struct hsq_slot {
+	struct mmc_request *mrq;
+};
+
+struct mmc_hsq {
+	struct mmc_host *mmc;
+	struct mmc_request *mrq;
+	wait_queue_head_t wait_queue;
+	struct hsq_slot *slot;
+	spinlock_t lock;
+	struct work_struct retry_work;
+
+	int next_tag;
+	int num_slots;
+	int qcnt;
+
+	bool enabled;
+	bool waiting_for_idle;
+	bool recovery_halt;
+};
+
+int mmc_hsq_init(struct mmc_hsq *hsq, struct mmc_host *mmc);
+void mmc_hsq_suspend(struct mmc_host *mmc);
+int mmc_hsq_resume(struct mmc_host *mmc);
+bool mmc_hsq_finalize_request(struct mmc_host *mmc, struct mmc_request *mrq);
+
+#endif
diff --git a/drivers/mmc/host/sdhci-sprd.c b/drivers/mmc/host/sdhci-sprd.c
index d07b97933..1f8229061 100644
--- a/drivers/mmc/host/sdhci-sprd.c
+++ b/drivers/mmc/host/sdhci-sprd.c
@@ -19,6 +19,7 @@
 #include <linux/slab.h>
 
 #include "sdhci-pltfm.h"
+#include "mmc_hsq.h"
 
 /* SDHCI_ARGUMENT2 register high 16bit */
 #define SDHCI_SPRD_ARG2_STUFF		GENMASK(31, 16)
@@ -379,6 +380,16 @@ static unsigned int sdhci_sprd_get_ro(struct sdhci_host *host)
 	return 0;
 }
 
+static void sdhci_sprd_request_done(struct sdhci_host *host,
+				    struct mmc_request *mrq)
+{
+	/* Validate if the request was from software queue firstly. */
+	if (mmc_hsq_finalize_request(host->mmc, mrq))
+		return;
+
+	 mmc_request_done(host->mmc, mrq);
+}
+
 static struct sdhci_ops sdhci_sprd_ops = {
 	.read_l = sdhci_sprd_readl,
 	.write_l = sdhci_sprd_writel,
@@ -392,9 +403,11 @@ static struct sdhci_ops sdhci_sprd_ops = {
 	.hw_reset = sdhci_sprd_hw_reset,
 	.get_max_timeout_count = sdhci_sprd_get_max_timeout_count,
 	.get_ro = sdhci_sprd_get_ro,
+	.request_done = sdhci_sprd_request_done,
 };
 
-static void sdhci_sprd_request(struct mmc_host *mmc, struct mmc_request *mrq)
+static void sdhci_sprd_check_auto_cmd23(struct mmc_host *mmc,
+					struct mmc_request *mrq)
 {
 	struct sdhci_host *host = mmc_priv(mmc);
 	struct sdhci_sprd_host *sprd_host = TO_SPRD_HOST(host);
@@ -410,10 +423,23 @@ static void sdhci_sprd_request(struct mmc_host *mmc, struct mmc_request *mrq)
 	    mrq->sbc && (mrq->sbc->arg & SDHCI_SPRD_ARG2_STUFF) &&
 	    (host->flags & SDHCI_AUTO_CMD23))
 		host->flags &= ~SDHCI_AUTO_CMD23;
+}
+
+static void sdhci_sprd_request(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	sdhci_sprd_check_auto_cmd23(mmc, mrq);
 
 	sdhci_request(mmc, mrq);
 }
 
+static int sdhci_sprd_request_atomic(struct mmc_host *mmc,
+				      struct mmc_request *mrq)
+{
+	sdhci_sprd_check_auto_cmd23(mmc, mrq);
+
+	return sdhci_request_atomic(mmc, mrq);
+}
+
 static int sdhci_sprd_voltage_switch(struct mmc_host *mmc, struct mmc_ios *ios)
 {
 	struct sdhci_host *host = mmc_priv(mmc);
@@ -521,6 +547,7 @@ static int sdhci_sprd_probe(struct platform_device *pdev)
 {
 	struct sdhci_host *host;
 	struct sdhci_sprd_host *sprd_host;
+	struct mmc_hsq *hsq;
 	struct clk *clk;
 	int ret = 0;
 
@@ -543,11 +570,17 @@ static int sdhci_sprd_probe(struct platform_device *pdev)
 		sdhci_sprd_voltage_switch;
 
 	host->mmc->caps = MMC_CAP_SD_HIGHSPEED | MMC_CAP_MMC_HIGHSPEED |
-		MMC_CAP_ERASE | MMC_CAP_CMD23;
+		MMC_CAP_WAIT_WHILE_BUSY;
+
 	ret = mmc_of_parse(host->mmc);
 	if (ret)
 		goto pltfm_free;
 
+	if (!mmc_card_is_removable(host->mmc))
+		host->mmc_host_ops.request_atomic = sdhci_sprd_request_atomic;
+	else
+		host->always_defer_done = true;
+
 	sprd_host = TO_SPRD_HOST(host);
 	sdhci_sprd_phy_param_parse(sprd_host, pdev->dev.of_node);
 
@@ -631,6 +664,16 @@ static int sdhci_sprd_probe(struct platform_device *pdev)
 
 	sprd_host->flags = host->flags;
 
+	hsq = devm_kzalloc(&pdev->dev, sizeof(*hsq), GFP_KERNEL);
+	if (!hsq) {
+		ret = -ENOMEM;
+		goto err_cleanup_host;
+	}
+
+	ret = mmc_hsq_init(hsq, host->mmc);
+	if (ret)
+		goto err_cleanup_host;
+
 	ret = __sdhci_add_host(host);
 	if (ret)
 		goto err_cleanup_host;
@@ -689,6 +732,7 @@ static int sdhci_sprd_runtime_suspend(struct device *dev)
 	struct sdhci_host *host = dev_get_drvdata(dev);
 	struct sdhci_sprd_host *sprd_host = TO_SPRD_HOST(host);
 
+	mmc_hsq_suspend(host->mmc);
 	sdhci_runtime_suspend_host(host);
 
 	clk_disable_unprepare(sprd_host->clk_sdio);
@@ -717,6 +761,8 @@ static int sdhci_sprd_runtime_resume(struct device *dev)
 		goto clk_disable;
 
 	sdhci_runtime_resume_host(host, 1);
+	mmc_hsq_resume(host->mmc);
+
 	return 0;
 
 clk_disable:
diff --git a/drivers/mmc/host/sdhci.c b/drivers/mmc/host/sdhci.c
index 136f97377..7b4007418 100644
--- a/drivers/mmc/host/sdhci.c
+++ b/drivers/mmc/host/sdhci.c
@@ -46,10 +46,10 @@
 static unsigned int debug_quirks = 0;
 static unsigned int debug_quirks2;
 
-static void sdhci_finish_data(struct sdhci_host *);
-
 static void sdhci_enable_preset_value(struct sdhci_host *host, bool enable);
 
+static bool sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd);
+
 void sdhci_dumpregs(struct sdhci_host *host)
 {
 	SDHCI_DUMP("============ SDHCI REGISTER DUMP ===========\n");
@@ -1150,13 +1150,25 @@ static inline bool sdhci_auto_cmd12(struct sdhci_host *host,
 	       !mrq->cap_cmd_during_tfr;
 }
 
+static inline bool sdhci_auto_cmd23(struct sdhci_host *host,
+				    struct mmc_request *mrq)
+{
+	return mrq->sbc && (host->flags & SDHCI_AUTO_CMD23);
+}
+
+static inline bool sdhci_manual_cmd23(struct sdhci_host *host,
+				      struct mmc_request *mrq)
+{
+	return mrq->sbc && !(host->flags & SDHCI_AUTO_CMD23);
+}
+
 static inline void sdhci_auto_cmd_select(struct sdhci_host *host,
 					 struct mmc_command *cmd,
 					 u16 *mode)
 {
 	bool use_cmd12 = sdhci_auto_cmd12(host, cmd->mrq) &&
 			 (cmd->opcode != SD_IO_RW_EXTENDED);
-	bool use_cmd23 = cmd->mrq->sbc && (host->flags & SDHCI_AUTO_CMD23);
+	bool use_cmd23 = sdhci_auto_cmd23(host, cmd->mrq);
 	u16 ctrl2;
 
 	/*
@@ -1216,7 +1228,7 @@ static void sdhci_set_transfer_mode(struct sdhci_host *host,
 	if (mmc_op_multi(cmd->opcode) || data->blocks > 1) {
 		mode = SDHCI_TRNS_BLK_CNT_EN | SDHCI_TRNS_MULTI;
 		sdhci_auto_cmd_select(host, cmd, &mode);
-		if (cmd->mrq->sbc && (host->flags & SDHCI_AUTO_CMD23))
+		if (sdhci_auto_cmd23(host, cmd->mrq))
 			sdhci_writel(host, cmd->mrq->sbc->arg, SDHCI_ARGUMENT2);
 	}
 
@@ -1247,6 +1259,9 @@ static void __sdhci_finish_mrq(struct sdhci_host *host, struct mmc_request *mrq)
 	if (host->data_cmd && host->data_cmd->mrq == mrq)
 		host->data_cmd = NULL;
 
+	if (host->deferred_cmd && host->deferred_cmd->mrq == mrq)
+		host->deferred_cmd = NULL;
+
 	if (host->data && host->data->mrq == mrq)
 		host->data = NULL;
 
@@ -1282,7 +1297,7 @@ static void sdhci_finish_mrq(struct sdhci_host *host, struct mmc_request *mrq)
 	queue_work(host->complete_wq, &host->complete_work);
 }
 
-static void sdhci_finish_data(struct sdhci_host *host)
+static void __sdhci_finish_data(struct sdhci_host *host, bool sw_data_timeout)
 {
 	struct mmc_command *data_cmd = host->data_cmd;
 	struct mmc_data *data = host->data;
@@ -1334,14 +1349,31 @@ static void sdhci_finish_data(struct sdhci_host *host)
 		} else {
 			/* Avoid triggering warning in sdhci_send_command() */
 			host->cmd = NULL;
-			sdhci_send_command(host, data->stop);
+			if (!sdhci_send_command(host, data->stop)) {
+				if (sw_data_timeout) {
+					/*
+					 * This is anyway a sw data timeout, so
+					 * give up now.
+					 */
+					data->stop->error = -EIO;
+					__sdhci_finish_mrq(host, data->mrq);
+				} else {
+					WARN_ON(host->deferred_cmd);
+					host->deferred_cmd = data->stop;
+				}
+			}
 		}
 	} else {
 		__sdhci_finish_mrq(host, data->mrq);
 	}
 }
 
-void sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd)
+static void sdhci_finish_data(struct sdhci_host *host)
+{
+	__sdhci_finish_data(host, false);
+}
+
+static bool sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd)
 {
 	int flags;
 	u32 mask;
@@ -1356,9 +1388,6 @@ void sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd)
 	    cmd->opcode == MMC_STOP_TRANSMISSION)
 		cmd->flags |= MMC_RSP_BUSY;
 
-	/* Wait max 10 ms */
-	timeout = 10;
-
 	mask = SDHCI_CMD_INHIBIT;
 	if (sdhci_data_line_cmd(cmd))
 		mask |= SDHCI_DATA_INHIBIT;
@@ -1368,18 +1397,8 @@ void sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd)
 	if (cmd->mrq->data && (cmd == cmd->mrq->data->stop))
 		mask &= ~SDHCI_DATA_INHIBIT;
 
-	while (sdhci_readl(host, SDHCI_PRESENT_STATE) & mask) {
-		if (timeout == 0) {
-			pr_err("%s: Controller never released inhibit bit(s).\n",
-			       mmc_hostname(host->mmc));
-			sdhci_dumpregs(host);
-			cmd->error = -EIO;
-			sdhci_finish_mrq(host, cmd->mrq);
-			return;
-		}
-		timeout--;
-		mdelay(1);
-	}
+	if (sdhci_readl(host, SDHCI_PRESENT_STATE) & mask)
+		return false;
 
 	host->cmd = cmd;
 	if (sdhci_data_line_cmd(cmd)) {
@@ -1394,11 +1413,13 @@ void sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd)
 	sdhci_set_transfer_mode(host, cmd);
 
 	if ((cmd->flags & MMC_RSP_136) && (cmd->flags & MMC_RSP_BUSY)) {
-		pr_err("%s: Unsupported response type!\n",
-			mmc_hostname(host->mmc));
-		cmd->error = -EINVAL;
-		sdhci_finish_mrq(host, cmd->mrq);
-		return;
+		WARN_ONCE(1, "Unsupported response type!\n");
+		/*
+		 * This does not happen in practice because 136-bit response
+		 * commands never have busy waiting, so rather than complicate
+		 * the error path, just remove busy waiting and continue.
+		 */
+		cmd->flags &= ~MMC_RSP_BUSY;
 	}
 
 	if (!(cmd->flags & MMC_RSP_PRESENT))
@@ -1430,8 +1451,61 @@ void sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd)
 	sdhci_mod_timer(host, cmd->mrq, timeout);
 
 	sdhci_writew(host, SDHCI_MAKE_CMD(cmd->opcode, flags), SDHCI_COMMAND);
+
+	return true;
+}
+
+static bool sdhci_present_error(struct sdhci_host *host,
+				struct mmc_command *cmd, bool present)
+{
+	if (!present || host->flags & SDHCI_DEVICE_DEAD) {
+		cmd->error = -ENOMEDIUM;
+		return true;
+	}
+
+	return false;
+}
+
+static bool sdhci_send_command_retry(struct sdhci_host *host,
+				     struct mmc_command *cmd,
+				     unsigned long flags)
+	__releases(host->lock)
+	__acquires(host->lock)
+{
+	struct mmc_command *deferred_cmd = host->deferred_cmd;
+	int timeout = 10; /* Approx. 10 ms */
+	bool present;
+
+	while (!sdhci_send_command(host, cmd)) {
+		if (!timeout--) {
+			pr_err("%s: Controller never released inhibit bit(s).\n",
+			       mmc_hostname(host->mmc));
+			sdhci_dumpregs(host);
+			cmd->error = -EIO;
+			return false;
+		}
+
+		spin_unlock_irqrestore(&host->lock, flags);
+
+		usleep_range(1000, 1250);
+
+		present = host->mmc->ops->get_cd(host->mmc);
+
+		spin_lock_irqsave(&host->lock, flags);
+
+		/* A deferred command might disappear, handle that */
+		if (cmd == deferred_cmd && cmd != host->deferred_cmd)
+			return true;
+
+		if (sdhci_present_error(host, cmd, present))
+			return false;
+	}
+
+	if (cmd == host->deferred_cmd)
+		host->deferred_cmd = NULL;
+
+	return true;
 }
-EXPORT_SYMBOL_GPL(sdhci_send_command);
 
 static void sdhci_read_rsp_136(struct sdhci_host *host, struct mmc_command *cmd)
 {
@@ -1492,7 +1566,10 @@ static void sdhci_finish_command(struct sdhci_host *host)
 
 	/* Finished CMD23, now send actual command. */
 	if (cmd == cmd->mrq->sbc) {
-		sdhci_send_command(host, cmd->mrq->cmd);
+		if (!sdhci_send_command(host, cmd->mrq->cmd)) {
+			WARN_ON(host->deferred_cmd);
+			host->deferred_cmd = cmd->mrq->cmd;
+		}
 	} else {
 
 		/* Processed actual command. */
@@ -1804,11 +1881,10 @@ EXPORT_SYMBOL_GPL(sdhci_set_power);
 
 void sdhci_request(struct mmc_host *mmc, struct mmc_request *mrq)
 {
-	struct sdhci_host *host;
-	int present;
+	struct sdhci_host *host = mmc_priv(mmc);
+	struct mmc_command *cmd;
 	unsigned long flags;
-
-	host = mmc_priv(mmc);
+	bool present;
 
 	/* Firstly check card presence */
 	present = mmc->ops->get_cd(mmc);
@@ -1828,19 +1904,58 @@ void sdhci_request(struct mmc_host *mmc, struct mmc_request *mrq)
 		}
 	}
 
-	if (!present || host->flags & SDHCI_DEVICE_DEAD) {
-		mrq->cmd->error = -ENOMEDIUM;
+
+	if (sdhci_present_error(host, mrq->cmd, present))
+		goto out_finish;
+
+	cmd = sdhci_manual_cmd23(host, mrq) ? mrq->sbc : mrq->cmd;
+
+	if (!sdhci_send_command_retry(host, cmd, flags))
+		goto out_finish;
+
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	return;
+
+out_finish:
+	sdhci_finish_mrq(host, mrq);
+	spin_unlock_irqrestore(&host->lock, flags);
+}
+EXPORT_SYMBOL_GPL(sdhci_request);
+
+int sdhci_request_atomic(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct sdhci_host *host = mmc_priv(mmc);
+	struct mmc_command *cmd;
+	unsigned long flags;
+	int ret = 0;
+
+	spin_lock_irqsave(&host->lock, flags);
+
+	if (sdhci_present_error(host, mrq->cmd, true)) {
 		sdhci_finish_mrq(host, mrq);
-	} else {
-		if (mrq->sbc && !(host->flags & SDHCI_AUTO_CMD23))
-			sdhci_send_command(host, mrq->sbc);
-		else
-			sdhci_send_command(host, mrq->cmd);
+		goto out_finish;
 	}
 
+	cmd = sdhci_manual_cmd23(host, mrq) ? mrq->sbc : mrq->cmd;
+
+	/*
+	 * The HSQ may send a command in interrupt context without polling
+	 * the busy signaling, which means we should return BUSY if controller
+	 * has not released inhibit bits to allow HSQ trying to send request
+	 * again in non-atomic context. So we should not finish this request
+	 * here.
+	 */
+	if (!sdhci_send_command(host, cmd))
+		ret = -EBUSY;
+	else
+		sdhci_led_activate(host);
+
+out_finish:
 	spin_unlock_irqrestore(&host->lock, flags);
+	return ret;
 }
-EXPORT_SYMBOL_GPL(sdhci_request);
+EXPORT_SYMBOL_GPL(sdhci_request_atomic);
 
 void sdhci_set_bus_width(struct sdhci_host *host, int width)
 {
@@ -2378,7 +2493,11 @@ void sdhci_send_tuning(struct sdhci_host *host, u32 opcode)
 	 */
 	sdhci_writew(host, SDHCI_TRNS_READ, SDHCI_TRANSFER_MODE);
 
-	sdhci_send_command(host, &cmd);
+	if (!sdhci_send_command_retry(host, &cmd, flags)) {
+		spin_unlock_irqrestore(&host->lock, flags);
+		host->tuning_done = 0;
+		return;
+	}
 
 	host->cmd = NULL;
 
@@ -2730,7 +2849,10 @@ static bool sdhci_request_done(struct sdhci_host *host)
 
 	spin_unlock_irqrestore(&host->lock, flags);
 
-	mmc_request_done(host->mmc, mrq);
+	if (host->ops->request_done)
+		host->ops->request_done(host, mrq);
+	else
+		mmc_request_done(host->mmc, mrq);
 
 	return false;
 }
@@ -2782,7 +2904,7 @@ static void sdhci_timeout_data_timer(struct timer_list *t)
 
 		if (host->data) {
 			host->data->error = -ETIMEDOUT;
-			sdhci_finish_data(host);
+			__sdhci_finish_data(host, true);
 			queue_work(host->complete_wq, &host->complete_work);
 		} else if (host->data_cmd) {
 			host->data_cmd->error = -ETIMEDOUT;
@@ -3033,7 +3155,7 @@ static inline bool sdhci_defer_done(struct sdhci_host *host,
 {
 	struct mmc_data *data = mrq->data;
 
-	return host->pending_reset ||
+	return host->pending_reset || host->always_defer_done ||
 	       ((host->flags & SDHCI_REQ_USE_DMA) && data &&
 		data->host_cookie == COOKIE_MAPPED);
 }
@@ -3154,11 +3276,19 @@ static irqreturn_t sdhci_irq(int irq, void *dev_id)
 		}
 	}
 out:
+	if (host->deferred_cmd)
+		result = IRQ_WAKE_THREAD;
+
 	spin_unlock(&host->lock);
 
 	/* Process mrqs ready for immediate completion */
 	for (i = 0; i < SDHCI_MAX_MRQS; i++) {
-		if (mrqs_done[i])
+		if (!mrqs_done[i])
+			continue;
+
+		if (host->ops->request_done)
+			host->ops->request_done(host, mrqs_done[i]);
+		else
 			mmc_request_done(host->mmc, mrqs_done[i]);
 	}
 
@@ -3174,6 +3304,7 @@ static irqreturn_t sdhci_irq(int irq, void *dev_id)
 static irqreturn_t sdhci_thread_irq(int irq, void *dev_id)
 {
 	struct sdhci_host *host = dev_id;
+	struct mmc_command *cmd;
 	unsigned long flags;
 	u32 isr;
 
@@ -3181,8 +3312,14 @@ static irqreturn_t sdhci_thread_irq(int irq, void *dev_id)
 		;
 
 	spin_lock_irqsave(&host->lock, flags);
+
 	isr = host->thread_isr;
 	host->thread_isr = 0;
+
+	cmd = host->deferred_cmd;
+	if (cmd && !sdhci_send_command_retry(host, cmd, flags))
+		sdhci_finish_mrq(host, cmd->mrq);
+
 	spin_unlock_irqrestore(&host->lock, flags);
 
 	if (isr & (SDHCI_INT_CARD_INSERT | SDHCI_INT_CARD_REMOVE)) {
@@ -3759,9 +3896,6 @@ int sdhci_setup_host(struct sdhci_host *host)
 		       mmc_hostname(mmc), host->version);
 	}
 
-	if (host->quirks & SDHCI_QUIRK_BROKEN_CQE)
-		mmc->caps2 &= ~MMC_CAP2_CQE;
-
 	if (host->quirks & SDHCI_QUIRK_FORCE_DMA)
 		host->flags |= SDHCI_USE_SDMA;
 	else if (!(host->caps & SDHCI_CAN_DO_SDMA))
@@ -4281,6 +4415,12 @@ int __sdhci_add_host(struct sdhci_host *host)
 	struct mmc_host *mmc = host->mmc;
 	int ret;
 
+	if ((mmc->caps2 & MMC_CAP2_CQE) &&
+	    (host->quirks & SDHCI_QUIRK_BROKEN_CQE)) {
+		mmc->caps2 &= ~MMC_CAP2_CQE;
+		mmc->cqe_ops = NULL;
+	}
+
 	host->complete_wq = alloc_workqueue("sdhci", flags, 0);
 	if (!host->complete_wq)
 		return -ENOMEM;
diff --git a/drivers/mmc/host/sdhci.h b/drivers/mmc/host/sdhci.h
index 76e692886..724d4e366 100644
--- a/drivers/mmc/host/sdhci.h
+++ b/drivers/mmc/host/sdhci.h
@@ -535,10 +535,12 @@ struct sdhci_host {
 	bool pending_reset;	/* Cmd/data reset is pending */
 	bool irq_wake_enabled;	/* IRQ wakeup is enabled */
 	bool v4_mode;		/* Host Version 4 Enable */
+	bool always_defer_done;	/* Always defer to complete requests */
 
 	struct mmc_request *mrqs_done[SDHCI_MAX_MRQS];	/* Requests done */
 	struct mmc_command *cmd;	/* Current command */
 	struct mmc_command *data_cmd;	/* Current data command */
+	struct mmc_command *deferred_cmd;	/* Deferred command */
 	struct mmc_data *data;	/* Current data request */
 	unsigned int data_early:1;	/* Data finished before cmd */
 
@@ -646,6 +648,8 @@ struct sdhci_ops {
 	void	(*voltage_switch)(struct sdhci_host *host);
 	void	(*adma_write_desc)(struct sdhci_host *host, void **desc,
 				   dma_addr_t addr, int len, unsigned int cmd);
+	void	(*request_done)(struct sdhci_host *host,
+				struct mmc_request *mrq);
 };
 
 #ifdef CONFIG_MMC_SDHCI_IO_ACCESSORS
@@ -748,7 +752,6 @@ void sdhci_cleanup_host(struct sdhci_host *host);
 int __sdhci_add_host(struct sdhci_host *host);
 int sdhci_add_host(struct sdhci_host *host);
 void sdhci_remove_host(struct sdhci_host *host, int dead);
-void sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd);
 
 static inline void sdhci_read_caps(struct sdhci_host *host)
 {
@@ -764,6 +767,7 @@ void sdhci_set_power(struct sdhci_host *host, unsigned char mode,
 void sdhci_set_power_noreg(struct sdhci_host *host, unsigned char mode,
 			   unsigned short vdd);
 void sdhci_request(struct mmc_host *mmc, struct mmc_request *mrq);
+int sdhci_request_atomic(struct mmc_host *mmc, struct mmc_request *mrq);
 void sdhci_set_bus_width(struct sdhci_host *host, int width);
 void sdhci_reset(struct sdhci_host *host, u8 mask);
 void sdhci_set_uhs_signaling(struct sdhci_host *host, unsigned timing);
diff --git a/drivers/mmc/host/sunxi-mmc-base.c b/drivers/mmc/host/sunxi-mmc-base.c
new file mode 100644
index 000000000..d577a6b0c
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-base.c
@@ -0,0 +1,1525 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * Driver for sunxi SD/MMC host controllers
+ * (C) Copyright 2007-2011 Reuuimlla Technology Co., Ltd.
+ * (C) Copyright 2007-2011 Aaron Maoye <leafy.myeh@reuuimllatech.com>
+ * (C) Copyright 2013-2014 O2S GmbH <www.o2s.ch>
+ * (C) Copyright 2013-2014 David Lanzendörfer <david.lanzendoerfer@o2s.ch>
+ * (C) Copyright 2013-2014 Hans de Goede <hdegoede@redhat.com>
+ * (C) Copyright 2017 Sootech SA
+ */
+
+#include <linux/clk.h>
+#include <linux/clk/sunxi-ng.h>
+#include <linux/delay.h>
+#include <linux/device.h>
+#include <linux/dma-mapping.h>
+#include <linux/err.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/kernel.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/host.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/slot-gpio.h>
+#include <linux/module.h>
+#include <linux/of_address.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/pm_runtime.h>
+#include <linux/regulator/consumer.h>
+#include <linux/reset.h>
+#include <linux/scatterlist.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+
+/* register offset definitions */
+#define SDXC_REG_GCTRL	(0x00) /* SMC Global Control Register */
+#define SDXC_REG_CLKCR	(0x04) /* SMC Clock Control Register */
+#define SDXC_REG_TMOUT	(0x08) /* SMC Time Out Register */
+#define SDXC_REG_WIDTH	(0x0C) /* SMC Bus Width Register */
+#define SDXC_REG_BLKSZ	(0x10) /* SMC Block Size Register */
+#define SDXC_REG_BCNTR	(0x14) /* SMC Byte Count Register */
+#define SDXC_REG_CMDR	(0x18) /* SMC Command Register */
+#define SDXC_REG_CARG	(0x1C) /* SMC Argument Register */
+#define SDXC_REG_RESP0	(0x20) /* SMC Response Register 0 */
+#define SDXC_REG_RESP1	(0x24) /* SMC Response Register 1 */
+#define SDXC_REG_RESP2	(0x28) /* SMC Response Register 2 */
+#define SDXC_REG_RESP3	(0x2C) /* SMC Response Register 3 */
+#define SDXC_REG_IMASK	(0x30) /* SMC Interrupt Mask Register */
+#define SDXC_REG_MISTA	(0x34) /* SMC Masked Interrupt Status Register */
+#define SDXC_REG_RINTR	(0x38) /* SMC Raw Interrupt Status Register */
+#define SDXC_REG_STAS	(0x3C) /* SMC Status Register */
+#define SDXC_REG_FTRGL	(0x40) /* SMC FIFO Threshold Watermark Registe */
+#define SDXC_REG_FUNS	(0x44) /* SMC Function Select Register */
+#define SDXC_REG_CBCR	(0x48) /* SMC CIU Byte Count Register */
+#define SDXC_REG_BBCR	(0x4C) /* SMC BIU Byte Count Register */
+#define SDXC_REG_DBGC	(0x50) /* SMC Debug Enable Register */
+#define SDXC_REG_HWRST	(0x78) /* SMC Card Hardware Reset for Register */
+#define SDXC_REG_DMAC	(0x80) /* SMC IDMAC Control Register */
+#define SDXC_REG_DLBA	(0x84) /* SMC IDMAC Descriptor List Base Addre */
+#define SDXC_REG_IDST	(0x88) /* SMC IDMAC Status Register */
+#define SDXC_REG_IDIE	(0x8C) /* SMC IDMAC Interrupt Enable Register */
+#define SDXC_REG_CHDA	(0x90)
+#define SDXC_REG_CBDA	(0x94)
+
+/* New registers introduced in A64 */
+#define SDXC_REG_A12A		0x058 /* SMC Auto Command 12 Register */
+#define SDXC_REG_SD_NTSR	0x05C /* SMC New Timing Set Register */
+#define SDXC_REG_DRV_DL		0x140 /* Drive Delay Control Register */
+#define SDXC_REG_SAMP_DL_REG	0x144 /* SMC sample delay control */
+#define SDXC_REG_DS_DL_REG	0x148 /* SMC data strobe delay control */
+
+#define mmc_readl(host, reg) \
+	readl((host)->reg_base + SDXC_##reg)
+#define mmc_writel(host, reg, value) \
+	writel((value), (host)->reg_base + SDXC_##reg)
+
+/* global control register bits */
+#define SDXC_SOFT_RESET			BIT(0)
+#define SDXC_FIFO_RESET			BIT(1)
+#define SDXC_DMA_RESET			BIT(2)
+#define SDXC_INTERRUPT_ENABLE_BIT	BIT(4)
+#define SDXC_DMA_ENABLE_BIT		BIT(5)
+#define SDXC_DEBOUNCE_ENABLE_BIT	BIT(8)
+#define SDXC_POSEDGE_LATCH_DATA		BIT(9)
+#define SDXC_DDR_MODE			BIT(10)
+#define SDXC_MEMORY_ACCESS_DONE		BIT(29)
+#define SDXC_ACCESS_DONE_DIRECT		BIT(30)
+#define SDXC_ACCESS_BY_AHB		BIT(31)
+#define SDXC_ACCESS_BY_DMA		(0 << 31)
+#define SDXC_HARDWARE_RESET \
+	(SDXC_SOFT_RESET | SDXC_FIFO_RESET | SDXC_DMA_RESET)
+
+/* clock control bits */
+#define SDXC_MASK_DATA0			BIT(31)
+#define SDXC_CARD_CLOCK_ON		BIT(16)
+#define SDXC_LOW_POWER_ON		BIT(17)
+
+/* bus width */
+#define SDXC_WIDTH1			0
+#define SDXC_WIDTH4			1
+#define SDXC_WIDTH8			2
+
+/* smc command bits */
+#define SDXC_RESP_EXPIRE		BIT(6)
+#define SDXC_LONG_RESPONSE		BIT(7)
+#define SDXC_CHECK_RESPONSE_CRC		BIT(8)
+#define SDXC_DATA_EXPIRE		BIT(9)
+#define SDXC_WRITE			BIT(10)
+#define SDXC_SEQUENCE_MODE		BIT(11)
+#define SDXC_SEND_AUTO_STOP		BIT(12)
+#define SDXC_WAIT_PRE_OVER		BIT(13)
+#define SDXC_STOP_ABORT_CMD		BIT(14)
+#define SDXC_SEND_INIT_SEQUENCE		BIT(15)
+#define SDXC_UPCLK_ONLY			BIT(21)
+#define SDXC_READ_CEATA_DEV		BIT(22)
+#define SDXC_CCS_EXPIRE			BIT(23)
+#define SDXC_ENABLE_BIT_BOOT		BIT(24)
+#define SDXC_ALT_BOOT_OPTIONS		BIT(25)
+#define SDXC_BOOT_ACK_EXPIRE		BIT(26)
+#define SDXC_BOOT_ABORT			BIT(27)
+#define SDXC_VOLTAGE_SWITCH	        BIT(28)
+#define SDXC_USE_HOLD_REGISTER	        BIT(29)
+#define SDXC_START			BIT(31)
+
+/* interrupt bits */
+#define SDXC_RESP_ERROR			BIT(1)
+#define SDXC_COMMAND_DONE		BIT(2)
+#define SDXC_DATA_OVER			BIT(3)
+#define SDXC_TX_DATA_REQUEST		BIT(4)
+#define SDXC_RX_DATA_REQUEST		BIT(5)
+#define SDXC_RESP_CRC_ERROR		BIT(6)
+#define SDXC_DATA_CRC_ERROR		BIT(7)
+#define SDXC_RESP_TIMEOUT		BIT(8)
+#define SDXC_DATA_TIMEOUT		BIT(9)
+#define SDXC_VOLTAGE_CHANGE_DONE	BIT(10)
+#define SDXC_FIFO_RUN_ERROR		BIT(11)
+#define SDXC_HARD_WARE_LOCKED		BIT(12)
+#define SDXC_START_BIT_ERROR		BIT(13)
+#define SDXC_AUTO_COMMAND_DONE		BIT(14)
+#define SDXC_END_BIT_ERROR		BIT(15)
+#define SDXC_SDIO_INTERRUPT		BIT(16)
+#define SDXC_CARD_INSERT		BIT(30)
+#define SDXC_CARD_REMOVE		BIT(31)
+#define SDXC_INTERRUPT_ERROR_BIT \
+	(SDXC_RESP_ERROR | SDXC_RESP_CRC_ERROR | SDXC_DATA_CRC_ERROR | \
+	 SDXC_RESP_TIMEOUT | SDXC_DATA_TIMEOUT | SDXC_FIFO_RUN_ERROR | \
+	 SDXC_HARD_WARE_LOCKED | SDXC_START_BIT_ERROR | SDXC_END_BIT_ERROR)
+#define SDXC_INTERRUPT_DONE_BIT \
+	(SDXC_AUTO_COMMAND_DONE | SDXC_DATA_OVER | \
+	 SDXC_COMMAND_DONE | SDXC_VOLTAGE_CHANGE_DONE)
+
+/* status */
+#define SDXC_RXWL_FLAG			BIT(0)
+#define SDXC_TXWL_FLAG			BIT(1)
+#define SDXC_FIFO_EMPTY			BIT(2)
+#define SDXC_FIFO_FULL			BIT(3)
+#define SDXC_CARD_PRESENT		BIT(8)
+#define SDXC_CARD_DATA_BUSY		BIT(9)
+#define SDXC_DATA_FSM_BUSY		BIT(10)
+#define SDXC_DMA_REQUEST		BIT(31)
+#define SDXC_FIFO_SIZE			16
+
+/* Function select */
+#define SDXC_CEATA_ON			(0xceaa << 16)
+#define SDXC_SEND_IRQ_RESPONSE		BIT(0)
+#define SDXC_SDIO_READ_WAIT		BIT(1)
+#define SDXC_ABORT_READ_DATA		BIT(2)
+#define SDXC_SEND_CCSD			BIT(8)
+#define SDXC_SEND_AUTO_STOPCCSD		BIT(9)
+#define SDXC_CEATA_DEV_IRQ_ENABLE	BIT(10)
+
+/* IDMA controller bus mod bit field */
+#define SDXC_IDMAC_SOFT_RESET		BIT(0)
+#define SDXC_IDMAC_FIX_BURST		BIT(1)
+#define SDXC_IDMAC_IDMA_ON		BIT(7)
+#define SDXC_IDMAC_REFETCH_DES		BIT(31)
+
+/* IDMA status bit field */
+#define SDXC_IDMAC_TRANSMIT_INTERRUPT		BIT(0)
+#define SDXC_IDMAC_RECEIVE_INTERRUPT		BIT(1)
+#define SDXC_IDMAC_FATAL_BUS_ERROR		BIT(2)
+#define SDXC_IDMAC_DESTINATION_INVALID		BIT(4)
+#define SDXC_IDMAC_CARD_ERROR_SUM		BIT(5)
+#define SDXC_IDMAC_NORMAL_INTERRUPT_SUM		BIT(8)
+#define SDXC_IDMAC_ABNORMAL_INTERRUPT_SUM	BIT(9)
+#define SDXC_IDMAC_HOST_ABORT_INTERRUPT		BIT(10)
+#define SDXC_IDMAC_IDLE				(0 << 13)
+#define SDXC_IDMAC_SUSPEND			(1 << 13)
+#define SDXC_IDMAC_DESC_READ			(2 << 13)
+#define SDXC_IDMAC_DESC_CHECK			(3 << 13)
+#define SDXC_IDMAC_READ_REQUEST_WAIT		(4 << 13)
+#define SDXC_IDMAC_WRITE_REQUEST_WAIT		(5 << 13)
+#define SDXC_IDMAC_READ				(6 << 13)
+#define SDXC_IDMAC_WRITE			(7 << 13)
+#define SDXC_IDMAC_DESC_CLOSE			(8 << 13)
+
+/*
+* If the idma-des-size-bits of property is ie 13, bufsize bits are:
+*  Bits  0-12: buf1 size
+*  Bits 13-25: buf2 size
+*  Bits 26-31: not used
+* Since we only ever set buf1 size, we can simply store it directly.
+*/
+#define SDXC_IDMAC_DES0_DIC	BIT(1)  /* disable interrupt on completion */
+#define SDXC_IDMAC_DES0_LD	BIT(2)  /* last descriptor */
+#define SDXC_IDMAC_DES0_FD	BIT(3)  /* first descriptor */
+#define SDXC_IDMAC_DES0_CH	BIT(4)  /* chain mode */
+#define SDXC_IDMAC_DES0_ER	BIT(5)  /* end of ring */
+#define SDXC_IDMAC_DES0_CES	BIT(30) /* card error summary */
+#define SDXC_IDMAC_DES0_OWN	BIT(31) /* 1-idma owns it, 0-host owns it */
+
+#define SDXC_CLK_400K		0
+#define SDXC_CLK_25M		1
+#define SDXC_CLK_50M		2
+#define SDXC_CLK_50M_DDR	3
+#define SDXC_CLK_50M_DDR_8BIT	4
+
+#define SDXC_2X_TIMING_MODE	BIT(31)
+
+#define SDXC_CAL_START		BIT(15)
+#define SDXC_CAL_DONE		BIT(14)
+#define SDXC_CAL_DL_SHIFT	8
+#define SDXC_CAL_DL_SW_EN	BIT(7)
+#define SDXC_CAL_DL_SW_SHIFT	0
+#define SDXC_CAL_DL_MASK	0x3f
+
+#define SDXC_CAL_TIMEOUT	3	/* in seconds, 3s is enough*/
+
+struct sunxi_mmc_clk_delay {
+	u32 output;
+	u32 sample;
+};
+
+struct sunxi_idma_des {
+	__le32 config;
+	__le32 buf_size;
+	__le32 buf_addr_ptr1;
+	__le32 buf_addr_ptr2;
+};
+
+struct sunxi_mmc_cfg {
+	u32 idma_des_size_bits;
+	const struct sunxi_mmc_clk_delay *clk_delays;
+
+	/* does the IP block support autocalibration? */
+	bool can_calibrate;
+
+	/* Does DATA0 needs to be masked while the clock is updated */
+	bool mask_data0;
+
+	/*
+	 * hardware only supports new timing mode, either due to lack of
+	 * a mode switch in the clock controller, or the mmc controller
+	 * is permanently configured in the new timing mode, without the
+	 * NTSR mode switch.
+	 */
+	bool needs_new_timings;
+
+	/* clock hardware can switch between old and new timing modes */
+	bool ccu_has_timings_switch;
+};
+
+struct sunxi_mmc_host {
+	struct device *dev;
+	struct mmc_host	*mmc;
+	struct reset_control *reset;
+	const struct sunxi_mmc_cfg *cfg;
+
+	/* IO mapping base */
+	void __iomem	*reg_base;
+
+	/* clock management */
+	struct clk	*clk_ahb;
+	struct clk	*clk_mmc;
+	struct clk	*clk_sample;
+	struct clk	*clk_output;
+
+	/* irq */
+	spinlock_t	lock;
+	int		irq;
+	u32		int_sum;
+	u32		sdio_imask;
+
+	/* dma */
+	dma_addr_t	sg_dma;
+	void		*sg_cpu;
+	bool		wait_dma;
+
+	struct mmc_request *mrq;
+	struct mmc_request *manual_stop_mrq;
+	int		ferror;
+
+	/* vqmmc */
+	bool		vqmmc_enabled;
+
+	/* timings */
+	bool		use_new_timings;
+};
+
+static int sunxi_mmc_reset_host(struct sunxi_mmc_host *host)
+{
+	unsigned long expire = jiffies + msecs_to_jiffies(250);
+	u32 rval;
+
+	mmc_writel(host, REG_GCTRL, SDXC_HARDWARE_RESET);
+	do {
+		rval = mmc_readl(host, REG_GCTRL);
+	} while (time_before(jiffies, expire) && (rval & SDXC_HARDWARE_RESET));
+
+	if (rval & SDXC_HARDWARE_RESET) {
+		dev_err(mmc_dev(host->mmc), "fatal err reset timeout\n");
+		return -EIO;
+	}
+
+	return 0;
+}
+
+static int sunxi_mmc_init_host(struct sunxi_mmc_host *host)
+{
+	u32 rval;
+
+	if (sunxi_mmc_reset_host(host))
+		return -EIO;
+
+	/*
+	 * Burst 8 transfers, RX trigger level: 7, TX trigger level: 8
+	 *
+	 * TODO: sun9i has a larger FIFO and supports higher trigger values
+	 */
+	mmc_writel(host, REG_FTRGL, 0x20070008);
+	/* Maximum timeout value */
+	mmc_writel(host, REG_TMOUT, 0xffffffff);
+	/* Unmask SDIO interrupt if needed */
+	mmc_writel(host, REG_IMASK, host->sdio_imask);
+	/* Clear all pending interrupts */
+	mmc_writel(host, REG_RINTR, 0xffffffff);
+	/* Debug register? undocumented */
+	mmc_writel(host, REG_DBGC, 0xdeb);
+	/* Enable CEATA support */
+	mmc_writel(host, REG_FUNS, SDXC_CEATA_ON);
+	/* Set DMA descriptor list base address */
+	mmc_writel(host, REG_DLBA, host->sg_dma);
+
+	rval = mmc_readl(host, REG_GCTRL);
+	rval |= SDXC_INTERRUPT_ENABLE_BIT;
+	/* Undocumented, but found in Allwinner code */
+	rval &= ~SDXC_ACCESS_DONE_DIRECT;
+	mmc_writel(host, REG_GCTRL, rval);
+
+	return 0;
+}
+
+static void sunxi_mmc_init_idma_des(struct sunxi_mmc_host *host,
+				    struct mmc_data *data)
+{
+	struct sunxi_idma_des *pdes = (struct sunxi_idma_des *)host->sg_cpu;
+	dma_addr_t next_desc = host->sg_dma;
+	int i, max_len = (1 << host->cfg->idma_des_size_bits);
+
+	for (i = 0; i < data->sg_len; i++) {
+		pdes[i].config = cpu_to_le32(SDXC_IDMAC_DES0_CH |
+					     SDXC_IDMAC_DES0_OWN |
+					     SDXC_IDMAC_DES0_DIC);
+
+		if (data->sg[i].length == max_len)
+			pdes[i].buf_size = 0; /* 0 == max_len */
+		else
+			pdes[i].buf_size = cpu_to_le32(data->sg[i].length);
+
+		next_desc += sizeof(struct sunxi_idma_des);
+		pdes[i].buf_addr_ptr1 =
+			cpu_to_le32(sg_dma_address(&data->sg[i]));
+		pdes[i].buf_addr_ptr2 = cpu_to_le32((u32)next_desc);
+	}
+
+	pdes[0].config |= cpu_to_le32(SDXC_IDMAC_DES0_FD);
+	pdes[i - 1].config |= cpu_to_le32(SDXC_IDMAC_DES0_LD |
+					  SDXC_IDMAC_DES0_ER);
+	pdes[i - 1].config &= cpu_to_le32(~SDXC_IDMAC_DES0_DIC);
+	pdes[i - 1].buf_addr_ptr2 = 0;
+
+	/*
+	 * Avoid the io-store starting the idmac hitting io-mem before the
+	 * descriptors hit the main-mem.
+	 */
+	wmb();
+}
+
+static int sunxi_mmc_map_dma(struct sunxi_mmc_host *host,
+			     struct mmc_data *data)
+{
+	u32 i, dma_len;
+	struct scatterlist *sg;
+
+	dma_len = dma_map_sg(mmc_dev(host->mmc), data->sg, data->sg_len,
+			     mmc_get_dma_dir(data));
+	if (dma_len == 0) {
+		dev_err(mmc_dev(host->mmc), "dma_map_sg failed\n");
+		return -ENOMEM;
+	}
+
+	for_each_sg(data->sg, sg, data->sg_len, i) {
+		if (sg->offset & 3 || sg->length & 3) {
+			dev_err(mmc_dev(host->mmc),
+				"unaligned scatterlist: os %x length %d\n",
+				sg->offset, sg->length);
+			return -EINVAL;
+		}
+	}
+
+	return 0;
+}
+
+static void sunxi_mmc_start_dma(struct sunxi_mmc_host *host,
+				struct mmc_data *data)
+{
+	u32 rval;
+
+	sunxi_mmc_init_idma_des(host, data);
+
+	rval = mmc_readl(host, REG_GCTRL);
+	rval |= SDXC_DMA_ENABLE_BIT;
+	mmc_writel(host, REG_GCTRL, rval);
+	rval |= SDXC_DMA_RESET;
+	mmc_writel(host, REG_GCTRL, rval);
+
+	mmc_writel(host, REG_DMAC, SDXC_IDMAC_SOFT_RESET);
+
+	if (!(data->flags & MMC_DATA_WRITE))
+		mmc_writel(host, REG_IDIE, SDXC_IDMAC_RECEIVE_INTERRUPT);
+
+	mmc_writel(host, REG_DMAC,
+		   SDXC_IDMAC_FIX_BURST | SDXC_IDMAC_IDMA_ON);
+}
+
+static void sunxi_mmc_send_manual_stop(struct sunxi_mmc_host *host,
+				       struct mmc_request *req)
+{
+	u32 arg, cmd_val, ri;
+	unsigned long expire = jiffies + msecs_to_jiffies(1000);
+
+	cmd_val = SDXC_START | SDXC_RESP_EXPIRE |
+		  SDXC_STOP_ABORT_CMD | SDXC_CHECK_RESPONSE_CRC;
+
+	if (req->cmd->opcode == SD_IO_RW_EXTENDED) {
+		cmd_val |= SD_IO_RW_DIRECT;
+		arg = (1 << 31) | (0 << 28) | (SDIO_CCCR_ABORT << 9) |
+		      ((req->cmd->arg >> 28) & 0x7);
+	} else {
+		cmd_val |= MMC_STOP_TRANSMISSION;
+		arg = 0;
+	}
+
+	mmc_writel(host, REG_CARG, arg);
+	mmc_writel(host, REG_CMDR, cmd_val);
+
+	do {
+		ri = mmc_readl(host, REG_RINTR);
+	} while (!(ri & (SDXC_COMMAND_DONE | SDXC_INTERRUPT_ERROR_BIT)) &&
+		 time_before(jiffies, expire));
+
+	if (!(ri & SDXC_COMMAND_DONE) || (ri & SDXC_INTERRUPT_ERROR_BIT)) {
+		dev_err(mmc_dev(host->mmc), "send stop command failed\n");
+		if (req->stop)
+			req->stop->resp[0] = -ETIMEDOUT;
+	} else {
+		if (req->stop)
+			req->stop->resp[0] = mmc_readl(host, REG_RESP0);
+	}
+
+	mmc_writel(host, REG_RINTR, 0xffff);
+}
+
+static void sunxi_mmc_dump_errinfo(struct sunxi_mmc_host *host)
+{
+	struct mmc_command *cmd = host->mrq->cmd;
+	struct mmc_data *data = host->mrq->data;
+
+	/* For some cmds timeout is normal with sd/mmc cards */
+	if ((host->int_sum & SDXC_INTERRUPT_ERROR_BIT) ==
+		SDXC_RESP_TIMEOUT && (cmd->opcode == SD_IO_SEND_OP_COND ||
+				      cmd->opcode == SD_IO_RW_DIRECT))
+		return;
+
+	dev_dbg(mmc_dev(host->mmc),
+		"smc %d err, cmd %d,%s%s%s%s%s%s%s%s%s%s !!\n",
+		host->mmc->index, cmd->opcode,
+		data ? (data->flags & MMC_DATA_WRITE ? " WR" : " RD") : "",
+		host->int_sum & SDXC_RESP_ERROR     ? " RE"     : "",
+		host->int_sum & SDXC_RESP_CRC_ERROR  ? " RCE"    : "",
+		host->int_sum & SDXC_DATA_CRC_ERROR  ? " DCE"    : "",
+		host->int_sum & SDXC_RESP_TIMEOUT ? " RTO"    : "",
+		host->int_sum & SDXC_DATA_TIMEOUT ? " DTO"    : "",
+		host->int_sum & SDXC_FIFO_RUN_ERROR  ? " FE"     : "",
+		host->int_sum & SDXC_HARD_WARE_LOCKED ? " HL"     : "",
+		host->int_sum & SDXC_START_BIT_ERROR ? " SBE"    : "",
+		host->int_sum & SDXC_END_BIT_ERROR   ? " EBE"    : ""
+		);
+}
+
+/* Called in interrupt context! */
+static irqreturn_t sunxi_mmc_finalize_request(struct sunxi_mmc_host *host)
+{
+	struct mmc_request *mrq = host->mrq;
+	struct mmc_data *data = mrq->data;
+	u32 rval;
+
+	mmc_writel(host, REG_IMASK, host->sdio_imask);
+	mmc_writel(host, REG_IDIE, 0);
+
+	if (host->int_sum & SDXC_INTERRUPT_ERROR_BIT) {
+		sunxi_mmc_dump_errinfo(host);
+		mrq->cmd->error = -ETIMEDOUT;
+
+		if (data) {
+			data->error = -ETIMEDOUT;
+			host->manual_stop_mrq = mrq;
+		}
+
+		if (mrq->stop)
+			mrq->stop->error = -ETIMEDOUT;
+	} else {
+		if (mrq->cmd->flags & MMC_RSP_136) {
+			mrq->cmd->resp[0] = mmc_readl(host, REG_RESP3);
+			mrq->cmd->resp[1] = mmc_readl(host, REG_RESP2);
+			mrq->cmd->resp[2] = mmc_readl(host, REG_RESP1);
+			mrq->cmd->resp[3] = mmc_readl(host, REG_RESP0);
+		} else {
+			mrq->cmd->resp[0] = mmc_readl(host, REG_RESP0);
+		}
+
+		if (data)
+			data->bytes_xfered = data->blocks * data->blksz;
+	}
+
+	if (data) {
+		mmc_writel(host, REG_IDST, 0x337);
+		mmc_writel(host, REG_DMAC, 0);
+		rval = mmc_readl(host, REG_GCTRL);
+		rval |= SDXC_DMA_RESET;
+		mmc_writel(host, REG_GCTRL, rval);
+		rval &= ~SDXC_DMA_ENABLE_BIT;
+		mmc_writel(host, REG_GCTRL, rval);
+		rval |= SDXC_FIFO_RESET;
+		mmc_writel(host, REG_GCTRL, rval);
+		dma_unmap_sg(mmc_dev(host->mmc), data->sg, data->sg_len,
+			     mmc_get_dma_dir(data));
+	}
+
+	mmc_writel(host, REG_RINTR, 0xffff);
+
+	host->mrq = NULL;
+	host->int_sum = 0;
+	host->wait_dma = false;
+
+	return host->manual_stop_mrq ? IRQ_WAKE_THREAD : IRQ_HANDLED;
+}
+
+static irqreturn_t sunxi_mmc_irq(int irq, void *dev_id)
+{
+	struct sunxi_mmc_host *host = dev_id;
+	struct mmc_request *mrq;
+	u32 msk_int, idma_int;
+	bool finalize = false;
+	bool sdio_int = false;
+	irqreturn_t ret = IRQ_HANDLED;
+
+	spin_lock(&host->lock);
+
+	idma_int  = mmc_readl(host, REG_IDST);
+	msk_int   = mmc_readl(host, REG_MISTA);
+
+	dev_dbg(mmc_dev(host->mmc), "irq: rq %p mi %08x idi %08x\n",
+		host->mrq, msk_int, idma_int);
+
+	mrq = host->mrq;
+	if (mrq) {
+		if (idma_int & SDXC_IDMAC_RECEIVE_INTERRUPT)
+			host->wait_dma = false;
+
+		host->int_sum |= msk_int;
+
+		/* Wait for COMMAND_DONE on RESPONSE_TIMEOUT before finalize */
+		if ((host->int_sum & SDXC_RESP_TIMEOUT) &&
+				!(host->int_sum & SDXC_COMMAND_DONE))
+			mmc_writel(host, REG_IMASK,
+				   host->sdio_imask | SDXC_COMMAND_DONE);
+		/* Don't wait for dma on error */
+		else if (host->int_sum & SDXC_INTERRUPT_ERROR_BIT)
+			finalize = true;
+		else if ((host->int_sum & SDXC_INTERRUPT_DONE_BIT) &&
+				!host->wait_dma)
+			finalize = true;
+	}
+
+	if (msk_int & SDXC_SDIO_INTERRUPT)
+		sdio_int = true;
+
+	mmc_writel(host, REG_RINTR, msk_int);
+	mmc_writel(host, REG_IDST, idma_int);
+
+	if (finalize)
+		ret = sunxi_mmc_finalize_request(host);
+
+	spin_unlock(&host->lock);
+
+	if (finalize && ret == IRQ_HANDLED)
+		mmc_request_done(host->mmc, mrq);
+
+	if (sdio_int)
+		mmc_signal_sdio_irq(host->mmc);
+
+	return ret;
+}
+
+static irqreturn_t sunxi_mmc_handle_manual_stop(int irq, void *dev_id)
+{
+	struct sunxi_mmc_host *host = dev_id;
+	struct mmc_request *mrq;
+	unsigned long iflags;
+
+	spin_lock_irqsave(&host->lock, iflags);
+	mrq = host->manual_stop_mrq;
+	spin_unlock_irqrestore(&host->lock, iflags);
+
+	if (!mrq) {
+		dev_err(mmc_dev(host->mmc), "no request for manual stop\n");
+		return IRQ_HANDLED;
+	}
+
+	dev_err(mmc_dev(host->mmc), "data error, sending stop command\n");
+
+	/*
+	 * We will never have more than one outstanding request,
+	 * and we do not complete the request until after
+	 * we've cleared host->manual_stop_mrq so we do not need to
+	 * spin lock this function.
+	 * Additionally we have wait states within this function
+	 * so having it in a lock is a very bad idea.
+	 */
+	sunxi_mmc_send_manual_stop(host, mrq);
+
+	spin_lock_irqsave(&host->lock, iflags);
+	host->manual_stop_mrq = NULL;
+	spin_unlock_irqrestore(&host->lock, iflags);
+
+	mmc_request_done(host->mmc, mrq);
+
+	return IRQ_HANDLED;
+}
+
+static int sunxi_mmc_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en)
+{
+	unsigned long expire = jiffies + msecs_to_jiffies(750);
+	u32 rval;
+
+	dev_dbg(mmc_dev(host->mmc), "%sabling the clock\n",
+		oclk_en ? "en" : "dis");
+
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~(SDXC_CARD_CLOCK_ON | SDXC_LOW_POWER_ON | SDXC_MASK_DATA0);
+
+	if (oclk_en)
+		rval |= SDXC_CARD_CLOCK_ON;
+	if (host->cfg->mask_data0)
+		rval |= SDXC_MASK_DATA0;
+
+	mmc_writel(host, REG_CLKCR, rval);
+
+	rval = SDXC_START | SDXC_UPCLK_ONLY | SDXC_WAIT_PRE_OVER;
+	mmc_writel(host, REG_CMDR, rval);
+
+	do {
+		rval = mmc_readl(host, REG_CMDR);
+	} while (time_before(jiffies, expire) && (rval & SDXC_START));
+
+	/* clear irq status bits set by the command */
+	mmc_writel(host, REG_RINTR,
+		   mmc_readl(host, REG_RINTR) & ~SDXC_SDIO_INTERRUPT);
+
+	if (rval & SDXC_START) {
+		dev_err(mmc_dev(host->mmc), "fatal err update clk timeout\n");
+		return -EIO;
+	}
+
+	if (host->cfg->mask_data0) {
+		rval = mmc_readl(host, REG_CLKCR);
+		mmc_writel(host, REG_CLKCR, rval & ~SDXC_MASK_DATA0);
+	}
+
+	return 0;
+}
+
+static int sunxi_mmc_calibrate(struct sunxi_mmc_host *host, int reg_off)
+{
+	if (!host->cfg->can_calibrate)
+		return 0;
+
+	/*
+	 * FIXME:
+	 * This is not clear how the calibration is supposed to work
+	 * yet. The best rate have been obtained by simply setting the
+	 * delay to 0, as Allwinner does in its BSP.
+	 *
+	 * The only mode that doesn't have such a delay is HS400, that
+	 * is in itself a TODO.
+	 */
+	writel(SDXC_CAL_DL_SW_EN, host->reg_base + reg_off);
+
+	return 0;
+}
+
+static int sunxi_mmc_clk_set_phase(struct sunxi_mmc_host *host,
+				   struct mmc_ios *ios, u32 rate)
+{
+	int index;
+
+	/* clk controller delays not used under new timings mode */
+	if (host->use_new_timings)
+		return 0;
+
+	/* some old controllers don't support delays */
+	if (!host->cfg->clk_delays)
+		return 0;
+
+	/* determine delays */
+	if (rate <= 400000) {
+		index = SDXC_CLK_400K;
+	} else if (rate <= 25000000) {
+		index = SDXC_CLK_25M;
+	} else if (rate <= 52000000) {
+		if (ios->timing != MMC_TIMING_UHS_DDR50 &&
+		    ios->timing != MMC_TIMING_MMC_DDR52) {
+			index = SDXC_CLK_50M;
+		} else if (ios->bus_width == MMC_BUS_WIDTH_8) {
+			index = SDXC_CLK_50M_DDR_8BIT;
+		} else {
+			index = SDXC_CLK_50M_DDR;
+		}
+	} else {
+		dev_dbg(mmc_dev(host->mmc), "Invalid clock... returning\n");
+		return -EINVAL;
+	}
+
+	clk_set_phase(host->clk_sample, host->cfg->clk_delays[index].sample);
+	clk_set_phase(host->clk_output, host->cfg->clk_delays[index].output);
+
+	return 0;
+}
+
+static int sunxi_mmc_clk_set_rate(struct sunxi_mmc_host *host,
+				  struct mmc_ios *ios)
+{
+	struct mmc_host *mmc = host->mmc;
+	long rate;
+	u32 rval, clock = ios->clock, div = 1;
+	int ret;
+
+	ret = sunxi_mmc_oclk_onoff(host, 0);
+	if (ret)
+		return ret;
+
+	/* Our clock is gated now */
+	mmc->actual_clock = 0;
+
+	if (!ios->clock)
+		return 0;
+
+	/*
+	 * Under the old timing mode, 8 bit DDR requires the module
+	 * clock to be double the card clock. Under the new timing
+	 * mode, all DDR modes require a doubled module clock.
+	 *
+	 * We currently only support the standard MMC DDR52 mode.
+	 * This block should be updated once support for other DDR
+	 * modes is added.
+	 */
+	if (ios->timing == MMC_TIMING_MMC_DDR52 &&
+	    (host->use_new_timings ||
+	     ios->bus_width == MMC_BUS_WIDTH_8)) {
+		div = 2;
+		clock <<= 1;
+	}
+
+	if (host->use_new_timings && host->cfg->ccu_has_timings_switch) {
+		ret = sunxi_ccu_set_mmc_timing_mode(host->clk_mmc, true);
+		if (ret) {
+			dev_err(mmc_dev(mmc),
+				"error setting new timing mode\n");
+			return ret;
+		}
+	}
+
+	rate = clk_round_rate(host->clk_mmc, clock);
+	if (rate < 0) {
+		dev_err(mmc_dev(mmc), "error rounding clk to %d: %ld\n",
+			clock, rate);
+		return rate;
+	}
+	dev_dbg(mmc_dev(mmc), "setting clk to %d, rounded %ld\n",
+		clock, rate);
+
+	/* setting clock rate */
+	ret = clk_set_rate(host->clk_mmc, rate);
+	if (ret) {
+		dev_err(mmc_dev(mmc), "error setting clk to %ld: %d\n",
+			rate, ret);
+		return ret;
+	}
+
+	/* set internal divider */
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~0xff;
+	rval |= div - 1;
+	mmc_writel(host, REG_CLKCR, rval);
+
+	/* update card clock rate to account for internal divider */
+	rate /= div;
+
+	/*
+	 * Configure the controller to use the new timing mode if needed.
+	 * On controllers that only support the new timing mode, such as
+	 * the eMMC controller on the A64, this register does not exist,
+	 * and any writes to it are ignored.
+	 */
+	if (host->use_new_timings) {
+		/* Don't touch the delay bits */
+		rval = mmc_readl(host, REG_SD_NTSR);
+		rval |= SDXC_2X_TIMING_MODE;
+		mmc_writel(host, REG_SD_NTSR, rval);
+	}
+
+	/* sunxi_mmc_clk_set_phase expects the actual card clock rate */
+	ret = sunxi_mmc_clk_set_phase(host, ios, rate);
+	if (ret)
+		return ret;
+
+	ret = sunxi_mmc_calibrate(host, SDXC_REG_SAMP_DL_REG);
+	if (ret)
+		return ret;
+
+	/*
+	 * FIXME:
+	 *
+	 * In HS400 we'll also need to calibrate the data strobe
+	 * signal. This should only happen on the MMC2 controller (at
+	 * least on the A64).
+	 */
+
+	ret = sunxi_mmc_oclk_onoff(host, 1);
+	if (ret)
+		return ret;
+
+	/* And we just enabled our clock back */
+	mmc->actual_clock = rate;
+
+	return 0;
+}
+
+static void sunxi_mmc_set_bus_width(struct sunxi_mmc_host *host,
+				   unsigned char width)
+{
+	switch (width) {
+	case MMC_BUS_WIDTH_1:
+		mmc_writel(host, REG_WIDTH, SDXC_WIDTH1);
+		break;
+	case MMC_BUS_WIDTH_4:
+		mmc_writel(host, REG_WIDTH, SDXC_WIDTH4);
+		break;
+	case MMC_BUS_WIDTH_8:
+		mmc_writel(host, REG_WIDTH, SDXC_WIDTH8);
+		break;
+	}
+}
+
+static void sunxi_mmc_set_clk(struct sunxi_mmc_host *host, struct mmc_ios *ios)
+{
+	u32 rval;
+
+	/* set ddr mode */
+	rval = mmc_readl(host, REG_GCTRL);
+	if (ios->timing == MMC_TIMING_UHS_DDR50 ||
+	    ios->timing == MMC_TIMING_MMC_DDR52)
+		rval |= SDXC_DDR_MODE;
+	else
+		rval &= ~SDXC_DDR_MODE;
+	mmc_writel(host, REG_GCTRL, rval);
+
+	host->ferror = sunxi_mmc_clk_set_rate(host, ios);
+	/* Android code had a usleep_range(50000, 55000); here */
+}
+
+static void sunxi_mmc_card_power(struct sunxi_mmc_host *host,
+				 struct mmc_ios *ios)
+{
+	struct mmc_host *mmc = host->mmc;
+
+	switch (ios->power_mode) {
+	case MMC_POWER_UP:
+		dev_dbg(mmc_dev(mmc), "Powering card up\n");
+
+		if (!IS_ERR(mmc->supply.vmmc)) {
+			host->ferror = mmc_regulator_set_ocr(mmc,
+							     mmc->supply.vmmc,
+							     ios->vdd);
+			if (host->ferror)
+				return;
+		}
+
+		if (!IS_ERR(mmc->supply.vqmmc)) {
+			host->ferror = regulator_enable(mmc->supply.vqmmc);
+			if (host->ferror) {
+				dev_err(mmc_dev(mmc),
+					"failed to enable vqmmc\n");
+				return;
+			}
+			host->vqmmc_enabled = true;
+		}
+		break;
+
+	case MMC_POWER_OFF:
+		dev_dbg(mmc_dev(mmc), "Powering card off\n");
+
+		if (!IS_ERR(mmc->supply.vmmc))
+			mmc_regulator_set_ocr(mmc, mmc->supply.vmmc, 0);
+
+		if (!IS_ERR(mmc->supply.vqmmc) && host->vqmmc_enabled)
+			regulator_disable(mmc->supply.vqmmc);
+
+		host->vqmmc_enabled = false;
+		break;
+
+	default:
+		dev_dbg(mmc_dev(mmc), "Ignoring unknown card power state\n");
+		break;
+	}
+}
+
+static void sunxi_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	sunxi_mmc_card_power(host, ios);
+	sunxi_mmc_set_bus_width(host, ios->bus_width);
+	sunxi_mmc_set_clk(host, ios);
+}
+
+static int sunxi_mmc_volt_switch(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	/* vqmmc regulator is available */
+	if (!IS_ERR(mmc->supply.vqmmc))
+		return mmc_regulator_set_vqmmc(mmc, ios);
+
+	/* no vqmmc regulator, assume fixed regulator at 3/3.3V */
+	if (mmc->ios.signal_voltage == MMC_SIGNAL_VOLTAGE_330)
+		return 0;
+
+	return -EINVAL;
+}
+
+static void sunxi_mmc_enable_sdio_irq(struct mmc_host *mmc, int enable)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	unsigned long flags;
+	u32 imask;
+
+	if (enable)
+		pm_runtime_get_noresume(host->dev);
+
+	spin_lock_irqsave(&host->lock, flags);
+
+	imask = mmc_readl(host, REG_IMASK);
+	if (enable) {
+		host->sdio_imask = SDXC_SDIO_INTERRUPT;
+		imask |= SDXC_SDIO_INTERRUPT;
+	} else {
+		host->sdio_imask = 0;
+		imask &= ~SDXC_SDIO_INTERRUPT;
+	}
+	mmc_writel(host, REG_IMASK, imask);
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	if (!enable)
+		pm_runtime_put_noidle(host->mmc->parent);
+}
+
+static void sunxi_mmc_hw_reset(struct mmc_host *mmc)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	mmc_writel(host, REG_HWRST, 0);
+	udelay(10);
+	mmc_writel(host, REG_HWRST, 1);
+	udelay(300);
+}
+
+static void sunxi_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	struct mmc_command *cmd = mrq->cmd;
+	struct mmc_data *data = mrq->data;
+	unsigned long iflags;
+	u32 imask = SDXC_INTERRUPT_ERROR_BIT;
+	u32 cmd_val = SDXC_START | (cmd->opcode & 0x3f);
+	bool wait_dma = host->wait_dma;
+	int ret;
+
+	/* Check for set_ios errors (should never happen) */
+	if (host->ferror) {
+		mrq->cmd->error = host->ferror;
+		mmc_request_done(mmc, mrq);
+		return;
+	}
+
+	if (data) {
+		ret = sunxi_mmc_map_dma(host, data);
+		if (ret < 0) {
+			dev_err(mmc_dev(mmc), "map DMA failed\n");
+			cmd->error = ret;
+			data->error = ret;
+			mmc_request_done(mmc, mrq);
+			return;
+		}
+	}
+
+	if (cmd->opcode == MMC_GO_IDLE_STATE) {
+		cmd_val |= SDXC_SEND_INIT_SEQUENCE;
+		imask |= SDXC_COMMAND_DONE;
+	}
+
+	if (cmd->flags & MMC_RSP_PRESENT) {
+		cmd_val |= SDXC_RESP_EXPIRE;
+		if (cmd->flags & MMC_RSP_136)
+			cmd_val |= SDXC_LONG_RESPONSE;
+		if (cmd->flags & MMC_RSP_CRC)
+			cmd_val |= SDXC_CHECK_RESPONSE_CRC;
+
+		if ((cmd->flags & MMC_CMD_MASK) == MMC_CMD_ADTC) {
+			cmd_val |= SDXC_DATA_EXPIRE | SDXC_WAIT_PRE_OVER;
+
+			if (cmd->data->stop) {
+				imask |= SDXC_AUTO_COMMAND_DONE;
+				cmd_val |= SDXC_SEND_AUTO_STOP;
+			} else {
+				imask |= SDXC_DATA_OVER;
+			}
+
+			if (cmd->data->flags & MMC_DATA_WRITE)
+				cmd_val |= SDXC_WRITE;
+			else
+				wait_dma = true;
+		} else {
+			imask |= SDXC_COMMAND_DONE;
+		}
+	} else {
+		imask |= SDXC_COMMAND_DONE;
+	}
+
+	dev_dbg(mmc_dev(mmc), "cmd %d(%08x) arg %x ie 0x%08x len %d\n",
+		cmd_val & 0x3f, cmd_val, cmd->arg, imask,
+		mrq->data ? mrq->data->blksz * mrq->data->blocks : 0);
+
+	spin_lock_irqsave(&host->lock, iflags);
+
+	if (host->mrq || host->manual_stop_mrq) {
+		spin_unlock_irqrestore(&host->lock, iflags);
+
+		if (data)
+			dma_unmap_sg(mmc_dev(mmc), data->sg, data->sg_len,
+				     mmc_get_dma_dir(data));
+
+		dev_err(mmc_dev(mmc), "request already pending\n");
+		mrq->cmd->error = -EBUSY;
+		mmc_request_done(mmc, mrq);
+		return;
+	}
+
+	if (data) {
+		mmc_writel(host, REG_BLKSZ, data->blksz);
+		mmc_writel(host, REG_BCNTR, data->blksz * data->blocks);
+		sunxi_mmc_start_dma(host, data);
+	}
+
+	host->mrq = mrq;
+	host->wait_dma = wait_dma;
+	mmc_writel(host, REG_IMASK, host->sdio_imask | imask);
+	mmc_writel(host, REG_CARG, cmd->arg);
+	mmc_writel(host, REG_CMDR, cmd_val);
+
+	spin_unlock_irqrestore(&host->lock, iflags);
+}
+
+static int sunxi_mmc_card_busy(struct mmc_host *mmc)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	return !!(mmc_readl(host, REG_STAS) & SDXC_CARD_DATA_BUSY);
+}
+
+static const struct mmc_host_ops sunxi_mmc_ops = {
+	.request	 = sunxi_mmc_request,
+	.set_ios	 = sunxi_mmc_set_ios,
+	.get_ro		 = mmc_gpio_get_ro,
+	.get_cd		 = mmc_gpio_get_cd,
+	.enable_sdio_irq = sunxi_mmc_enable_sdio_irq,
+	.start_signal_voltage_switch = sunxi_mmc_volt_switch,
+	.hw_reset	 = sunxi_mmc_hw_reset,
+	.card_busy	 = sunxi_mmc_card_busy,
+};
+
+static const struct sunxi_mmc_clk_delay sunxi_mmc_clk_delays[] = {
+	[SDXC_CLK_400K]		= { .output = 180, .sample = 180 },
+	[SDXC_CLK_25M]		= { .output = 180, .sample =  75 },
+	[SDXC_CLK_50M]		= { .output =  90, .sample = 120 },
+	[SDXC_CLK_50M_DDR]	= { .output =  60, .sample = 120 },
+	/* Value from A83T "new timing mode". Works but might not be right. */
+	[SDXC_CLK_50M_DDR_8BIT]	= { .output =  90, .sample = 180 },
+};
+
+static const struct sunxi_mmc_clk_delay sun9i_mmc_clk_delays[] = {
+	[SDXC_CLK_400K]		= { .output = 180, .sample = 180 },
+	[SDXC_CLK_25M]		= { .output = 180, .sample =  75 },
+	[SDXC_CLK_50M]		= { .output = 150, .sample = 120 },
+	[SDXC_CLK_50M_DDR]	= { .output =  54, .sample =  36 },
+	[SDXC_CLK_50M_DDR_8BIT]	= { .output =  72, .sample =  72 },
+};
+
+static const struct sunxi_mmc_cfg sun4i_a10_cfg = {
+	.idma_des_size_bits = 13,
+	.clk_delays = NULL,
+	.can_calibrate = false,
+};
+
+static const struct sunxi_mmc_cfg sun5i_a13_cfg = {
+	.idma_des_size_bits = 16,
+	.clk_delays = NULL,
+	.can_calibrate = false,
+};
+
+static const struct sunxi_mmc_cfg sun7i_a20_cfg = {
+	.idma_des_size_bits = 16,
+	.clk_delays = sunxi_mmc_clk_delays,
+	.can_calibrate = false,
+};
+
+static const struct sunxi_mmc_cfg sun8i_a83t_emmc_cfg = {
+	.idma_des_size_bits = 16,
+	.clk_delays = sunxi_mmc_clk_delays,
+	.can_calibrate = false,
+	.ccu_has_timings_switch = true,
+};
+
+static const struct sunxi_mmc_cfg sun9i_a80_cfg = {
+	.idma_des_size_bits = 16,
+	.clk_delays = sun9i_mmc_clk_delays,
+	.can_calibrate = false,
+};
+
+static const struct sunxi_mmc_cfg sun50i_a64_cfg = {
+	.idma_des_size_bits = 16,
+	.clk_delays = NULL,
+	.can_calibrate = true,
+	.mask_data0 = true,
+	.needs_new_timings = true,
+};
+
+static const struct sunxi_mmc_cfg sun50i_a64_emmc_cfg = {
+	.idma_des_size_bits = 13,
+	.clk_delays = NULL,
+	.can_calibrate = true,
+	.needs_new_timings = true,
+};
+
+static const struct of_device_id sunxi_mmc_of_match[] = {
+	{ .compatible = "allwinner,sun4i-a10-mmc", .data = &sun4i_a10_cfg },
+	{ .compatible = "allwinner,sun5i-a13-mmc", .data = &sun5i_a13_cfg },
+	{ .compatible = "allwinner,sun7i-a20-mmc", .data = &sun7i_a20_cfg },
+	{ .compatible = "allwinner,sun8i-a83t-emmc", .data = &sun8i_a83t_emmc_cfg },
+	{ .compatible = "allwinner,sun9i-a80-mmc", .data = &sun9i_a80_cfg },
+	{ .compatible = "allwinner,sun50i-a64-mmc", .data = &sun50i_a64_cfg },
+	{ .compatible = "allwinner,sun50i-a64-emmc", .data = &sun50i_a64_emmc_cfg },
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, sunxi_mmc_of_match);
+
+static int sunxi_mmc_enable(struct sunxi_mmc_host *host)
+{
+	int ret;
+
+	if (!IS_ERR(host->reset)) {
+		ret = reset_control_reset(host->reset);
+		if (ret) {
+			dev_err(host->dev, "Couldn't reset the MMC controller (%d)\n",
+				ret);
+			return ret;
+		}
+	}
+
+	ret = clk_prepare_enable(host->clk_ahb);
+	if (ret) {
+		dev_err(host->dev, "Couldn't enable the bus clocks (%d)\n", ret);
+		goto error_assert_reset;
+	}
+
+	ret = clk_prepare_enable(host->clk_mmc);
+	if (ret) {
+		dev_err(host->dev, "Enable mmc clk err %d\n", ret);
+		goto error_disable_clk_ahb;
+	}
+
+	ret = clk_prepare_enable(host->clk_output);
+	if (ret) {
+		dev_err(host->dev, "Enable output clk err %d\n", ret);
+		goto error_disable_clk_mmc;
+	}
+
+	ret = clk_prepare_enable(host->clk_sample);
+	if (ret) {
+		dev_err(host->dev, "Enable sample clk err %d\n", ret);
+		goto error_disable_clk_output;
+	}
+
+	/*
+	 * Sometimes the controller asserts the irq on boot for some reason,
+	 * make sure the controller is in a sane state before enabling irqs.
+	 */
+	ret = sunxi_mmc_reset_host(host);
+	if (ret)
+		goto error_disable_clk_sample;
+
+	return 0;
+
+error_disable_clk_sample:
+	clk_disable_unprepare(host->clk_sample);
+error_disable_clk_output:
+	clk_disable_unprepare(host->clk_output);
+error_disable_clk_mmc:
+	clk_disable_unprepare(host->clk_mmc);
+error_disable_clk_ahb:
+	clk_disable_unprepare(host->clk_ahb);
+error_assert_reset:
+	if (!IS_ERR(host->reset))
+		reset_control_assert(host->reset);
+	return ret;
+}
+
+static void sunxi_mmc_disable(struct sunxi_mmc_host *host)
+{
+	sunxi_mmc_reset_host(host);
+
+	clk_disable_unprepare(host->clk_sample);
+	clk_disable_unprepare(host->clk_output);
+	clk_disable_unprepare(host->clk_mmc);
+	clk_disable_unprepare(host->clk_ahb);
+
+	if (!IS_ERR(host->reset))
+		reset_control_assert(host->reset);
+}
+
+static int sunxi_mmc_resource_request(struct sunxi_mmc_host *host,
+				      struct platform_device *pdev)
+{
+	int ret;
+
+	host->cfg = of_device_get_match_data(&pdev->dev);
+	if (!host->cfg)
+		return -EINVAL;
+
+	ret = mmc_regulator_get_supply(host->mmc);
+	if (ret)
+		return ret;
+
+	host->reg_base = devm_ioremap_resource(&pdev->dev,
+			      platform_get_resource(pdev, IORESOURCE_MEM, 0));
+	if (IS_ERR(host->reg_base))
+		return PTR_ERR(host->reg_base);
+
+	host->clk_ahb = devm_clk_get(&pdev->dev, "ahb");
+	if (IS_ERR(host->clk_ahb)) {
+		dev_err(&pdev->dev, "Could not get ahb clock\n");
+		return PTR_ERR(host->clk_ahb);
+	}
+
+	host->clk_mmc = devm_clk_get(&pdev->dev, "mmc");
+	if (IS_ERR(host->clk_mmc)) {
+		dev_err(&pdev->dev, "Could not get mmc clock\n");
+		return PTR_ERR(host->clk_mmc);
+	}
+
+	if (host->cfg->clk_delays) {
+		host->clk_output = devm_clk_get(&pdev->dev, "output");
+		if (IS_ERR(host->clk_output)) {
+			dev_err(&pdev->dev, "Could not get output clock\n");
+			return PTR_ERR(host->clk_output);
+		}
+
+		host->clk_sample = devm_clk_get(&pdev->dev, "sample");
+		if (IS_ERR(host->clk_sample)) {
+			dev_err(&pdev->dev, "Could not get sample clock\n");
+			return PTR_ERR(host->clk_sample);
+		}
+	}
+
+	host->reset = devm_reset_control_get_optional_exclusive(&pdev->dev,
+								"ahb");
+	if (PTR_ERR(host->reset) == -EPROBE_DEFER)
+		return PTR_ERR(host->reset);
+
+	ret = sunxi_mmc_enable(host);
+	if (ret)
+		return ret;
+
+	host->irq = platform_get_irq(pdev, 0);
+	if (host->irq <= 0) {
+		ret = -EINVAL;
+		goto error_disable_mmc;
+	}
+
+	return devm_request_threaded_irq(&pdev->dev, host->irq, sunxi_mmc_irq,
+			sunxi_mmc_handle_manual_stop, 0, "sunxi-mmc", host);
+
+error_disable_mmc:
+	sunxi_mmc_disable(host);
+	return ret;
+}
+
+static int sunxi_mmc_probe(struct platform_device *pdev)
+{
+	struct sunxi_mmc_host *host;
+	struct mmc_host *mmc;
+	int ret;
+
+	mmc = mmc_alloc_host(sizeof(struct sunxi_mmc_host), &pdev->dev);
+	if (!mmc) {
+		dev_err(&pdev->dev, "mmc alloc host failed\n");
+		return -ENOMEM;
+	}
+	platform_set_drvdata(pdev, mmc);
+
+	host = mmc_priv(mmc);
+	host->dev = &pdev->dev;
+	host->mmc = mmc;
+	spin_lock_init(&host->lock);
+
+	ret = sunxi_mmc_resource_request(host, pdev);
+	if (ret)
+		goto error_free_host;
+
+	host->sg_cpu = dma_alloc_coherent(&pdev->dev, PAGE_SIZE,
+					  &host->sg_dma, GFP_KERNEL);
+	if (!host->sg_cpu) {
+		dev_err(&pdev->dev, "Failed to allocate DMA descriptor mem\n");
+		ret = -ENOMEM;
+		goto error_free_host;
+	}
+
+	if (host->cfg->ccu_has_timings_switch) {
+		/*
+		 * Supports both old and new timing modes.
+		 * Try setting the clk to new timing mode.
+		 */
+		sunxi_ccu_set_mmc_timing_mode(host->clk_mmc, true);
+
+		/* And check the result */
+		ret = sunxi_ccu_get_mmc_timing_mode(host->clk_mmc);
+		if (ret < 0) {
+			/*
+			 * For whatever reason we were not able to get
+			 * the current active mode. Default to old mode.
+			 */
+			dev_warn(&pdev->dev, "MMC clk timing mode unknown\n");
+			host->use_new_timings = false;
+		} else {
+			host->use_new_timings = !!ret;
+		}
+	} else if (host->cfg->needs_new_timings) {
+		/* Supports new timing mode only */
+		host->use_new_timings = true;
+	}
+
+	mmc->ops		= &sunxi_mmc_ops;
+	mmc->max_blk_count	= 8192;
+	mmc->max_blk_size	= 4096;
+	mmc->max_segs		= PAGE_SIZE / sizeof(struct sunxi_idma_des);
+	mmc->max_seg_size	= (1 << host->cfg->idma_des_size_bits);
+	mmc->max_req_size	= mmc->max_seg_size * mmc->max_segs;
+	/* 400kHz ~ 52MHz */
+	mmc->f_min		=   400000;
+	mmc->f_max		= 52000000;
+	mmc->caps	       |= MMC_CAP_MMC_HIGHSPEED | MMC_CAP_SD_HIGHSPEED |
+				  MMC_CAP_ERASE | MMC_CAP_SDIO_IRQ;
+
+	/*
+	 * Some H5 devices do not have signal traces precise enough to
+	 * use HS DDR mode for their eMMC chips.
+	 *
+	 * We still enable HS DDR modes for all the other controller
+	 * variants that support them.
+	 */
+	if ((host->cfg->clk_delays || host->use_new_timings) &&
+	    !of_device_is_compatible(pdev->dev.of_node,
+				     "allwinner,sun50i-h5-emmc"))
+		mmc->caps      |= MMC_CAP_1_8V_DDR | MMC_CAP_3_3V_DDR;
+
+	ret = mmc_of_parse(mmc);
+	if (ret)
+		goto error_free_dma;
+
+	/*
+	 * If we don't support delay chains in the SoC, we can't use any
+	 * of the higher speed modes. Mask them out in case the device
+	 * tree specifies the properties for them, which gets added to
+	 * the caps by mmc_of_parse() above.
+	 */
+	if (!(host->cfg->clk_delays || host->use_new_timings)) {
+		mmc->caps &= ~(MMC_CAP_3_3V_DDR | MMC_CAP_1_8V_DDR |
+			       MMC_CAP_1_2V_DDR | MMC_CAP_UHS);
+		mmc->caps2 &= ~MMC_CAP2_HS200;
+	}
+
+	/* TODO: This driver doesn't support HS400 mode yet */
+	mmc->caps2 &= ~MMC_CAP2_HS400;
+
+	ret = sunxi_mmc_init_host(host);
+	if (ret)
+		goto error_free_dma;
+
+	pm_runtime_set_active(&pdev->dev);
+	pm_runtime_set_autosuspend_delay(&pdev->dev, 50);
+	pm_runtime_use_autosuspend(&pdev->dev);
+	pm_runtime_enable(&pdev->dev);
+
+	ret = mmc_add_host(mmc);
+	if (ret)
+		goto error_free_dma;
+
+	dev_info(&pdev->dev, "initialized, max. request size: %u KB%s\n",
+		 mmc->max_req_size >> 10,
+		 host->use_new_timings ? ", uses new timings mode" : "");
+
+	return 0;
+
+error_free_dma:
+	dma_free_coherent(&pdev->dev, PAGE_SIZE, host->sg_cpu, host->sg_dma);
+error_free_host:
+	mmc_free_host(mmc);
+	return ret;
+}
+
+static int sunxi_mmc_remove(struct platform_device *pdev)
+{
+	struct mmc_host	*mmc = platform_get_drvdata(pdev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	mmc_remove_host(mmc);
+	pm_runtime_force_suspend(&pdev->dev);
+	disable_irq(host->irq);
+	sunxi_mmc_disable(host);
+	dma_free_coherent(&pdev->dev, PAGE_SIZE, host->sg_cpu, host->sg_dma);
+	mmc_free_host(mmc);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int sunxi_mmc_runtime_resume(struct device *dev)
+{
+	struct mmc_host	*mmc = dev_get_drvdata(dev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	int ret;
+
+	ret = sunxi_mmc_enable(host);
+	if (ret)
+		return ret;
+
+	sunxi_mmc_init_host(host);
+	sunxi_mmc_set_bus_width(host, mmc->ios.bus_width);
+	sunxi_mmc_set_clk(host, &mmc->ios);
+	enable_irq(host->irq);
+
+	return 0;
+}
+
+static int sunxi_mmc_runtime_suspend(struct device *dev)
+{
+	struct mmc_host	*mmc = dev_get_drvdata(dev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	/*
+	 * When clocks are off, it's possible receiving
+	 * fake interrupts, which will stall the system.
+	 * Disabling the irq  will prevent this.
+	 */
+	disable_irq(host->irq);
+	sunxi_mmc_reset_host(host);
+	sunxi_mmc_disable(host);
+
+	return 0;
+}
+#endif
+
+static const struct dev_pm_ops sunxi_mmc_pm_ops = {
+	SET_RUNTIME_PM_OPS(sunxi_mmc_runtime_suspend,
+			   sunxi_mmc_runtime_resume,
+			   NULL)
+};
+
+static struct platform_driver sunxi_mmc_driver = {
+	.driver = {
+		.name	= "sunxi-mmc",
+		.of_match_table = of_match_ptr(sunxi_mmc_of_match),
+		.pm = &sunxi_mmc_pm_ops,
+	},
+	.probe		= sunxi_mmc_probe,
+	.remove		= sunxi_mmc_remove,
+};
+module_platform_driver(sunxi_mmc_driver);
+
+MODULE_DESCRIPTION("Allwinner's SD/MMC Card Controller Driver");
+MODULE_LICENSE("GPL v2");
+MODULE_AUTHOR("David Lanzendörfer <david.lanzendoerfer@o2s.ch>");
+MODULE_ALIAS("platform:sunxi-mmc");
diff --git a/drivers/mmc/host/sunxi-mmc-debug.c b/drivers/mmc/host/sunxi-mmc-debug.c
new file mode 100644
index 000000000..3fc38d1f7
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-debug.c
@@ -0,0 +1,800 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+
+#include <linux/clk.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+#include <linux/stat.h>
+
+#include <linux/mmc/core.h>
+#include <linux/mmc/host.h>
+#include "sunxi-mmc.h"
+#include "sunxi-mmc-debug.h"
+#include "sunxi-mmc-export.h"
+#include "sunxi-mmc-sun50iw1p1-2.h"
+#include "sunxi-mmc-panic.h"
+
+
+#define GPIO_BASE_ADDR	0x1c20800
+/*nc platform no use these value*/
+#define CCMU_BASE_ADDR_BEFORE_V2P1H	0x1c20000
+
+#define SUNXI_MMC_MAX_HOST_PRT_ADDR  0x150
+#define SUNXI_MMC_MAX_GPIO_PRT_ADDR	0x120
+#define SUNXI_GPIOIC_PRT_EADDR	0x380
+#define SUNXI_GPIOIC_PRT_SADDR	0x200
+
+/*mmc bus clock gating register*/
+#define SUNXI_BCLKG_SADDR  0x60
+#define SUNXI_BCLKG_EADDR	0x80
+
+/*mmc moudule clock register*/
+#define SUNXI_CLK_PRT_SADDR  0x80
+#define SUNXI_CLK_PRT_EADDR	0xa0
+
+/*mmc bus soft reset register*/
+#define SUNXI_BSRES_SADDR  0x2C0
+#define SUNXI_BSRES_EADDR	0x2DC
+
+
+/*NC mmc bus gating,reset,moudule clouck register*/
+#define SUNXI_NCCM_EADDR	0x850
+#define SUNXI_NCCM_SADDR	0x830
+
+/*NC mmc PLL PERI register*/
+#define SUNXI_PP_NCM_EADDR	0x2C
+#define SUNXI_PP_NCM_SADDR	0x20
+
+#define SUNXI_DEG_MAX_MAP_REG	0x900
+
+static struct device_attribute dump_register[3];
+
+void sunxi_mmc_dumphex32(struct sunxi_mmc_host *host, char *name, char *base,
+			 int len)
+{
+	u32 i;
+
+	pr_cont("dump %s registers:", name);
+	for (i = 0; i < len; i += 4) {
+		if (!(i&0xf))
+			pr_cont("\n0x%px : ", base + i);
+		pr_cont("0x%08x ", __raw_readl(base+i));
+	}
+	pr_cont("\n");
+}
+
+void sunxi_mmc_dump_des(struct sunxi_mmc_host *host, char *base, int len)
+{
+	u32 i;
+
+	pr_cont("dump des mem\n");
+	for (i = 0; i < len; i += 4) {
+		if (!(i&0xf))
+			pr_cont("\n0x%px : ", base + i);
+		pr_cont("0x%08x ", *(u32 *)(base+i));
+	}
+	pr_cont("\n");
+}
+
+static unsigned int sunxi_mmc_get_rate(uint64_t bytes, uint64_t time_us)
+{
+	uint64_t ns;
+
+	ns = time_us * 1000;
+	bytes *= 1000000000;
+
+	while (ns > UINT_MAX) {
+		bytes >>= 1;
+		ns >>= 1;
+	}
+
+	if (!ns)
+		return 0;
+
+	do_div(bytes, (uint32_t)ns);
+
+	return bytes;
+}
+
+static void sunxi_mmc_filter_rate(struct sunxi_mmc_host *host, struct mmc_data *data, int64_t bytes, uint64_t time_us)
+{
+	unsigned int rate = 0;
+
+	if (!(host->filter_sector)
+		|| !(host->filter_speed))
+		return;
+
+	if ((data->blocks) >= (host->filter_sector)) {
+		rate = sunxi_mmc_get_rate(bytes, time_us);
+		if (rate < (host->filter_speed))
+			printk("c=%u,a=0x%8x,""bs=%5u,""t=%9lluus,""sp=%7uKB/s\n",
+			data->mrq->cmd->opcode, data->mrq->cmd->arg,
+			data->blocks, time_us, rate/1024);
+	}
+}
+
+
+static ssize_t maual_insert_show(struct device *dev,
+				 struct device_attribute *attr, char *buf)
+{
+	int ret;
+
+	ret =
+	    snprintf(buf, PAGE_SIZE,
+		     "Usage: \"echo 1 > insert\" to scan card\n");
+	return ret;
+}
+
+static ssize_t maual_insert_store(struct device *dev,
+				  struct device_attribute *attr,
+				  const char *buf, size_t count)
+{
+	int ret;
+
+	unsigned long insert = 0;
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+
+	ret = kstrtoul(buf, 0, &insert);
+	if (ret) {
+		ret = -EINVAL;
+		return ret;
+	}
+
+	dev_info(dev, "insert %ld\n", insert);
+	if (insert)
+		mmc_detect_change(mmc, 0);
+	else
+		dev_info(dev, "no detect change\n");
+
+	ret = count;
+	return ret;
+}
+
+int sunxi_mmc_res_start_addr(const char * const res_str,
+		resource_size_t *res_addr)
+{
+	struct device_node *np = NULL;
+	int ret = 0;
+	struct resource res;
+
+	if (res_str == NULL || res_addr == NULL) {
+		pr_err("input arg is error\n");
+		return -EINVAL;
+	}
+
+	np = of_find_node_by_type(NULL, res_str);
+	if (IS_ERR(np)) {
+		pr_err("Can not find device type\n");
+		return -EINVAL;
+	}
+
+	ret = of_address_to_resource(np, 0, &res);
+	if (ret || !res.start) {
+		pr_err("Can not find resouce\n");
+		return -EINVAL;
+	}
+	*res_addr = res.start;
+
+	return 0;
+}
+
+void sunxi_dump_reg(struct mmc_host *mmc)
+{
+	int i = 0;
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	int ret = 0;
+	void __iomem *gpio_ptr =  NULL;
+	void __iomem *ccmu_ptr =  NULL;
+	resource_size_t res_saddr_ccmu;
+	resource_size_t res_saddr_gpio;
+
+
+	pr_cont("Dump %s (p%x) regs :\n", mmc_hostname(mmc), host->phy_index);
+	for (i = 0; i < SUNXI_MMC_MAX_HOST_PRT_ADDR; i += 4) {
+		if (!(i&0xf))
+			pr_cont("\n0x%px : ", (host->reg_base + i));
+		pr_cont("%08x ", readl(host->reg_base + i));
+	}
+	pr_cont("\n");
+
+	ret = sunxi_mmc_res_start_addr("pio", &res_saddr_gpio);
+	if (ret < 0)
+		goto map_ccmu;
+	gpio_ptr = ioremap(res_saddr_gpio, SUNXI_DEG_MAX_MAP_REG);
+	if (gpio_ptr == NULL) {
+		pr_err("Can not map gpio resource\n");
+		goto map_ccmu;
+	}
+
+	pr_cont("Dump gpio regs:\n");
+	for (i = 0; i < SUNXI_MMC_MAX_GPIO_PRT_ADDR; i += 4) {
+		if (!(i&0xf))
+			pr_cont("\n0x%px : ", (gpio_ptr + i));
+		pr_cont("%08x ", readl(gpio_ptr + i));
+	}
+	pr_cont("\n");
+
+	pr_cont("Dump gpio irqc regs:\n");
+	for (i = SUNXI_GPIOIC_PRT_SADDR; i < SUNXI_GPIOIC_PRT_EADDR; i += 4) {
+		if (!(i&0xf))
+			pr_cont("\n0x%px : ", (gpio_ptr + i));
+		pr_cont("%08x ", readl(gpio_ptr + i));
+	}
+	pr_cont("\n");
+
+	iounmap(gpio_ptr);
+
+map_ccmu:
+	ret = sunxi_mmc_res_start_addr("clocks", &res_saddr_ccmu);
+	if (ret < 0)
+		return;
+	ccmu_ptr = ioremap(res_saddr_ccmu, SUNXI_DEG_MAX_MAP_REG);
+	if (ccmu_ptr == NULL) {
+		pr_err("Can not map ccmu resource\n");
+		return;
+	}
+
+	if (res_saddr_ccmu == CCMU_BASE_ADDR_BEFORE_V2P1H) {
+		pr_cont("Dump ccmu regs:gating\n");
+		for (i = SUNXI_BCLKG_SADDR; i < SUNXI_BCLKG_EADDR; i += 4) {
+			if (!(i&0xf))
+				pr_cont("\n0x%px : ", (ccmu_ptr + i));
+			pr_cont("%08x ", readl(ccmu_ptr + i));
+		}
+		pr_cont("\n");
+
+		pr_cont("Dump ccmu regs:module clk\n");
+		for (i = SUNXI_CLK_PRT_SADDR; i < SUNXI_CLK_PRT_EADDR; i += 4) {
+			if (!(i&0xf))
+				pr_cont("\n0x%px : ", (ccmu_ptr + i));
+			pr_cont("%08x ", readl(ccmu_ptr + i));
+		}
+		pr_cont("\n");
+
+		pr_cont("Dump ccmu regs:reset\n");
+		for (i = SUNXI_BSRES_SADDR; i < SUNXI_BSRES_EADDR; i += 4) {
+			if (!(i&0xf))
+				pr_cont("\n0x%px : ", (ccmu_ptr + i));
+			pr_cont("%08x ", readl(ccmu_ptr + i));
+		}
+		pr_cont("\n");
+	} else {
+		pr_cont("Dump ccmu regs:pll,gating,reset,module clk\n");
+
+		for (i = SUNXI_PP_NCM_SADDR; i < SUNXI_PP_NCM_EADDR; i += 4) {
+			if (!(i&0xf))
+				pr_cont("\n0x%px : ", (ccmu_ptr + i));
+			pr_cont("%08x ", readl(ccmu_ptr + i));
+		}
+		pr_cont("\n");
+
+		for (i = SUNXI_NCCM_SADDR; i < SUNXI_NCCM_EADDR; i += 4) {
+			if (!(i&0xf))
+				pr_cont("\n0x%px : ", (ccmu_ptr + i));
+			pr_cont("%08x ", readl(ccmu_ptr + i));
+		}
+		pr_cont("\n");
+	}
+
+	iounmap(ccmu_ptr);
+
+}
+
+static ssize_t dump_host_reg_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	char *p = buf;
+	int i = 0;
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	p += sprintf(p, "Dump sdmmc regs:\n");
+	for (i = 0; i < SUNXI_MMC_MAX_HOST_PRT_ADDR; i += 4) {
+		if (!(i&0xf))
+			p += sprintf(p, "\n0x%lx : ", (size_t)(host->reg_base + i));
+		p += sprintf(p, "%08x ", readl(host->reg_base + i));
+	}
+	p += sprintf(p, "\n");
+
+	return p - buf;
+
+}
+
+static ssize_t dump_gpio_reg_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	char *p = buf;
+	int i = 0;
+	void __iomem *gpio_ptr =  NULL;
+	resource_size_t res_saddr_gpio;
+	int ret = 0;
+
+	ret = sunxi_mmc_res_start_addr("pio", &res_saddr_gpio);
+	if (ret < 0)
+		goto out;
+
+	gpio_ptr = ioremap(res_saddr_gpio, SUNXI_DEG_MAX_MAP_REG);
+	if (!gpio_ptr) {
+		pr_err("Can not map gpio resource\n");
+		goto out;
+	}
+
+	p += sprintf(p, "Dump gpio regs:\n");
+	for (i = 0; i < SUNXI_MMC_MAX_GPIO_PRT_ADDR; i += 4) {
+		if (!(i&0xf))
+			p += sprintf(p, "\n0x%lx : ", (size_t)(gpio_ptr + i));
+		p += sprintf(p, "%08x ", readl(gpio_ptr + i));
+	}
+	p += sprintf(p, "\n");
+
+	p += sprintf(p, "Dump gpio irqc regs:\n");
+	for (i = SUNXI_GPIOIC_PRT_SADDR; i < SUNXI_GPIOIC_PRT_EADDR; i += 4) {
+		if (!(i&0xf))
+			p += sprintf(p, "\n0x%lx : ", (size_t) (gpio_ptr + i));
+		p += sprintf(p, "%08x ", readl(gpio_ptr + i));
+	}
+	p += sprintf(p, "\n");
+
+	iounmap(gpio_ptr);
+out:
+	return p-buf;
+
+}
+
+static ssize_t dump_ccmu_reg_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	char *p = buf;
+	int i = 0;
+	void __iomem *ccmu_ptr =  NULL;
+	int ret = 0;
+	resource_size_t res_saddr_ccmu;
+
+	ret = sunxi_mmc_res_start_addr("clocks", &res_saddr_ccmu);
+	if (ret < 0)
+		goto out;
+
+	ccmu_ptr = ioremap(res_saddr_ccmu, SUNXI_DEG_MAX_MAP_REG);
+	if (!ccmu_ptr) {
+		pr_err("Can not map ccmu resource\n");
+		goto out;
+	}
+
+	p += sprintf(p, "Dump ccmu\n");
+	if (res_saddr_ccmu == CCMU_BASE_ADDR_BEFORE_V2P1H) {
+
+		p += sprintf(p, "Dump ccmu regs:gating\n");
+		for (i = SUNXI_BCLKG_SADDR; i < SUNXI_BCLKG_EADDR; i += 4) {
+			if (!(i&0xf))
+				p += sprintf(p, "\n0x%lx : ", (size_t)(ccmu_ptr + i));
+			p += sprintf(p, "%08x ", readl(ccmu_ptr + i));
+		}
+		p += sprintf(p, "\n");
+
+		p += sprintf(p, "Dump ccmu regs:module clk\n");
+		for (i = SUNXI_CLK_PRT_SADDR; i < SUNXI_CLK_PRT_EADDR; i += 4) {
+			if (!(i&0xf))
+				p += sprintf(p, "\n0x%lx : ", (size_t)(ccmu_ptr + i));
+			p += sprintf(p, "%08x ", readl(ccmu_ptr + i));
+		}
+		p += sprintf(p, "\n");
+
+		p += sprintf(p, "Dump ccmu regs:reset\n");
+		for (i = SUNXI_BSRES_SADDR; i < SUNXI_BSRES_EADDR; i += 4) {
+			if (!(i&0xf))
+				p += sprintf(p, "\n0x%lx : ", (size_t)(ccmu_ptr + i));
+			p += sprintf(p, "%08x ", readl(ccmu_ptr + i));
+		}
+		p += sprintf(p, "\n");
+
+	} else {
+		p += sprintf(p, "Dump ccmu regs:pll,gating,reset,module clk\n");
+
+		for (i = SUNXI_PP_NCM_SADDR; i < SUNXI_PP_NCM_EADDR; i += 4) {
+			if (!(i&0xf))
+				p += sprintf(p, "\n0x%lx : ", (size_t)(ccmu_ptr + i));
+			p += sprintf(p, "%08x ", readl(ccmu_ptr + i));
+		}
+		p += sprintf(p, "\n");
+
+		for (i = SUNXI_NCCM_SADDR; i < SUNXI_NCCM_EADDR; i += 4) {
+			if (!(i&0xf))
+				p += sprintf(p, "\n0x%lx : ", (size_t)(ccmu_ptr + i));
+			p += sprintf(p, "%08x ", readl(ccmu_ptr + i));
+		}
+		p += sprintf(p, "\n");
+	}
+	p += sprintf(p, "\n");
+
+	iounmap(ccmu_ptr);
+
+out:
+	return p-buf;
+
+}
+
+static ssize_t dump_clk_dly_show(struct device *dev,
+				 struct device_attribute *attr, char *buf)
+{
+	char *p = buf;
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	if (host->sunxi_mmc_dump_dly_table)
+		host->sunxi_mmc_dump_dly_table(host);
+	else
+		dev_warn(mmc_dev(mmc), "not found the dump dly table\n");
+
+	return p - buf;
+}
+
+int sunxi_mmc_uperf_stat(struct sunxi_mmc_host *host,
+	struct mmc_data *data,
+	struct mmc_request *mrq_busy,
+	bool bhalf)
+{
+	ktime_t diff;
+
+	if (!bhalf) {
+		if (host->perf_enable && data) {
+			diff = ktime_sub(ktime_get(), host->perf.start);
+			if (data->flags & MMC_DATA_READ) {
+				host->perf.rbytes += data->bytes_xfered;
+				host->perf.rtime =
+					ktime_add(host->perf.rtime, diff);
+			} else if (data->flags & MMC_DATA_WRITE) {
+				if (!mrq_busy) {
+					host->perf.wbytes +=
+						data->bytes_xfered;
+					host->perf.wtime =
+					ktime_add(host->perf.wtime, diff);
+					sunxi_mmc_filter_rate(host, data, data->bytes_xfered, ktime_to_us(diff));
+				}
+				host->perf.wbytestran += data->bytes_xfered;
+				host->perf.wtimetran =
+					ktime_add(host->perf.wtimetran, diff);
+			}
+		}
+	} else {
+		if (host->perf_enable
+			&& mrq_busy->data
+			&& (mrq_busy->data->flags & MMC_DATA_WRITE)) {
+			diff = ktime_sub(ktime_get(), host->perf.start);
+			host->perf.wbytes += mrq_busy->data->bytes_xfered;
+			host->perf.wtime = ktime_add(host->perf.wtime, diff);
+			sunxi_mmc_filter_rate(host, data, data->bytes_xfered, ktime_to_us(diff));
+		}
+	}
+	return 0;
+}
+EXPORT_SYMBOL_GPL(sunxi_mmc_uperf_stat);
+
+static ssize_t
+sunxi_mmc_show_perf(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host	*mmc = platform_get_drvdata(pdev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	int64_t rtime_drv, wtime_drv, wtime_drv_tran;
+	int64_t rbytes_drv, wbytes_drv, wbytes_drv_tran;
+
+
+	mmc_claim_host(mmc);
+
+	rbytes_drv = host->perf.rbytes;
+	wbytes_drv = host->perf.wbytes;
+	wbytes_drv_tran = host->perf.wbytestran;
+
+	rtime_drv = ktime_to_us(host->perf.rtime);
+	wtime_drv = ktime_to_us(host->perf.wtime);
+	wtime_drv_tran = ktime_to_us(host->perf.wtimetran);
+
+	mmc_release_host(mmc);
+
+	return snprintf(buf, PAGE_SIZE, "Write performance at host driver Level:"
+					"%lld bytes in %lld microseconds\n"
+					"Read performance at host driver Level:"
+					"%lld bytes in %lld microseconds\n"
+					"write performance at host driver Level(no wait busy):"
+					"%lld bytes in %lld microseconds\n",
+					wbytes_drv, wtime_drv,
+					rbytes_drv, rtime_drv,
+					wbytes_drv_tran, wtime_drv_tran);
+}
+
+static ssize_t
+sunxi_mmc_set_perf(struct device *dev, struct device_attribute *attr,
+		const char *buf, size_t count)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host	*mmc = platform_get_drvdata(pdev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	int64_t value;
+
+	sscanf(buf, "%lld", &value);
+	printk("set perf value %lld\n", value);
+
+	mmc_claim_host(mmc);
+	if (!value) {
+		memset(&host->perf, 0, sizeof(host->perf));
+		host->perf_enable = false;
+	} else {
+		host->perf_enable = true;
+	}
+	mmc_release_host(mmc);
+
+	return count;
+}
+
+extern void sunxi_mmc_set_ds_dl_raw(struct sunxi_mmc_host *host, int sunxi_ds_dl);
+extern void sunxi_mmc_set_samp_dl_raw(struct sunxi_mmc_host *host, int sunxi_samp_dl);
+
+int sunxi_mmc_bus_clk_en(struct sunxi_mmc_host *host, int enable);
+void sunxi_mmc_regs_save(struct sunxi_mmc_host *host);
+void sunxi_mmc_regs_restore(struct sunxi_mmc_host *host);
+
+static ssize_t
+sunxi_mmc_set_samp_dly_sys(struct device *dev, struct device_attribute *attr,
+				const char *buf, size_t count)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host	*mmc = platform_get_drvdata(pdev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	int64_t value;
+
+	sscanf(buf, "%lld", &value);
+	printk("set sample delay %lld\n", value);
+	mmc_claim_host(mmc);
+	sunxi_mmc_set_samp_dl_raw(host, value);
+	mmc_release_host(mmc);
+
+	return count;
+}
+
+static ssize_t
+sunxi_mmc_set_ds_dly_sys(struct device *dev, struct device_attribute *attr,
+				const char *buf, size_t count)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host	*mmc = platform_get_drvdata(pdev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	int64_t value;
+
+	sscanf(buf, "%lld", &value);
+	printk("set ds delay %lld\n", value);
+	mmc_claim_host(mmc);
+	sunxi_mmc_set_ds_dl_raw(host, value);
+	mmc_release_host(mmc);
+
+	return count;
+}
+
+static ssize_t
+sunxi_mmc_send_status(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host	*mmc = platform_get_drvdata(pdev);
+	u32 status = 0;
+
+	mmc_claim_host(mmc);
+	mmc_send_status(mmc->card, &status);
+	printk("mmc status %x\n", status);
+	mmc_release_host(mmc);
+
+	return (ssize_t)buf;
+}
+
+static ssize_t
+sunxi_mmc_show_filter_sector(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host	*mmc = platform_get_drvdata(pdev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	return snprintf(buf, PAGE_SIZE, "filter speed %d\n", host->filter_sector);
+}
+
+static ssize_t
+sunxi_mmc_set_filter_sector(struct device *dev, struct device_attribute *attr,
+		const char *buf, size_t count)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host	*mmc = platform_get_drvdata(pdev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	int64_t value;
+
+	sscanf(buf, "%lld", &value);
+	printk("get filter sector %lld\n", value);
+	host->filter_sector = value;
+
+	return count;
+}
+
+
+static ssize_t
+sunxi_mmc_show_filter_speed(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host	*mmc = platform_get_drvdata(pdev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	return snprintf(buf, PAGE_SIZE, "filter speed %d\n", host->filter_speed);
+}
+
+static ssize_t
+sunxi_mmc_set_filter_speed(struct device *dev, struct device_attribute *attr,
+		const char *buf, size_t count)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host	*mmc = platform_get_drvdata(pdev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	int64_t value;
+
+	sscanf(buf, "%lld", &value);
+	printk("get filter speed %lld\n", value);
+	host->filter_speed = value;
+
+	return count;
+}
+
+
+
+
+
+int mmc_create_sys_fs(struct sunxi_mmc_host *host, struct platform_device *pdev)
+{
+	int ret;
+
+	host->maual_insert.show = maual_insert_show;
+	host->maual_insert.store = maual_insert_store;
+	sysfs_attr_init(&(host->maual_insert.attr));
+	host->maual_insert.attr.name = "sunxi_insert";
+	host->maual_insert.attr.mode = S_IRUGO | S_IWUSR;
+	ret = device_create_file(&pdev->dev, &host->maual_insert);
+	if (ret)
+		return ret;
+
+	host->host_perf.show = sunxi_mmc_show_perf;
+	host->host_perf.store = sunxi_mmc_set_perf;
+	sysfs_attr_init(&(host->host_perf.attr));
+	host->host_perf.attr.mode = S_IRUGO | S_IWUSR;
+	host->host_perf.attr.name = "sunxi_host_perf";
+	ret = device_create_file(&pdev->dev, &host->host_perf);
+	if (ret)
+		return ret;
+
+	host->filter_sector_perf.show = sunxi_mmc_show_filter_sector;
+	host->filter_sector_perf.store = sunxi_mmc_set_filter_sector;
+	sysfs_attr_init(&(host->filter_sector_perf.attr));
+	host->filter_sector_perf.attr.name = "sunxi_host_filter_w_sector";
+	host->filter_sector_perf.attr.mode = S_IRUGO | S_IWUSR;
+	ret = device_create_file(&pdev->dev, &host->filter_sector_perf);
+	if (ret)
+		return ret;
+
+	host->filter_speed_perf.show = sunxi_mmc_show_filter_speed;;
+	host->filter_speed_perf.store = sunxi_mmc_set_filter_speed;;
+	sysfs_attr_init(&(host->filter_speed_perf.attr));
+	host->filter_speed_perf.attr.name = "sunxi_host_filter_w_speed";
+	host->filter_speed_perf.attr.mode = S_IRUGO | S_IWUSR;
+	ret = device_create_file(&pdev->dev, &host->filter_speed_perf);
+	if (ret)
+		return ret;
+
+
+	host->dump_register = dump_register;
+	host->dump_register[0].show = dump_host_reg_show;
+	sysfs_attr_init(&(host->dump_register[0].attr));
+	host->dump_register[0].attr.name = "sunxi_dump_host_register";
+	host->dump_register[0].attr.mode = S_IRUGO;
+	ret = device_create_file(&pdev->dev, &host->dump_register[0]);
+	if (ret)
+		return ret;
+
+	host->dump_register[1].show = dump_gpio_reg_show;
+	sysfs_attr_init(&(host->dump_register[1].attr));
+	host->dump_register[1].attr.name = "sunxi_dump_gpio_register";
+	host->dump_register[1].attr.mode = S_IRUGO;
+	ret = device_create_file(&pdev->dev, &host->dump_register[1]);
+	if (ret)
+		return ret;
+
+	host->dump_register[2].show = dump_ccmu_reg_show;
+	sysfs_attr_init(&(host->dump_register[2].attr));
+	host->dump_register[2].attr.name = "sunxi_dump_ccmu_register";
+	host->dump_register[2].attr.mode = S_IRUGO;
+	ret = device_create_file(&pdev->dev, &host->dump_register[2]);
+	if (ret)
+		return ret;
+
+	host->dump_clk_dly.show = dump_clk_dly_show;
+	sysfs_attr_init(&(host->dump_clk_dly.attr));
+	host->dump_clk_dly.attr.name = "sunxi_dump_clk_dly";
+	host->dump_clk_dly.attr.mode = S_IRUGO;
+	ret = device_create_file(&pdev->dev, &host->dump_clk_dly);
+	if (ret)
+		return ret;
+
+	host->host_sample_dly.show = NULL;
+	host->host_sample_dly.store = sunxi_mmc_set_samp_dly_sys;
+	sysfs_attr_init(&(host->host_sample_dly.attr));
+	host->host_sample_dly.attr.name = "sunxi_host_set_sample_dly";
+	host->host_sample_dly.attr.mode =  S_IWUSR;
+	ret = device_create_file(&pdev->dev, &host->host_sample_dly);
+	if (ret)
+		return ret;
+
+	host->host_ds_dly.show = NULL;
+	host->host_ds_dly.store = sunxi_mmc_set_ds_dly_sys;
+	sysfs_attr_init(&(host->host_ds_dly.attr));
+	host->host_ds_dly.attr.name = "sunxi_host_set_ds_dly";
+	host->host_ds_dly.attr.mode =  S_IWUSR;
+	ret = device_create_file(&pdev->dev, &host->host_ds_dly);
+	if (ret)
+		return ret;
+
+	host->host_send_status.show = sunxi_mmc_send_status;
+	host->host_send_status.store = NULL;
+	sysfs_attr_init(&(host->host_send_status.attr));
+	host->host_send_status.attr.name = "sunxi_mmc_send_status";
+	host->host_send_status.attr.mode =  S_IRUGO;
+	ret = device_create_file(&pdev->dev, &host->host_send_status);
+	if (ret)
+		return ret;
+
+	host->host_mwr.show = sunxi_mmc_panic_rtest;
+	host->host_mwr.store = sunxi_mmc_pancic_wrtest;
+	sysfs_attr_init(&(host->host_mwr.attr));
+	host->host_mwr.attr.name = "sunxi_host_panic_wr";
+	host->host_mwr.attr.mode = S_IRUGO | S_IWUSR;
+	ret = device_create_file(&pdev->dev, &host->host_mwr);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(mmc_create_sys_fs);
+
+void mmc_remove_sys_fs(struct sunxi_mmc_host *host,
+		       struct platform_device *pdev)
+{
+	device_remove_file(&pdev->dev, &host->host_mwr);
+	device_remove_file(&pdev->dev, &host->host_perf);
+	device_remove_file(&pdev->dev, &host->maual_insert);
+	device_remove_file(&pdev->dev, &host->dump_register[0]);
+	device_remove_file(&pdev->dev, &host->dump_register[1]);
+	device_remove_file(&pdev->dev, &host->dump_register[2]);
+	device_remove_file(&pdev->dev, &host->dump_clk_dly);
+	device_remove_file(&pdev->dev, &host->filter_sector_perf);
+	device_remove_file(&pdev->dev, &host->filter_speed_perf);
+	device_remove_file(&pdev->dev, &host->host_sample_dly);
+	device_remove_file(&pdev->dev, &host->host_ds_dly);
+	device_remove_file(&pdev->dev, &host->host_send_status);
+}
+EXPORT_SYMBOL_GPL(mmc_remove_sys_fs);
diff --git a/drivers/mmc/host/sunxi-mmc-debug.h b/drivers/mmc/host/sunxi-mmc-debug.h
new file mode 100644
index 000000000..ff712ef24
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-debug.h
@@ -0,0 +1,49 @@
+/*
+ * Sunxi SD/MMC host driver
+ *
+ * Copyright (C) 2015 AllWinnertech Ltd.
+ * Author: lixiang <lixiang@allwinnertech>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed "as is" WITHOUT ANY WARRANTY of any
+ * kind, whether express or implied; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __SUNXI_MMC_DEBUG_H__
+#define __SUNXI_MMC_DEBUG_H__
+#include <linux/clk.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+
+void sunxi_mmc_dumphex32(struct sunxi_mmc_host *host, char *name, char *base,
+			 int len);
+void sunxi_mmc_dump_des(struct sunxi_mmc_host *host, char *base, int len);
+
+int sunxi_mmc_uperf_stat(struct sunxi_mmc_host *host,
+						struct mmc_data *data,
+						struct mmc_request *mrq_busy,
+						bool bhalf);
+
+int mmc_create_sys_fs(struct sunxi_mmc_host *host,
+		      struct platform_device *pdev);
+void mmc_remove_sys_fs(struct sunxi_mmc_host *host,
+		       struct platform_device *pdev);
+void sunxi_dump_reg(struct mmc_host *mmc);
+
+#endif
diff --git a/drivers/mmc/host/sunxi-mmc-export.c b/drivers/mmc/host/sunxi-mmc-export.c
new file mode 100644
index 000000000..e49641a61
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-export.c
@@ -0,0 +1,98 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+
+#include <linux/clk.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+#include <linux/regulator/consumer.h>
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/slot-gpio.h>
+
+#include "sunxi-mmc.h"
+#include "sunxi-mmc-export.h"
+
+#define SUNXI_MAX_CONTROL	4
+
+static struct sunxi_mmc_host *sunxi_hosts[SUNXI_MAX_CONTROL] = { NULL };
+
+void sunxi_mmc_rescan_card(unsigned id)
+{
+
+	if (id > SUNXI_MAX_CONTROL) {
+		pr_err("%d id over max id", id);
+		return;
+	}
+
+	if (sunxi_hosts[id] == NULL) {
+		pr_err("sunxi_hosts[%d] should not be null", id);
+		return;
+	}
+
+	if (sunxi_hosts[id] == NULL) {
+		dev_err(mmc_dev(sunxi_hosts[id]->mmc),
+			"%s:can't find the host\n", __func__);
+		return;
+	}
+	mmc_detect_change(sunxi_hosts[id]->mmc, 0);
+}
+EXPORT_SYMBOL_GPL(sunxi_mmc_rescan_card);
+
+void sunxi_mmc_reg_ex_res_inter(struct sunxi_mmc_host *host, u32 phy_id)
+{
+	if (phy_id > SUNXI_MAX_CONTROL) {
+		pr_err("%d id over max id", phy_id);
+		return;
+	}
+	sunxi_hosts[phy_id] = host;
+}
+EXPORT_SYMBOL_GPL(sunxi_mmc_reg_ex_res_inter);
+
+int sunxi_mmc_check_r1_ready(struct mmc_host *mmc, unsigned ms)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	unsigned long expire = jiffies + msecs_to_jiffies(ms);
+
+	do {
+		if (!(mmc_readl(host, REG_STAS) & SDXC_CARD_DATA_BUSY))
+			break;
+	} while (time_before(jiffies, expire));
+
+	if ((mmc_readl(host, REG_STAS) & SDXC_CARD_DATA_BUSY)) {
+		dev_err(mmc_dev(mmc), "wait r1 rdy %d ms timeout\n", ms);
+		return -1;
+	} else
+		return 0;
+}
+EXPORT_SYMBOL_GPL(sunxi_mmc_check_r1_ready);
+
diff --git a/drivers/mmc/host/sunxi-mmc-export.h b/drivers/mmc/host/sunxi-mmc-export.h
new file mode 100644
index 000000000..d95176e9b
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-export.h
@@ -0,0 +1,23 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#ifndef __SUNXI_MMC_EXPORT_H__
+#define __SUNXI_MMC_EXPORT_H__
+void sunxi_mmc_rescan_card(unsigned id);
+void sunxi_mmc_reg_ex_res_inter(struct sunxi_mmc_host *host, u32 phy_id);
+int sunxi_mmc_check_r1_ready(struct mmc_host *mmc, unsigned ms);
+
+#endif
diff --git a/drivers/mmc/host/sunxi-mmc-panic.c b/drivers/mmc/host/sunxi-mmc-panic.c
new file mode 100644
index 000000000..ab8239cf6
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-panic.c
@@ -0,0 +1,1087 @@
+/*
+* Sunxi SD/MMC panic host driver
+*
+* Copyright (C) 2019 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#include <linux/clk.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+#include <linux/regulator/consumer.h>
+#include <linux/delay.h>
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/slot-gpio.h>
+
+#include "sunxi-mmc.h"
+#include "sunxi-mmc-export.h"
+
+
+#ifdef CONFIG_SUNXI_PANICPART
+#include <linux/sunxi-panicpart.h>
+#endif
+
+#define NCAT
+//#define MMC_DEBUG
+#define SUNXI_TEST_SIZE	(512*4)
+
+#define MWR_TO_NS		(250*1000*1000)
+#define MWR_RFAIL	-1
+#define MWR_ROK	0
+
+#if 0
+#define mmc_mreadl(reg_base, reg) \
+	({\
+		int val = readl(reg_base + SDXC_##reg);\
+		printk("%x\n", val);\
+		val;\
+	})
+#define mmc_mwritel(reg_base, reg, value) \
+({\
+	int val = 0;\
+	writel((value), reg_base + SDXC_##reg);\
+	val = readl(reg_base + SDXC_##reg);\
+	printk("%x\n", val);\
+	val;\
+})
+
+#else
+
+#define mmc_mreadl(reg_base, reg) \
+	({\
+		int val = readl(reg_base + SDXC_##reg);\
+		/*printk("%x\n", val);*/\
+		val;\
+	})
+#define mmc_mwritel(reg_base, reg, value) \
+({\
+	int val = 0;\
+	writel((value), reg_base + SDXC_##reg);\
+	/*val = readl(reg_base + SDXC_##reg);*/\
+	/*printk("%x\n", val);*/\
+	val;\
+})
+#endif
+
+
+
+#ifndef NCAT
+#define SUNXI_SMHC_BASE  0x1c11000
+#define SUNXI_CCMU_BASE  0x1c20000
+#else
+#define SUNXI_SMHC_BASE  0x4022000
+#define SUNXI_CCMU_BASE		0x3001000
+#endif
+
+
+#define SDXC_REG_EDSD		(0x010C)
+#define SDXC_REG_CSDC		(0x0054)
+#define SDXC_REG_SD_NTSR	(0x005C)
+#define SDXC_REG_THLD		(0x0100)
+#define SDXC_REG_DRV_DL		(0x0140)
+#define SDXC_REG_SAMP_DL	(0x0144)
+#define SDXC_REG_DS_DL		(0x0148)
+
+
+#define SDXC_DAT_STARV_ERR	SDXC_VOLTAGE_CHANGE_DONE
+
+
+#ifndef NCAT
+#define SUNXI_MMC_GATR		(0x60)
+#define SUNXI_MMC_MODR		(0x90)
+#define SUNXI_MMC_RST		(0x2C0)
+#else
+#define SUNXI_MMC_GATR		(0x84c)
+#define SUNXI_MMC_MODR		(0x838)
+#define SUNXI_MMC_RST		(0x84c)
+#endif
+
+
+#ifdef MMC_DEBUG
+#define mmcinfo(fmt...) printk(KERN_INFO "[mmc]: "fmt)
+#define mmcdbg(fmt...)  printk(KERN_DEBUG "[mmc]: "fmt)
+#define mmcerr(fmt...)  printk(KERN_ERR "[mmc]: "fmt)
+#else
+#define mmcinfo(fmt...) printk(KERN_INFO "[mmc]: "fmt)
+#define mmcdbg(fmt...)
+#define mmcerr(fmt...)	printk(KERN_ERR "[mmc]: "fmt)
+#endif
+
+
+
+struct sunxi_mmc_mbak_regs {
+	u32 gctrl;
+	u32 clkc;
+	u32 timeout;
+	u32 buswid;
+	u32 waterlvl;
+	u32 funcsel;
+	u32 debugc;
+	u32 idmacc;
+	u32 dlba;
+	u32 imask;
+	u32 drv_dl;
+	u32 samp_dl;
+	u32 ds_dl;
+	u32 edsd;
+	u32 csdc;
+	u32 sd_ntsr;
+};
+
+static struct sunxi_mmc_mbak_regs gmbak_regs;
+static char *gccmu_base_reg;
+static char *ghost_base_reg;
+
+#ifdef CONFIG_SUNXI_PANICPART
+static int init_cnt;
+#endif
+
+#ifdef NCAT
+static void sunxi_mmc_mbusrst_host(char *host)
+{
+	char *ccmu_reg = gccmu_base_reg;
+
+	u32 rval = 0;
+	rval = readl(ccmu_reg + SUNXI_MMC_GATR);
+	rval &= ~((1u<<2)|(1u<<18));
+	writel(rval, ccmu_reg + SUNXI_MMC_GATR);
+
+	rval = readl(ccmu_reg + SUNXI_MMC_MODR);
+	rval &= ~((1<<31));
+	writel(rval, ccmu_reg + SUNXI_MMC_MODR);
+
+	rval = readl(ccmu_reg + SUNXI_MMC_MODR);
+	rval |= (1<<31);
+	writel(rval, ccmu_reg + SUNXI_MMC_MODR);
+
+	rval = readl(ccmu_reg + SUNXI_MMC_GATR);
+	rval |= ((1u<<2)|(1u<<18));
+	writel(rval, ccmu_reg + SUNXI_MMC_GATR);
+}
+#else
+
+static void sunxi_mmc_mbusrst_host(char *host)
+{
+	char *ccmu_reg = gccmu_base_reg;
+	u32 rval = 0;
+
+	rval = readl(ccmu_reg + SUNXI_MMC_GATR);
+	rval &= ~(1u<<10);
+	writel(rval, ccmu_reg + SUNXI_MMC_GATR);
+
+	rval = readl(ccmu_reg + SUNXI_MMC_RST);
+	rval &= ~(1u<<10);
+	writel(rval, ccmu_reg + SUNXI_MMC_RST);
+
+	rval = readl(ccmu_reg + SUNXI_MMC_MODR);
+	rval &= ~((1<<31));
+	writel(rval, ccmu_reg + SUNXI_MMC_MODR);
+
+	rval = readl(ccmu_reg + SUNXI_MMC_MODR);
+	rval |= (1<<31);
+	writel(rval, ccmu_reg + SUNXI_MMC_MODR);
+
+	rval = readl(ccmu_reg + SUNXI_MMC_RST);
+	rval |= (1u<<10);
+	writel(rval, ccmu_reg + SUNXI_MMC_RST);
+
+	rval = readl(ccmu_reg + SUNXI_MMC_GATR);
+	rval |= (1u<<10);
+	writel(rval, ccmu_reg + SUNXI_MMC_GATR);
+}
+#endif
+
+
+static const char mtsdat[512] = {
+	0xff, 0xff, 0x00, 0xff, 0xff, 0xff, 0x00, 0x00,
+	0xff, 0xff, 0xcc, 0xcc, 0xcc, 0x33, 0xcc, 0xcc,
+	0xcc, 0x33, 0x33, 0xcc, 0xcc, 0xcc, 0xff, 0xff,
+	0xff, 0xee, 0xff, 0xff, 0xff, 0xee, 0xee, 0xff,
+	0xff, 0xff, 0xdd, 0xff, 0xff, 0xff, 0xdd, 0xdd,
+	0xff, 0xff, 0xff, 0xbb, 0xff, 0xff, 0xff, 0xbb,
+	0xbb, 0xff, 0xff, 0xff, 0x77, 0xff, 0xff, 0xff,
+	0x77, 0x77, 0xff, 0x77, 0xbb, 0xdd, 0xee, 0xff,
+	0xff, 0xff, 0xff, 0x00, 0xff, 0xff, 0xff, 0x00,
+	0x00, 0xff, 0xff, 0xcc, 0xcc, 0xcc, 0x33, 0xcc,
+	0xcc, 0xcc, 0x33, 0x33, 0xcc, 0xcc, 0xcc, 0xff,
+	0xff, 0xff, 0xee, 0xff, 0xff, 0xff, 0xee, 0xee,
+	0xff, 0xff, 0xff, 0xdd, 0xff, 0xff, 0xff, 0xdd,
+	0xdd, 0xff, 0xff, 0xff, 0xbb, 0xff, 0xff, 0xff,
+	0xbb, 0xbb, 0xff, 0xff, 0xff, 0x77, 0xff, 0xff,
+	0xff, 0x77, 0x77, 0xff, 0x77, 0xbb, 0xdd, 0xee,
+
+	0xff, 0xff, 0x00, 0xff, 0xff, 0xff, 0x00, 0x00,
+	0xff, 0xff, 0xcc, 0xcc, 0xcc, 0x33, 0xcc, 0xcc,
+	0xcc, 0x33, 0x33, 0xcc, 0xcc, 0xcc, 0xff, 0xff,
+	0xff, 0xee, 0xff, 0xff, 0xff, 0xee, 0xee, 0xff,
+	0xff, 0xff, 0xdd, 0xff, 0xff, 0xff, 0xdd, 0xdd,
+	0xff, 0xff, 0xff, 0xbb, 0xff, 0xff, 0xff, 0xbb,
+	0xbb, 0xff, 0xff, 0xff, 0x77, 0xff, 0xff, 0xff,
+	0x77, 0x77, 0xff, 0x77, 0xbb, 0xdd, 0xee, 0xff,
+	0xff, 0xff, 0xff, 0x00, 0xff, 0xff, 0xff, 0x00,
+	0x00, 0xff, 0xff, 0xcc, 0xcc, 0xcc, 0x33, 0xcc,
+	0xcc, 0xcc, 0x33, 0x33, 0xcc, 0xcc, 0xcc, 0xff,
+	0xff, 0xff, 0xee, 0xff, 0xff, 0xff, 0xee, 0xee,
+	0xff, 0xff, 0xff, 0xdd, 0xff, 0xff, 0xff, 0xdd,
+	0xdd, 0xff, 0xff, 0xff, 0xbb, 0xff, 0xff, 0xff,
+	0xbb, 0xbb, 0xff, 0xff, 0xff, 0x77, 0xff, 0xff,
+	0xff, 0x77, 0x77, 0xff, 0x77, 0xbb, 0xdd, 0xee,
+
+	0xff, 0xff, 0x00, 0xff, 0xff, 0xff, 0x00, 0x00,
+	0xff, 0xff, 0xcc, 0xcc, 0xcc, 0x33, 0xcc, 0xcc,
+	0xcc, 0x33, 0x33, 0xcc, 0xcc, 0xcc, 0xff, 0xff,
+	0xff, 0xee, 0xff, 0xff, 0xff, 0xee, 0xee, 0xff,
+	0xff, 0xff, 0xdd, 0xff, 0xff, 0xff, 0xdd, 0xdd,
+	0xff, 0xff, 0xff, 0xbb, 0xff, 0xff, 0xff, 0xbb,
+	0xbb, 0xff, 0xff, 0xff, 0x77, 0xff, 0xff, 0xff,
+	0x77, 0x77, 0xff, 0x77, 0xbb, 0xdd, 0xee, 0xff,
+	0xff, 0xff, 0xff, 0x00, 0xff, 0xff, 0xff, 0x00,
+	0x00, 0xff, 0xff, 0xcc, 0xcc, 0xcc, 0x33, 0xcc,
+	0xcc, 0xcc, 0x33, 0x33, 0xcc, 0xcc, 0xcc, 0xff,
+	0xff, 0xff, 0xee, 0xff, 0xff, 0xff, 0xee, 0xee,
+	0xff, 0xff, 0xff, 0xdd, 0xff, 0xff, 0xff, 0xdd,
+	0xdd, 0xff, 0xff, 0xff, 0xbb, 0xff, 0xff, 0xff,
+	0xbb, 0xbb, 0xff, 0xff, 0xff, 0x77, 0xff, 0xff,
+	0xff, 0x77, 0x77, 0xff, 0x77, 0xbb, 0xdd, 0xee,
+
+	0xff, 0xff, 0x00, 0xff, 0xff, 0xff, 0x00, 0x00,
+	0xff, 0xff, 0xcc, 0xcc, 0xcc, 0x33, 0xcc, 0xcc,
+	0xcc, 0x33, 0x33, 0xcc, 0xcc, 0xcc, 0xff, 0xff,
+	0xff, 0xee, 0xff, 0xff, 0xff, 0xee, 0xee, 0xff,
+	0xff, 0xff, 0xdd, 0xff, 0xff, 0xff, 0xdd, 0xdd,
+	0xff, 0xff, 0xff, 0xbb, 0xff, 0xff, 0xff, 0xbb,
+	0xbb, 0xff, 0xff, 0xff, 0x77, 0xff, 0xff, 0xff,
+	0x77, 0x77, 0xff, 0x77, 0xbb, 0xdd, 0xee, 0xff,
+	0xff, 0xff, 0xff, 0x00, 0xff, 0xff, 0xff, 0x00,
+	0x00, 0xff, 0xff, 0xcc, 0xcc, 0xcc, 0x33, 0xcc,
+	0xcc, 0xcc, 0x33, 0x33, 0xcc, 0xcc, 0xcc, 0xff,
+	0xff, 0xff, 0xee, 0xff, 0xff, 0xff, 0xee, 0xee,
+	0xff, 0xff, 0xff, 0xdd, 0xff, 0xff, 0xff, 0xdd,
+	0xdd, 0xff, 0xff, 0xff, 0xbb, 0xff, 0xff, 0xff,
+	0xbb, 0xbb, 0xff, 0xff, 0xff, 0x77, 0xff, 0xff,
+	0xff, 0x77, 0x77, 0xff, 0x77, 0xbb, 0xdd, 0xee,
+};
+
+static void buf_dumphex32(char *name, const char *base, int len)
+{
+#ifdef MMC_DEBUG
+	u32 i;
+
+	pr_cont("dump %s\n", name);
+
+	for (i = 0; i < len; i += 4) {
+		if (!(i&0xf))
+			pr_cont("\n0x%p : ", base + i);
+		pr_cont("0x%08x ", *((u32 *)&base[i]));
+	}
+	pr_cont("\n");
+#endif
+}
+
+static void sunxi_mmc_regs_save(char *host)
+{
+	struct sunxi_mmc_mbak_regs *bak_regs = &gmbak_regs;
+
+	/*save public register */
+	bak_regs->gctrl = mmc_mreadl(host, REG_GCTRL);
+	bak_regs->clkc = mmc_mreadl(host, REG_CLKCR);
+	bak_regs->timeout = mmc_mreadl(host, REG_TMOUT);
+	bak_regs->buswid = mmc_mreadl(host, REG_WIDTH);
+	bak_regs->debugc = 0xdeb;
+
+	bak_regs->drv_dl = mmc_mreadl(host, REG_DRV_DL);
+	bak_regs->samp_dl = mmc_mreadl(host, REG_SAMP_DL);
+	bak_regs->ds_dl = mmc_mreadl(host, REG_DS_DL);
+	bak_regs->sd_ntsr = mmc_mreadl(host, REG_SD_NTSR);
+	bak_regs->edsd = mmc_mreadl(host, REG_EDSD);
+	bak_regs->csdc = mmc_mreadl(host, REG_CSDC);
+}
+
+static void sunxi_mmc_regs_restore(char *host)
+{
+	struct sunxi_mmc_mbak_regs *bak_regs = &gmbak_regs;
+	char *ccmu_reg = gccmu_base_reg;
+	u32 rval = 0;
+
+	/*restore public register */
+	mmc_mwritel(host, REG_GCTRL, bak_regs->gctrl);
+	mmc_mwritel(host, REG_CLKCR, bak_regs->clkc);
+	mmc_mwritel(host, REG_TMOUT, bak_regs->timeout);
+	mmc_mwritel(host, REG_WIDTH, bak_regs->buswid);
+	mmc_mwritel(host, REG_DBGC, bak_regs->debugc);
+
+	rval = readl(ccmu_reg + SUNXI_MMC_MODR);
+	rval &= ~((1<<31));
+	writel(rval, ccmu_reg + SUNXI_MMC_MODR);
+	mmc_mwritel(host, REG_DRV_DL, bak_regs->drv_dl);
+	rval = readl(ccmu_reg + SUNXI_MMC_MODR);
+	rval |= (1<<31);
+	writel(rval, ccmu_reg + SUNXI_MMC_MODR);
+
+	mmc_mwritel(host, REG_SAMP_DL, bak_regs->samp_dl);
+	mmc_mwritel(host, REG_DS_DL, bak_regs->ds_dl);
+	mmc_mwritel(host, REG_SD_NTSR, bak_regs->sd_ntsr);
+	mmc_mwritel(host, REG_EDSD, bak_regs->edsd);
+	mmc_mwritel(host, REG_CSDC, bak_regs->csdc);
+}
+
+static int sunxi_mmc_mupdate_clk(char *host)
+{
+	u32 rval;
+	int i = 0;
+
+	rval = mmc_mreadl(host, REG_CLKCR);
+	rval &= ~(SDXC_CARD_CLOCK_ON | SDXC_LOW_POWER_ON | SDXC_MASK_DATA0);
+
+	rval |= SDXC_CARD_CLOCK_ON;
+	rval |= SDXC_LOW_POWER_ON;
+	rval |= SDXC_MASK_DATA0;
+
+	mmc_mwritel(host, REG_CLKCR, rval);
+
+	mmcdbg("%s REG_CLKCR:%x\n", __func__,
+		mmc_mreadl(host, REG_CLKCR));
+
+	rval = SDXC_START | SDXC_UPCLK_ONLY | SDXC_WAIT_PRE_OVER;
+	mmc_mwritel(host, REG_CMDR, rval);
+
+	do {
+		rval = mmc_mreadl(host, REG_CMDR);
+		ndelay(1);
+	} while (((i++) < MWR_TO_NS) && (rval & SDXC_START));
+
+	/* clear irq status bits set by the command */
+	mmc_mwritel(host, REG_RINTR,
+		   mmc_mreadl(host, REG_RINTR) & ~SDXC_SDIO_INTERRUPT);
+
+	if (rval & SDXC_START) {
+		mmcerr("fatal err update clk timeout\n");
+		return -EIO;
+	}
+
+	mmc_mwritel(host, REG_CLKCR,
+			   mmc_mreadl(host, REG_CLKCR) & ~SDXC_MASK_DATA0);
+
+	return 0;
+}
+
+
+
+static void sunxi_mmc_rcover_host(char *host)
+{
+	sunxi_mmc_regs_save(host);
+	sunxi_mmc_mbusrst_host(host);
+	sunxi_mmc_regs_restore(host);
+	sunxi_mmc_mupdate_clk(host);
+}
+
+static int sunxi_mmc_mchk_r1_rdy(char *reg, int to_ns)
+{
+	int i = 0;
+	/*wait busy over*/
+	for (i = 0; i < to_ns; i++) {
+		if (!(mmc_mreadl(reg, REG_STAS) & SDXC_CARD_DATA_BUSY))
+			break;
+		ndelay(1);
+	}
+
+	if ((mmc_mreadl(reg, REG_STAS) & SDXC_CARD_DATA_BUSY)) {
+		printk("dead Wait r1 rdy failed\n");
+		return MWR_RFAIL;
+	}
+	return MWR_ROK;
+}
+
+
+static int sunxi_mmc_raw_write(char *reg, u32 sec_addr,
+			u32 sec_cnt, const char *inbuf)
+{
+	u32 cmd_val, ri;
+	u32 rval;
+	int to = 0;
+	int wcnt = (sec_cnt<<9)>>2;
+	int i = 0;
+	u32 *buf = (u32 *)inbuf;
+
+
+	rval = mmc_mreadl(reg, REG_GCTRL);
+	rval |= SDXC_ACCESS_BY_AHB | SDXC_FIFO_RESET;
+	rval &= ~SDXC_DMA_ENABLE_BIT;
+	mmc_mwritel(reg, REG_GCTRL, rval);
+	for (to = 0; to < MWR_TO_NS; to++) {
+		rval = mmc_mreadl(reg, REG_GCTRL);
+		if (!(rval & SDXC_FIFO_RESET))
+			break;
+		ndelay(1);
+	}
+	if (to == MWR_TO_NS) {
+		mmcerr("wait fifo rest timout\n");
+		goto eout;
+	}
+
+	/**cmd seting**/
+	cmd_val = SDXC_START | SDXC_RESP_EXPECT \
+				| SDXC_CHECK_RESPONSE_CRC | SDXC_DATA_EXPECT\
+				| SDXC_WRITE | SDXC_SEND_AUTO_STOP
+				| SDXC_WAIT_PRE_OVER | MMC_WRITE_MULTIPLE_BLOCK;
+	mmc_mwritel(reg, REG_CARG, sec_addr);
+	mmc_mwritel(reg, REG_A12A, 0);
+
+	/**data setting*/
+	mmc_mwritel(reg, REG_BLKSZ, 512);
+	mmc_mwritel(reg, REG_BCNTR, sec_cnt<<9);
+
+	mmc_mwritel(reg, REG_THLD, (512<<16)|(1<<2)|(1<<0));
+	mmcdbg("thld %x\n", readl(reg + 0x100));
+
+	/**int seting*/
+	rval = mmc_mreadl(reg, REG_GCTRL);
+	rval &= ~SDXC_INTERRUPT_ENABLE_BIT;
+	mmc_mwritel(reg, REG_GCTRL, rval);
+	mmc_mwritel(reg, REG_MISTA, 0);
+	mmc_mwritel(reg, REG_RINTR, 0xffffffff);
+
+	/**exe cmd**/
+	mmc_mwritel(reg, REG_CMDR, cmd_val);
+
+	/*write data*/
+	for (i = 0; i < wcnt; i++) {
+		/*wait data not full*/
+		for (to = 0; to < MWR_TO_NS; to++) {
+			if (!(mmc_mreadl(reg, REG_STAS) & SDXC_FIFO_FULL))
+				break;
+			ri = mmc_mreadl(reg, REG_RINTR);
+			if (ri & (SDXC_INTERRUPT_ERROR_BIT)) {
+				mmcerr("trans err %x\n", ri);
+				goto eout;
+			}
+			ndelay(1);
+		}
+		if (to == MWR_TO_NS) {
+			mmcerr("wait fifo not full timeout\n");
+			goto eout;
+		}
+
+		mmc_mwritel(reg, REG_FIFO, buf[i]);
+	}
+
+	/*wait busy over*/
+	for (i = 0; i < MWR_TO_NS; i++) {
+		if (!(mmc_mreadl(reg, REG_STAS) & SDXC_CARD_DATA_BUSY))
+			break;
+		ndelay(1);
+	}
+
+	if ((mmc_mreadl(reg, REG_STAS) & SDXC_CARD_DATA_BUSY)) {
+		mmcerr("dead Wait r1 rdy failed\n");
+		goto eout;
+	}
+
+	for (to = 0; to < MWR_TO_NS; to++) {
+		ri = mmc_mreadl(reg, REG_RINTR);
+		if (ri & (SDXC_AUTO_COMMAND_DONE))
+			break;
+		ndelay(1);
+	}
+	if (to == MWR_TO_NS) {
+		mmcerr("wait auto cmd done timout\n");
+		goto eout;
+	}
+
+	mmc_mwritel(reg, REG_RINTR, 0xffff);
+	mmcdbg("manul write ok\n");
+	return MWR_ROK;
+
+eout:
+	mmcerr("mau write failed\n");
+	return MWR_RFAIL;
+}
+
+
+static int sunxi_mmc_raw_half_write(char *reg, u32 sec_addr,
+				u32 sec_cnt, u32 stp_wd, const char *inbuf)
+{
+	u32 cmd_val, ri;
+	u32 rval;
+	int to = 0;
+	int wcnt = (sec_cnt<<9)>>2;
+	int i = 0;
+	u32 *buf = (u32 *)inbuf;
+
+	/**cmd seting**/
+	cmd_val = SDXC_START | SDXC_RESP_EXPECT \
+				| SDXC_CHECK_RESPONSE_CRC | SDXC_DATA_EXPECT\
+				| SDXC_WRITE | SDXC_SEND_AUTO_STOP
+				| SDXC_WAIT_PRE_OVER | MMC_WRITE_MULTIPLE_BLOCK;
+	mmc_mwritel(reg, REG_CARG, sec_addr);
+	mmc_mwritel(reg, REG_A12A, 0);
+
+	/**data setting*/
+	mmc_mwritel(reg, REG_BLKSZ, 512);
+	mmc_mwritel(reg, REG_BCNTR, sec_cnt<<9);
+	rval = mmc_mreadl(reg, REG_GCTRL);
+	rval |= SDXC_ACCESS_BY_AHB | SDXC_FIFO_RESET;
+	rval &= ~SDXC_DMA_ENABLE_BIT;
+	mmc_mwritel(reg, REG_GCTRL, rval);
+	for (to = 0; to < MWR_TO_NS; to++) {
+		rval = mmc_mreadl(reg, REG_GCTRL);
+		if (!(rval & SDXC_FIFO_RESET))
+			break;
+		ndelay(1);
+	}
+	if (to == MWR_TO_NS) {
+		mmcerr("wait fifo rest timout\n");
+		goto eout;
+	}
+
+	/**int seting*/
+	rval &= ~SDXC_INTERRUPT_ENABLE_BIT;
+	mmc_mwritel(reg, REG_GCTRL, rval);
+	mmc_mwritel(reg, REG_MISTA, 0);
+	mmc_mwritel(reg, REG_RINTR, 0xffff);
+
+	/**exe cmd**/
+	mmc_mwritel(reg, REG_CMDR, cmd_val);
+
+	/*write data*/
+	for (i = 0; (i < wcnt) && (i < stp_wd); i++) {
+		/*wait data not full*/
+		for (to = 0; to < MWR_TO_NS; to++) {
+			if (!(mmc_mreadl(reg, REG_STAS) & SDXC_FIFO_FULL))
+				break;
+			ri = mmc_mreadl(reg, REG_RINTR);
+			if (ri & (SDXC_INTERRUPT_ERROR_BIT)) {
+				mmcerr("trans err %x\n", ri);
+				goto eout;
+			}
+			ndelay(1);
+		}
+		if (to == MWR_TO_NS) {
+			mmcerr("wait fifo not full timeout\n");
+			goto eout;
+		}
+
+		mmc_mwritel(reg, REG_FIFO, buf[i]);
+	}
+
+	mmc_mwritel(reg, REG_RINTR, 0xffff);
+	mmcdbg("manul half write ok\n");
+	return MWR_ROK;
+
+eout:
+	mmcerr("mau write failed\n");
+	return MWR_RFAIL;
+}
+
+static int sunxi_mmc_raw_wcmd_clr(char *reg, int *out_cmd_val)
+{
+	int i = 0;
+	u32 cmd_val = 0;
+
+	do {
+		cmd_val = mmc_mreadl(reg, REG_CMDR);
+		if (!(cmd_val & SDXC_START)) {
+			*out_cmd_val = cmd_val;
+			return MWR_ROK;
+		}
+		ndelay(1);
+	} while ((i++) < MWR_TO_NS);
+
+	mmcerr("Wait cmd over timout\n");
+	return MWR_RFAIL;
+}
+
+static void sunxi_mmc_raw_stop(char *reg)
+{
+	u32 arg, cmd_val, ri;
+	int i = 0;
+	int rval = 0;
+
+	cmd_val = SDXC_START | SDXC_RESP_EXPECT
+			|SDXC_STOP_ABORT_CMD | SDXC_CHECK_RESPONSE_CRC
+			|MMC_STOP_TRANSMISSION;
+	arg = 0;
+
+	/**int seting*/
+	rval = mmc_mreadl(reg, REG_GCTRL);
+	rval &= ~SDXC_INTERRUPT_ENABLE_BIT;
+	mmc_mwritel(reg, REG_GCTRL, rval);
+	mmc_mwritel(reg, REG_MISTA, 0);
+	mmc_mwritel(reg, REG_RINTR, 0xffff);
+
+	mmc_mwritel(reg, REG_CARG, arg);
+	mmc_mwritel(reg, REG_CMDR, cmd_val);
+
+	do {
+		ri = mmc_mreadl(reg, REG_RINTR);
+		if (ri & (SDXC_COMMAND_DONE |
+					(SDXC_INTERRUPT_ERROR_BIT|SDXC_DAT_STARV_ERR)))
+			break;
+		ndelay(1);
+	} while ((i++) < MWR_TO_NS);
+
+	if (!(ri & SDXC_COMMAND_DONE) ||
+				(ri & (SDXC_INTERRUPT_ERROR_BIT|SDXC_DAT_STARV_ERR))) {
+		ri = mmc_mreadl(reg, REG_RINTR);
+		if (!(ri & SDXC_COMMAND_DONE) ||
+					(ri & (SDXC_INTERRUPT_ERROR_BIT|SDXC_DAT_STARV_ERR))) {
+			mmcdbg("send  manual stop command failed, %x\n", ri);
+		} else {
+			mmcdbg("send manual stop command ok\n");
+			}
+	} else
+		mmcdbg("send manual stop command ok\n");
+
+
+	mmc_mwritel(reg, REG_RINTR, 0xffff);
+}
+
+static int sunxi_mmc_raw_read(char *reg, u32 sec_addr,
+			u32 sec_cnt, char *outbuf)
+{
+	u32 cmd_val, ri;
+	u32 rval;
+	int to = 0;
+	int wcnt = (sec_cnt<<9)>>2;
+	int i = 0;
+	u32 *buf = (u32 *)outbuf;
+	int fifo_level = 0;
+
+	/**int seting*/
+	rval = mmc_mreadl(reg, REG_GCTRL);
+	rval &= ~SDXC_INTERRUPT_ENABLE_BIT;
+	mmc_mwritel(reg, REG_GCTRL, rval);
+	mmc_mwritel(reg, REG_MISTA, 0);
+	mmc_mwritel(reg, REG_RINTR, 0xffff);
+
+	/**cmd seting**/
+	cmd_val = SDXC_START | SDXC_RESP_EXPECT \
+				| SDXC_CHECK_RESPONSE_CRC | SDXC_DATA_EXPECT\
+				| SDXC_SEND_AUTO_STOP
+				| SDXC_WAIT_PRE_OVER | MMC_READ_MULTIPLE_BLOCK;
+	mmc_mwritel(reg, REG_CARG, sec_addr);
+	mmc_mwritel(reg, REG_A12A, 0);
+
+	/**data setting*/
+	mmc_mwritel(reg, REG_BLKSZ, 512);
+	mmc_mwritel(reg, REG_BCNTR, sec_cnt<<9);
+	mmc_mwritel(reg, REG_THLD, (512<<16)|(1<<2)|(1<<0));
+	mmcdbg("thld %x\n", readl(reg + 0x100));
+
+	rval = mmc_mreadl(reg, REG_GCTRL);
+	rval |= SDXC_ACCESS_BY_AHB | SDXC_FIFO_RESET;
+	rval &= ~SDXC_DMA_ENABLE_BIT;
+	mmc_mwritel(reg, REG_GCTRL, rval);
+	for (to = 0; to < MWR_TO_NS; to++) {
+		rval = mmc_mreadl(reg, REG_GCTRL);
+		if (!(rval & SDXC_FIFO_RESET))
+			break;
+		ndelay(1);
+	}
+	if (to == MWR_TO_NS) {
+		mmcerr("wait fifo rest timout\n");
+		goto eout;
+	}
+
+
+	/**exe cmd**/
+	mmc_mwritel(reg, REG_CMDR, cmd_val);
+
+	/*read data*/
+	do {
+		/*wait data not full*/
+		for (to = 0; to < MWR_TO_NS; to++) {
+			if (!(mmc_mreadl(reg, REG_STAS)
+				& SDXC_FIFO_EMPTY))
+				break;
+			ri = mmc_mreadl(reg, REG_RINTR);
+			if (ri & (SDXC_INTERRUPT_ERROR_BIT)) {
+				mmcerr("trans err %x\n", ri);
+				goto eout;
+			}
+			ndelay(1);
+		}
+		if (to == MWR_TO_NS) {
+			mmcerr("wait fifo no empty timeout %x\n", ri);
+			goto eout;
+		}
+
+		fifo_level = (mmc_mreadl(reg, REG_STAS) >> 17) & 0x1f;
+		if (fifo_level && (fifo_level <= 16))
+			while (fifo_level--)
+				buf[i++] = mmc_mreadl(reg, REG_FIFO);
+		else
+			buf[i++] = mmc_mreadl(reg, REG_FIFO);
+	} while (i < wcnt);
+
+
+
+	for (to = 0; to < MWR_TO_NS; to++) {
+		ri = mmc_mreadl(reg, REG_RINTR);
+		if (ri & (SDXC_AUTO_COMMAND_DONE))
+			break;
+		ndelay(1);
+	}
+	if (to == MWR_TO_NS) {
+		mmcerr("wait auto cmd done timout\n");
+		goto eout;
+	}
+
+
+	mmc_mwritel(reg, REG_RINTR, 0xffff);
+	return MWR_ROK;
+
+eout:
+	mmcerr("mau read failed\n");
+	return MWR_RFAIL;
+}
+
+
+static int sunxi_mmc_raw_half_read(char *reg, u32 sec_addr, u32 sec_cnt, u32 stp_wd, char *outbuf)
+{
+	u32 cmd_val, ri;
+	u32 rval;
+	int to = 0;
+	int wcnt = (sec_cnt<<9)>>2;
+	int i = 0;
+	u32 *buf = (u32 *)outbuf;
+	int fifo_level = 0;
+
+
+	/**int seting*/
+	rval = mmc_mreadl(reg, REG_GCTRL);
+	rval &= ~SDXC_INTERRUPT_ENABLE_BIT;
+	mmc_mwritel(reg, REG_GCTRL, rval);
+	mmc_mwritel(reg, REG_MISTA, 0);
+	mmc_mwritel(reg, REG_RINTR, 0xffff);
+
+	/**cmd seting**/
+	cmd_val = SDXC_START | SDXC_RESP_EXPECT \
+				| SDXC_CHECK_RESPONSE_CRC | SDXC_DATA_EXPECT\
+				| SDXC_SEND_AUTO_STOP
+				| SDXC_WAIT_PRE_OVER | MMC_READ_MULTIPLE_BLOCK;
+	mmc_mwritel(reg, REG_CARG, sec_addr);
+	mmc_mwritel(reg, REG_A12A, 0);
+
+	/**data setting*/
+	mmc_mwritel(reg, REG_BLKSZ, 512);
+	mmc_mwritel(reg, REG_BCNTR, sec_cnt<<9);
+	rval = mmc_mreadl(reg, REG_GCTRL);
+	rval |= SDXC_ACCESS_BY_AHB | SDXC_FIFO_RESET;
+	rval &= ~SDXC_DMA_ENABLE_BIT;
+	mmc_mwritel(reg, REG_GCTRL, rval);
+	for (to = 0; to < MWR_TO_NS; to++) {
+		rval = mmc_mreadl(reg, REG_GCTRL);
+		if (!(rval & SDXC_FIFO_RESET))
+			break;
+		ndelay(1);
+	}
+	if (to == MWR_TO_NS) {
+		mmcerr("wait fifo rest timout\n");
+		goto eout;
+	}
+
+	/**exe cmd**/
+	mmc_mwritel(reg, REG_CMDR, cmd_val);
+
+	/*read data*/
+	do {
+		/*wait data not full*/
+		for (to = 0; to < MWR_TO_NS; to++) {
+			if (!(mmc_mreadl(reg, REG_STAS) & SDXC_FIFO_EMPTY))
+				break;
+			ri = mmc_mreadl(reg, REG_RINTR);
+			if (ri & (SDXC_INTERRUPT_ERROR_BIT)) {
+				mmcerr("trans err %x\n", ri);
+				goto eout;
+			}
+			ndelay(1);
+		}
+		if (to == MWR_TO_NS)
+			goto eout;
+
+		fifo_level = (mmc_mreadl(reg, REG_STAS) >> 17) & 0x1f;
+		if (fifo_level && (fifo_level <= 16))
+			while (fifo_level--)
+				buf[i++] = mmc_mreadl(reg, REG_FIFO);
+		else
+			buf[i++] = mmc_mreadl(reg, REG_FIFO);
+	} while ((i < wcnt) && (i < stp_wd));
+
+	mmc_mwritel(reg, REG_RINTR, 0xffff);
+	return MWR_ROK;
+
+eout:
+	mmcerr("mau read failed\n");
+	return MWR_RFAIL;
+}
+
+
+
+/**use for panic situation,no irq,no lock,no dma**/
+int sunxi_mmc_panic_read(u32 sec_addr, u32 sec_cnt, char *outbuf)
+{
+	char *reg = ghost_base_reg;
+	int ret = 0;
+	u32 cmd_val = 0;
+
+	BUG_ON(outbuf == NULL);
+	if (!ghost_base_reg || !gccmu_base_reg) {
+		mmcerr("host,ccmu reg has not init\n");
+		return MWR_RFAIL;
+	}
+
+	cmd_val = mmc_mreadl(reg, REG_CMDR);
+
+	ret = sunxi_mmc_raw_wcmd_clr(reg, &cmd_val);
+	if (ret)
+		return ret;
+
+	if (cmd_val & SDXC_DATA_EXPECT)
+		sunxi_mmc_raw_stop(reg);
+
+	sunxi_mmc_rcover_host(reg);
+
+	if (cmd_val & SDXC_DATA_EXPECT)
+		sunxi_mmc_raw_stop(reg);
+
+	if (cmd_val & SDXC_WRITE)
+			ret = sunxi_mmc_mchk_r1_rdy(reg, MWR_TO_NS);
+	if (ret)
+		return ret;
+
+	return sunxi_mmc_raw_read(reg, sec_addr, sec_cnt, outbuf);
+}
+
+/**use for panic situation,no irq,no lock,no dma**/
+int sunxi_mmc_panic_write(u32 sec_addr, u32 sec_cnt, const char *inbuf)
+{
+	int ret = 0;
+	u32 cmd_val = 0;
+	char *reg = ghost_base_reg;
+
+	cmd_val = mmc_mreadl(reg, REG_CMDR);
+	BUG_ON(inbuf == NULL);
+	if (!ghost_base_reg || !gccmu_base_reg) {
+		mmcerr("host,ccmu reg has not init\n");
+		return MWR_RFAIL;
+	}
+
+	ret = sunxi_mmc_raw_wcmd_clr(reg, &cmd_val);
+	if (ret)
+		return ret;
+
+	if (cmd_val & SDXC_DATA_EXPECT)
+		sunxi_mmc_raw_stop(reg);
+
+	sunxi_mmc_rcover_host(reg);
+
+	if (cmd_val & SDXC_DATA_EXPECT)
+		sunxi_mmc_raw_stop(reg);
+
+	if (cmd_val & SDXC_WRITE)
+			ret = sunxi_mmc_mchk_r1_rdy(reg, MWR_TO_NS);
+	if (ret)
+		return ret;
+
+	return sunxi_mmc_raw_write(reg, sec_addr, sec_cnt, inbuf);
+}
+
+int sunxi_mmc_panic_init(void)
+{
+	gccmu_base_reg = ioremap(SUNXI_CCMU_BASE, 0x900);
+	if (!gccmu_base_reg) {
+		mmcerr("*iormap ccmu failed*\n");
+		return MWR_RFAIL;
+	}
+
+	ghost_base_reg = ioremap(SUNXI_SMHC_BASE, 0x300);
+	if (!ghost_base_reg) {
+		mmcerr("*iormap host failed*\n");
+		return MWR_RFAIL;
+	}
+	return MWR_ROK;
+}
+
+
+
+void sunxi_mmc_panic_exit(void)
+{
+	iounmap(gccmu_base_reg);
+	iounmap(ghost_base_reg);
+}
+
+ssize_t
+sunxi_mmc_panic_rtest(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host	*mmc = platform_get_drvdata(pdev);
+	char *rxbuf = kzalloc(SUNXI_TEST_SIZE, GFP_KERNEL);
+	int ret = 0;
+
+	printk("Start panic read test\n");
+
+	mmc_claim_host(mmc);
+	sunxi_mmc_panic_init();
+	ret = sunxi_mmc_panic_read(16, SUNXI_TEST_SIZE/512, rxbuf);
+	if (ret)
+		goto out;
+	buf_dumphex32("rxbuf", rxbuf, SUNXI_TEST_SIZE);
+	printk(KERN_INFO "panic read ok\n");
+	mmc_release_host(mmc);
+
+out:
+	kfree(rxbuf);
+	return SUNXI_TEST_SIZE;
+}
+
+ssize_t
+sunxi_mmc_pancic_wrtest(struct device *dev, struct device_attribute *attr,
+		const char *buf, size_t count)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host	*mmc = platform_get_drvdata(pdev);
+	char *rxbuf = kzalloc(SUNXI_TEST_SIZE, GFP_KERNEL);
+	char *mwr_tsdat = kzalloc(SUNXI_TEST_SIZE, GFP_KERNEL);
+	int sc = 0;
+	int i = 0;
+	char *reg = NULL;
+	if (kstrtoint(buf, 0, &sc))
+		goto out;
+
+	mmcinfo(KERN_INFO "Start test sec %d\n", sc);
+	for (i = 0; i < (SUNXI_TEST_SIZE/512); i++)
+		memcpy(mwr_tsdat+i*512, mtsdat, 512);
+
+
+	mmc_claim_host(mmc);
+	sunxi_mmc_panic_init();
+	reg = ghost_base_reg;
+	mmcinfo("***Test normal w/r***\n");
+	buf_dumphex32("test data", mwr_tsdat, SUNXI_TEST_SIZE);
+	mmcdbg("Write test data\n");
+	sunxi_mmc_panic_write(sc, SUNXI_TEST_SIZE/512, mwr_tsdat);
+	mmcdbg("Read test data\n");
+	sunxi_mmc_panic_read(sc, SUNXI_TEST_SIZE/512, rxbuf);
+	buf_dumphex32("read data from mmc after write", rxbuf, SUNXI_TEST_SIZE);
+	if (memcmp(mwr_tsdat, rxbuf, SUNXI_TEST_SIZE) != 0) {
+		mmcinfo("write read failed\n");
+		goto out;
+	}
+	mmcinfo(KERN_INFO "***write read compare ok,test ok***\n");
+
+#if 1
+	mmcinfo("\n***test half read***\n");
+	memset(rxbuf, 0, SUNXI_TEST_SIZE);
+	buf_dumphex32("0 test data", rxbuf, SUNXI_TEST_SIZE);;
+	sunxi_mmc_raw_half_read(reg, sc, SUNXI_TEST_SIZE/512, 160, rxbuf);
+	buf_dumphex32("half read data", rxbuf, SUNXI_TEST_SIZE);
+	sunxi_mmc_panic_read(sc, SUNXI_TEST_SIZE/512, rxbuf);
+	buf_dumphex32("read test data", rxbuf, SUNXI_TEST_SIZE);
+	if (memcmp(mwr_tsdat, rxbuf, SUNXI_TEST_SIZE) != 0) {
+		mmcinfo("half read compare failed\n");
+		goto out;
+	}
+	mmcinfo("***test half read test ok***\n");
+
+
+	mmcinfo("\n***test half write***\n");
+	memset(rxbuf, 0, SUNXI_TEST_SIZE);
+	sunxi_mmc_raw_half_write(reg, sc, SUNXI_TEST_SIZE/512, 160, mwr_tsdat);
+	sunxi_mmc_panic_read(sc, SUNXI_TEST_SIZE/512, rxbuf);
+	buf_dumphex32("read half test data", rxbuf, SUNXI_TEST_SIZE);
+	if (memcmp(mwr_tsdat, rxbuf, SUNXI_TEST_SIZE) != 0) {
+		mmcinfo("half write compare failed\n");
+		return count;
+	}
+	mmcinfo("***test half write test ok***\n\n");
+#endif
+out:
+	sunxi_mmc_panic_exit();
+	mmc_release_host(mmc);
+
+
+	kfree(rxbuf);
+	kfree(mwr_tsdat);
+	return count;
+}
+
+#ifdef CONFIG_SUNXI_PANICPART
+static ssize_t sunxi_mmc_panic_read_ps(struct panic_part *part, loff_t sec_off,
+		size_t sec_cnt, char *buf)
+{
+	int ret;
+
+	ret = sunxi_mmc_panic_read(part->start_sect + sec_off, sec_cnt, buf);
+	if (ret)
+		return ret;
+	return sec_cnt;
+}
+
+static ssize_t sunxi_mmc_panic_write_ps(struct panic_part *part, loff_t sec_off,
+		size_t sec_cnt, const char *buf)
+{
+	int ret;
+
+	ret =  sunxi_mmc_panic_write(part->start_sect + sec_off, sec_cnt, buf);
+	if (ret)
+		return ret;
+	return sec_cnt;
+}
+
+
+static struct panic_part sunxi_mmc_panic_ps = {
+	.type = SUNXI_FLASH_MMC,
+	.panic_read = sunxi_mmc_panic_read_ps,
+	.panic_write = sunxi_mmc_panic_write_ps,
+};
+#endif
+
+int sunxi_mmc_panic_init_ps(void *data)
+{
+	int ret = 0;
+
+#ifdef CONFIG_SUNXI_PANICPART
+	if (init_cnt) {
+		mmcdbg("error Has init sunxi mmc panic\n");
+		return MWR_RFAIL;
+	}
+
+	ret = sunxi_mmc_panic_init();
+	if (ret <= MWR_RFAIL)
+		return ret;
+	if (!ret)
+		init_cnt = 1;
+
+	ret = sunxi_panicpart_init(&sunxi_mmc_panic_ps);
+#endif
+	return ret;
+}
+
diff --git a/drivers/mmc/host/sunxi-mmc-panic.h b/drivers/mmc/host/sunxi-mmc-panic.h
new file mode 100644
index 000000000..cdab02982
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-panic.h
@@ -0,0 +1,25 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2019 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#ifndef __SUNXI_MMC_PANIC_H__
+#define __SUNXI_MMC_PANIC_H__
+ssize_t
+sunxi_mmc_panic_rtest(struct device *dev, struct device_attribute *attr, char *buf);
+ssize_t
+sunxi_mmc_pancic_wrtest(struct device *dev, struct device_attribute *attr,
+		const char *buf, size_t count);
+int sunxi_mmc_panic_init_ps(void *data);
+#endif
diff --git a/drivers/mmc/host/sunxi-mmc-sun50iw1p1-0.c b/drivers/mmc/host/sunxi-mmc-sun50iw1p1-0.c
new file mode 100644
index 000000000..7cc824e87
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-sun50iw1p1-0.c
@@ -0,0 +1,586 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#ifdef CONFIG_ARCH_SUN50IW1P1
+
+#include <linux/clk.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/slot-gpio.h>
+
+#include "sunxi-mmc.h"
+#include "sunxi-mmc-sun50iw1p1-0.h"
+
+/*reg*/
+/*SMHC eMMC4.5 DDR Start Bit Detection Control Register */
+/*SMHC CRC Status Detect Control Register */
+/*SMHC Card Threshold Control Register */
+/*SMHC Drive Delay Control Register */
+/*SMHC Sample Delay Control Register */
+/*SMHC Data Strobe Delay Control Register */
+/*SMHC NewTiming Set Register */
+#define SDXC_REG_EDSD		(0x010C)
+#define SDXC_REG_CSDC		(0x0054)
+#define SDXC_REG_THLD		(0x0100)
+#define SDXC_REG_DRV_DL		(0x0140)
+#define SDXC_REG_SAMP_DL	(0x0144)
+#define SDXC_REG_DS_DL		(0x0148)
+#define SDXC_REG_SD_NTSR	(0x005C)
+
+/*bit*/
+#define SDXC_HS400_MD_EN				(1U<<31)
+#define SDXC_CARD_WR_THLD_ENB		(1U<<2)
+#define SDXC_CARD_RD_THLD_ENB		(1U)
+
+#define SDXC_DAT_DRV_PH_SEL			(1U<<17)
+#define SDXC_CMD_DRV_PH_SEL			(1U<<16)
+#define SDXC_SAMP_DL_SW_EN			(1u<<7)
+#define SDXC_DS_DL_SW_EN			(1u<<7)
+
+#define	SDXC_2X_TIMING_MODE			(1U<<31)
+
+/*mask*/
+#define SDXC_CRC_DET_PARA_MASK		(0xf)
+#define SDXC_CARD_RD_THLD_MASK		(0x0FFF0000)
+#define SDXC_TX_TL_MASK				(0xff)
+#define SDXC_RX_TL_MASK				(0x00FF0000)
+
+#define SDXC_SAMP_DL_SW_MASK		(0x0000003F)
+#define SDXC_DS_DL_SW_MASK			(0x0000003F)
+
+#define SDXC_SAM_TIMING_PH_MASK		(0x00000030)
+
+/*value*/
+#define SDXC_CRC_DET_PARA_HS400		(6)
+#define SDXC_CRC_DET_PARA_OTHER		(3)
+#define SDXC_FIFO_DETH					(1024>>2)
+
+/*size*/
+#define SDXC_CARD_RD_THLD_SIZE		(0x00000FFF)
+
+/*shit*/
+#define SDXC_CARD_RD_THLD_SIZE_SHIFT		(16)
+
+#define SDXC_SAM_TIMING_PH_SHIFT			(4)
+
+enum sunxi_mmc_clk_mode {
+	mmc_clk_400k = 0,
+	mmc_clk_26M,
+	mmc_clk_52M,
+	mmc_clk_52M_DDR4,
+	mmc_clk_52M_DDR8,
+	mmc_clk_104M,
+	mmc_clk_208M,
+	mmc_clk_104M_DDR,
+	mmc_clk_208M_DDR,
+	mmc_clk_mod_num,
+};
+
+struct sunxi_mmc_clk_dly {
+	enum sunxi_mmc_clk_mode cmod;
+	char *mod_str;
+	u32 cmd_drv_ph;
+	u32 dat_drv_ph;
+	u32 sam_dly;
+	u32 ds_dly;
+	u32 sam_ph;
+};
+
+	/*sample delay and output deley setting */
+static struct sunxi_mmc_clk_dly mmc_clk_dly[mmc_clk_mod_num] = {
+	[mmc_clk_400k] = {
+			  .cmod = mmc_clk_400k,
+			  .mod_str = "sunxi-dly-400k",
+			  .cmd_drv_ph = 1,
+			  .dat_drv_ph = 0,
+			  .sam_dly = 0,
+			  .ds_dly = 0,
+			  .sam_ph = 0,
+			  },
+	[mmc_clk_26M] = {
+			 .cmod = mmc_clk_26M,
+			 .mod_str = "sunxi-dly-26M",
+			 .cmd_drv_ph = 1,
+			 .dat_drv_ph = 0,
+			 .sam_dly = 0,
+			 .ds_dly = 0,
+			 .sam_ph = 0,
+			 },
+	[mmc_clk_52M] = {
+			 .cmod = mmc_clk_52M,
+			 .mod_str = "sunxi-dly-52M",
+			 .cmd_drv_ph = 1,
+			 .dat_drv_ph = 0,
+			 .sam_dly = 0,
+			 .ds_dly = 0,
+			 .sam_ph = 0,
+			 },
+	[mmc_clk_52M_DDR4] = {
+			      .cmod = mmc_clk_52M_DDR4,
+			      .mod_str = "sunxi-dly-52M-ddr4",
+			      .cmd_drv_ph = 1,
+			      .dat_drv_ph = 0,
+			      .sam_dly = 0,
+			      .ds_dly = 0,
+			      .sam_ph = 0,
+			      },
+	[mmc_clk_52M_DDR8] = {
+			      .cmod = mmc_clk_52M_DDR8,
+			      .mod_str = "sunxi-dly-52M-ddr8",
+			      .cmd_drv_ph = 1,
+			      .dat_drv_ph = 0,
+			      .sam_dly = 0,
+			      .ds_dly = 0,
+			      .sam_ph = 0,
+			      },
+	[mmc_clk_104M] = {
+			  .cmod = mmc_clk_104M,
+			  .mod_str = "sunxi-dly-104M",
+			  .cmd_drv_ph = 1,
+			  .dat_drv_ph = 0,
+			  .sam_dly = 0,
+			  .ds_dly = 0,
+			  .sam_ph = 0,
+
+			  },
+	[mmc_clk_208M] = {
+			  .cmod = mmc_clk_208M,
+			  .mod_str = "sunxi-dly-208M",
+			  .cmd_drv_ph = 1,
+			  .dat_drv_ph = 0,
+			  .sam_dly = 0,
+			  .ds_dly = 0,
+			  .sam_ph = 0,
+			  },
+	[mmc_clk_104M_DDR] = {
+			      .cmod = mmc_clk_104M_DDR,
+			      .mod_str = "sunxi-dly-104M-ddr",
+			      .cmd_drv_ph = 1,
+			      .dat_drv_ph = 0,
+			      .sam_dly = 0,
+			      .ds_dly = 0,
+			      .sam_ph = 0,
+			      },
+	[mmc_clk_208M_DDR] = {
+			      .cmod = mmc_clk_208M_DDR,
+			      .mod_str = "sunxi-dly-208M-ddr",
+			      .cmd_drv_ph = 1,
+			      .dat_drv_ph = 0,
+			      .sam_dly = 0,
+			      .ds_dly = 0,
+			      .sam_ph = 0,
+			      },
+};
+
+struct sunxi_mmc_spec_regs {
+	u32 drv_dl;		/*REG_DRV_DL */
+	u32 samp_dl;		/*REG_SAMP_DL */
+	u32 ds_dl;		/*REG_DS_DL */
+	u32 sd_ntsr;		/*REG_SD_NTSR */
+};
+
+static struct sunxi_mmc_spec_regs bak_spec_regs;
+
+
+static void sunxi_mmc_set_clk_dly(struct sunxi_mmc_host *host, int clk,
+				  int bus_width, int timing)
+{
+	struct mmc_host *mhost = host->mmc;
+	u32 rval = 0;
+	enum sunxi_mmc_clk_mode cmod = mmc_clk_400k;
+	u32 in_clk_dly[5] = { 0 };
+	int ret = 0;
+	struct device_node *np = NULL;
+
+	if (!mhost->parent || !mhost->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse clk dly,use default\n");
+		return;
+	}
+
+	np = mhost->parent->of_node;
+
+	if (clk <= 400 * 1000) {
+		cmod = mmc_clk_400k;
+	} else if (clk <= 26 * 1000 * 1000) {
+		cmod = mmc_clk_26M;
+	} else if (clk <= 52 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_4)
+		    && sunxi_mmc_ddr_timing(timing)) {
+			cmod = mmc_clk_52M_DDR4;
+		} else if ((bus_width == MMC_BUS_WIDTH_8)
+			   && (timing == MMC_TIMING_MMC_DDR52)) {
+			cmod = mmc_clk_52M_DDR8;
+		} else {
+			cmod = mmc_clk_52M;
+		}
+	} else if (clk <= 104 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_8)
+		    && (timing == MMC_TIMING_MMC_HS400)) {
+			cmod = mmc_clk_104M_DDR;
+		} else {
+			cmod = mmc_clk_104M;
+		}
+	} else if (clk <= 208 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_8)
+		    && (timing == MMC_TIMING_MMC_HS400)) {
+			cmod = mmc_clk_208M_DDR;
+		} else {
+			cmod = mmc_clk_208M;
+		}
+	} else {
+		dev_err(mmc_dev(mhost), "clk %d is out of range\n", clk);
+		return;
+	}
+
+	ret = of_property_read_u32_array(np, mmc_clk_dly[cmod].mod_str,
+					 in_clk_dly, ARRAY_SIZE(in_clk_dly));
+	if (ret) {
+		dev_dbg(mmc_dev(host->mmc), "failded to get %s used default\n",
+			mmc_clk_dly[cmod].mod_str);
+	} else {
+		mmc_clk_dly[cmod].cmd_drv_ph = in_clk_dly[0];
+		mmc_clk_dly[cmod].dat_drv_ph = in_clk_dly[1];
+		/*mmc_clk_dly[cmod].sam_dly             = in_clk_dly[2]; */
+		/*mmc_clk_dly[cmod].ds_dly              = in_clk_dly[3]; */
+		mmc_clk_dly[cmod].sam_ph = in_clk_dly[4];
+		dev_dbg(mmc_dev(host->mmc), "Get %s clk dly ok\n",
+			mmc_clk_dly[cmod].mod_str);
+
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "Try set %s clk dly       ok\n",
+		mmc_clk_dly[cmod].mod_str);
+	dev_dbg(mmc_dev(host->mmc), "cmd_drv_ph	%d\n",
+			mmc_clk_dly[cmod].cmd_drv_ph);
+	dev_dbg(mmc_dev(host->mmc), "dat_drv_ph	%d\n",
+		mmc_clk_dly[cmod].dat_drv_ph);
+	/*dev_dbg(mmc_dev(host->mmc),
+	*	"sam_dly %d\n",mmc_clk_dly[cmod].sam_dly);
+	*/
+	/*dev_dbg(mmc_dev(host->mmc),
+	*	"ds_dly  %d\n",mmc_clk_dly[cmod].ds_dly);
+	*/
+	dev_dbg(mmc_dev(host->mmc), "sam_ph	%d\n",
+		mmc_clk_dly[cmod].sam_ph);
+
+	rval = mmc_readl(host, REG_DRV_DL);
+	if (mmc_clk_dly[cmod].cmd_drv_ph)
+		rval |= SDXC_CMD_DRV_PH_SEL;	/*180 phase */
+	else
+		rval &= ~SDXC_CMD_DRV_PH_SEL;	/*90 phase */
+
+
+	if (mmc_clk_dly[cmod].dat_drv_ph)
+		rval |= SDXC_DAT_DRV_PH_SEL;	/*180 phase */
+	else
+		rval &= ~SDXC_DAT_DRV_PH_SEL;	/*90 phase */
+
+	sunxi_r_op(host, mmc_writel(host, REG_DRV_DL, rval));
+
+/*
+*	rval = mmc_readl(host,REG_SAMP_DL);
+*	rval &= ~SDXC_SAMP_DL_SW_MASK;
+*	rval |= mmc_clk_dly[cmod].sam_dly & SDXC_SAMP_DL_SW_MASK;
+*	rval |= SDXC_SAMP_DL_SW_EN;
+*	mmc_writel(host,REG_SAMP_DL,rval);
+*
+*	rval = mmc_readl(host,REG_DS_DL);
+*	rval &= ~SDXC_DS_DL_SW_MASK;
+*	rval |= mmc_clk_dly[cmod].ds_dly & SDXC_DS_DL_SW_MASK;
+*	rval |= SDXC_DS_DL_SW_EN;
+*	mmc_writel(host,REG_DS_DL,rval);
+*/
+
+	rval = mmc_readl(host, REG_SD_NTSR);
+	rval &= ~SDXC_SAM_TIMING_PH_MASK;
+	rval |=
+	    (mmc_clk_dly[cmod].
+	     sam_ph << SDXC_SAM_TIMING_PH_SHIFT) & SDXC_SAM_TIMING_PH_MASK;
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), " REG_DRV_DL    %08x\n",
+		mmc_readl(host, REG_DRV_DL));
+	dev_dbg(mmc_dev(host->mmc), " REG_SAMP_DL  %08x\n",
+		mmc_readl(host, REG_SAMP_DL));
+	dev_dbg(mmc_dev(host->mmc), " REG_DS_DL      %08x\n",
+		mmc_readl(host, REG_DS_DL));
+
+}
+
+static int __sunxi_mmc_do_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en,
+				     u32 pwr_save, u32 ignore_dat0)
+{
+	unsigned long expire = jiffies + msecs_to_jiffies(250);
+	u32 rval;
+
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~(SDXC_CARD_CLOCK_ON | SDXC_LOW_POWER_ON | SDXC_MASK_DATA0);
+
+	if (oclk_en)
+		rval |= SDXC_CARD_CLOCK_ON;
+	if (pwr_save)
+		rval |= SDXC_LOW_POWER_ON;
+	if (ignore_dat0)
+		rval |= SDXC_MASK_DATA0;
+
+	mmc_writel(host, REG_CLKCR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), "%s REG_CLKCR:%x\n", __func__,
+		mmc_readl(host, REG_CLKCR));
+
+	rval = SDXC_START | SDXC_UPCLK_ONLY | SDXC_WAIT_PRE_OVER;
+	mmc_writel(host, REG_CMDR, rval);
+
+	do {
+		rval = mmc_readl(host, REG_CMDR);
+	} while (time_before(jiffies, expire) && (rval & SDXC_START));
+
+	/* clear irq status bits set by the command */
+	/*? */
+	mmc_writel(host, REG_RINTR,
+			mmc_readl(host, REG_RINTR) & ~SDXC_SDIO_INTERRUPT);
+
+	if (rval & SDXC_START) {
+		dev_err(mmc_dev(host->mmc), "fatal err update clk timeout\n");
+		return -EIO;
+	}
+
+	/*only use mask data0 when update clk,clear it when not update clk */
+	if (ignore_dat0)
+		mmc_writel(host, REG_CLKCR,
+			   mmc_readl(host, REG_CLKCR) & ~SDXC_MASK_DATA0);
+
+	return 0;
+}
+
+static int sunxi_mmc_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en)
+{
+	struct device_node *np = NULL;
+	struct mmc_host *mmc = host->mmc;
+	int pwr_save = 0;
+	int len = 0;
+
+	if (!mmc->parent || !mmc->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse power save mode\n");
+		return -EIO;
+	}
+
+	np = mmc->parent->of_node;
+	if (of_find_property(np, "sunxi-power-save-mode", &len))
+		pwr_save = 1;
+	return __sunxi_mmc_do_oclk_onoff(host, oclk_en, pwr_save, 1);
+}
+
+int sunxi_mmc_oclk_onoff_sdmmc0(struct sunxi_mmc_host *host, u32 oclk_en)
+{
+	return sunxi_mmc_oclk_onoff(host, oclk_en);
+}
+
+static void sunxi_mmc_2xmod_onoff(struct sunxi_mmc_host *host, u32 newmode_en)
+{
+	u32 rval = mmc_readl(host, REG_SD_NTSR);
+
+	if (newmode_en)
+		rval |= SDXC_2X_TIMING_MODE;
+	else
+		rval &= ~SDXC_2X_TIMING_MODE;
+
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), "REG_SD_NTSR: 0x%08x ,val %x\n",
+		mmc_readl(host, REG_SD_NTSR), rval);
+}
+
+int sunxi_mmc_clk_set_rate_for_sdmmc0(struct sunxi_mmc_host *host,
+				      struct mmc_ios *ios)
+{
+	u32 mod_clk = 0;
+	u32 src_clk = 0;
+	u32 rval = 0;
+	s32 err = 0;
+	u32 rate = 0;
+	char *sclk_name = NULL;
+	struct clk *mclk = host->clk_mmc;
+	struct clk *sclk = NULL;
+	struct device *dev = mmc_dev(host->mmc);
+	int div = 0;
+
+	if (ios->clock == 0) {
+		__sunxi_mmc_do_oclk_onoff(host, 0, 0, 1);
+		return 0;
+	}
+
+	if (sunxi_mmc_ddr_timing(ios->timing)) {
+		mod_clk = ios->clock << 2;
+		div = 1;
+	} else {
+		mod_clk = ios->clock << 1;
+		div = 0;
+	}
+
+	if (ios->clock <= 400000) {
+		sclk = clk_get(dev, "osc24m");
+		sclk_name = "osc24m";
+	} else {
+		sclk = clk_get(dev, "pll_periph");
+		sclk_name = "pll_periph";
+	}
+	if (IS_ERR(sclk)) {
+		dev_err(mmc_dev(host->mmc), "Error to get source clock %s\n",
+			sclk_name);
+		return -1;
+	}
+
+	sunxi_mmc_oclk_onoff(host, 0);
+
+	err = clk_set_parent(mclk, sclk);
+	if (err) {
+		dev_err(mmc_dev(host->mmc), "set parent failed\n");
+		clk_put(sclk);
+		return -1;
+	}
+
+	rate = clk_round_rate(mclk, mod_clk);
+
+	dev_dbg(mmc_dev(host->mmc), "get round rate %d\n", rate);
+
+	clk_disable_unprepare(host->clk_mmc);
+
+	err = clk_set_rate(mclk, rate);
+	if (err) {
+		dev_err(mmc_dev(host->mmc), "set mclk rate error, rate %dHz\n",
+			rate);
+		clk_put(sclk);
+		return -1;
+	}
+
+	rval = clk_prepare_enable(host->clk_mmc);
+	if (rval) {
+		dev_err(mmc_dev(host->mmc), "Enable mmc clk err %d\n", rval);
+		return -1;
+	}
+
+	src_clk = clk_get_rate(sclk);
+	clk_put(sclk);
+
+	dev_dbg(mmc_dev(host->mmc), "set round clock %d, soure clk is %d\n",
+		rate, src_clk);
+
+#ifdef MMC_FPGA
+	if (sunxi_mmc_ddr_timing(ios->timing)) {
+		/* clear internal divider */
+		rval = mmc_readl(host, REG_CLKCR);
+		rval &= ~0xff;
+		rval |= 1;
+	} else {
+		/* support internal divide clock under fpga environment  */
+		rval = mmc_readl(host, REG_CLKCR);
+		rval &= ~0xff;
+		rval |= 24000000 / mod_clk / 2;	/* =24M/400K/2=0x1E */
+	}
+	mmc_writel(host, REG_CLKCR, rval);
+	dev_info(mmc_dev(host->mmc), "--FPGA REG_CLKCR: 0x%08x\n",
+		mmc_readl(host, REG_CLKCR));
+#else
+	/* clear internal divider */
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~0xff;
+	rval |= div;
+	mmc_writel(host, REG_CLKCR, rval);
+#endif
+
+	/*sunxi_of_parse_clk_dly(host); */
+	sunxi_mmc_2xmod_onoff(host, 1);
+
+	if (sunxi_mmc_ddr_timing(ios->timing))
+		ios->clock = rate >> 2;
+	else
+		ios->clock = rate >> 1;
+
+
+	sunxi_mmc_set_clk_dly(host, ios->clock, ios->bus_width, ios->timing);
+
+	return sunxi_mmc_oclk_onoff(host, 1);
+}
+
+void sunxi_mmc_thld_ctl_for_sdmmc0(struct sunxi_mmc_host *host,
+				   struct mmc_ios *ios, struct mmc_data *data)
+{
+	u32 bsz = data->blksz;
+	/*unit:byte */
+	/*u32 tdtl = (host->dma_tl & SDXC_TX_TL_MASK)<<2; */
+	/*unit:byte*/
+	u32 rdtl = ((host->dma_tl & SDXC_RX_TL_MASK) >> 16) << 2;
+	u32 rval = 0;
+
+	if ((data->flags & MMC_DATA_READ)
+	    && (bsz <= SDXC_CARD_RD_THLD_SIZE)
+	    /*((SDXC_FIFO_DETH<<2)-bsz) >= (rdtl) */
+	    && ((SDXC_FIFO_DETH << 2) >= (rdtl + bsz))
+	    && (ios->timing == MMC_TIMING_MMC_HS200)) {
+		rval = mmc_readl(host, REG_THLD);
+		rval &= ~SDXC_CARD_RD_THLD_MASK;
+		rval |= data->blksz << SDXC_CARD_RD_THLD_SIZE_SHIFT;
+		rval |= SDXC_CARD_RD_THLD_ENB;
+		mmc_writel(host, REG_THLD, rval);
+	} else {
+		rval = mmc_readl(host, REG_THLD);
+		rval &= ~SDXC_CARD_RD_THLD_ENB;
+		mmc_writel(host, REG_THLD, rval);
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "--SDXC_REG_THLD: 0x%08x\n",
+		mmc_readl(host, REG_THLD));
+
+}
+
+void sunxi_mmc_save_spec_reg0(struct sunxi_mmc_host *host)
+{
+	bak_spec_regs.drv_dl = mmc_readl(host, REG_DRV_DL);
+	bak_spec_regs.samp_dl = mmc_readl(host, REG_SAMP_DL);
+	bak_spec_regs.ds_dl = mmc_readl(host, REG_DS_DL);
+	bak_spec_regs.sd_ntsr = mmc_readl(host, REG_SD_NTSR);
+}
+
+void sunxi_mmc_restore_spec_reg0(struct sunxi_mmc_host *host)
+{
+	sunxi_r_op(host, mmc_writel(host, REG_DRV_DL, bak_spec_regs.drv_dl));
+	mmc_writel(host, REG_SAMP_DL, bak_spec_regs.samp_dl);
+	mmc_writel(host, REG_DS_DL, bak_spec_regs.ds_dl);
+	mmc_writel(host, REG_SD_NTSR, bak_spec_regs.sd_ntsr);
+}
+
+#endif
diff --git a/drivers/mmc/host/sunxi-mmc-sun50iw1p1-0.h b/drivers/mmc/host/sunxi-mmc-sun50iw1p1-0.h
new file mode 100644
index 000000000..777aaac19
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-sun50iw1p1-0.h
@@ -0,0 +1,40 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#ifdef CONFIG_ARCH_SUN50IW1P1
+
+#ifndef __SUNXI_MMC_SUN50IW1P1_0_H__
+#define __SUNXI_MMC_SUN50IW1P1_0_H__
+
+#define SUNXI_SDMMC0
+
+/*dma triger level setting*/
+#define SUNXI_DMA_TL_SDMMC0		((0x2<<28)|(7<<16)|248)
+/*one dma des can transfer data size = 1<<SUNXI_DES_SIZE_SDMMC0*/
+#define SUNXI_DES_SIZE_SDMMC0	(15)
+
+extern int sunxi_mmc_clk_set_rate_for_sdmmc0(struct sunxi_mmc_host *host,
+					     struct mmc_ios *ios);
+extern void sunxi_mmc_thld_ctl_for_sdmmc0(struct sunxi_mmc_host *host,
+					  struct mmc_ios *ios,
+					  struct mmc_data *data);
+
+void sunxi_mmc_save_spec_reg0(struct sunxi_mmc_host *host);
+void sunxi_mmc_restore_spec_reg0(struct sunxi_mmc_host *host);
+int sunxi_mmc_oclk_onoff_sdmmc0(struct sunxi_mmc_host *host, u32 oclk_en);
+#endif
+
+#endif
diff --git a/drivers/mmc/host/sunxi-mmc-sun50iw1p1-1.c b/drivers/mmc/host/sunxi-mmc-sun50iw1p1-1.c
new file mode 100644
index 000000000..16b89c675
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-sun50iw1p1-1.c
@@ -0,0 +1,580 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+
+#ifdef CONFIG_ARCH_SUN50IW1P1
+
+#include <linux/clk.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/slot-gpio.h>
+
+#include "sunxi-mmc.h"
+#include "sunxi-mmc-sun50iw1p1-1.h"
+
+/*reg*/
+/*SMHC eMMC4.5 DDR Start Bit Detection Control Register */
+/*SMHC CRC Status Detect Control Register */
+/*SMHC Card Threshold Control Register */
+/*SMHC Drive Delay Control Register */
+/*SMHC Sample Delay Control Register */
+/*SMHC Data Strobe Delay Control Register */
+/*SMHC NewTiming Set Register */
+#define SDXC_REG_EDSD		(0x010C)
+#define SDXC_REG_CSDC		(0x0054)
+#define SDXC_REG_THLD		(0x0100)
+#define SDXC_REG_DRV_DL		(0x0140)
+#define SDXC_REG_SAMP_DL	(0x0144)
+#define SDXC_REG_DS_DL		(0x0148)
+#define SDXC_REG_SD_NTSR	(0x005C)
+
+/*bit*/
+#define SDXC_HS400_MD_EN				(1U<<31)
+#define SDXC_CARD_WR_THLD_ENB		(1U<<2)
+#define SDXC_CARD_RD_THLD_ENB		(1U)
+
+#define SDXC_DAT_DRV_PH_SEL			(1U<<17)
+#define SDXC_CMD_DRV_PH_SEL			(1U<<16)
+#define SDXC_SAMP_DL_SW_EN			(1u<<7)
+#define SDXC_DS_DL_SW_EN			(1u<<7)
+
+#define	SDXC_2X_TIMING_MODE			(1U<<31)
+
+/*mask*/
+#define SDXC_CRC_DET_PARA_MASK		(0xf)
+#define SDXC_CARD_RD_THLD_MASK		(0x0FFF0000)
+#define SDXC_TX_TL_MASK				(0xff)
+#define SDXC_RX_TL_MASK				(0x00FF0000)
+
+#define SDXC_SAMP_DL_SW_MASK		(0x0000003F)
+#define SDXC_DS_DL_SW_MASK			(0x0000003F)
+
+#define SDXC_SAM_TIMING_PH_MASK		(0x00000030)
+
+/*value*/
+#define SDXC_CRC_DET_PARA_HS400		(6)
+#define SDXC_CRC_DET_PARA_OTHER		(3)
+#define SDXC_FIFO_DETH					(1024>>2)
+
+/*size*/
+#define SDXC_CARD_RD_THLD_SIZE		(0x00000FFF)
+
+/*shit*/
+#define SDXC_CARD_RD_THLD_SIZE_SHIFT		(16)
+
+#define SDXC_SAM_TIMING_PH_SHIFT			(4)
+
+enum sunxi_mmc_clk_mode {
+	mmc_clk_400k = 0,
+	mmc_clk_26M,
+	mmc_clk_52M,
+	mmc_clk_52M_DDR4,
+	mmc_clk_52M_DDR8,
+	mmc_clk_104M,
+	mmc_clk_208M,
+	mmc_clk_104M_DDR,
+	mmc_clk_208M_DDR,
+	mmc_clk_mod_num,
+};
+
+struct sunxi_mmc_clk_dly {
+	enum sunxi_mmc_clk_mode cmod;
+	char *mod_str;
+	u32 cmd_drv_ph;
+	u32 dat_drv_ph;
+	u32 sam_dly;
+	u32 ds_dly;
+	u32 sam_ph;
+};
+
+	/*sample delay and output deley setting */
+static struct sunxi_mmc_clk_dly mmc_clk_dly[mmc_clk_mod_num] = {
+	[mmc_clk_400k] = {
+			  .cmod = mmc_clk_400k,
+			  .mod_str = "sunxi-dly-400k",
+			  .cmd_drv_ph = 1,
+			  .dat_drv_ph = 0,
+			  .sam_dly = 0,
+			  .ds_dly = 0,
+			  .sam_ph = 0,
+			  },
+	[mmc_clk_26M] = {
+			 .cmod = mmc_clk_26M,
+			 .mod_str = "sunxi-dly-26M",
+			 .cmd_drv_ph = 1,
+			 .dat_drv_ph = 0,
+			 .sam_dly = 0,
+			 .ds_dly = 0,
+			 .sam_ph = 0,
+			 },
+	[mmc_clk_52M] = {
+			 .cmod = mmc_clk_52M,
+			 .mod_str = "sunxi-dly-52M",
+			 .cmd_drv_ph = 1,
+			 .dat_drv_ph = 0,
+			 .sam_dly = 0,
+			 .ds_dly = 0,
+			 .sam_ph = 0,
+			 },
+	[mmc_clk_52M_DDR4] = {
+			      .cmod = mmc_clk_52M_DDR4,
+			      .mod_str = "sunxi-dly-52M-ddr4",
+			      .cmd_drv_ph = 1,
+			      .dat_drv_ph = 0,
+			      .sam_dly = 0,
+			      .ds_dly = 0,
+			      .sam_ph = 0,
+			      },
+	[mmc_clk_52M_DDR8] = {
+			      .cmod = mmc_clk_52M_DDR8,
+			      .mod_str = "sunxi-dly-52M-ddr8",
+			      .cmd_drv_ph = 1,
+			      .dat_drv_ph = 0,
+			      .sam_dly = 0,
+			      .ds_dly = 0,
+			      .sam_ph = 0,
+			      },
+	[mmc_clk_104M] = {
+			  .cmod = mmc_clk_104M,
+			  .mod_str = "sunxi-dly-104M",
+			  .cmd_drv_ph = 1,
+			  .dat_drv_ph = 0,
+			  .sam_dly = 0,
+			  .ds_dly = 0,
+			  .sam_ph = 0,
+
+			  },
+	[mmc_clk_208M] = {
+			  .cmod = mmc_clk_208M,
+			  .mod_str = "sunxi-dly-208M",
+			  .cmd_drv_ph = 1,
+			  .dat_drv_ph = 0,
+			  .sam_dly = 0,
+			  .ds_dly = 0,
+			  .sam_ph = 0,
+			  },
+	[mmc_clk_104M_DDR] = {
+			      .cmod = mmc_clk_104M_DDR,
+			      .mod_str = "sunxi-dly-104M-ddr",
+			      .cmd_drv_ph = 1,
+			      .dat_drv_ph = 0,
+			      .sam_dly = 0,
+			      .ds_dly = 0,
+			      .sam_ph = 0,
+			      },
+	[mmc_clk_208M_DDR] = {
+			      .cmod = mmc_clk_208M_DDR,
+			      .mod_str = "sunxi-dly-208M-ddr",
+			      .cmd_drv_ph = 1,
+			      .dat_drv_ph = 0,
+			      .sam_dly = 0,
+			      .ds_dly = 0,
+			      .sam_ph = 0,
+			      },
+};
+
+struct sunxi_mmc_spec_regs {
+	u32 drv_dl;		/*REG_DRV_DL */
+	u32 samp_dl;		/*REG_SAMP_DL */
+	u32 ds_dl;		/*REG_DS_DL */
+	u32 sd_ntsr;		/*REG_SD_NTSR */
+};
+
+static struct sunxi_mmc_spec_regs bak_spec_regs;
+
+static void sunxi_mmc_set_clk_dly(struct sunxi_mmc_host *host, int clk,
+				  int bus_width, int timing)
+{
+	struct mmc_host *mhost = host->mmc;
+	u32 rval = 0;
+	enum sunxi_mmc_clk_mode cmod = mmc_clk_400k;
+	u32 in_clk_dly[5] = { 0 };
+	int ret = 0;
+	struct device_node *np = NULL;
+
+	if (!mhost->parent || !mhost->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse clk dly,use default\n");
+		return;
+	}
+
+	np = mhost->parent->of_node;
+
+	if (clk <= 400 * 1000) {
+		cmod = mmc_clk_400k;
+	} else if (clk <= 26 * 1000 * 1000) {
+		cmod = mmc_clk_26M;
+	} else if (clk <= 52 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_4)
+		    && sunxi_mmc_ddr_timing(timing)) {
+			cmod = mmc_clk_52M_DDR4;
+		} else if ((bus_width == MMC_BUS_WIDTH_8)
+			   && (timing == MMC_TIMING_MMC_DDR52)) {
+			cmod = mmc_clk_52M_DDR8;
+		} else {
+			cmod = mmc_clk_52M;
+		}
+	} else if (clk <= 104 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_8)
+		    && (timing == MMC_TIMING_MMC_HS400)) {
+			cmod = mmc_clk_104M_DDR;
+		} else {
+			cmod = mmc_clk_104M;
+		}
+	} else if (clk <= 208 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_8)
+		    && (timing == MMC_TIMING_MMC_HS400)) {
+			cmod = mmc_clk_208M_DDR;
+		} else {
+			cmod = mmc_clk_208M;
+		}
+	} else {
+		dev_err(mmc_dev(mhost), "clk %d is out of range\n", clk);
+		return;
+	}
+
+	ret = of_property_read_u32_array(np, mmc_clk_dly[cmod].mod_str,
+					 in_clk_dly, ARRAY_SIZE(in_clk_dly));
+	if (ret) {
+		dev_dbg(mmc_dev(host->mmc), "failded to get %s used default\n",
+			mmc_clk_dly[cmod].mod_str);
+	} else {
+		mmc_clk_dly[cmod].cmd_drv_ph = in_clk_dly[0];
+		mmc_clk_dly[cmod].dat_drv_ph = in_clk_dly[1];
+		/*mmc_clk_dly[cmod].sam_dly             = in_clk_dly[2]; */
+		/*mmc_clk_dly[cmod].ds_dly              = in_clk_dly[3]; */
+		mmc_clk_dly[cmod].sam_ph = in_clk_dly[4];
+		dev_dbg(mmc_dev(host->mmc), "Get %s clk dly ok\n",
+			mmc_clk_dly[cmod].mod_str);
+
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "Try set %s clk dly       ok\n",
+		mmc_clk_dly[cmod].mod_str);
+	dev_dbg(mmc_dev(host->mmc), "cmd_drv_ph	%d\n",
+		mmc_clk_dly[cmod].cmd_drv_ph);
+	dev_dbg(mmc_dev(host->mmc), "dat_drv_ph	%d\n",
+		mmc_clk_dly[cmod].dat_drv_ph);
+	dev_dbg(mmc_dev(host->mmc), "sam_ph	%d\n",
+		mmc_clk_dly[cmod].sam_ph);
+
+	rval = mmc_readl(host, REG_DRV_DL);
+	if (mmc_clk_dly[cmod].cmd_drv_ph)
+		rval |= SDXC_CMD_DRV_PH_SEL;	/*180 phase */
+	else
+		rval &= ~SDXC_CMD_DRV_PH_SEL;	/*90 phase */
+
+
+	if (mmc_clk_dly[cmod].dat_drv_ph)
+		rval |= SDXC_DAT_DRV_PH_SEL;	/*180 phase */
+	 else
+		rval &= ~SDXC_DAT_DRV_PH_SEL;	/*90 phase */
+
+	sunxi_r_op(host, mmc_writel(host, REG_DRV_DL, rval));
+
+/*
+*	rval = mmc_readl(host,REG_SAMP_DL);
+*	rval &= ~SDXC_SAMP_DL_SW_MASK;
+*	rval |= mmc_clk_dly[cmod].sam_dly & SDXC_SAMP_DL_SW_MASK;
+*	rval |= SDXC_SAMP_DL_SW_EN;
+*	mmc_writel(host,REG_SAMP_DL,rval);
+*
+*	rval = mmc_readl(host,REG_DS_DL);
+*	rval &= ~SDXC_DS_DL_SW_MASK;
+*	rval |= mmc_clk_dly[cmod].ds_dly & SDXC_DS_DL_SW_MASK;
+*	rval |= SDXC_DS_DL_SW_EN;
+*	mmc_writel(host,REG_DS_DL,rval);
+*/
+	rval = mmc_readl(host, REG_SD_NTSR);
+	rval &= ~SDXC_SAM_TIMING_PH_MASK;
+	rval |=
+	    (mmc_clk_dly[cmod].
+	     sam_ph << SDXC_SAM_TIMING_PH_SHIFT) & SDXC_SAM_TIMING_PH_MASK;
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), " REG_DRV_DL    %08x\n",
+		mmc_readl(host, REG_DRV_DL));
+	dev_dbg(mmc_dev(host->mmc), " REG_SAMP_DL  %08x\n",
+		mmc_readl(host, REG_SAMP_DL));
+	dev_dbg(mmc_dev(host->mmc), " REG_DS_DL      %08x\n",
+		mmc_readl(host, REG_DS_DL));
+
+}
+
+static int __sunxi_mmc_do_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en,
+				     u32 pwr_save, u32 ignore_dat0)
+{
+	unsigned long expire = jiffies + msecs_to_jiffies(250);
+	u32 rval;
+
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~(SDXC_CARD_CLOCK_ON | SDXC_LOW_POWER_ON | SDXC_MASK_DATA0);
+
+	if (oclk_en)
+		rval |= SDXC_CARD_CLOCK_ON;
+	if (pwr_save)
+		rval |= SDXC_LOW_POWER_ON;
+	if (ignore_dat0)
+		rval |= SDXC_MASK_DATA0;
+
+	mmc_writel(host, REG_CLKCR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), "%s REG_CLKCR:%x\n", __func__,
+		mmc_readl(host, REG_CLKCR));
+
+	rval = SDXC_START | SDXC_UPCLK_ONLY | SDXC_WAIT_PRE_OVER;
+	mmc_writel(host, REG_CMDR, rval);
+
+	do {
+		rval = mmc_readl(host, REG_CMDR);
+	} while (time_before(jiffies, expire) && (rval & SDXC_START));
+
+	/* clear irq status bits set by the command */
+	/*? */
+	mmc_writel(host, REG_RINTR,
+			mmc_readl(host, REG_RINTR) & ~SDXC_SDIO_INTERRUPT);
+
+	if (rval & SDXC_START) {
+		dev_err(mmc_dev(host->mmc), "fatal err update clk timeout\n");
+		return -EIO;
+	}
+
+	/*only use mask data0 when update clk,clear it when not update clk */
+	if (ignore_dat0)
+		mmc_writel(host, REG_CLKCR,
+			   mmc_readl(host, REG_CLKCR) & ~SDXC_MASK_DATA0);
+
+	return 0;
+}
+
+static int sunxi_mmc_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en)
+{
+	struct device_node *np = NULL;
+	struct mmc_host *mmc = host->mmc;
+	int pwr_save = 0;
+	int len = 0;
+
+	if (!mmc->parent || !mmc->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse power save mode\n");
+		return -EIO;
+	}
+
+	np = mmc->parent->of_node;
+	if (of_find_property(np, "sunxi-power-save-mode", &len))
+		pwr_save = 1;
+	return __sunxi_mmc_do_oclk_onoff(host, oclk_en, pwr_save, 1);
+}
+
+int sunxi_mmc_oclk_onoff_sdmmc1(struct sunxi_mmc_host *host, u32 oclk_en)
+{
+	return sunxi_mmc_oclk_onoff(host, oclk_en);
+}
+
+static void sunxi_mmc_2xmod_onoff(struct sunxi_mmc_host *host, u32 newmode_en)
+{
+	u32 rval = mmc_readl(host, REG_SD_NTSR);
+
+	if (newmode_en)
+		rval |= SDXC_2X_TIMING_MODE;
+	else
+		rval &= ~SDXC_2X_TIMING_MODE;
+
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), "REG_SD_NTSR: 0x%08x ,val %x\n",
+		mmc_readl(host, REG_SD_NTSR), rval);
+}
+
+int sunxi_mmc_clk_set_rate_for_sdmmc1(struct sunxi_mmc_host *host,
+				      struct mmc_ios *ios)
+{
+	u32 mod_clk = 0;
+	u32 src_clk = 0;
+	u32 rval = 0;
+	s32 err = 0;
+	u32 rate = 0;
+	char *sclk_name = NULL;
+	struct clk *mclk = host->clk_mmc;
+	struct clk *sclk = NULL;
+	struct device *dev = mmc_dev(host->mmc);
+	int div = 0;
+
+	if (ios->clock == 0) {
+		__sunxi_mmc_do_oclk_onoff(host, 0, 0, 1);
+		return 0;
+	}
+
+	if (sunxi_mmc_ddr_timing(ios->timing)) {
+		mod_clk = ios->clock << 2;
+		div = 1;
+	} else {
+		mod_clk = ios->clock << 1;
+		div = 0;
+	}
+
+	if (ios->clock <= 400000) {
+		sclk = clk_get(dev, "osc24m");
+		sclk_name = "osc24m";
+	} else {
+		sclk = clk_get(dev, "pll_periph");
+		sclk_name = "pll_periph";
+	}
+
+	if (IS_ERR(sclk)) {
+		dev_err(mmc_dev(host->mmc), "Error to get source clock %s\n",
+			sclk_name);
+		return -1;
+	}
+
+	sunxi_mmc_oclk_onoff(host, 0);
+
+	err = clk_set_parent(mclk, sclk);
+	if (err) {
+		dev_err(mmc_dev(host->mmc), "set parent failed\n");
+		clk_put(sclk);
+		return -1;
+	}
+
+	rate = clk_round_rate(mclk, mod_clk);
+
+	dev_dbg(mmc_dev(host->mmc), "get round rate %d\n", rate);
+
+	clk_disable_unprepare(host->clk_mmc);
+
+	err = clk_set_rate(mclk, rate);
+	if (err) {
+		dev_err(mmc_dev(host->mmc), "set mclk rate error, rate %dHz\n",
+			rate);
+		clk_put(sclk);
+		return -1;
+	}
+
+	rval = clk_prepare_enable(host->clk_mmc);
+	if (rval) {
+		dev_err(mmc_dev(host->mmc), "Enable mmc clk err %d\n", rval);
+		return -1;
+	}
+
+	src_clk = clk_get_rate(sclk);
+	clk_put(sclk);
+
+	dev_dbg(mmc_dev(host->mmc), "set round clock %d, soure clk is %d\n",
+		rate, src_clk);
+
+#ifdef MMC_FPGA
+	if (sunxi_mmc_ddr_timing(ios->timing)) {
+		/* clear internal divider */
+		rval = mmc_readl(host, REG_CLKCR);
+		rval &= ~0xff;
+		rval |= 1;
+	} else {
+		/* support internal divide clock under fpga environment  */
+		rval = mmc_readl(host, REG_CLKCR);
+		rval &= ~0xff;
+		rval |= 24000000 / mod_clk / 2;	/* =24M/400K/2=0x1E*/
+	}
+	mmc_writel(host, REG_CLKCR, rval);
+	dev_info(mmc_dev(host->mmc), "FPGA REG_CLKCR: 0x%08x\n",
+		mmc_readl(host, REG_CLKCR));
+#else
+	/* clear internal divider */
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~0xff;
+	rval |= div;
+	mmc_writel(host, REG_CLKCR, rval);
+#endif
+
+	/*sunxi_of_parse_clk_dly(host);*/
+	sunxi_mmc_2xmod_onoff(host, 1);
+
+	if (sunxi_mmc_ddr_timing(ios->timing))
+		ios->clock = rate >> 2;
+	else
+		ios->clock = rate >> 1;
+
+
+	sunxi_mmc_set_clk_dly(host, ios->clock, ios->bus_width, ios->timing);
+
+	return sunxi_mmc_oclk_onoff(host, 1);
+}
+
+void sunxi_mmc_thld_ctl_for_sdmmc1(struct sunxi_mmc_host *host,
+				   struct mmc_ios *ios, struct mmc_data *data)
+{
+	u32 bsz = data->blksz;
+	/*unit:byte */
+	u32 rdtl = ((host->dma_tl & SDXC_RX_TL_MASK) >> 16) << 2;
+	u32 rval = 0;
+
+	if ((data->flags & MMC_DATA_READ)
+	    && (bsz <= SDXC_CARD_RD_THLD_SIZE)
+	    /*((SDXC_FIFO_DETH<<2)-bsz) >= (rdtl)*/
+	    && ((SDXC_FIFO_DETH << 2) >= (rdtl + bsz))
+	    && ((ios->timing == MMC_TIMING_MMC_HS200)
+		|| (ios->timing == MMC_TIMING_UHS_SDR50)
+		|| (ios->timing == MMC_TIMING_UHS_SDR104))) {
+		rval = mmc_readl(host, REG_THLD);
+		rval &= ~SDXC_CARD_RD_THLD_MASK;
+		rval |= data->blksz << SDXC_CARD_RD_THLD_SIZE_SHIFT;
+		rval |= SDXC_CARD_RD_THLD_ENB;
+		mmc_writel(host, REG_THLD, rval);
+	} else {
+		rval = mmc_readl(host, REG_THLD);
+		rval &= ~SDXC_CARD_RD_THLD_ENB;
+		mmc_writel(host, REG_THLD, rval);
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "SDXC_REG_THLD: 0x%08x\n",
+		mmc_readl(host, REG_THLD));
+
+}
+
+void sunxi_mmc_save_spec_reg1(struct sunxi_mmc_host *host)
+{
+	bak_spec_regs.drv_dl = mmc_readl(host, REG_DRV_DL);
+	bak_spec_regs.samp_dl = mmc_readl(host, REG_SAMP_DL);
+	bak_spec_regs.ds_dl = mmc_readl(host, REG_DS_DL);
+	bak_spec_regs.sd_ntsr = mmc_readl(host, REG_SD_NTSR);
+}
+
+void sunxi_mmc_restore_spec_reg1(struct sunxi_mmc_host *host)
+{
+	sunxi_r_op(host, mmc_writel(host, REG_DRV_DL, bak_spec_regs.drv_dl));
+	mmc_writel(host, REG_SAMP_DL, bak_spec_regs.samp_dl);
+	mmc_writel(host, REG_DS_DL, bak_spec_regs.ds_dl);
+	mmc_writel(host, REG_SD_NTSR, bak_spec_regs.sd_ntsr);
+}
+
+#endif
diff --git a/drivers/mmc/host/sunxi-mmc-sun50iw1p1-1.h b/drivers/mmc/host/sunxi-mmc-sun50iw1p1-1.h
new file mode 100644
index 000000000..3cbce069a
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-sun50iw1p1-1.h
@@ -0,0 +1,40 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+
+#ifdef CONFIG_ARCH_SUN50IW1P1
+
+#ifndef __SUNXI_MMC_SUN50IW1P1_1_H__
+#define __SUNXI_MMC_SUN50IW1P1_1_H__
+
+#define SUNXI_SDMMC1
+
+#define SUNXI_DMA_TL_SDMMC1 ((0x3<<28)|(15<<16)|240)
+/*one dma des can transfer data size = 1<<SUNXI_DES_SIZE_SDMMC1*/
+#define SUNXI_DES_SIZE_SDMMC1	(15)
+
+extern int sunxi_mmc_clk_set_rate_for_sdmmc1(struct sunxi_mmc_host *host,
+					     struct mmc_ios *ios);
+extern void sunxi_mmc_thld_ctl_for_sdmmc1(struct sunxi_mmc_host *host,
+					  struct mmc_ios *ios,
+					  struct mmc_data *data);
+
+void sunxi_mmc_save_spec_reg1(struct sunxi_mmc_host *host);
+void sunxi_mmc_restore_spec_reg1(struct sunxi_mmc_host *host);
+int sunxi_mmc_oclk_onoff_sdmmc1(struct sunxi_mmc_host *host, u32 oclk_en);
+#endif
+
+#endif
diff --git a/drivers/mmc/host/sunxi-mmc-sun50iw1p1-2.c b/drivers/mmc/host/sunxi-mmc-sun50iw1p1-2.c
new file mode 100644
index 000000000..aa100b941
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-sun50iw1p1-2.c
@@ -0,0 +1,629 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+
+#ifdef CONFIG_ARCH_SUN50IW1P1
+
+#include <linux/clk.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/slot-gpio.h>
+
+#include "sunxi-mmc.h"
+#include "sunxi-mmc-sun50iw1p1-2.h"
+
+/*reg*/
+/*SMHC eMMC4.5 DDR Start Bit Detection Control Register */
+/*SMHC CRC Status Detect Control Register */
+/*SMHC Card Threshold Control Register */
+/*SMHC Drive Delay Control Register */
+/*SMHC Sample Delay Control Register */
+/*SMHC Data Strobe Delay Control Register */
+#define SDXC_REG_EDSD		(0x010C)
+#define SDXC_REG_CSDC		(0x0054)
+#define SDXC_REG_THLD		(0x0100)
+#define SDXC_REG_DRV_DL		(0x0140)
+#define SDXC_REG_SAMP_DL	(0x0144)
+#define SDXC_REG_DS_DL		(0x0148)
+
+/*bit*/
+#define SDXC_HS400_MD_EN				(1U<<31)
+#define SDXC_CARD_WR_THLD_ENB		(1U<<2)
+#define SDXC_CARD_RD_THLD_ENB		(1U)
+
+#define SDXC_DAT_DRV_PH_SEL			(1U<<17)
+#define SDXC_CMD_DRV_PH_SEL			(1U<<16)
+#define SDXC_SAMP_DL_SW_EN			(1u<<7)
+#define SDXC_DS_DL_SW_EN			(1u<<7)
+
+/*mask*/
+#define SDXC_CRC_DET_PARA_MASK		(0xf)
+#define SDXC_CARD_RD_THLD_MASK		(0x0FFF0000)
+#define SDXC_TX_TL_MASK				(0xff)
+#define SDXC_RX_TL_MASK				(0x00FF0000)
+
+#define SDXC_SAMP_DL_SW_MASK		(0x0000003F)
+#define SDXC_DS_DL_SW_MASK			(0x0000003F)
+
+/*value*/
+#define SDXC_CRC_DET_PARA_HS400		(6)
+#define SDXC_CRC_DET_PARA_OTHER		(3)
+#define SDXC_FIFO_DETH					(1024>>2)
+
+/*size*/
+#define SDXC_CARD_RD_THLD_SIZE		(0x00000FFF)
+
+/*shit*/
+#define SDXC_CARD_RD_THLD_SIZE_SHIFT		(16)
+
+struct sunxi_mmc_spec_regs {
+	u32 drv_dl;		/*REG_DRV_DL */
+	u32 samp_dl;		/*REG_SAMP_DL */
+	u32 ds_dl;		/*REG_DS_DL */
+	/*u32 sd_ntsr;//REG_SD_NTSR */
+	u32 edsd;		/*REG_EDSD */
+	u32 csdc;		/*REG_CSDC */
+};
+
+static struct sunxi_mmc_spec_regs bak_spec_regs;
+
+enum sunxi_mmc_speed_mode {
+	SM0_DS26_SDR12 = 0,
+	SM1_HSSDR52_SDR25,
+	SM2_HSDDR52_DDR50,
+	SM3_HS200_SDR104,
+	SM4_HS400,
+	SM_NUM,
+};
+
+struct sunxi_mmc_clk_dly {
+	enum sunxi_mmc_speed_mode spm;
+	char *mod_str;
+	char *raw_tm_sm_str[2];
+	u32 raw_tm_sm[2];
+	u32 raw_tm_sm_def[2];
+};
+
+static struct sunxi_mmc_clk_dly mmc_clk_dly[SM_NUM] = {
+	[SM0_DS26_SDR12] = {
+			    .spm = SM0_DS26_SDR12,
+			    .mod_str = "DS26_SDR12",
+			    .raw_tm_sm_str[0] = "sdc_tm4_sm0_freq0",
+			    .raw_tm_sm_str[1] = "sdc_tm4_sm0_freq1",
+			    .raw_tm_sm[0] = 0,
+			    .raw_tm_sm[1] = 0,
+			    .raw_tm_sm_def[0] = 0,
+			    .raw_tm_sm_def[1] = 0,
+			    },
+	[SM1_HSSDR52_SDR25] = {
+			       .spm = SM1_HSSDR52_SDR25,
+			       .mod_str = "HSSDR52_SDR25",
+			       .raw_tm_sm_str[0] = "sdc_tm4_sm1_freq0",
+			       .raw_tm_sm_str[1] = "sdc_tm4_sm1_freq1",
+			       .raw_tm_sm[0] = 0,
+			       .raw_tm_sm[1] = 0,
+			       .raw_tm_sm_def[0] = 0,
+			       .raw_tm_sm_def[1] = 0,
+			       },
+	[SM2_HSDDR52_DDR50] = {
+			       .spm = SM2_HSDDR52_DDR50,
+			       .mod_str = "HSDDR52_DDR50",
+			       .raw_tm_sm_str[0] = "sdc_tm4_sm2_freq0",
+			       .raw_tm_sm_str[1] = "sdc_tm4_sm2_freq1",
+			       .raw_tm_sm[0] = 0,
+			       .raw_tm_sm[1] = 0,
+			       .raw_tm_sm_def[0] = 0,
+			       .raw_tm_sm_def[1] = 0,
+			       },
+	[SM3_HS200_SDR104] = {
+			      .spm = SM3_HS200_SDR104,
+			      .mod_str = "HS200_SDR104",
+			      .raw_tm_sm_str[0] = "sdc_tm4_sm3_freq0",
+			      .raw_tm_sm_str[1] = "sdc_tm4_sm3_freq1",
+			      .raw_tm_sm[0] = 0,
+			      .raw_tm_sm[1] = 0,
+			      .raw_tm_sm_def[0] = 0,
+			      .raw_tm_sm_def[1] = 0x00000405,
+			      },
+	[SM4_HS400] = {
+		       .spm = SM4_HS400,
+		       .mod_str = "HS400",
+		       .raw_tm_sm_str[0] = "sdc_tm4_sm4_freq0",
+		       .raw_tm_sm_str[1] = "sdc_tm4_sm4_freq1",
+		       .raw_tm_sm[0] = 0,
+		       .raw_tm_sm[1] = 0x00000608,
+		       .raw_tm_sm_def[0] = 0,
+		       .raw_tm_sm_def[1] = 0x00000408,
+		       },
+};
+
+static void sunxi_mmc_set_clk_dly(struct sunxi_mmc_host *host, int clk,
+				  int bus_width, int timing)
+{
+	struct mmc_host *mmc = host->mmc;
+	enum sunxi_mmc_speed_mode speed_mod = SM0_DS26_SDR12;
+	char *raw_sm_str = NULL;
+	char *m_str = NULL;
+	struct device_node *np = NULL;
+	u32 *raw_sm = 0;
+	u32 *raw_sm_def = 0;
+	u32 rval = 0;
+	int frq_index = 0;
+	u32 cmd_drv_ph = 1;
+	u32 dat_drv_ph = 0;
+	u32 sam_dly = 0;
+	u32 ds_dly = 0;
+
+	if (!mmc->parent || !mmc->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse clk dly,use default\n");
+		return;
+	}
+
+	np = mmc->parent->of_node;
+
+	switch (timing) {
+	case MMC_TIMING_LEGACY:
+	case MMC_TIMING_UHS_SDR12:
+		speed_mod = SM0_DS26_SDR12;
+		break;
+	case MMC_TIMING_MMC_HS:
+	case MMC_TIMING_SD_HS:
+	case MMC_TIMING_UHS_SDR25:
+		speed_mod = SM1_HSSDR52_SDR25;
+		break;
+	case MMC_TIMING_UHS_DDR50:
+	case MMC_TIMING_MMC_DDR52:
+		speed_mod = SM2_HSDDR52_DDR50;
+		dat_drv_ph = 1;
+		break;
+	case MMC_TIMING_UHS_SDR50:
+	case MMC_TIMING_UHS_SDR104:
+	case MMC_TIMING_MMC_HS200:
+		speed_mod = SM3_HS200_SDR104;
+		break;
+	case MMC_TIMING_MMC_HS400:
+		speed_mod = SM4_HS400;
+		break;
+	default:
+		dev_err(mmc_dev(mmc), "Wrong timing input\n");
+		return;
+	}
+
+	if (clk <= 400 * 1000) {
+		frq_index = 0;
+	} else if (clk <= 25 * 1000 * 1000) {
+		frq_index = 1;
+	} else if (clk <= 50 * 1000 * 1000) {
+		frq_index = 2;
+	} else if (clk <= 100 * 1000 * 1000) {
+		frq_index = 3;
+	} else if (clk <= 150 * 1000 * 1000) {
+		frq_index = 4;
+	} else if (clk <= 200 * 1000 * 1000) {
+		frq_index = 5;
+	} else if (clk <= 250 * 1000 * 1000) {
+		frq_index = 6;
+	} else if (clk <= 300 * 1000 * 1000) {
+		frq_index = 7;
+	} else {
+		dev_err(mmc_dev(mmc), "clk is over 300mhz\n");
+		return;
+	}
+
+	if (frq_index / 4 > 2) {
+		dev_err(mmc_dev(host->mmc), "err frq_index\n");
+		return;
+	}
+	dev_dbg(mmc_dev(host->mmc), "freq %d frq index %d,frq/4 %x\n", clk,
+		frq_index, frq_index / 4);
+	raw_sm_str = mmc_clk_dly[speed_mod].raw_tm_sm_str[frq_index / 4];
+	raw_sm = &mmc_clk_dly[speed_mod].raw_tm_sm[frq_index / 4];
+	raw_sm_def = &mmc_clk_dly[speed_mod].raw_tm_sm_def[frq_index / 4];
+	m_str = mmc_clk_dly[speed_mod].mod_str;
+
+	rval = of_property_read_u32(np, raw_sm_str, raw_sm);
+	if (rval) {
+		dev_info(mmc_dev(host->mmc), "failded to get %s used default\n",
+			 m_str);
+	} else {
+		u32 sm_shift = (frq_index % 4) * 8;
+
+		rval = ((*raw_sm) >> sm_shift) & 0xff;
+		if (rval != 0xff) {
+			if (timing == MMC_TIMING_MMC_HS400) {
+				u32 raw_sm_hs200 = 0;
+
+				ds_dly = rval;
+				raw_sm_hs200 =
+				    mmc_clk_dly[SM3_HS200_SDR104].
+				    raw_tm_sm[frq_index / 4];
+				sam_dly = ((raw_sm_hs200) >> sm_shift) & 0xff;
+			} else {
+				sam_dly = rval;
+			}
+			dev_dbg(mmc_dev(host->mmc),
+				"Get speed mode %s clk dly %s ok\n", m_str,
+				raw_sm_str);
+		} else {
+			u32 sm_shift = (frq_index % 4) * 8;
+
+			dev_dbg(mmc_dev(host->mmc), "%s use default value\n",
+				m_str);
+			rval = ((*raw_sm_def) >> sm_shift) & 0xff;
+			if (timing == MMC_TIMING_MMC_HS400) {
+				u32 raw_sm_hs200 = 0;
+
+				ds_dly = rval;
+				raw_sm_hs200 =
+				    mmc_clk_dly[SM3_HS200_SDR104].
+				    raw_tm_sm_def[frq_index / 4];
+				sam_dly = ((raw_sm_hs200) >> sm_shift) & 0xff;
+			} else {
+				sam_dly = rval;
+			}
+		}
+
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "Try set %s clk dly	ok\n", m_str);
+	dev_dbg(mmc_dev(host->mmc), "cmd_drv_ph	%d\n", cmd_drv_ph);
+	dev_dbg(mmc_dev(host->mmc), "dat_drv_ph	%d\n", dat_drv_ph);
+	dev_dbg(mmc_dev(host->mmc), "sam_dly	%d\n", sam_dly);
+	dev_dbg(mmc_dev(host->mmc), "ds_dly		%d\n", ds_dly);
+
+	rval = mmc_readl(host, REG_DRV_DL);
+	if (cmd_drv_ph)
+		rval |= SDXC_CMD_DRV_PH_SEL;	/*180 phase */
+	else
+		rval &= ~SDXC_CMD_DRV_PH_SEL;	/*90 phase */
+
+
+	if (dat_drv_ph)
+		rval |= SDXC_DAT_DRV_PH_SEL;	/*180 phase */
+	else
+		rval &= ~SDXC_DAT_DRV_PH_SEL;	/*90 phase */
+
+	sunxi_r_op(host, mmc_writel(host, REG_DRV_DL, rval));
+
+	rval = mmc_readl(host, REG_SAMP_DL);
+	rval &= ~SDXC_SAMP_DL_SW_MASK;
+	rval |= sam_dly & SDXC_SAMP_DL_SW_MASK;
+	rval |= SDXC_SAMP_DL_SW_EN;
+	mmc_writel(host, REG_SAMP_DL, rval);
+
+	rval = mmc_readl(host, REG_DS_DL);
+	rval &= ~SDXC_DS_DL_SW_MASK;
+	rval |= ds_dly & SDXC_DS_DL_SW_MASK;
+	rval |= SDXC_DS_DL_SW_EN;
+	mmc_writel(host, REG_DS_DL, rval);
+
+	dev_dbg(mmc_dev(host->mmc), " REG_DRV_DL    %08x\n",
+		mmc_readl(host, REG_DRV_DL));
+	dev_dbg(mmc_dev(host->mmc), " REG_SAMP_DL  %08x\n",
+		mmc_readl(host, REG_SAMP_DL));
+	dev_dbg(mmc_dev(host->mmc), " REG_DS_DL      %08x\n",
+		mmc_readl(host, REG_DS_DL));
+
+}
+
+void sunxi_mmc_dump_dly2(struct sunxi_mmc_host *host)
+{
+	int i = 0;
+
+	for (i = 0; i < SM_NUM; i++) {
+		pr_info("mod_str %s\n", mmc_clk_dly[i].mod_str);
+		pr_info("raw_tm_sm_str %s\n", mmc_clk_dly[i].raw_tm_sm_str[0]);
+		pr_info("raw_tm_sm_str %s\n", mmc_clk_dly[i].raw_tm_sm_str[1]);
+		pr_info("raw_tm_sm0 %x\n", mmc_clk_dly[i].raw_tm_sm[0]);
+		pr_info("raw_tm_sm1 %x\n", mmc_clk_dly[i].raw_tm_sm[1]);
+		pr_info("********************\n");
+	}
+}
+
+static int __sunxi_mmc_do_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en,
+				     u32 pwr_save, u32 ignore_dat0)
+{
+	unsigned long expire = jiffies + msecs_to_jiffies(250);
+	u32 rval;
+
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~(SDXC_CARD_CLOCK_ON | SDXC_LOW_POWER_ON | SDXC_MASK_DATA0);
+
+	if (oclk_en)
+		rval |= SDXC_CARD_CLOCK_ON;
+	if (pwr_save)
+		rval |= SDXC_LOW_POWER_ON;
+	if (ignore_dat0)
+		rval |= SDXC_MASK_DATA0;
+
+	mmc_writel(host, REG_CLKCR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), "%s REG_CLKCR:%x\n", __func__,
+		mmc_readl(host, REG_CLKCR));
+
+	rval = SDXC_START | SDXC_UPCLK_ONLY | SDXC_WAIT_PRE_OVER;
+	mmc_writel(host, REG_CMDR, rval);
+
+	do {
+		rval = mmc_readl(host, REG_CMDR);
+	} while (time_before(jiffies, expire) && (rval & SDXC_START));
+
+	/* clear irq status bits set by the command */
+	/*? */
+	mmc_writel(host, REG_RINTR,
+			mmc_readl(host, REG_RINTR) & ~SDXC_SDIO_INTERRUPT);
+
+	if (rval & SDXC_START) {
+		dev_err(mmc_dev(host->mmc), "fatal err update clk timeout\n");
+		return -EIO;
+	}
+
+	/*only use mask data0 when update clk,clear it when not update clk */
+	if (ignore_dat0)
+		mmc_writel(host, REG_CLKCR,
+			   mmc_readl(host, REG_CLKCR) & ~SDXC_MASK_DATA0);
+
+	return 0;
+}
+
+static int sunxi_mmc_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en)
+{
+	struct device_node *np = NULL;
+	struct mmc_host *mmc = host->mmc;
+	int pwr_save = 0;
+	int len = 0;
+
+	if (!mmc->parent || !mmc->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse power save mode\n");
+		return -EIO;
+	}
+
+	np = mmc->parent->of_node;
+	if (of_find_property(np, "sunxi-power-save-mode", &len))
+		pwr_save = 1;
+	return __sunxi_mmc_do_oclk_onoff(host, oclk_en, pwr_save, 1);
+}
+
+int sunxi_mmc_oclk_onoff_sdmmc2(struct sunxi_mmc_host *host, u32 oclk_en)
+{
+	return sunxi_mmc_oclk_onoff(host, oclk_en);
+}
+
+int sunxi_mmc_clk_set_rate_for_sdmmc2(struct sunxi_mmc_host *host,
+				      struct mmc_ios *ios)
+{
+	u32 mod_clk = 0;
+	u32 src_clk = 0;
+	u32 rval = 0;
+	s32 err = 0;
+	u32 rate = 0;
+	char *sclk_name = NULL;
+	struct clk *mclk = host->clk_mmc;
+	struct clk *sclk = NULL;
+	struct device *dev = mmc_dev(host->mmc);
+	int div = 0;
+
+	if (ios->clock == 0) {
+		__sunxi_mmc_do_oclk_onoff(host, 0, 0, 1);
+		return 0;
+	}
+
+	if ((ios->bus_width == MMC_BUS_WIDTH_8)
+	    && (ios->timing == MMC_TIMING_MMC_DDR52)
+	    ) {
+		mod_clk = ios->clock << 2;
+		div = 1;
+	} else {
+		mod_clk = ios->clock << 1;
+		div = 0;
+	}
+
+	if (ios->clock <= 400000) {
+		sclk = clk_get(dev, "osc24m");
+		sclk_name = "osc24m";
+	} else {
+		sclk = clk_get(dev, "pll_periph");
+		sclk_name = "pll_periph";
+	}
+	if (IS_ERR(sclk)) {
+		dev_err(mmc_dev(host->mmc), "Error to get source clock %s\n",
+			sclk_name);
+		return -1;
+	}
+
+	sunxi_mmc_oclk_onoff(host, 0);
+
+	err = clk_set_parent(mclk, sclk);
+	if (err) {
+		dev_err(mmc_dev(host->mmc), "set parent failed\n");
+		clk_put(sclk);
+		return -1;
+	}
+
+	rate = clk_round_rate(mclk, mod_clk);
+
+	dev_dbg(mmc_dev(host->mmc), "get round rate %d\n", rate);
+
+	clk_disable_unprepare(host->clk_mmc);
+
+	err = clk_set_rate(mclk, rate);
+	if (err) {
+		dev_err(mmc_dev(host->mmc), "set mclk rate error, rate %dHz\n",
+			rate);
+		clk_put(sclk);
+		return -1;
+	}
+
+	rval = clk_prepare_enable(host->clk_mmc);
+	if (rval) {
+		dev_err(mmc_dev(host->mmc), "Enable mmc clk err %d\n", rval);
+		return -1;
+	}
+
+	src_clk = clk_get_rate(sclk);
+	clk_put(sclk);
+
+	dev_dbg(mmc_dev(host->mmc), "set round clock %d, soure clk is %d\n",
+		rate, src_clk);
+
+#ifdef MMC_FPGA
+	if ((ios->bus_width == MMC_BUS_WIDTH_8)
+	    && (ios->timing == MMC_TIMING_MMC_DDR52)
+	    ) {
+		/* clear internal divider */
+		rval = mmc_readl(host, REG_CLKCR);
+		rval &= ~0xff;
+		rval |= 1;
+	} else {
+		/* support internal divide clock under fpga environment  */
+		rval = mmc_readl(host, REG_CLKCR);
+		rval &= ~0xff;
+		rval |= 24000000 / mod_clk / 2;	/* =24M/400K/2=0x1E*/
+	}
+	mmc_writel(host, REG_CLKCR, rval);
+		dev_info(mmc_dev(host->mmc), "--FPGA REG_CLKCR: 0x%08x\n",
+	mmc_readl(host, REG_CLKCR));
+#else
+	/* clear internal divider */
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~0xff;
+	rval |= div;
+	mmc_writel(host, REG_CLKCR, rval);
+#endif
+
+	if ((ios->bus_width == MMC_BUS_WIDTH_8)
+	    && (ios->timing == MMC_TIMING_MMC_HS400)
+	    ) {
+		rval = mmc_readl(host, REG_EDSD);
+		rval |= SDXC_HS400_MD_EN;
+		mmc_writel(host, REG_EDSD, rval);
+		rval = mmc_readl(host, REG_CSDC);
+		rval &= ~SDXC_CRC_DET_PARA_MASK;
+		rval |= SDXC_CRC_DET_PARA_HS400;
+		mmc_writel(host, REG_CSDC, rval);
+	} else {
+		rval = mmc_readl(host, REG_EDSD);
+		rval &= ~SDXC_HS400_MD_EN;
+		mmc_writel(host, REG_EDSD, rval);
+		rval = mmc_readl(host, REG_CSDC);
+		rval &= ~SDXC_CRC_DET_PARA_MASK;
+		rval |= SDXC_CRC_DET_PARA_OTHER;
+		mmc_writel(host, REG_CSDC, rval);
+	}
+	dev_dbg(mmc_dev(host->mmc), "SDXC_REG_EDSD: 0x%08x\n",
+		mmc_readl(host, REG_EDSD));
+	dev_dbg(mmc_dev(host->mmc), "SDXC_REG_CSDC: 0x%08x\n",
+		mmc_readl(host, REG_CSDC));
+
+	if ((ios->bus_width == MMC_BUS_WIDTH_8)
+	    && (ios->timing == MMC_TIMING_MMC_DDR52)
+	    ) {
+		ios->clock = rate >> 2;
+	} else {
+		ios->clock = rate >> 1;
+	}
+
+	sunxi_mmc_set_clk_dly(host, ios->clock, ios->bus_width, ios->timing);
+
+	return sunxi_mmc_oclk_onoff(host, 1);
+}
+
+void sunxi_mmc_thld_ctl_for_sdmmc2(struct sunxi_mmc_host *host,
+				   struct mmc_ios *ios, struct mmc_data *data)
+{
+	u32 bsz = data->blksz;
+	/*unit:byte */
+	u32 tdtl = (host->dma_tl & SDXC_TX_TL_MASK) << 2;
+	/*unit:byte */
+	u32 rdtl = ((host->dma_tl & SDXC_RX_TL_MASK) >> 16) << 2;
+	u32 rval = 0;
+
+	if ((data->flags & MMC_DATA_WRITE)
+	    && (bsz <= SDXC_CARD_RD_THLD_SIZE)
+	    && (bsz <= tdtl)) {
+		rval = mmc_readl(host, REG_THLD);
+		rval &= ~SDXC_CARD_RD_THLD_MASK;
+		rval |= data->blksz << SDXC_CARD_RD_THLD_SIZE_SHIFT;
+		rval |= SDXC_CARD_WR_THLD_ENB;
+		mmc_writel(host, REG_THLD, rval);
+	} else {
+		rval = mmc_readl(host, REG_THLD);
+		rval &= ~SDXC_CARD_WR_THLD_ENB;
+		mmc_writel(host, REG_THLD, rval);
+	}
+
+	if ((data->flags & MMC_DATA_READ)
+	    && (bsz <= SDXC_CARD_RD_THLD_SIZE)
+	    /*((SDXC_FIFO_DETH<<2)-bsz) >= (rdtl) */
+	    && ((SDXC_FIFO_DETH << 2) >= (rdtl + bsz))
+	    && ((ios->timing == MMC_TIMING_MMC_HS200)
+	       || (ios->timing == MMC_TIMING_MMC_HS400))) {
+		rval = mmc_readl(host, REG_THLD);
+		rval &= ~SDXC_CARD_RD_THLD_MASK;
+		rval |= data->blksz << SDXC_CARD_RD_THLD_SIZE_SHIFT;
+		rval |= SDXC_CARD_RD_THLD_ENB;
+		mmc_writel(host, REG_THLD, rval);
+	} else {
+		rval = mmc_readl(host, REG_THLD);
+		rval &= ~SDXC_CARD_RD_THLD_ENB;
+		mmc_writel(host, REG_THLD, rval);
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "--SDXC_REG_THLD: 0x%08x\n",
+		mmc_readl(host, REG_THLD));
+
+}
+
+void sunxi_mmc_save_spec_reg2(struct sunxi_mmc_host *host)
+{
+	bak_spec_regs.drv_dl = mmc_readl(host, REG_DRV_DL);
+	bak_spec_regs.samp_dl = mmc_readl(host, REG_SAMP_DL);
+	bak_spec_regs.ds_dl = mmc_readl(host, REG_DS_DL);
+	/*bak_spec_regs.sd_ntsr = mmc_readl(host,REG_SD_NTSR);*/
+	bak_spec_regs.edsd = mmc_readl(host, REG_EDSD);
+	bak_spec_regs.csdc = mmc_readl(host, REG_CSDC);
+}
+
+void sunxi_mmc_restore_spec_reg2(struct sunxi_mmc_host *host)
+{
+	sunxi_r_op(host, mmc_writel(host, REG_DRV_DL, bak_spec_regs.drv_dl));
+	mmc_writel(host, REG_SAMP_DL, bak_spec_regs.samp_dl);
+	mmc_writel(host, REG_DS_DL, bak_spec_regs.ds_dl);
+	/*mmc_writel(host,REG_SD_NTSR,bak_spec_regs.sd_ntsr);*/
+	mmc_writel(host, REG_EDSD, bak_spec_regs.edsd);
+	mmc_writel(host, REG_CSDC, bak_spec_regs.csdc);
+}
+#endif
diff --git a/drivers/mmc/host/sunxi-mmc-sun50iw1p1-2.h b/drivers/mmc/host/sunxi-mmc-sun50iw1p1-2.h
new file mode 100644
index 000000000..48840d2c4
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-sun50iw1p1-2.h
@@ -0,0 +1,47 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#ifdef CONFIG_ARCH_SUN50IW1P1
+
+#ifndef __SUNXI_MMC_SUN50IW1P1_2_H__
+#define __SUNXI_MMC_SUN50IW1P1_2_H__
+
+#define SUNXI_SDMMC2
+
+#define SUNXI_DMA_TL_SDMMC2		((0x3<<28)|(15<<16)|240)
+/*one dma des can transfer data size = 1<<SUNXI_DES_SIZE_SDMMC2*/
+#define SUNXI_DES_SIZE_SDMMC2	(12)
+
+extern int sunxi_mmc_clk_set_rate_for_sdmmc2(struct sunxi_mmc_host *host,
+					     struct mmc_ios *ios);
+extern void sunxi_mmc_thld_ctl_for_sdmmc2(struct sunxi_mmc_host *host,
+					  struct mmc_ios *ios,
+					  struct mmc_data *data);
+
+void sunxi_mmc_save_spec_reg2(struct sunxi_mmc_host *host);
+void sunxi_mmc_restore_spec_reg2(struct sunxi_mmc_host *host);
+void sunxi_mmc_dump_dly2(struct sunxi_mmc_host *host);
+void sunxi_mmc_do_shutdown2(struct platform_device *pdev);
+int sunxi_mmc_oclk_onoff_sdmmc2(struct sunxi_mmc_host *host, u32 oclk_en);
+
+extern int mmc_card_sleep(struct mmc_host *host);
+extern int mmc_deselect_cards(struct mmc_host *host);
+extern void mmc_power_off(struct mmc_host *host);
+extern int mmc_card_sleepawake(struct mmc_host *host, int sleep);
+
+#endif
+
+#endif
diff --git a/drivers/mmc/host/sunxi-mmc-v4p00x.c b/drivers/mmc/host/sunxi-mmc-v4p00x.c
new file mode 100644
index 000000000..e442d5cfd
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-v4p00x.c
@@ -0,0 +1,465 @@
+/*
+* SUNXI EMMC/SD driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lijuan <lijuan@allwinnertech.com>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#include <linux/clk.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/slot-gpio.h>
+
+#include "sunxi-mmc.h"
+#include "sunxi-mmc-v4p00x.h"
+#include "sunxi-mmc-export.h"
+#include "sunxi-mmc-debug.h"
+
+#define MMC_SRCCLK_PLL	"pll_periph"
+#define MMC_SRCCLK_HOSC	"hosc"
+#define SUNXI_RETRY_CNT_PER_PHA_V4P00X		3
+
+/*dma triger level setting*/
+#define SUNXI_DMA_TL_SDMMC_V4P0X	((0x2<<28)|(7<<16)|16)
+/*one dma des can transfer data size = 1<<SUNXI_DES_SIZE_SDMMC*/
+#define SUNXI_DES_SIZE_SDMMC_V4P0X	(15)
+
+/*reg*/
+#define CCMU_BASE_ADDR		(0x1c20000)
+
+/*bit*/
+#define	SDXC_2X_TIMING_MODE			(1U<<31)
+
+/*mask*/
+#define SDXC_TX_TL_MASK				(0x0f)
+#define SDXC_RX_TL_MASK				(0x000F0000)
+#define SDXC_STIMING_PH_MASK		(0x00700000)
+#define SDXC_DRV_PH_MASK		(0x00000700)
+
+/*shift*/
+#define SDXC_STIMING_PH_SHIFT			(20)
+#define SDXC_DRV_PH_SHIFT			(8)
+
+enum sunxi_mmc_clk_mode {
+	mmc_clk_400k = 0,
+	mmc_clk_26M,
+	mmc_clk_52M,
+	mmc_clk_52M_DDR4,
+	mmc_clk_52M_DDR8,
+	mmc_clk_104M,
+	mmc_clk_208M,
+	mmc_clk_104M_DDR,
+	mmc_clk_208M_DDR,
+	mmc_clk_mod_num,
+};
+
+struct sunxi_mmc_clk_dly {
+	enum sunxi_mmc_clk_mode cmod;
+	char *mod_str;
+	u32 drv_ph;
+	u32 sam_ph;
+};
+
+
+struct sunxi_mmc_spec_regs {
+	u32 sd_ccmu;
+};
+
+struct sunxi_mmc_ver_priv {
+	struct sunxi_mmc_spec_regs bak_spec_regs;
+	struct sunxi_mmc_clk_dly mmc_clk_dly[mmc_clk_mod_num];
+};
+
+static void sunxi_mmc_set_clk_dly(struct sunxi_mmc_host *host, int clk,
+				  int bus_width, int timing)
+{
+	struct mmc_host *mhost = host->mmc;
+	u32 rval = 0;
+	enum sunxi_mmc_clk_mode cmod = mmc_clk_400k;
+	u32 in_clk_dly[5] = { 0 };
+	int ret = 0;
+	struct device_node *np = NULL;
+	void __iomem *ccmu_ptr = NULL;
+	struct sunxi_mmc_clk_dly *mmc_clk_dly =
+	    ((struct sunxi_mmc_ver_priv *)host->version_priv_dat)->mmc_clk_dly;
+
+	if (!mhost->parent || !mhost->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse clk dly,use default\n");
+		return;
+	}
+
+	np = mhost->parent->of_node;
+
+	if (clk <= 400 * 1000) {
+		cmod = mmc_clk_400k;
+	} else if (clk <= 26 * 1000 * 1000) {
+		cmod = mmc_clk_26M;
+	} else if (clk <= 52 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_4)
+		    && (timing == MMC_TIMING_UHS_DDR50)) {
+			cmod = mmc_clk_52M_DDR4;
+		} else if ((bus_width == MMC_BUS_WIDTH_8)
+			   && (timing == MMC_TIMING_UHS_DDR50)) {
+			cmod = mmc_clk_52M_DDR8;
+		} else {
+			cmod = mmc_clk_52M;
+		}
+	} else if (clk <= 104 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_8)
+		    && (timing == MMC_TIMING_MMC_HS400)) {
+			cmod = mmc_clk_104M_DDR;
+		} else {
+			cmod = mmc_clk_104M;
+		}
+	} else if (clk <= 208 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_8)
+		    && (timing == MMC_TIMING_MMC_HS400)) {
+			cmod = mmc_clk_208M_DDR;
+		} else {
+			cmod = mmc_clk_208M;
+		}
+	} else {
+		dev_err(mmc_dev(mhost), "clk %d is out of range\n", clk);
+		return;
+	}
+
+	ret = of_property_read_u32_array(np, mmc_clk_dly[cmod].mod_str,
+					 in_clk_dly, ARRAY_SIZE(in_clk_dly));
+	if (ret) {
+		dev_dbg(mmc_dev(host->mmc), "failed to get %s used default\n",
+			mmc_clk_dly[cmod].mod_str);
+	} else {
+		mmc_clk_dly[cmod].drv_ph = in_clk_dly[0];
+		/*mmc_clk_dly[cmod].sam_dly = in_clk_dly[2];*/
+		/*mmc_clk_dly[cmod].ds_dly =in_clk_dly[3];*/
+		mmc_clk_dly[cmod].sam_ph = in_clk_dly[4];
+		dev_dbg(mmc_dev(host->mmc), "Get %s clk dly ok\n",
+		mmc_clk_dly[cmod].mod_str);
+	}
+	dev_dbg(mmc_dev(host->mmc), "Try set %s clk dly	ok\n",
+		mmc_clk_dly[cmod].mod_str);
+	dev_dbg(mmc_dev(host->mmc), "drv_ph %d\n",
+		mmc_clk_dly[cmod].drv_ph);
+	dev_dbg(mmc_dev(host->mmc), "sam_ph %d\n",
+		mmc_clk_dly[cmod].sam_ph);
+
+/*
+*	rval = mmc_readl(host,REG_SAMP_DL);
+*	rval &= ~SDXC_SAMP_DL_SW_MASK;
+*	rval |= mmc_clk_dly[cmod].sam_dly & SDXC_SAMP_DL_SW_MASK;
+*	rval |= SDXC_SAMP_DL_SW_EN;
+*	mmc_writel(host,REG_SAMP_DL,rval);
+
+*	rval = mmc_readl(host,REG_DS_DL);
+*	rval &= ~SDXC_DS_DL_SW_MASK;
+*	rval |= mmc_clk_dly[cmod].ds_dly & SDXC_DS_DL_SW_MASK;
+*	rval |= SDXC_DS_DL_SW_EN;
+*	mmc_writel(host,REG_DS_DL,rval);
+*/
+	ccmu_ptr =  ioremap(CCMU_BASE_ADDR+0x88+0x4*
+							(host->phy_index), 0x4);
+	rval = readl(ccmu_ptr);
+	rval &= ~SDXC_DRV_PH_MASK;
+	rval |=
+	    (mmc_clk_dly[cmod].
+	     drv_ph << SDXC_DRV_PH_SHIFT) & SDXC_DRV_PH_MASK;
+	writel(rval, ccmu_ptr);
+	rval = readl(ccmu_ptr);
+	rval &= ~SDXC_STIMING_PH_MASK;
+	rval |=
+	    (mmc_clk_dly[cmod].
+	     sam_ph << SDXC_STIMING_PH_SHIFT) & SDXC_STIMING_PH_MASK;
+	writel(rval, ccmu_ptr);
+	dev_dbg(mmc_dev(host->mmc), " CCMU_BASE_ADDR %08x\n",
+		readl(ccmu_ptr));
+	iounmap(ccmu_ptr);
+
+}
+
+static int __sunxi_mmc_do_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en,
+				     u32 pwr_save, u32 ignore_dat0)
+{
+	unsigned long expire = jiffies + msecs_to_jiffies(250);
+	u32 rval;
+
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~(SDXC_CARD_CLOCK_ON | SDXC_LOW_POWER_ON | SDXC_MASK_DATA0);
+
+	if (oclk_en)
+		rval |= SDXC_CARD_CLOCK_ON;
+	if (pwr_save)
+		rval |= SDXC_LOW_POWER_ON;
+	if (ignore_dat0)
+		rval |= SDXC_MASK_DATA0;
+
+	mmc_writel(host, REG_CLKCR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), "%s REG_CLKCR:%x\n", __func__,
+		mmc_readl(host, REG_CLKCR));
+
+	rval = SDXC_START | SDXC_UPCLK_ONLY | SDXC_WAIT_PRE_OVER;
+	mmc_writel(host, REG_CMDR, rval);
+
+	do {
+		rval = mmc_readl(host, REG_CMDR);
+	} while (time_before(jiffies, expire) && (rval & SDXC_START));
+
+	/* clear irq status bits set by the command */
+	mmc_writel(host, REG_RINTR,
+		mmc_readl(host, REG_RINTR) & ~SDXC_SDIO_INTERRUPT);
+
+	if (rval & SDXC_START) {
+		dev_err(mmc_dev(host->mmc), "fatal err update clk timeout\n");
+		return -EIO;
+	}
+
+	/*only use mask data0 when update clk,clear it when not update clk */
+	if (ignore_dat0)
+		mmc_writel(host, REG_CLKCR,
+			   mmc_readl(host, REG_CLKCR) & ~SDXC_MASK_DATA0);
+
+	return 0;
+}
+
+static int sunxi_mmc_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en)
+{
+	struct device_node *np = NULL;
+	struct mmc_host *mmc = host->mmc;
+	int pwr_save = 0;
+	int len = 0;
+
+	if (!mmc->parent || !mmc->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse power save mode\n");
+		return -EIO;
+	}
+
+	np = mmc->parent->of_node;
+	if (of_find_property(np, "sunxi-power-save-mode", &len))
+		pwr_save = 1;
+	return __sunxi_mmc_do_oclk_onoff(host, oclk_en, pwr_save, 1);
+}
+
+static int sunxi_mmc_clk_set_rate_for_sdmmc_v4p00x(
+	struct sunxi_mmc_host *host, struct mmc_ios *ios)
+{
+	u32 mod_clk = 0;
+	u32 src_clk = 0;
+	u32 rval1 = 0;
+	s32 err = 0;
+	u32 rate = 0;
+	char *sclk_name = NULL;
+	struct clk *sclk = NULL;
+	struct device *dev = mmc_dev(host->mmc);
+
+	if (ios->clock == 0) {
+		__sunxi_mmc_do_oclk_onoff(host, 0, 0, 1);
+		return 0;
+	}
+
+	mod_clk = ios->clock;
+
+	if (ios->clock <= 400000) {
+		sclk_name = MMC_SRCCLK_HOSC;
+		sclk = clk_get(dev, sclk_name);
+	} else {
+		sclk_name = MMC_SRCCLK_PLL;
+		sclk = clk_get(dev, sclk_name);
+	}
+	if ((sclk == NULL) || IS_ERR(sclk)) {
+		dev_err(mmc_dev(host->mmc),
+			"Error to get source clock %s %ld\n",
+			sclk_name, (long)sclk);
+		return -1;
+	}
+
+
+	err = clk_set_parent(host->clk_mmc, sclk);
+
+	rate = clk_round_rate(host->clk_mmc, mod_clk);
+
+	dev_dbg(mmc_dev(host->mmc), "get round rate %d\n", rate);
+
+	/*clk_disable_unprepare(host->clk_mmc);	*/
+	/*sunxi_dump_reg(NULL);*/
+	err = clk_set_rate(host->clk_mmc, rate);
+	if (err) {
+		dev_err(mmc_dev(host->mmc),
+			"set mclk rate error, rate %dHz\n", rate);
+		clk_put(sclk);
+		return -1;
+	}
+
+	/*
+	*rval1 = clk_prepare_enable(host->clk_mmc);
+	*if (rval1) {
+	*	dev_err(mmc_dev(host->mmc), "Enable mmc clk err %d\n", rval1);
+	*	return -1;
+	*}
+	*/
+	/*sunxi_dump_reg(NULL);*/
+	src_clk = clk_get_rate(sclk);
+	clk_put(sclk);
+
+	rval1 = mmc_readl(host, REG_CLKCR);
+	rval1 &= ~0xff;
+	mmc_writel(host, REG_CLKCR, rval1);
+
+	dev_dbg(mmc_dev(host->mmc),
+		"set round clock %d, soure clk is %d\n",
+		rate, src_clk);
+
+	sunxi_mmc_set_clk_dly(host, ios->clock, ios->bus_width, ios->timing);
+	return sunxi_mmc_oclk_onoff(host, 1);
+}
+
+static void sunxi_mmc_save_spec_reg_v4p00x(struct sunxi_mmc_host *host)
+{
+	struct sunxi_mmc_spec_regs *spec_regs =
+	    &((struct sunxi_mmc_ver_priv *)(host->version_priv_dat))->
+	    bak_spec_regs;
+	void __iomem *ccmu_ptr =  ioremap(CCMU_BASE_ADDR + 0x88
+		+ 0x4 * (host->phy_index), 0x4);
+
+	spec_regs->sd_ccmu = readl(ccmu_ptr);
+	iounmap(ccmu_ptr);
+}
+
+static void sunxi_mmc_restore_spec_reg_v4p00x(struct sunxi_mmc_host *host)
+{
+	struct sunxi_mmc_spec_regs *spec_regs =
+	    &((struct sunxi_mmc_ver_priv *)(host->version_priv_dat))->
+	    bak_spec_regs;
+	void __iomem *ccmu_ptr =  ioremap(CCMU_BASE_ADDR + 0x88
+		+ 0x4 * (host->phy_index), 0x4);
+
+	writel(spec_regs->sd_ccmu, ccmu_ptr);
+	iounmap(ccmu_ptr);
+}
+
+static inline void sunxi_mmc_set_dly_raw(struct sunxi_mmc_host *host,
+		s32 opha, s32 ipha)
+{
+	void __iomem *ccmu_ptr =  ioremap(CCMU_BASE_ADDR + 0x88
+		+ 0x4 * (host->phy_index), 0x4);
+	u32 rval =  readl(ccmu_ptr);
+
+	if (ipha >= 0) {
+		rval &= ~SDXC_STIMING_PH_MASK;
+		rval |= (ipha << SDXC_STIMING_PH_SHIFT) & SDXC_STIMING_PH_MASK;
+	}
+
+	if (opha >= 0) {
+		rval &= ~SDXC_DRV_PH_MASK;
+		rval |= (opha << SDXC_DRV_PH_SHIFT) & SDXC_DRV_PH_MASK;
+	}
+
+	writel(rval, ccmu_ptr);
+	dev_info(mmc_dev(host->mmc), "CCMU_BASE_ADDR: 0x%08x\n",
+		readl(ccmu_ptr));
+	iounmap(ccmu_ptr);
+}
+
+
+static int sunxi_mmc_judge_retry_v4p00x(
+	struct sunxi_mmc_host *host, struct mmc_command *cmd,
+	u32 rcnt, u32 errno, void *other)
+{
+
+	const s32 sunxi_phase[10][2] = {{-1, -1}, {1, 1},
+			{0, 0}, {1, 0}, {0, 1}, {1, 2}, {0, 2} };
+
+	if (rcnt < (SUNXI_RETRY_CNT_PER_PHA_V4P00X*10)) {
+		sunxi_mmc_set_dly_raw(host,
+			sunxi_phase[rcnt/SUNXI_RETRY_CNT_PER_PHA_V4P00X][0],
+			sunxi_phase[rcnt/SUNXI_RETRY_CNT_PER_PHA_V4P00X][1]);
+	} else {
+		sunxi_mmc_set_dly_raw(host, sunxi_phase[0][0],
+							sunxi_phase[0][1]);
+		dev_info(mmc_dev(host->mmc), "sunxi v4p00x retry give up\n");
+		return -1;
+	}
+	return 0;
+}
+
+void sunxi_mmc_init_priv_v4p00x(struct sunxi_mmc_host *host,
+			       struct platform_device *pdev, int phy_index)
+{
+	struct sunxi_mmc_ver_priv *ver_priv =
+	    devm_kzalloc(&pdev->dev, sizeof(struct sunxi_mmc_ver_priv),
+			 GFP_KERNEL);
+	host->version_priv_dat = ver_priv;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].cmod = mmc_clk_400k;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].mod_str = "sunxi-dly-400k";
+	ver_priv->mmc_clk_dly[mmc_clk_400k].drv_ph = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].sam_ph = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].cmod = mmc_clk_26M;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].mod_str = "sunxi-dly-26M";
+	ver_priv->mmc_clk_dly[mmc_clk_26M].drv_ph = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].sam_ph = 5;
+	ver_priv->mmc_clk_dly[mmc_clk_52M].cmod = mmc_clk_52M,
+	ver_priv->mmc_clk_dly[mmc_clk_52M].mod_str = "sunxi-dly-52M";
+	ver_priv->mmc_clk_dly[mmc_clk_52M].drv_ph = 3;
+	ver_priv->mmc_clk_dly[mmc_clk_52M].sam_ph = 4;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].cmod = mmc_clk_52M_DDR4;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].mod_str =
+		"sunxi-dly-52M-ddr4";
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].drv_ph = 2;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].sam_ph = 4;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].cmod = mmc_clk_52M_DDR8;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].mod_str =
+		"sunxi-dly-52M-ddr8";
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].drv_ph = 2;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].sam_ph = 4;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].cmod = mmc_clk_104M;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].mod_str =
+		"sunxi-dly-104M";
+	ver_priv->mmc_clk_dly[mmc_clk_104M].drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].sam_ph = 4;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].cmod = mmc_clk_208M;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].mod_str =
+		"sunxi-dly-208M";
+	ver_priv->mmc_clk_dly[mmc_clk_208M].drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].sam_ph = 4;
+	host->sunxi_mmc_clk_set_rate = sunxi_mmc_clk_set_rate_for_sdmmc_v4p00x;
+	host->dma_tl = SUNXI_DMA_TL_SDMMC_V4P0X;
+	host->idma_des_size_bits = SUNXI_DES_SIZE_SDMMC_V4P0X;
+	host->sunxi_mmc_thld_ctl = NULL;
+	host->sunxi_mmc_save_spec_reg = sunxi_mmc_save_spec_reg_v4p00x;
+	host->sunxi_mmc_restore_spec_reg = sunxi_mmc_restore_spec_reg_v4p00x;
+	sunxi_mmc_reg_ex_res_inter(host, phy_index);
+	host->sunxi_mmc_set_acmda = sunxi_mmc_set_a12a;
+	host->phy_index = phy_index;
+	host->sunxi_mmc_oclk_en = sunxi_mmc_oclk_onoff;
+	host->sunxi_mmc_judge_retry = sunxi_mmc_judge_retry_v4p00x;
+	/*sunxi_of_parse_clk_dly(host);*/
+}
+EXPORT_SYMBOL_GPL(sunxi_mmc_init_priv_v4p00x);
diff --git a/drivers/mmc/host/sunxi-mmc-v4p00x.h b/drivers/mmc/host/sunxi-mmc-v4p00x.h
new file mode 100644
index 000000000..6f1e0ae38
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-v4p00x.h
@@ -0,0 +1,23 @@
+/*
+* SUNXI EMMC/SD driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lijuan <lijuan@allwinnertech.com>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#ifndef __SUNXI_MMC_V4P00X_H__
+#define __SUNXI_MMC_V4P00X_H__
+
+void sunxi_mmc_init_priv_v4p00x(struct sunxi_mmc_host *host,
+			       struct platform_device *pdev, int phy_index);
+#endif
+
diff --git a/drivers/mmc/host/sunxi-mmc-v4p10x.c b/drivers/mmc/host/sunxi-mmc-v4p10x.c
new file mode 100644
index 000000000..10044ad07
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-v4p10x.c
@@ -0,0 +1,579 @@
+/*
+* SUNXI EMMC/SD driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lijuan <lijuan@allwinnertech.com>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#include <linux/clk.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/sunxi-gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/slot-gpio.h>
+
+#include "sunxi-mmc.h"
+#include "sunxi-mmc-v4p10x.h"
+#include "sunxi-mmc-export.h"
+#include "sunxi-mmc-debug.h"
+
+
+
+#define MMC_2MOD_CLK	"sdmmc2mod"
+#define MMC_SRCCLK_PLL	"pll_periph"
+#define MMC_SRCCLK_HOSC	"hosc"
+#define SUNXI_RETRY_CNT_PER_PHA_V4P1X		3
+
+/*dma triger level setting*/
+#define SUNXI_DMA_TL_SDMMC_V4P1X	((0x2<<28)|(7<<16)|16)
+/*one dma des can transfer data size = 1<<SUNXI_DES_SIZE_SDMMC*/
+#define SUNXI_DES_SIZE_SDMMC_V4P1X	(15)
+
+/*reg*/
+#define SDXC_REG_SD_NTSR	(0x005C)
+/*bit*/
+#define	SDXC_2X_TIMING_MODE			(1U<<31)
+
+
+/*mask*/
+#define SDXC_TX_TL_MASK				(0x1f)
+#define SDXC_RX_TL_MASK				(0x001F0000)
+#define SDXC_STIMING_PH_MASK		(0x00000030)
+#define SDXC_DRV_PH_MASK		(0x00000003)
+
+/*shift*/
+#define SDXC_STIMING_PH_SHIFT			(4)
+#define SDXC_DRV_PH_SHIFT			(0)
+
+enum sunxi_mmc_clk_mode {
+	mmc_clk_400k = 0,
+	mmc_clk_26M,
+	mmc_clk_52M,
+	mmc_clk_52M_DDR4,
+	mmc_clk_52M_DDR8,
+	mmc_clk_104M,
+	mmc_clk_208M,
+	mmc_clk_104M_DDR,
+	mmc_clk_208M_DDR,
+	mmc_clk_mod_num,
+};
+
+struct sunxi_mmc_clk_dly {
+	enum sunxi_mmc_clk_mode cmod;
+	char *mod_str;
+	u32 drv_ph;
+	u32 sam_ph;
+};
+
+
+/*sample delay and output deley setting */
+
+struct sunxi_mmc_spec_regs {
+	u32 sd_ntsr;		/*REG_SD_NTSR*/
+
+};
+
+struct sunxi_mmc_ver_priv {
+	struct sunxi_mmc_spec_regs bak_spec_regs;
+	struct sunxi_mmc_clk_dly mmc_clk_dly[mmc_clk_mod_num];
+};
+
+
+static void sunxi_mmc_set_clk_dly(struct sunxi_mmc_host *host, int clk,
+				  int bus_width, int timing)
+{
+	struct mmc_host *mhost = host->mmc;
+	u32 rval = 0;
+	enum sunxi_mmc_clk_mode cmod = mmc_clk_400k;
+	u32 in_clk_dly[5] = { 0 };
+	int ret = 0;
+	struct device_node *np = NULL;
+	struct sunxi_mmc_clk_dly *mmc_clk_dly =
+	    ((struct sunxi_mmc_ver_priv *)host->version_priv_dat)->mmc_clk_dly;
+
+	if (!mhost->parent || !mhost->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse clk dly,use default\n");
+		return;
+	}
+
+	np = mhost->parent->of_node;
+
+	if (clk <= 400 * 1000) {
+		cmod = mmc_clk_400k;
+	} else if (clk <= 26 * 1000 * 1000) {
+		cmod = mmc_clk_26M;
+	} else if (clk <= 52 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_4)
+		    && sunxi_mmc_ddr_timing(timing)) {
+			cmod = mmc_clk_52M_DDR4;
+		} else if ((bus_width == MMC_BUS_WIDTH_8)
+			   && (timing == MMC_TIMING_MMC_DDR52)) {
+			cmod = mmc_clk_52M_DDR8;
+		} else {
+			cmod = mmc_clk_52M;
+		}
+	} else if (clk <= 104 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_8)
+		    && (timing == MMC_TIMING_MMC_HS400)) {
+			cmod = mmc_clk_104M_DDR;
+		} else {
+			cmod = mmc_clk_104M;
+		}
+	} else if (clk <= 208 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_8)
+		    && (timing == MMC_TIMING_MMC_HS400)) {
+			cmod = mmc_clk_208M_DDR;
+		} else {
+			cmod = mmc_clk_208M;
+		}
+	} else {
+		dev_err(mmc_dev(mhost), "clk %d is out of range\n", clk);
+		return;
+	}
+
+	ret = of_property_read_u32_array(np, mmc_clk_dly[cmod].mod_str,
+					 in_clk_dly, ARRAY_SIZE(in_clk_dly));
+	if (ret) {
+		dev_dbg(mmc_dev(host->mmc), "failed to get %s used default\n",
+			mmc_clk_dly[cmod].mod_str);
+	} else {
+		mmc_clk_dly[cmod].drv_ph = in_clk_dly[0];
+		/*mmc_clk_dly[cmod].sam_dly = in_clk_dly[2];*/
+		/*mmc_clk_dly[cmod].ds_dly = in_clk_dly[3];*/
+		mmc_clk_dly[cmod].sam_ph = in_clk_dly[3];
+		dev_dbg(mmc_dev(host->mmc), "Get %s clk dly ok\n",
+		mmc_clk_dly[cmod].mod_str);
+	}
+	dev_dbg(mmc_dev(host->mmc), "Try set %s clk dly ok\n",
+		mmc_clk_dly[cmod].mod_str);
+	dev_dbg(mmc_dev(host->mmc), "drv_ph %d\n",
+		mmc_clk_dly[cmod].drv_ph);
+	dev_dbg(mmc_dev(host->mmc), "sam_ph %d\n",
+		mmc_clk_dly[cmod].sam_ph);
+
+/*
+*		rval = mmc_readl(host,REG_SAMP_DL);
+*		rval &= ~SDXC_SAMP_DL_SW_MASK;
+*		rval |= mmc_clk_dly[cmod].sam_dly & SDXC_SAMP_DL_SW_MASK;
+*		rval |= SDXC_SAMP_DL_SW_EN;
+*		mmc_writel(host,REG_SAMP_DL,rval);
+
+*		rval = mmc_readl(host,REG_DS_DL);
+*		rval &= ~SDXC_DS_DL_SW_MASK;
+*		rval |= mmc_clk_dly[cmod].ds_dly & SDXC_DS_DL_SW_MASK;
+*		rval |= SDXC_DS_DL_SW_EN;
+*		mmc_writel(host,REG_DS_DL,rval);
+*/
+
+	rval = mmc_readl(host, REG_SD_NTSR);
+	rval &= ~SDXC_DRV_PH_MASK;
+	rval |=
+	    (mmc_clk_dly[cmod].
+	     drv_ph << SDXC_DRV_PH_SHIFT) & SDXC_DRV_PH_MASK;
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	rval = mmc_readl(host, REG_SD_NTSR);
+	rval &= ~SDXC_STIMING_PH_MASK;
+	rval |=
+	    (mmc_clk_dly[cmod].
+	     sam_ph << SDXC_STIMING_PH_SHIFT) & SDXC_STIMING_PH_MASK;
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), "REG_SD_NTSR %08x\n",
+		mmc_readl(host, REG_SD_NTSR));
+
+}
+
+static int __sunxi_mmc_do_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en,
+				     u32 pwr_save, u32 ignore_dat0)
+{
+	unsigned long expire = jiffies + msecs_to_jiffies(250);
+	u32 rval;
+
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~(SDXC_CARD_CLOCK_ON | SDXC_LOW_POWER_ON | SDXC_MASK_DATA0);
+
+	if (oclk_en)
+		rval |= SDXC_CARD_CLOCK_ON;
+	if (pwr_save)
+		rval |= SDXC_LOW_POWER_ON;
+	if (ignore_dat0)
+		rval |= SDXC_MASK_DATA0;
+
+	mmc_writel(host, REG_CLKCR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), "%s REG_CLKCR:%x\n", __func__,
+		mmc_readl(host, REG_CLKCR));
+
+	rval = SDXC_START | SDXC_UPCLK_ONLY | SDXC_WAIT_PRE_OVER;
+	mmc_writel(host, REG_CMDR, rval);
+
+	do {
+		rval = mmc_readl(host, REG_CMDR);
+	} while (time_before(jiffies, expire) && (rval & SDXC_START));
+
+	/* clear irq status bits set by the command */
+	mmc_writel(host, REG_RINTR,
+		mmc_readl(host, REG_RINTR) & ~SDXC_SDIO_INTERRUPT);
+
+	if (rval & SDXC_START) {
+		dev_err(mmc_dev(host->mmc), "fatal err update clk timeout\n");
+		return -EIO;
+	}
+
+	/*only use mask data0 when update clk,clear it when not update clk */
+	if (ignore_dat0)
+		mmc_writel(host, REG_CLKCR,
+			   mmc_readl(host, REG_CLKCR) & ~SDXC_MASK_DATA0);
+
+	return 0;
+}
+
+static int sunxi_mmc_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en)
+{
+	struct device_node *np = NULL;
+	struct mmc_host *mmc = host->mmc;
+	int pwr_save = 0;
+	int len = 0;
+
+	if (!mmc->parent || !mmc->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse power save mode\n");
+		return -EIO;
+	}
+
+	np = mmc->parent->of_node;
+	if (of_find_property(np, "sunxi-power-save-mode", &len))
+		pwr_save = 1;
+	return __sunxi_mmc_do_oclk_onoff(host, oclk_en, pwr_save, 1);
+}
+
+static int sunxi_mmc_updata_pha_v4p10x(struct sunxi_mmc_host *host,
+		struct mmc_command *cmd, struct mmc_data *data)
+{
+	return sunxi_mmc_oclk_onoff(host, 1);
+}
+
+static void sunxi_mmc_2xmod_onoff(struct sunxi_mmc_host *host, u32 newmode_en)
+{
+	u32 rval = mmc_readl(host, REG_SD_NTSR);
+
+	if (newmode_en)
+		rval |= SDXC_2X_TIMING_MODE;
+	else
+		rval &= ~SDXC_2X_TIMING_MODE;
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), "REG_SD_NTSR: 0x%08x ,val %x\n",
+		mmc_readl(host, REG_SD_NTSR), rval);
+}
+static int sunxi_mmc_clk_set_rate_for_sdmmc_v4p10x(
+	struct sunxi_mmc_host *host, struct mmc_ios *ios)
+{
+	u32 mod_clk = 0;
+	u32 src_clk = 0;
+	u32 rval = 0;
+	u32 rval1 = 0;
+	s32 err = 0;
+	u32 rate = 0;
+	u32 clk = 0;
+	u32 source_rate = 0;
+	u32 sdmmc2mod_rate = 0;
+	char *sclk_name = NULL;
+	struct clk *sclk = NULL;
+	struct clk *mclk2 = NULL;
+	struct device *dev = mmc_dev(host->mmc);
+
+	if (ios->clock == 0) {
+		__sunxi_mmc_do_oclk_onoff(host, 0, 0, 1);
+		return 0;
+	}
+	if (sunxi_mmc_ddr_timing(ios->timing))
+		mod_clk = ios->clock << 1;
+	else
+		mod_clk = ios->clock;
+
+	if (ios->clock <= 400000) {
+		sclk_name = MMC_SRCCLK_HOSC;
+		sclk = clk_get(dev, sclk_name);
+	} else {
+		sclk_name = MMC_SRCCLK_PLL;
+		sclk = clk_get(dev, sclk_name);
+	}
+	if ((sclk == NULL) || IS_ERR(sclk)) {
+		dev_err(mmc_dev(host->mmc),
+			"Error to get source clock %s %ld\n",
+			sclk_name, (long)sclk);
+		return -1;
+	}
+	sunxi_mmc_2xmod_onoff(host, 1);
+	mclk2 = clk_get(dev, MMC_2MOD_CLK);
+
+	if (IS_ERR_OR_NULL(mclk2)) {
+		dev_err(mmc_dev(host->mmc),
+		"Error to get source clock for clk %dHz\n", clk);
+		return -1;
+	}
+
+	err = clk_set_parent(mclk2, sclk);
+
+	source_rate = clk_get_rate(sclk);
+	sdmmc2mod_rate = source_rate/2;
+	clk_set_rate(mclk2, sdmmc2mod_rate);
+
+	clk_put(mclk2);
+	if (err) {
+		clk_put(mclk2);
+		return -1;
+	}
+
+	rate = clk_round_rate(host->clk_mmc, mod_clk);
+	dev_dbg(mmc_dev(host->mmc), "get round rate %d\n", rate);
+
+	clk_disable_unprepare(host->clk_mmc);
+	/* sunxi_dump_reg(NULL); */
+
+	err = clk_set_rate(host->clk_mmc, rate);
+	if (err) {
+		dev_err(mmc_dev(host->mmc),
+			"set mclk rate error, rate %dHz\n",
+			rate);
+		clk_put(sclk);
+		return -1;
+	}
+
+	rval1 = clk_prepare_enable(host->clk_mmc);
+	if (rval1) {
+		dev_err(mmc_dev(host->mmc),
+			"Enable mmc clk err %d\n", rval1);
+		return -1;
+	}
+
+	/* sunxi_dump_reg(NULL); */
+	src_clk = clk_get_rate(sclk);
+	clk_put(sclk);
+
+	dev_dbg(mmc_dev(host->mmc),
+		"set round clock %d, soure clk is %d\n",
+		rate, src_clk);
+
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~0xff;
+	if (sunxi_mmc_ddr_timing(ios->timing)) {
+		rval |= 1;
+		ios->clock = rate >> 1;
+		clk = ios->clock;
+		dev_dbg(mmc_dev(host->mmc), "card clk%d\n", clk);
+	} else {
+		ios->clock = rate;
+		clk = ios->clock;
+	}
+	mmc_writel(host, REG_CLKCR, rval);
+	sunxi_mmc_set_clk_dly(host, ios->clock, ios->bus_width, ios->timing);
+	return sunxi_mmc_oclk_onoff(host, 1);
+}
+
+static void sunxi_mmc_save_spec_reg_v4p10x(struct sunxi_mmc_host *host)
+{
+	struct sunxi_mmc_spec_regs *spec_regs = NULL;
+
+	spec_regs = &((struct sunxi_mmc_ver_priv *)(host->version_priv_dat))
+					->bak_spec_regs;
+
+	spec_regs->sd_ntsr = mmc_readl(host, REG_SD_NTSR);
+}
+
+static void sunxi_mmc_restore_spec_reg_v4p10x(struct sunxi_mmc_host *host)
+{
+	struct sunxi_mmc_spec_regs *spec_regs = NULL;
+
+	spec_regs = &((struct sunxi_mmc_ver_priv *)(host->version_priv_dat))
+						->bak_spec_regs;
+
+	mmc_writel(host, REG_SD_NTSR, spec_regs->sd_ntsr);
+}
+
+static inline void sunxi_mmc_set_dly_raw(
+	struct sunxi_mmc_host *host,
+			s32 opha, s32 ipha)
+{
+	u32 rval =  mmc_readl(host, REG_SD_NTSR);
+
+	if (ipha >= 0) {
+		rval &= ~SDXC_STIMING_PH_MASK;
+		rval |= (ipha << SDXC_STIMING_PH_SHIFT) & SDXC_STIMING_PH_MASK;
+	}
+
+	if (opha >= 0) {
+		rval &= ~SDXC_DRV_PH_MASK;
+		rval |= (opha << SDXC_DRV_PH_SHIFT) & SDXC_DRV_PH_MASK;
+	}
+
+	rval &= ~SDXC_2X_TIMING_MODE;
+	mmc_writel(host, REG_SD_NTSR, rval);
+	rval |= SDXC_2X_TIMING_MODE;
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	dev_info(mmc_dev(host->mmc), "REG_SD_NTSR: 0x%08x\n",
+		mmc_readl(host, REG_SD_NTSR));
+}
+
+static int sunxi_mmc_judge_retry_v4p10x(
+	struct sunxi_mmc_host *host,
+	struct mmc_command *cmd, u32 rcnt,
+	u32 errno, void *other)
+{
+
+	const s32 sunxi_phase[10][2] = {{-1, -1},
+		{1, 1}, {0, 0}, {1, 0}, {0, 1},
+		{1, 2}, {0, 2} };
+
+	if (rcnt < (SUNXI_RETRY_CNT_PER_PHA_V4P1X*10)) {
+		sunxi_mmc_set_dly_raw(host,
+			sunxi_phase[rcnt/SUNXI_RETRY_CNT_PER_PHA_V4P1X][0],
+			sunxi_phase[rcnt/SUNXI_RETRY_CNT_PER_PHA_V4P1X][1]);
+	} else {
+		sunxi_mmc_set_dly_raw(host, sunxi_phase[0][0],
+							sunxi_phase[0][1]);
+		dev_info(mmc_dev(host->mmc), "sunxi v4p10x retry give up\n");
+		return -1;
+	}
+	return 0;
+}
+
+static bool sunxi_mmc_hw_busy_v4p10x(struct sunxi_mmc_host *host)
+{
+	/**if use v4p10x sdmc, all use dat0-gpio check card busy status*/
+	if (host->sunxi_mmc_dat0_busy)
+		return true;
+
+	return false;
+}
+
+static int sunxi_mmc_dat0_busy_v4p10x(struct sunxi_mmc_host *host)
+{
+	struct device_node *np;
+	struct mmc_host *mmc = host->mmc;
+	unsigned long config_set;
+	unsigned long config_get = 0;
+	struct gpio_config gpio_flags;
+	int gpio;
+
+	if (!mmc->parent || !mmc->parent->of_node)
+		return 0;
+
+	np = mmc->parent->of_node;
+	gpio = of_get_named_gpio_flags(np, "dat0-gpios", 0,
+					(enum of_gpio_flags *)&gpio_flags);
+	if (!gpio_is_valid(gpio))
+		pr_err("mmc:failed to get dat0-gpios\n");
+	else {
+		/***********change gpio func to input*************/
+		config_set = pinconf_to_config_packed((enum pin_config_param)SUNXI_PINCFG_TYPE_FUNC, 0);
+		pinctrl_gpio_set_config(gpio, config_set);
+
+		/***********get sdcx_dat0 value*************/
+		config_get = gpio_get_value(gpio);
+
+		/***********change gpio func to sdcx_dat0*************/
+		config_set = pinconf_to_config_packed((enum pin_config_param)SUNXI_PINCFG_TYPE_FUNC, 3);
+		pinctrl_gpio_set_config(gpio, config_set);
+	}
+
+	return (!config_get);
+}
+
+void sunxi_mmc_init_priv_v4p10x(struct sunxi_mmc_host *host,
+			       struct platform_device *pdev, int phy_index)
+{
+	struct sunxi_mmc_ver_priv *ver_priv =
+	    devm_kzalloc(&pdev->dev, sizeof(struct sunxi_mmc_ver_priv),
+			 GFP_KERNEL);
+	host->version_priv_dat = ver_priv;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].cmod = mmc_clk_400k;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].mod_str = "sunxi-dly-400k";
+	ver_priv->mmc_clk_dly[mmc_clk_400k].drv_ph = 01;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].sam_ph = 01;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].cmod = mmc_clk_26M;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].mod_str = "sunxi-dly-26M";
+	ver_priv->mmc_clk_dly[mmc_clk_26M].drv_ph = 01;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].sam_ph = 01;
+	ver_priv->mmc_clk_dly[mmc_clk_52M].cmod = mmc_clk_52M,
+	ver_priv->mmc_clk_dly[mmc_clk_52M].mod_str = "sunxi-dly-52M";
+	ver_priv->mmc_clk_dly[mmc_clk_52M].drv_ph = 01;
+	ver_priv->mmc_clk_dly[mmc_clk_52M].sam_ph = 01;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].cmod = mmc_clk_52M_DDR4;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].mod_str =
+		"sunxi-dly-52M-ddr4";
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].drv_ph = 01;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].sam_ph = 01;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].cmod = mmc_clk_52M_DDR8;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].mod_str =
+		"sunxi-dly-52M-ddr8";
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].drv_ph = 01;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].sam_ph = 01;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].cmod = mmc_clk_104M;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].mod_str =
+		"sunxi-dly-104M";
+	ver_priv->mmc_clk_dly[mmc_clk_104M].drv_ph = 01;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].sam_ph = 00;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].cmod = mmc_clk_208M;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].mod_str =
+		"sunxi-dly-208M";
+	ver_priv->mmc_clk_dly[mmc_clk_208M].drv_ph = 01;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].sam_ph = 00;
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].cmod = mmc_clk_104M_DDR;
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].mod_str =
+		"sunxi-dly-104M-ddr";
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].drv_ph = 01;
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].sam_ph = 00;
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].cmod = mmc_clk_208M_DDR;
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].mod_str =
+		"sunxi-dly-208M-ddr";
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].drv_ph = 01;
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].sam_ph = 00;
+
+	host->sunxi_mmc_clk_set_rate = sunxi_mmc_clk_set_rate_for_sdmmc_v4p10x;
+	host->dma_tl = SUNXI_DMA_TL_SDMMC_V4P1X;
+	host->idma_des_size_bits = SUNXI_DES_SIZE_SDMMC_V4P1X;
+	host->sunxi_mmc_thld_ctl = NULL;
+	host->sunxi_mmc_save_spec_reg = sunxi_mmc_save_spec_reg_v4p10x;
+	host->sunxi_mmc_restore_spec_reg = sunxi_mmc_restore_spec_reg_v4p10x;
+	sunxi_mmc_reg_ex_res_inter(host, phy_index);
+	host->sunxi_mmc_set_acmda = sunxi_mmc_set_a12a;
+	host->phy_index = phy_index;
+	host->sunxi_mmc_oclk_en = sunxi_mmc_oclk_onoff;
+	host->sunxi_mmc_judge_retry = sunxi_mmc_judge_retry_v4p10x;
+	host->sunxi_mmc_updata_pha = sunxi_mmc_updata_pha_v4p10x;
+	host->sunxi_mmc_hw_busy = sunxi_mmc_hw_busy_v4p10x;
+	host->sunxi_mmc_dat0_busy = sunxi_mmc_dat0_busy_v4p10x;
+	/*sunxi_of_parse_clk_dly(host);*/
+}
+EXPORT_SYMBOL_GPL(sunxi_mmc_init_priv_v4p10x);
diff --git a/drivers/mmc/host/sunxi-mmc-v4p10x.h b/drivers/mmc/host/sunxi-mmc-v4p10x.h
new file mode 100644
index 000000000..6d4b41763
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-v4p10x.h
@@ -0,0 +1,23 @@
+/*
+* SUNXI EMMC/SD driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lijuan <lijuan@allwinnertech.com>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#ifndef __SUNXI_MMC_V4P10X_H__
+#define __SUNXI_MMC_V4P10X_H__
+
+void sunxi_mmc_init_priv_v4p10x(struct sunxi_mmc_host *host,
+			       struct platform_device *pdev, int phy_index);
+#endif
+
diff --git a/drivers/mmc/host/sunxi-mmc-v4p1x.c b/drivers/mmc/host/sunxi-mmc-v4p1x.c
new file mode 100644
index 000000000..20544a068
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-v4p1x.c
@@ -0,0 +1,725 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+
+#include <linux/clk.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/slot-gpio.h>
+
+#include "sunxi-mmc.h"
+#include "sunxi-mmc-v4p1x.h"
+#include "sunxi-mmc-export.h"
+
+#define SUNXI_RETRY_CNT_PER_PHA_V4P1X		3
+
+/*dma triger level setting*/
+#define SUNXI_DMA_TL_SDMMC_V4P1X	((0x2<<28)|(7<<16)|248)
+/*one dma des can transfer data size = 1<<SUNXI_DES_SIZE_SDMMC*/
+#if defined(CONFIG_ARCH_SUN50IW10)
+#define SUNXI_DES_SIZE_SDMMC_V4P1X	(12)
+#else
+#define SUNXI_DES_SIZE_SDMMC_V4P1X	(15)
+#endif
+
+/*reg*/
+/*SMHC eMMC4.5 DDR Start Bit Detection Control Register */
+/*SMHC CRC Status Detect Control Register */
+/*SMHC Card Threshold Control Register */
+/*SMHC Drive Delay Control Register */
+/*SMHC Sample Delay Control Register */
+/*SMHC Data Strobe Delay Control Register */
+/*SMHC NewTiming Set Register */
+#define SDXC_REG_EDSD		(0x010C)
+#define SDXC_REG_CSDC		(0x0054)
+#define SDXC_REG_THLD		(0x0100)
+#define SDXC_REG_DRV_DL		(0x0140)
+#define SDXC_REG_SAMP_DL	(0x0144)
+#define SDXC_REG_DS_DL		(0x0148)
+#define SDXC_REG_SD_NTSR	(0x005C)
+
+/*bit*/
+#define SDXC_HS400_MD_EN				(1U<<31)
+#define SDXC_CARD_WR_THLD_ENB		(1U<<2)
+#define SDXC_CARD_RD_THLD_ENB		(1U)
+
+#define SDXC_DAT_DRV_PH_SEL			(1U<<17)
+#define SDXC_CMD_DRV_PH_SEL			(1U<<16)
+#define SDXC_SAMP_DL_SW_EN			(1u<<7)
+#define SDXC_DS_DL_SW_EN			(1u<<7)
+
+#define	SDXC_2X_TIMING_MODE			(1U<<31)
+
+/*mask*/
+#define SDXC_CRC_DET_PARA_MASK		(0xf)
+#define SDXC_CARD_RD_THLD_MASK		(0x0FFF0000)
+#define SDXC_TX_TL_MASK				(0xff)
+#define SDXC_RX_TL_MASK				(0x00FF0000)
+
+#define SDXC_SAMP_DL_SW_MASK		(0x0000003F)
+#define SDXC_DS_DL_SW_MASK			(0x0000003F)
+
+#define SDXC_STIMING_CMD_PH_MASK		(0x00000030)
+#define SDXC_STIMING_DAT_PH_MASK		(0x00000300)
+
+/*value*/
+#define SDXC_CRC_DET_PARA_HS400		(6)
+#define SDXC_CRC_DET_PARA_OTHER		(3)
+#define SDXC_FIFO_DETH					(1024>>2)
+
+/*size*/
+#define SDXC_CARD_RD_THLD_SIZE		(0x00000FFF)
+
+/*shit*/
+#define SDXC_CARD_RD_THLD_SIZE_SHIFT		(16)
+
+#define SDXC_STIMING_CMD_PH_SHIFT			(4)
+#define SDXC_STIMING_DAT_PH_SHIFT			(8)
+
+enum sunxi_mmc_clk_mode {
+	mmc_clk_400k = 0,
+	mmc_clk_26M,
+	mmc_clk_52M,
+	mmc_clk_52M_DDR4,
+	mmc_clk_52M_DDR8,
+	mmc_clk_104M,
+	mmc_clk_208M,
+	mmc_clk_104M_DDR,
+	mmc_clk_208M_DDR,
+	mmc_clk_mod_num,
+};
+
+struct sunxi_mmc_clk_dly {
+	enum sunxi_mmc_clk_mode cmod;
+	char *mod_str;
+	u32 cmd_drv_ph;
+	u32 dat_drv_ph;
+	u32 sam_dly;
+	u32 ds_dly;
+	u32 sam_ph_dat;
+	u32 sam_ph_cmd;
+};
+
+struct sunxi_mmc_spec_regs {
+	u32 drv_dl;		/*REG_DRV_DL */
+	u32 samp_dl;		/*REG_SAMP_DL */
+	u32 ds_dl;		/*REG_DS_DL */
+	u32 sd_ntsr;		/*REG_SD_NTSR */
+};
+
+struct sunxi_mmc_ver_priv {
+	struct sunxi_mmc_spec_regs bak_spec_regs;
+	struct sunxi_mmc_clk_dly mmc_clk_dly[mmc_clk_mod_num];
+};
+
+
+static void sunxi_mmc_set_clk_dly(struct sunxi_mmc_host *host, int clk,
+				  int bus_width, int timing)
+{
+	struct mmc_host *mhost = host->mmc;
+	u32 rval = 0;
+	enum sunxi_mmc_clk_mode cmod = mmc_clk_400k;
+	u32 in_clk_dly[6] = { 0 };
+	int ret = 0;
+	struct device_node *np = NULL;
+	struct sunxi_mmc_clk_dly *mmc_clk_dly =
+	    ((struct sunxi_mmc_ver_priv *)host->version_priv_dat)->mmc_clk_dly;
+
+	if (!mhost->parent || !mhost->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse clk dly,use default\n");
+		return;
+	}
+
+	np = mhost->parent->of_node;
+
+	if (clk <= 400 * 1000) {
+		cmod = mmc_clk_400k;
+	} else if (clk <= 26 * 1000 * 1000) {
+		cmod = mmc_clk_26M;
+	} else if (clk <= 52 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_4)
+		    && sunxi_mmc_ddr_timing(timing)) {
+			cmod = mmc_clk_52M_DDR4;
+		} else if ((bus_width == MMC_BUS_WIDTH_8)
+			   && (timing == MMC_TIMING_MMC_DDR52)) {
+			cmod = mmc_clk_52M_DDR8;
+		} else {
+			cmod = mmc_clk_52M;
+		}
+	} else if (clk <= 104 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_8)
+		    && (timing == MMC_TIMING_MMC_HS400)) {
+			cmod = mmc_clk_104M_DDR;
+		} else {
+			cmod = mmc_clk_104M;
+		}
+	} else if (clk <= 208 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_8)
+		    && (timing == MMC_TIMING_MMC_HS400)) {
+			cmod = mmc_clk_208M_DDR;
+		} else {
+			cmod = mmc_clk_208M;
+		}
+	} else {
+		dev_err(mmc_dev(mhost), "clk %d is out of range\n", clk);
+		return;
+	}
+
+	ret = of_property_read_u32_array(np, mmc_clk_dly[cmod].mod_str,
+					 in_clk_dly, ARRAY_SIZE(in_clk_dly));
+	if (ret) {
+		dev_dbg(mmc_dev(host->mmc), "failed to get %s used default\n",
+			mmc_clk_dly[cmod].mod_str);
+	} else {
+		mmc_clk_dly[cmod].cmd_drv_ph = in_clk_dly[0];
+		mmc_clk_dly[cmod].dat_drv_ph = in_clk_dly[1];
+		/*mmc_clk_dly[cmod].sam_dly             = in_clk_dly[2]; */
+		/*mmc_clk_dly[cmod].ds_dly              = in_clk_dly[3]; */
+		mmc_clk_dly[cmod].sam_ph_dat = in_clk_dly[4];
+		mmc_clk_dly[cmod].sam_ph_cmd = in_clk_dly[5];
+		dev_dbg(mmc_dev(host->mmc), "Get %s clk dly ok\n",
+			mmc_clk_dly[cmod].mod_str);
+
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "Try set %s clk dly	ok\n",
+		mmc_clk_dly[cmod].mod_str);
+	dev_dbg(mmc_dev(host->mmc), "cmd_drv_ph	%d\n",
+		mmc_clk_dly[cmod].cmd_drv_ph);
+	dev_dbg(mmc_dev(host->mmc), "dat_drv_ph	%d\n",
+		mmc_clk_dly[cmod].dat_drv_ph);
+	dev_dbg(mmc_dev(host->mmc), "sam_ph_dat	%d\n",
+		mmc_clk_dly[cmod].sam_ph_dat);
+	dev_dbg(mmc_dev(host->mmc), "sam_ph_cmd	%d\n",
+		mmc_clk_dly[cmod].sam_ph_cmd);
+
+	rval = mmc_readl(host, REG_DRV_DL);
+	if (mmc_clk_dly[cmod].cmd_drv_ph)
+		rval |= SDXC_CMD_DRV_PH_SEL;	/*180 phase */
+	else
+		rval &= ~SDXC_CMD_DRV_PH_SEL;	/*90 phase */
+
+	if (mmc_clk_dly[cmod].dat_drv_ph)
+		rval |= SDXC_DAT_DRV_PH_SEL;	/*180 phase */
+	else
+		rval &= ~SDXC_DAT_DRV_PH_SEL;	/*90 phase */
+
+	sunxi_r_op(host, mmc_writel(host, REG_DRV_DL, rval));
+
+/*
+*      rval = mmc_readl(host,REG_SAMP_DL);
+*      rval &= ~SDXC_SAMP_DL_SW_MASK;
+*      rval |= mmc_clk_dly[cmod].sam_dly & SDXC_SAMP_DL_SW_MASK;
+*      rval |= SDXC_SAMP_DL_SW_EN;
+*      mmc_writel(host,REG_SAMP_DL,rval);
+*
+*     rval = mmc_readl(host,REG_DS_DL);
+*     rval &= ~SDXC_DS_DL_SW_MASK;
+*     rval |= mmc_clk_dly[cmod].ds_dly & SDXC_DS_DL_SW_MASK;
+*     rval |= SDXC_DS_DL_SW_EN;
+*    mmc_writel(host,REG_DS_DL,rval);
+*/
+
+	rval = mmc_readl(host, REG_SD_NTSR);
+	rval &= ~SDXC_STIMING_DAT_PH_MASK;
+	rval |=
+	    (mmc_clk_dly[cmod].
+	     sam_ph_dat << SDXC_STIMING_DAT_PH_SHIFT) &
+	    SDXC_STIMING_DAT_PH_MASK;
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	rval = mmc_readl(host, REG_SD_NTSR);
+	rval &= ~SDXC_STIMING_CMD_PH_MASK;
+	rval |=
+	    (mmc_clk_dly[cmod].
+	     sam_ph_cmd << SDXC_STIMING_CMD_PH_SHIFT) &
+	    SDXC_STIMING_CMD_PH_MASK;
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), " REG_DRV_DL    %08x\n",
+		mmc_readl(host, REG_DRV_DL));
+	dev_dbg(mmc_dev(host->mmc), " REG_SAMP_DL  %08x\n",
+		mmc_readl(host, REG_SAMP_DL));
+	dev_dbg(mmc_dev(host->mmc), " REG_DS_DL      %08x\n",
+		mmc_readl(host, REG_DS_DL));
+	dev_dbg(mmc_dev(host->mmc), " REG_SD_NTSR      %08x\n",
+		mmc_readl(host, REG_SD_NTSR));
+
+}
+
+static int __sunxi_mmc_do_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en,
+				     u32 pwr_save, u32 ignore_dat0)
+{
+	unsigned long expire = jiffies + msecs_to_jiffies(250);
+	u32 rval;
+
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~(SDXC_CARD_CLOCK_ON | SDXC_LOW_POWER_ON | SDXC_MASK_DATA0);
+
+	if (oclk_en)
+		rval |= SDXC_CARD_CLOCK_ON;
+	if (pwr_save && host->voltage_switching == 0)
+		rval |= SDXC_LOW_POWER_ON;
+	if (ignore_dat0)
+		rval |= SDXC_MASK_DATA0;
+
+	mmc_writel(host, REG_CLKCR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), "%s REG_CLKCR:%x\n", __func__,
+		mmc_readl(host, REG_CLKCR));
+
+	if (host->voltage_switching == 1) {
+		rval = SDXC_START | SDXC_UPCLK_ONLY | SDXC_WAIT_PRE_OVER | SDXC_VOLTAGE_SWITCH;
+	} else {
+		rval = SDXC_START | SDXC_UPCLK_ONLY | SDXC_WAIT_PRE_OVER;
+	}
+	mmc_writel(host, REG_CMDR, rval);
+
+	do {
+		rval = mmc_readl(host, REG_CMDR);
+	} while (time_before(jiffies, expire) && (rval & SDXC_START));
+
+	/* clear irq status bits set by the command */
+	mmc_writel(host, REG_RINTR,
+		   mmc_readl(host, REG_RINTR) & ~SDXC_SDIO_INTERRUPT);
+
+	if (rval & SDXC_START) {
+		dev_err(mmc_dev(host->mmc), "fatal err update clk timeout\n");
+		return -EIO;
+	}
+
+	/*only use mask data0 when update clk,clear it when not update clk */
+	if (ignore_dat0)
+		mmc_writel(host, REG_CLKCR,
+			   mmc_readl(host, REG_CLKCR) & ~SDXC_MASK_DATA0);
+
+	return 0;
+}
+
+static int sunxi_mmc_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en)
+{
+	struct device_node *np = NULL;
+	struct mmc_host *mmc = host->mmc;
+	int pwr_save = 0;
+	int len = 0;
+
+	if (!mmc->parent || !mmc->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse power save mode\n");
+		return -EIO;
+	}
+
+	np = mmc->parent->of_node;
+	if (of_find_property(np, "sunxi-power-save-mode", &len))
+		pwr_save = 1;
+	return __sunxi_mmc_do_oclk_onoff(host, oclk_en, pwr_save, 1);
+}
+
+static void sunxi_mmc_2xmod_onoff(struct sunxi_mmc_host *host, u32 newmode_en)
+{
+	u32 rval = mmc_readl(host, REG_SD_NTSR);
+
+	if (newmode_en)
+		rval |= SDXC_2X_TIMING_MODE;
+	else
+		rval &= ~SDXC_2X_TIMING_MODE;
+
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), "REG_SD_NTSR: 0x%08x ,val %x\n",
+		mmc_readl(host, REG_SD_NTSR), rval);
+}
+
+static int sunxi_mmc_clk_set_rate_for_sdmmc_v4p1x(struct sunxi_mmc_host *host,
+						  struct mmc_ios *ios)
+{
+	u32 mod_clk = 0;
+	u32 src_clk = 0;
+	u32 rval = 0;
+	s32 err = 0;
+	u32 rate = 0;
+	char *sclk_name = NULL;
+	struct clk *mclk = host->clk_mmc;
+	struct clk *sclk = NULL;
+	struct device *dev = mmc_dev(host->mmc);
+	int div = 0;
+
+	if (ios->clock == 0) {
+		__sunxi_mmc_do_oclk_onoff(host, 0, 0, 1);
+		return 0;
+	}
+
+	if (sunxi_mmc_ddr_timing(ios->timing)) {
+		mod_clk = ios->clock << 2;
+		div = 1;
+	} else {
+		mod_clk = ios->clock << 1;
+		div = 0;
+	}
+
+	sclk = clk_get(dev, "osc24m");
+	sclk_name = "osc24m";
+	if (IS_ERR(sclk)) {
+		dev_err(mmc_dev(host->mmc), "Error to get source clock %s\n",
+			sclk_name);
+		return -1;
+	}
+
+	src_clk = clk_get_rate(sclk);
+	if (mod_clk > src_clk) {
+		clk_put(sclk);
+		sclk = clk_get(dev, "pll_periph");
+		sclk_name = "pll_periph";
+	}
+	if (IS_ERR(sclk)) {
+		dev_err(mmc_dev(host->mmc), "Error to get source clock %s\n",
+			sclk_name);
+		return -1;
+	}
+
+	sunxi_mmc_oclk_onoff(host, 0);
+
+	err = clk_set_parent(mclk, sclk);
+	if (err) {
+		dev_err(mmc_dev(host->mmc), "set parent failed\n");
+		clk_put(sclk);
+		return -1;
+	}
+
+	rate = clk_round_rate(mclk, mod_clk);
+
+	dev_dbg(mmc_dev(host->mmc), "get round rate %d\n", rate);
+
+	/*clk_disable_unprepare(host->clk_mmc);*/
+
+	err = clk_set_rate(mclk, rate);
+	if (err) {
+		dev_err(mmc_dev(host->mmc), "set mclk rate error, rate %dHz\n",
+			rate);
+		clk_put(sclk);
+		return -1;
+	}
+/*
+	rval = clk_prepare_enable(host->clk_mmc);
+	if (rval) {
+		dev_err(mmc_dev(host->mmc), "Enable mmc clk err %d\n", rval);
+		return -1;
+	}
+*/
+	src_clk = clk_get_rate(sclk);
+	clk_put(sclk);
+
+	dev_dbg(mmc_dev(host->mmc), "set round clock %d, soure clk is %d\n",
+		rate, src_clk);
+
+#ifdef MMC_FPGA
+	if (sunxi_mmc_ddr_timing(ios->timing)) {
+		/* clear internal divider */
+		rval = mmc_readl(host, REG_CLKCR);
+		rval &= ~0xff;
+		rval |= 1;
+	} else {
+		/* support internal divide clock under fpga environment  */
+		rval = mmc_readl(host, REG_CLKCR);
+		rval &= ~0xff;
+		rval |= 24000000 / mod_clk / 2;	/* =24M/400K/2=0x1E */
+	}
+	mmc_writel(host, REG_CLKCR, rval);
+	dev_info(mmc_dev(host->mmc), "FPGA REG_CLKCR: 0x%08x\n",
+		mmc_readl(host, REG_CLKCR));
+#else
+	/* clear internal divider */
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~0xff;
+	rval |= div;
+	mmc_writel(host, REG_CLKCR, rval);
+#endif
+
+	/*sunxi_of_parse_clk_dly(host); */
+	sunxi_mmc_2xmod_onoff(host, 1);
+
+	if (sunxi_mmc_ddr_timing(ios->timing))
+		ios->clock = rate >> 2;
+	else
+		ios->clock = rate >> 1;
+
+	sunxi_mmc_set_clk_dly(host, ios->clock, ios->bus_width, ios->timing);
+
+	return sunxi_mmc_oclk_onoff(host, 1);
+}
+
+static void sunxi_mmc_thld_ctl_for_sdmmc_v4p1x(struct sunxi_mmc_host *host,
+					       struct mmc_ios *ios,
+					       struct mmc_data *data)
+{
+	u32 bsz = data->blksz;
+	/*unit:byte */
+	/*u32 tdtl = (host->dma_tl & SDXC_TX_TL_MASK)<<2;*/
+	/*unit:byte */
+	u32 rdtl = ((host->dma_tl & SDXC_RX_TL_MASK) >> 16) << 2;
+	u32 rval = 0;
+
+	if ((data->flags & MMC_DATA_READ)
+	    && (bsz <= SDXC_CARD_RD_THLD_SIZE)
+	    /*((SDXC_FIFO_DETH<<2)-bsz) >= (rdtl) */
+	    && ((SDXC_FIFO_DETH << 2) >= (rdtl + bsz))
+	    && ((ios->timing == MMC_TIMING_MMC_HS200)
+	       || (ios->timing == MMC_TIMING_UHS_SDR50)
+	       || (ios->timing == MMC_TIMING_UHS_SDR104))) {
+		rval = mmc_readl(host, REG_THLD);
+		rval &= ~SDXC_CARD_RD_THLD_MASK;
+		rval |= data->blksz << SDXC_CARD_RD_THLD_SIZE_SHIFT;
+		rval |= SDXC_CARD_RD_THLD_ENB;
+		mmc_writel(host, REG_THLD, rval);
+	} else {
+		rval = mmc_readl(host, REG_THLD);
+		rval &= ~SDXC_CARD_RD_THLD_ENB;
+		mmc_writel(host, REG_THLD, rval);
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "SDXC_REG_THLD: 0x%08x\n",
+		mmc_readl(host, REG_THLD));
+
+}
+
+static void sunxi_mmc_save_spec_reg_v4p1x(struct sunxi_mmc_host *host)
+{
+	struct sunxi_mmc_spec_regs *spec_regs =
+	    &((struct sunxi_mmc_ver_priv *)(host->version_priv_dat))->
+	    bak_spec_regs;
+	spec_regs->drv_dl = mmc_readl(host, REG_DRV_DL);
+	spec_regs->samp_dl = mmc_readl(host, REG_SAMP_DL);
+	spec_regs->ds_dl = mmc_readl(host, REG_DS_DL);
+	spec_regs->sd_ntsr = mmc_readl(host, REG_SD_NTSR);
+}
+
+static void sunxi_mmc_restore_spec_reg_v4p1x(struct sunxi_mmc_host *host)
+{
+	struct sunxi_mmc_spec_regs *spec_regs =
+	    &((struct sunxi_mmc_ver_priv *)(host->version_priv_dat))->
+	    bak_spec_regs;
+	sunxi_r_op(host, mmc_writel(host, REG_DRV_DL, spec_regs->drv_dl));
+	mmc_writel(host, REG_SAMP_DL, spec_regs->samp_dl);
+	mmc_writel(host, REG_DS_DL, spec_regs->ds_dl);
+	mmc_writel(host, REG_SD_NTSR, spec_regs->sd_ntsr);
+}
+
+static inline void sunxi_mmc_set_dly_raw(struct sunxi_mmc_host *host,
+					 s32 opha_cmd, s32 ipha_cmd,
+					 s32 opha_dat, s32 ipha_dat)
+{
+	u32 rval = mmc_readl(host, REG_DRV_DL);
+
+	if (opha_cmd > 0)
+		rval |= SDXC_CMD_DRV_PH_SEL;	/*180 phase */
+	else if (opha_cmd == 0)
+		rval &= ~SDXC_CMD_DRV_PH_SEL;	/*90 phase */
+
+	if (opha_dat > 0)
+		rval |= SDXC_DAT_DRV_PH_SEL;	/*180 phase */
+	else if (opha_dat == 0)
+		rval &= ~SDXC_DAT_DRV_PH_SEL;	/*90 phase */
+
+	sunxi_r_op(host, mmc_writel(host, REG_DRV_DL, rval));
+
+	rval = mmc_readl(host, REG_SD_NTSR);
+
+	if (ipha_cmd >= 0) {
+		rval &= ~SDXC_STIMING_CMD_PH_MASK;
+		rval |=
+		    (ipha_cmd << SDXC_STIMING_CMD_PH_SHIFT) &
+		    SDXC_STIMING_CMD_PH_MASK;
+	}
+
+	if (ipha_dat >= 0) {
+		rval &= ~SDXC_STIMING_DAT_PH_MASK;
+		rval |=
+		    (ipha_dat << SDXC_STIMING_DAT_PH_SHIFT) &
+		    SDXC_STIMING_DAT_PH_MASK;
+	}
+
+	rval &= ~SDXC_2X_TIMING_MODE;
+	mmc_writel(host, REG_SD_NTSR, rval);
+	rval |= SDXC_2X_TIMING_MODE;
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	dev_info(mmc_dev(host->mmc), "REG_DRV_DL: 0x%08x\n",
+		 mmc_readl(host, REG_DRV_DL));
+	dev_info(mmc_dev(host->mmc), "REG_SD_NTSR: 0x%08x\n",
+		 mmc_readl(host, REG_SD_NTSR));
+}
+
+static int sunxi_mmc_judge_retry_v4p1x(struct sunxi_mmc_host *host,
+				       struct mmc_command *cmd, u32 rcnt,
+				       u32 errno, void *other)
+{
+	/****-1 means use default value***/
+	/*
+	*We use {-1,-1} as first member,because we want to
+	*retry current delay first.
+	*Only If current delay failed,we try new delay
+	*/
+	const s32 sunxi_phase[10][2] = { {-1, -1},
+		{1, 1}, {0, 0}, {1, 0}, {0, 1}, {1, 2}, {0, 2} };
+
+	if (rcnt < (SUNXI_RETRY_CNT_PER_PHA_V4P1X * 10)) {
+		sunxi_mmc_set_dly_raw(host,
+				      sunxi_phase[rcnt /
+						  SUNXI_RETRY_CNT_PER_PHA_V4P1X]
+				      [0],
+				      sunxi_phase[rcnt /
+						  SUNXI_RETRY_CNT_PER_PHA_V4P1X]
+				      [1],
+				      sunxi_phase[rcnt /
+						  SUNXI_RETRY_CNT_PER_PHA_V4P1X]
+				      [0],
+				      sunxi_phase[rcnt /
+						  SUNXI_RETRY_CNT_PER_PHA_V4P1X]
+				      [1]);
+		return 0;
+	}
+
+	sunxi_mmc_set_dly_raw(host, sunxi_phase[0][0],
+			      sunxi_phase[0][1],
+			      sunxi_phase[0][0], sunxi_phase[0][1]);
+	dev_info(mmc_dev(host->mmc), "sunxi v4p1x retry give up\n");
+	return -1;
+}
+
+void sunxi_mmc_init_priv_v4p1x(struct sunxi_mmc_host *host,
+			       struct platform_device *pdev, int phy_index)
+{
+	struct sunxi_mmc_ver_priv *ver_priv =
+	    devm_kzalloc(&pdev->dev, sizeof(struct sunxi_mmc_ver_priv),
+			 GFP_KERNEL);
+	host->version_priv_dat = ver_priv;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].cmod = mmc_clk_400k;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].mod_str = "sunxi-dly-400k";
+	ver_priv->mmc_clk_dly[mmc_clk_400k].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].dat_drv_ph = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].sam_ph_dat = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].sam_ph_cmd = 0;
+
+	ver_priv->mmc_clk_dly[mmc_clk_26M].cmod = mmc_clk_26M;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].mod_str = "sunxi-dly-26M";
+	ver_priv->mmc_clk_dly[mmc_clk_26M].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].dat_drv_ph = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].sam_ph_dat = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].sam_ph_cmd = 0;
+
+	ver_priv->mmc_clk_dly[mmc_clk_52M].cmod = mmc_clk_52M,
+	    ver_priv->mmc_clk_dly[mmc_clk_52M].mod_str = "sunxi-dly-52M";
+	ver_priv->mmc_clk_dly[mmc_clk_52M].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M].dat_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_52M].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_52M].sam_ph_dat = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M].sam_ph_cmd = 1;
+
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].cmod = mmc_clk_52M_DDR4;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].mod_str = "sunxi-dly-52M-ddr4";
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].dat_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].sam_ph_dat = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].sam_ph_cmd = 1;
+
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].cmod = mmc_clk_52M_DDR8;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].mod_str = "sunxi-dly-52M-ddr8";
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].dat_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].sam_ph_dat = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].sam_ph_cmd = 1;
+
+	ver_priv->mmc_clk_dly[mmc_clk_104M].cmod = mmc_clk_104M;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].mod_str = "sunxi-dly-104M";
+	ver_priv->mmc_clk_dly[mmc_clk_104M].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].dat_drv_ph = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].sam_ph_dat = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].sam_ph_cmd = 0;
+
+	ver_priv->mmc_clk_dly[mmc_clk_208M].cmod = mmc_clk_208M;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].mod_str = "sunxi-dly-208M";
+	ver_priv->mmc_clk_dly[mmc_clk_208M].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].dat_drv_ph = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].sam_ph_dat = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].sam_ph_cmd = 0;
+
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].cmod = mmc_clk_104M_DDR;
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].mod_str = "sunxi-dly-104M-ddr";
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].dat_drv_ph = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].sam_ph_dat = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].sam_ph_cmd = 0;
+
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].cmod = mmc_clk_208M_DDR;
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].mod_str = "sunxi-dly-208M-ddr";
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].dat_drv_ph = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].sam_ph_dat = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].sam_ph_cmd = 0;
+
+	host->sunxi_mmc_clk_set_rate = sunxi_mmc_clk_set_rate_for_sdmmc_v4p1x;
+	host->dma_tl = SUNXI_DMA_TL_SDMMC_V4P1X;
+	host->idma_des_size_bits = SUNXI_DES_SIZE_SDMMC_V4P1X;
+	host->sunxi_mmc_thld_ctl = sunxi_mmc_thld_ctl_for_sdmmc_v4p1x;
+	host->sunxi_mmc_save_spec_reg = sunxi_mmc_save_spec_reg_v4p1x;
+	host->sunxi_mmc_restore_spec_reg = sunxi_mmc_restore_spec_reg_v4p1x;
+	sunxi_mmc_reg_ex_res_inter(host, phy_index);
+	host->sunxi_mmc_set_acmda = sunxi_mmc_set_a12a;
+	host->phy_index = phy_index;
+	host->sunxi_mmc_oclk_en = sunxi_mmc_oclk_onoff;
+	host->sunxi_mmc_judge_retry = sunxi_mmc_judge_retry_v4p1x;
+	/*sunxi_of_parse_clk_dly(host); */
+#if (defined(CONFIG_ARCH_SUN50IW9) || defined(CONFIG_ARCH_SUN50IW10))
+	host->des_addr_shift = 2;
+#endif
+}
+EXPORT_SYMBOL_GPL(sunxi_mmc_init_priv_v4p1x);
diff --git a/drivers/mmc/host/sunxi-mmc-v4p1x.h b/drivers/mmc/host/sunxi-mmc-v4p1x.h
new file mode 100644
index 000000000..9d8787ca5
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-v4p1x.h
@@ -0,0 +1,22 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#ifndef __SUNXI_MMC_V4P1X_H__
+#define __SUNXI_MMC_V4P1X_H__
+
+void sunxi_mmc_init_priv_v4p1x(struct sunxi_mmc_host *host,
+			       struct platform_device *pdev, int phy_index);
+#endif
diff --git a/drivers/mmc/host/sunxi-mmc-v4p5x.c b/drivers/mmc/host/sunxi-mmc-v4p5x.c
new file mode 100644
index 000000000..d3a1d7382
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-v4p5x.c
@@ -0,0 +1,1075 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#include <linux/clk.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/slot-gpio.h>
+
+#include "sunxi-mmc.h"
+#include "sunxi-mmc-v4p5x.h"
+#include "sunxi-mmc-export.h"
+
+/*reg*/
+/*SMHC eMMC4.5 DDR Start Bit Detection Control Register */
+/*SMHC CRC Status Detect Control Register */
+/*SMHC Card Threshold Control Register */
+/*SMHC Drive Delay Control Register */
+/*SMHC Sample Delay Control Register */
+/*SMHC Data Strobe Delay Control Register */
+#define SDXC_REG_SFC		(0x0104)
+#define SDXC_REG_EDSD		(0x010C)
+#define SDXC_REG_CSDC		(0x0054)
+#define SDXC_REG_THLD		(0x0100)
+#define SDXC_REG_DRV_DL		(0x0140)
+#define SDXC_REG_SAMP_DL	(0x0144)
+#define SDXC_REG_DS_DL		(0x0148)
+#define SDXC_REG_EMCE		(0x64)		/*SMHC EMCE Control Register*/
+#define SDXC_REG_SD_NTSR	(0x005C)
+#define SDXC_REG_SMCV		(0x300)		/*SMHC Version Register */
+
+/*use only for version after or equel 4.9*/
+#define SDXC_REG_A23A		(0X108)
+#define SDXC_REG_ECMD	(0X138)
+#define SDXC_REG_ERESP	(0X13C)
+
+
+
+/*bit*/
+#define SDXC_HS400_MD_EN				(1U<<31)
+#define SDXC_CARD_WR_THLD_ENB		(1U<<2)
+#define SDXC_CARD_RD_THLD_ENB		(1U)
+
+#define SDXC_DAT_DRV_PH_SEL			(1U<<17)
+#define SDXC_CMD_DRV_PH_SEL			(1U<<16)
+#define SDXC_SAMP_DL_SW_EN			(1u<<7)
+#define SDXC_DS_DL_SW_EN			(1u<<7)
+
+#define	SDXC_2X_TIMING_MODE			(1U<<31)
+
+#define SDXC_SFC_BP					BIT(0)
+
+/*for SDXC_REG_ECMD register*/
+#define SDXC_A23_EN				(1u<<0)
+
+
+/*mask*/
+#define SDXC_CRC_DET_PARA_MASK		(0xf)
+#define SDXC_CARD_RD_THLD_MASK		(0x0FFF0000)
+#define SDXC_TX_TL_MASK				(0xff)
+#define SDXC_RX_TL_MASK				(0x00FF0000)
+
+#define SDXC_SAMP_DL_SW_MASK		(0x0000003F)
+#define SDXC_DS_DL_SW_MASK			(0x0000003F)
+
+/*value*/
+#define SDXC_CRC_DET_PARA_HS400		(6)
+#define SDXC_CRC_DET_PARA_OTHER		(3)
+#define SDXC_FIFO_DETH					(1024>>2)
+
+/*size*/
+#define SDXC_CARD_RD_THLD_SIZE		(0x00000FFF)
+
+/*shit*/
+#define SDXC_CARD_RD_THLD_SIZE_SHIFT		(16)
+
+#define SUNXI_DMA_TL_SDMMC_V4P5X		((0x3<<28)|(15<<16)|240)
+/*one dma des can transfer data size = 1<<SUNXI_DES_SIZE_SDMMC2*/
+#define SUNXI_DES_SIZE_SDMMC_V4P5X	(12)
+
+/* EMCE controller  */
+#define SDXC_EMCE_ENCR		BIT(4)
+#define SDXC_EMCE_AC_MD		BIT(1)
+#define SDXC_EMCE_ENB		BIT(0)
+
+/*Sunxi MMC Host Controller Version*/
+#define SMHC_VERSION_V4P7	0x40700
+#define SMHC_VERSION_V4P9	0x40900
+#define SMHC_VERSION_V4P5P1     0x40501
+#define SMHC_VERSION_V4P5P2	0x40502
+#define SMHC_VERSION_V5P3	0x50300
+
+#if IS_ENABLED(CONFIG_SUNXI_EMCE)
+extern int sunxi_emce_set_task_des(int data_len, int bypass);
+extern void sunxi_emce_set_task_load(int para);
+#endif
+
+struct sunxi_mmc_spec_regs {
+	u32 drv_dl;		/*REG_DRV_DL */
+	u32 samp_dl;		/*REG_SAMP_DL */
+	u32 ds_dl;		/*REG_DS_DL */
+	u32 sd_ntsr;//REG_SD_NTSR
+	u32 edsd;		/*REG_EDSD */
+	u32 csdc;		/*REG_CSDC */
+};
+
+enum sunxi_mmc_speed_mode {
+	SM0_DS26_SDR12 = 0,
+	SM1_HSSDR52_SDR25,
+	SM2_HSDDR52_DDR50,
+	SM3_HS200_SDR104,
+	SM4_HS400,
+	SM4_HS400_CMD,
+	SMX_UNUSED0,
+	SMX_UNUSED1,
+	SM_NUM,
+};
+
+struct sunxi_mmc_clk_dly {
+	enum sunxi_mmc_speed_mode spm;
+	char *mod_str;
+	char *raw_tm_sm_str[2];
+	u32 raw_tm_sm[2];
+	u32 raw_tm_sm_def[2];
+};
+
+
+struct sunxi_mmc_ver_priv {
+	struct sunxi_mmc_spec_regs bak_spec_regs;
+	struct sunxi_mmc_clk_dly mmc_clk_dly[SM_NUM];
+};
+
+static  u32 sunxi_mmc_get_hs400_cmd_dly(struct sunxi_mmc_host *host, u32 clk, u32 *out_dly)
+{
+	struct mmc_host *mmc = host->mmc;
+	enum sunxi_mmc_speed_mode speed_mod = SM0_DS26_SDR12;
+	char *raw_sm_str = NULL;
+	char *m_str = NULL;
+	struct device_node *np = NULL;
+	u32 *raw_sm = 0;
+	u32 *raw_sm_def = 0;
+	u32 rval = 0;
+	int frq_index = 0;
+	u32 sam_dly = 0;
+	struct sunxi_mmc_clk_dly *mmc_clk_dly = ((struct sunxi_mmc_ver_priv *)host->version_priv_dat)->mmc_clk_dly;
+
+	if (!mmc->parent || !mmc->parent->of_node) {
+		dev_err(mmc_dev(host->mmc), "no dts to parse clk dly,use default\n");
+		return -EINVAL;
+	}
+
+	np = mmc->parent->of_node;
+	speed_mod = SM4_HS400_CMD;
+
+	if (clk <= 400 * 1000) {
+		frq_index = 0;
+	} else if (clk <= 25 * 1000 * 1000) {
+		frq_index = 1;
+	} else if (clk <= 50 * 1000 * 1000) {
+		frq_index = 2;
+	} else if (clk <= 100 * 1000 * 1000) {
+		frq_index = 3;
+	} else if (clk <= 150 * 1000 * 1000) {
+		frq_index = 4;
+	} else if (clk <= 200 * 1000 * 1000) {
+		frq_index = 5;
+	} else if (clk <= 250 * 1000 * 1000) {
+		frq_index = 6;
+	} else if (clk <= 300 * 1000 * 1000) {
+		frq_index = 7;
+	} else {
+		dev_err(mmc_dev(mmc), "clkver 300mhz\n");
+		return -EINVAL;
+	}
+
+	if (frq_index / 4 > 2) {
+		dev_err(mmc_dev(host->mmc), "err frq_index\n");
+		return -EINVAL;
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "freq %d frq index %d,frq/4 %x\n", clk, frq_index, frq_index / 4);
+	raw_sm_str = mmc_clk_dly[speed_mod].raw_tm_sm_str[frq_index / 4];
+	raw_sm = &mmc_clk_dly[speed_mod].raw_tm_sm[frq_index / 4];
+	raw_sm_def = &mmc_clk_dly[speed_mod].raw_tm_sm_def[frq_index / 4];
+	m_str = mmc_clk_dly[speed_mod].mod_str;
+
+	rval = of_property_read_u32(np, raw_sm_str, raw_sm);
+	if (rval) {
+		dev_info(mmc_dev(host->mmc), "failed to get %s used default\n", m_str);
+		return -EINVAL;
+	} else {
+		u32 sm_shift = (frq_index % 4) * 8;
+		rval = ((*raw_sm) >> sm_shift) & 0xff;
+
+		if (rval != 0xff) {
+			sam_dly = rval;
+			dev_dbg(mmc_dev(host->mmc), "Get speed mode %s clk dly %s ok\n", m_str, raw_sm_str);
+		} else {
+			u32 sm_shift = (frq_index % 4) * 8;
+			dev_dbg(mmc_dev(host->mmc), "%s use default value\n", m_str);
+			rval = ((*raw_sm_def) >> sm_shift) & 0xff;
+			sam_dly = rval;
+		}
+		*out_dly = sam_dly;
+	}
+
+	return 0;
+}
+
+static void sunxi_mmc_set_clk_dly(struct sunxi_mmc_host *host, int clk,
+				  int bus_width, int timing)
+{
+	struct mmc_host *mmc = host->mmc;
+	enum sunxi_mmc_speed_mode speed_mod = SM0_DS26_SDR12;
+	char *raw_sm_str = NULL;
+	char *m_str = NULL;
+	struct device_node *np = NULL;
+	u32 *raw_sm = 0;
+	u32 *raw_sm_def = 0;
+	u32 rval = 0;
+	int frq_index = 0;
+	u32 cmd_drv_ph = 1;
+	u32 dat_drv_ph = 0;
+	u32 sam_dly = 0;
+	u32 ds_dly = 0;
+	struct sunxi_mmc_clk_dly *mmc_clk_dly =
+	    ((struct sunxi_mmc_ver_priv *)host->version_priv_dat)->mmc_clk_dly;
+
+	if (!mmc->parent || !mmc->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse clk dly,use default\n");
+		return;
+	}
+
+	np = mmc->parent->of_node;
+
+	switch (timing) {
+	case MMC_TIMING_LEGACY:
+	case MMC_TIMING_UHS_SDR12:
+		speed_mod = SM0_DS26_SDR12;
+		break;
+	case MMC_TIMING_MMC_HS:
+	case MMC_TIMING_SD_HS:
+	case MMC_TIMING_UHS_SDR25:
+		speed_mod = SM1_HSSDR52_SDR25;
+		break;
+	case MMC_TIMING_UHS_DDR50:
+	case MMC_TIMING_MMC_DDR52:
+		if (bus_width == 8)
+			dat_drv_ph = 1;
+		speed_mod = SM2_HSDDR52_DDR50;
+		break;
+	case MMC_TIMING_UHS_SDR50:
+	case MMC_TIMING_UHS_SDR104:
+	case MMC_TIMING_MMC_HS200:
+		speed_mod = SM3_HS200_SDR104;
+		break;
+	case MMC_TIMING_MMC_HS400:
+		speed_mod = SM4_HS400;
+		break;
+	default:
+		dev_err(mmc_dev(mmc), "Wrong timing input\n");
+		return;
+	}
+
+	if (clk <= 400 * 1000) {
+		frq_index = 0;
+	} else if (clk <= 25 * 1000 * 1000) {
+		frq_index = 1;
+	} else if (clk <= 50 * 1000 * 1000) {
+		frq_index = 2;
+	} else if (clk <= 100 * 1000 * 1000) {
+		frq_index = 3;
+	} else if (clk <= 150 * 1000 * 1000) {
+		frq_index = 4;
+	} else if (clk <= 200 * 1000 * 1000) {
+		frq_index = 5;
+	} else if (clk <= 250 * 1000 * 1000) {
+		frq_index = 6;
+	} else if (clk <= 300 * 1000 * 1000) {
+		frq_index = 7;
+	} else {
+		dev_err(mmc_dev(mmc), "clk is over 300mhz\n");
+		return;
+	}
+
+	if (frq_index / 4 > 2) {
+		dev_err(mmc_dev(host->mmc), "err frq_index\n");
+		return;
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "freq %d frq index %d,frq/4 %x\n", clk,
+		frq_index, frq_index / 4);
+	raw_sm_str = mmc_clk_dly[speed_mod].raw_tm_sm_str[frq_index / 4];
+	raw_sm = &mmc_clk_dly[speed_mod].raw_tm_sm[frq_index / 4];
+	raw_sm_def = &mmc_clk_dly[speed_mod].raw_tm_sm_def[frq_index / 4];
+	m_str = mmc_clk_dly[speed_mod].mod_str;
+
+	rval = of_property_read_u32(np, raw_sm_str, raw_sm);
+	if (rval) {
+		dev_info(mmc_dev(host->mmc), "failed to get %s used default\n",
+			 m_str);
+	} else {
+		u32 sm_shift = (frq_index % 4) * 8;
+
+		rval = ((*raw_sm) >> sm_shift) & 0xff;
+		if (rval != 0xff) {
+			if (timing == MMC_TIMING_MMC_HS400) {
+				u32 raw_sm_hs200 = 0;
+				u32 hs400_cmd_dly = 0;
+				s32 ret = sunxi_mmc_get_hs400_cmd_dly(host, clk,  &hs400_cmd_dly);
+
+				ds_dly = rval;
+				if (ret != 0) {
+					raw_sm_hs200 =
+					    mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm[frq_index / 4];
+					sam_dly = ((raw_sm_hs200) >> sm_shift) & 0xff;
+				} else {
+					sam_dly = hs400_cmd_dly;
+					//sam_dly = 57;
+					//printk("forec 57 sample dly\n");
+				}
+			} else {
+				sam_dly = rval;
+			}
+			dev_dbg(mmc_dev(host->mmc),
+				"Get speed mode %s clk dly %s ok\n", m_str,
+				raw_sm_str);
+		} else {
+			u32 sm_shift = (frq_index % 4) * 8;
+
+			dev_dbg(mmc_dev(host->mmc), "%s use default value\n",
+				m_str);
+			rval = ((*raw_sm_def) >> sm_shift) & 0xff;
+			if (timing == MMC_TIMING_MMC_HS400) {
+				u32 raw_sm_hs200 = 0;
+
+				ds_dly = rval;
+				raw_sm_hs200 =
+				    mmc_clk_dly[SM3_HS200_SDR104].
+				    raw_tm_sm_def[frq_index / 4];
+				sam_dly = ((raw_sm_hs200) >> sm_shift) & 0xff;
+			} else {
+				sam_dly = rval;
+			}
+		}
+
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "Try set %s clk dly	ok\n", m_str);
+	dev_dbg(mmc_dev(host->mmc), "cmd_drv_ph	%d\n", cmd_drv_ph);
+	dev_dbg(mmc_dev(host->mmc), "dat_drv_ph	%d\n", dat_drv_ph);
+	dev_dbg(mmc_dev(host->mmc), "sam_dly	%d\n", sam_dly);
+	dev_dbg(mmc_dev(host->mmc), "ds_dly		%d\n", ds_dly);
+
+	rval = mmc_readl(host, REG_DRV_DL);
+	if (cmd_drv_ph)
+		rval |= SDXC_CMD_DRV_PH_SEL;	/*180 phase */
+	else
+		rval &= ~SDXC_CMD_DRV_PH_SEL;	/*90 phase */
+
+	if (dat_drv_ph)
+		rval |= SDXC_DAT_DRV_PH_SEL;	/*180 phase */
+	else
+		rval &= ~SDXC_DAT_DRV_PH_SEL;	/*90 phase */
+
+	sunxi_r_op(host, mmc_writel(host, REG_DRV_DL, rval));
+	rval = mmc_readl(host, REG_SAMP_DL);
+	rval &= ~SDXC_SAMP_DL_SW_MASK;
+	rval |= sam_dly & SDXC_SAMP_DL_SW_MASK;
+	rval |= SDXC_SAMP_DL_SW_EN;
+	mmc_writel(host, REG_SAMP_DL, rval);
+
+	rval = mmc_readl(host, REG_DS_DL);
+	rval &= ~SDXC_DS_DL_SW_MASK;
+	rval |= ds_dly & SDXC_DS_DL_SW_MASK;
+	rval |= SDXC_DS_DL_SW_EN;
+	mmc_writel(host, REG_DS_DL, rval);
+
+	if (host->sfc_dis == true) {
+		rval = mmc_readl(host, REG_SFC);
+		rval |= SDXC_SFC_BP;
+		mmc_writel(host, REG_SFC, rval);
+		dev_dbg(mmc_dev(host->mmc), "sfc 0x%x\n", mmc_readl(host, REG_SFC));
+	}
+
+	dev_dbg(mmc_dev(host->mmc), " REG_DRV_DL    %08x\n",
+		mmc_readl(host, REG_DRV_DL));
+	dev_dbg(mmc_dev(host->mmc), " REG_SAMP_DL  %08x\n",
+		mmc_readl(host, REG_SAMP_DL));
+	dev_dbg(mmc_dev(host->mmc), " REG_DS_DL      %08x\n",
+		mmc_readl(host, REG_DS_DL));
+
+}
+
+static void sunxi_mmc_dump_dly2(struct sunxi_mmc_host *host)
+{
+	struct sunxi_mmc_clk_dly *mmc_clk_dly =
+	    ((struct sunxi_mmc_ver_priv *)host->version_priv_dat)->mmc_clk_dly;
+	int i = 0;
+
+	for (i = 0; i < SM_NUM; i++) {
+		pr_info("mod_str %s\n", mmc_clk_dly[i].mod_str);
+		pr_info("raw_tm_sm_str %s\n", mmc_clk_dly[i].raw_tm_sm_str[0]);
+		pr_info("raw_tm_sm_str %s\n", mmc_clk_dly[i].raw_tm_sm_str[1]);
+		pr_info("raw_tm_sm0 %x\n", mmc_clk_dly[i].raw_tm_sm[0]);
+		pr_info("raw_tm_sm1 %x\n", mmc_clk_dly[i].raw_tm_sm[1]);
+		pr_info("********************\n");
+	}
+}
+
+static void sunxi_mmc_on_off_emce_v4p6x(struct sunxi_mmc_host *host,
+		u32 en_crypt, u32 ac_mode, u32 en_emce, int data_len,
+		int bypass, int task_load)
+{
+	u32 rval = 0;
+
+#if IS_ENABLED(CONFIG_SUNXI_EMCE)
+	sunxi_emce_set_task_des(data_len, bypass);
+#endif
+	rval = mmc_readl(host, REG_EMCE);
+	rval &= 0x0000FFFF;
+	rval |= (0x200 << 16);
+	mmc_writel(host, REG_EMCE, rval);
+	rval &= ~(SDXC_EMCE_ENB | SDXC_EMCE_ENCR | SDXC_EMCE_AC_MD);
+	if (en_emce)
+		rval |= SDXC_EMCE_ENB;
+	if (en_crypt)
+		rval |= SDXC_EMCE_ENCR;
+	if (ac_mode)
+		rval |= SDXC_EMCE_AC_MD;
+	mmc_writel(host, REG_EMCE, rval);
+	dev_dbg(mmc_dev(host->mmc), "%s REG_EMCE:%x\n", __func__,
+		mmc_readl(host, REG_EMCE));
+#if IS_ENABLED(CONFIG_SUNXI_EMCE)
+	sunxi_emce_set_task_load(task_load);
+#endif
+}
+
+static int __sunxi_mmc_do_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en,
+				     u32 pwr_save, u32 ignore_dat0)
+{
+	unsigned long expire = jiffies + msecs_to_jiffies(250);
+	u32 rval;
+
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~(SDXC_CARD_CLOCK_ON | SDXC_LOW_POWER_ON | SDXC_MASK_DATA0);
+
+	if (oclk_en)
+		rval |= SDXC_CARD_CLOCK_ON;
+	if (pwr_save)
+		rval |= SDXC_LOW_POWER_ON;
+	if (ignore_dat0)
+		rval |= SDXC_MASK_DATA0;
+
+	mmc_writel(host, REG_CLKCR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), "%s REG_CLKCR:%x\n", __func__,
+		mmc_readl(host, REG_CLKCR));
+
+	rval = SDXC_START | SDXC_UPCLK_ONLY | SDXC_WAIT_PRE_OVER;
+	mmc_writel(host, REG_CMDR, rval);
+
+	do {
+		rval = mmc_readl(host, REG_CMDR);
+	} while (time_before(jiffies, expire) && (rval & SDXC_START));
+
+	/* clear irq status bits set by the command */
+	mmc_writel(host, REG_RINTR,
+		   mmc_readl(host, REG_RINTR) & ~SDXC_SDIO_INTERRUPT);
+
+	if (rval & SDXC_START) {
+		dev_err(mmc_dev(host->mmc), "fatal err update clk timeout\n");
+		return -EIO;
+	}
+
+	/*only use mask data0 when update clk,clear it when not update clk */
+	if (ignore_dat0)
+		mmc_writel(host, REG_CLKCR,
+			   mmc_readl(host, REG_CLKCR) & ~SDXC_MASK_DATA0);
+
+	return 0;
+}
+
+static int sunxi_mmc_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en)
+{
+	struct device_node *np = NULL;
+	struct mmc_host *mmc = host->mmc;
+	int pwr_save = 0;
+	int len = 0;
+
+	if (!mmc->parent || !mmc->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse power save mode\n");
+		return -EIO;
+	}
+
+	np = mmc->parent->of_node;
+	if (of_find_property(np, "sunxi-power-save-mode", &len))
+		pwr_save = 1;
+	return __sunxi_mmc_do_oclk_onoff(host, oclk_en, pwr_save, 1);
+}
+int sunxi_mmc_clk_set_rate_for_sdmmc_v4p5x(struct sunxi_mmc_host *host,
+					   struct mmc_ios *ios)
+{
+	u32 mod_clk = 0;
+	u32 src_clk = 0;
+	u32 rval = 0;
+	s32 err = 0;
+	u32 rate = 0;
+	char *sclk_name = NULL;
+	struct clk *mclk = host->clk_mmc;
+	struct clk *sclk = NULL;
+	struct device *dev = mmc_dev(host->mmc);
+	int div = 0;
+
+	if (ios->clock == 0) {
+		__sunxi_mmc_do_oclk_onoff(host, 0, 0, 1);
+		return 0;
+	}
+
+	if ((ios->bus_width == MMC_BUS_WIDTH_8)
+	    && (ios->timing == MMC_TIMING_MMC_DDR52)
+	    ) {
+		mod_clk = ios->clock << 2;
+		div = 1;
+	} else {
+		mod_clk = ios->clock << 1;
+		div = 0;
+	}
+
+	sclk = clk_get(dev, "osc24m");
+	sclk_name = "osc24m";
+	if (IS_ERR(sclk)) {
+		dev_err(mmc_dev(host->mmc), "Error to get source clock %s\n",
+			sclk_name);
+		return -1;
+	}
+
+	src_clk = clk_get_rate(sclk);
+	if (mod_clk > src_clk) {
+		clk_put(sclk);
+		sclk = clk_get(dev, "pll_periph");
+		sclk_name = "pll_periph";
+	}
+	if (IS_ERR(sclk)) {
+		dev_err(mmc_dev(host->mmc), "Error to get source clock %s\n",
+			sclk_name);
+		return -1;
+	}
+
+	sunxi_mmc_oclk_onoff(host, 0);
+
+	err = clk_set_parent(mclk, sclk);
+	if (err) {
+		dev_err(mmc_dev(host->mmc), "set parent failed\n");
+		clk_put(sclk);
+		return -1;
+	}
+
+	rate = clk_round_rate(mclk, mod_clk);
+
+	dev_dbg(mmc_dev(host->mmc), "get round rate %d\n", rate);
+
+	clk_disable_unprepare(host->clk_mmc);
+
+	err = clk_set_rate(mclk, rate);
+	if (err) {
+		dev_err(mmc_dev(host->mmc), "set mclk rate error, rate %dHz\n",
+			rate);
+		clk_put(sclk);
+		return -1;
+	}
+
+	rval = clk_prepare_enable(host->clk_mmc);
+	if (rval) {
+		dev_err(mmc_dev(host->mmc), "Enable mmc clk err %d\n", rval);
+		return -1;
+	}
+
+	src_clk = clk_get_rate(sclk);
+	clk_put(sclk);
+
+	dev_dbg(mmc_dev(host->mmc), "set round clock %d, soure clk is %d\n",
+		rate, src_clk);
+
+#ifdef MMC_FPGA
+	if ((ios->bus_width == MMC_BUS_WIDTH_8)
+	    && (ios->timing == MMC_TIMING_MMC_DDR52)
+	    ) {
+		/* clear internal divider */
+		rval = mmc_readl(host, REG_CLKCR);
+		rval &= ~0xff;
+		rval |= 1;
+	} else {
+		/* support internal divide clock under fpga environment  */
+		rval = mmc_readl(host, REG_CLKCR);
+		rval &= ~0xff;
+		rval |= 24000000 / mod_clk / 2;	/* =24M/400K/2=0x1E */
+	}
+	mmc_writel(host, REG_CLKCR, rval);
+	dev_info(mmc_dev(host->mmc), "--FPGA REG_CLKCR: 0x%08x\n",
+		 mmc_readl(host, REG_CLKCR));
+#else
+	/* clear internal divider */
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~0xff;
+	rval |= div;
+	mmc_writel(host, REG_CLKCR, rval);
+#endif
+
+	/*enable 1x mode*/
+	rval = mmc_readl(host, REG_SD_NTSR);
+	rval &= ~(SDXC_2X_TIMING_MODE);
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	if ((ios->bus_width == MMC_BUS_WIDTH_8)
+	    && (ios->timing == MMC_TIMING_MMC_HS400)
+	    ) {
+		rval = mmc_readl(host, REG_EDSD);
+		rval |= SDXC_HS400_MD_EN;
+		mmc_writel(host, REG_EDSD, rval);
+		rval = mmc_readl(host, REG_CSDC);
+		rval &= ~SDXC_CRC_DET_PARA_MASK;
+		rval |= SDXC_CRC_DET_PARA_HS400;
+		mmc_writel(host, REG_CSDC, rval);
+	} else {
+		rval = mmc_readl(host, REG_EDSD);
+		rval &= ~SDXC_HS400_MD_EN;
+		mmc_writel(host, REG_EDSD, rval);
+		rval = mmc_readl(host, REG_CSDC);
+		rval &= ~SDXC_CRC_DET_PARA_MASK;
+		rval |= SDXC_CRC_DET_PARA_OTHER;
+		mmc_writel(host, REG_CSDC, rval);
+	}
+	dev_dbg(mmc_dev(host->mmc), "SDXC_REG_EDSD: 0x%08x\n",
+		mmc_readl(host, REG_EDSD));
+	dev_dbg(mmc_dev(host->mmc), "SDXC_REG_CSDC: 0x%08x\n",
+		mmc_readl(host, REG_CSDC));
+
+	/*sunxi_of_parse_clk_dly(host); */
+	if ((ios->bus_width == MMC_BUS_WIDTH_8)
+	    && (ios->timing == MMC_TIMING_MMC_DDR52)
+	    ) {
+		ios->clock = rate >> 2;
+	} else {
+		ios->clock = rate >> 1;
+	}
+
+	sunxi_mmc_set_clk_dly(host, ios->clock, ios->bus_width, ios->timing);
+
+	return sunxi_mmc_oclk_onoff(host, 1);
+}
+
+void sunxi_mmc_thld_ctl_for_sdmmc_v4p5x(struct sunxi_mmc_host *host,
+					struct mmc_ios *ios,
+					struct mmc_data *data)
+{
+	u32 bsz = data->blksz;
+	/*unit:byte */
+	u32 tdtl = (host->dma_tl & SDXC_TX_TL_MASK) << 2;
+	/*unit:byte */
+	u32 rdtl = ((host->dma_tl & SDXC_RX_TL_MASK) >> 16) << 2;
+	u32 rval = 0;
+
+	if ((data->flags & MMC_DATA_WRITE)
+	    && (bsz <= SDXC_CARD_RD_THLD_SIZE)
+	    && (bsz <= tdtl)) {
+		rval = mmc_readl(host, REG_THLD);
+		rval &= ~SDXC_CARD_RD_THLD_MASK;
+		rval |= data->blksz << SDXC_CARD_RD_THLD_SIZE_SHIFT;
+		rval |= SDXC_CARD_WR_THLD_ENB;
+		mmc_writel(host, REG_THLD, rval);
+	} else {
+		rval = mmc_readl(host, REG_THLD);
+		rval &= ~SDXC_CARD_WR_THLD_ENB;
+		mmc_writel(host, REG_THLD, rval);
+	}
+
+	if ((data->flags & MMC_DATA_READ)
+	    && (bsz <= SDXC_CARD_RD_THLD_SIZE)
+	    /*((SDXC_FIFO_DETH<<2)-bsz) >= (rdtl) */
+	    && ((SDXC_FIFO_DETH << 2) >= (rdtl + bsz))
+	    && ((ios->timing == MMC_TIMING_MMC_HS200)
+	       || (ios->timing == MMC_TIMING_MMC_HS400))) {
+		rval = mmc_readl(host, REG_THLD);
+		rval &= ~SDXC_CARD_RD_THLD_MASK;
+		rval |= data->blksz << SDXC_CARD_RD_THLD_SIZE_SHIFT;
+		rval |= SDXC_CARD_RD_THLD_ENB;
+		mmc_writel(host, REG_THLD, rval);
+	} else {
+		rval = mmc_readl(host, REG_THLD);
+		rval &= ~SDXC_CARD_RD_THLD_ENB;
+		mmc_writel(host, REG_THLD, rval);
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "--SDXC_REG_THLD: 0x%08x\n",
+		mmc_readl(host, REG_THLD));
+
+}
+
+void sunxi_mmc_save_spec_reg_v4p5x(struct sunxi_mmc_host *host)
+{
+	struct sunxi_mmc_spec_regs *spec_regs =
+	    &((struct sunxi_mmc_ver_priv *)(host->version_priv_dat))->
+	    bak_spec_regs;
+	spec_regs->drv_dl = mmc_readl(host, REG_DRV_DL);
+	spec_regs->samp_dl = mmc_readl(host, REG_SAMP_DL);
+	spec_regs->ds_dl = mmc_readl(host, REG_DS_DL);
+	spec_regs->sd_ntsr = mmc_readl(host, REG_SD_NTSR);
+	spec_regs->edsd = mmc_readl(host, REG_EDSD);
+	spec_regs->csdc = mmc_readl(host, REG_CSDC);
+}
+
+void sunxi_mmc_restore_spec_reg_v4p5x(struct sunxi_mmc_host *host)
+{
+	struct sunxi_mmc_spec_regs *spec_regs =
+	    &((struct sunxi_mmc_ver_priv *)(host->version_priv_dat))->
+	    bak_spec_regs;
+	sunxi_r_op(host, mmc_writel(host, REG_DRV_DL, spec_regs->drv_dl));
+	mmc_writel(host, REG_SAMP_DL, spec_regs->samp_dl);
+	mmc_writel(host, REG_DS_DL, spec_regs->ds_dl);
+	mmc_writel(host, REG_SD_NTSR, spec_regs->sd_ntsr);
+	mmc_writel(host, REG_EDSD, spec_regs->edsd);
+	mmc_writel(host, REG_CSDC, spec_regs->csdc);
+}
+
+
+bool sunxi_mmc_opacmd23_v4p9(struct sunxi_mmc_host *host, bool set, u32 arg, u32 *rep)
+{
+	if (set) {
+		mmc_writel(host, REG_A23A, arg);
+		mmc_writel(host, REG_ECMD, mmc_readl(host, REG_ECMD) | SDXC_A23_EN);
+		dev_dbg(mmc_dev(host->mmc), "REG_ECMD %x,REG_A23A %x\n", mmc_readl(host, REG_ECMD), mmc_readl(host, REG_A23A));
+	} else {
+		if (rep)
+			*rep = mmc_readl(host, REG_ERESP);
+		else
+			dev_err(mmc_dev(host->mmc), "wrong fun rep point\n");
+	}
+	return set;
+}
+
+void sunxi_mmc_set_ds_dl_raw(struct sunxi_mmc_host *host,
+					 int sunxi_ds_dl)
+{
+	u32 rval;
+
+	rval = mmc_readl(host, REG_DS_DL);
+	rval &= ~SDXC_DS_DL_SW_MASK;
+	rval |= sunxi_ds_dl & SDXC_DS_DL_SW_MASK;
+	rval |= SDXC_DS_DL_SW_EN;
+	mmc_writel(host, REG_DS_DL, rval);
+
+	dev_info(mmc_dev(host->mmc), "RETRY: REG_DS_DL: 0x%08x\n",
+		 mmc_readl(host, REG_DS_DL));
+}
+
+void sunxi_mmc_set_samp_dl_raw(struct sunxi_mmc_host *host,
+					 int sunxi_samp_dl)
+{
+	u32 rval;
+
+	rval = mmc_readl(host, REG_SAMP_DL);
+	rval &= ~SDXC_SAMP_DL_SW_MASK;
+	rval |= sunxi_samp_dl & SDXC_SAMP_DL_SW_MASK;
+	rval |= SDXC_SAMP_DL_SW_EN;
+	mmc_writel(host, REG_SAMP_DL, rval);
+
+	dev_info(mmc_dev(host->mmc), "RETRY: REG_SAMP_DL: 0x%08x\n",
+		 mmc_readl(host, REG_SAMP_DL));
+}
+
+/*#define SUNXI_RETRY_TEST 1*/
+
+#ifdef SUNXI_RETRY_TEST
+#define  SUNXI_MAX_RETRY_INTERVAL_V4P5X  32
+#else
+#define  SUNXI_MAX_RETRY_INTERVAL_V4P5X  2
+#endif
+#define  SUNXI_MAX_DELAY_POINT_V4P5X  64
+#define  SUNXI_MAX_RETRY_CNT_V4P5X  (SUNXI_MAX_DELAY_POINT_V4P5X/SUNXI_MAX_RETRY_INTERVAL_V4P5X)
+
+static int sunxi_mmc_judge_retry_v4p6x(struct sunxi_mmc_host *host,
+				       struct mmc_command *cmd, u32 rcnt,
+				       u32 herrno, void *other)
+{
+	struct mmc_host *mmc = host->mmc;
+	struct mmc_card *card = mmc->card;
+
+	if (mmc->ios.timing == MMC_TIMING_MMC_HS400) {
+		if (rcnt < SUNXI_MAX_RETRY_CNT_V4P5X * 2) {
+			if (herrno) {
+				dev_dbg(mmc_dev(host->mmc), "<error retry>\n");
+				if (herrno & SDXC_INTERRUPT_CMD_ERROR_BIT) {
+					if (host->sunxi_samp_dl_cnt >= SUNXI_MAX_RETRY_CNT_V4P5X)
+						goto TO_HS;
+				sunxi_mmc_set_samp_dl_raw(host, (host->sunxi_samp_dl) % SUNXI_MAX_DELAY_POINT_V4P5X);
+#ifdef SUNXI_RETRY_TEST
+				sunxi_mmc_set_samp_dl_raw(host, 52);
+#endif
+				host->sunxi_samp_dl += SUNXI_MAX_RETRY_INTERVAL_V4P5X ;
+				host->sunxi_samp_dl_cnt++;
+				return 0;
+				} else if (host->sunxi_ds_dl_cnt < SUNXI_MAX_RETRY_CNT_V4P5X) {
+					sunxi_mmc_set_ds_dl_raw(host, (host->sunxi_ds_dl) % SUNXI_MAX_DELAY_POINT_V4P5X);
+#ifdef SUNXI_RETRY_TEST
+					sunxi_mmc_set_ds_dl_raw(host, 55);
+#endif
+					host->sunxi_ds_dl += SUNXI_MAX_RETRY_INTERVAL_V4P5X;
+					host->sunxi_ds_dl_cnt++;
+					return 0;
+				}
+			} else {
+				dev_dbg(mmc_dev(host->mmc), "<timeout retry>\n");
+				if (host->sunxi_samp_dl_cnt < SUNXI_MAX_RETRY_CNT_V4P5X) {
+					sunxi_mmc_set_samp_dl_raw(host, (host->sunxi_samp_dl) % SUNXI_MAX_DELAY_POINT_V4P5X);
+#ifdef SUNXI_RETRY_TEST
+					sunxi_mmc_set_samp_dl_raw(host, 52);
+#endif
+					host->sunxi_samp_dl_cnt++;
+					host->sunxi_samp_dl += SUNXI_MAX_RETRY_INTERVAL_V4P5X;
+					return 0;
+				} else if (host->sunxi_ds_dl_cnt < SUNXI_MAX_RETRY_CNT_V4P5X) {
+					sunxi_mmc_set_ds_dl_raw(host, (host->sunxi_ds_dl) % SUNXI_MAX_DELAY_POINT_V4P5X);
+#ifdef SUNXI_RETRY_TEST
+					sunxi_mmc_set_ds_dl_raw(host, 55);
+#endif
+					host->sunxi_ds_dl_cnt++;
+					host->sunxi_ds_dl += SUNXI_MAX_RETRY_INTERVAL_V4P5X;
+					return 0;
+				}
+			}
+		}
+TO_HS:
+		/* Reset and disabled mmc_avail_type to switch speed mode to HSDDR */
+		dev_info(mmc_dev(host->mmc), "sunxi v4p5x/v4p6x retry give up, return to HS\n");
+		card->mmc_avail_type &= ~(EXT_CSD_CARD_TYPE_HS200 | EXT_CSD_CARD_TYPE_HS400
+				| EXT_CSD_CARD_TYPE_HS400ES | EXT_CSD_CARD_TYPE_DDR_52);
+		return -1;
+	} else {
+		if (rcnt < SUNXI_MAX_RETRY_CNT_V4P5X) {
+			sunxi_mmc_set_samp_dl_raw(host, (host->sunxi_samp_dl) % 64);
+			host->sunxi_samp_dl += SUNXI_MAX_RETRY_INTERVAL_V4P5X;
+			return 0;
+		}
+
+		dev_info(mmc_dev(host->mmc), "sunxi v4p5x/v4p6x retry give up!\n");
+		return -1;
+	}
+}
+
+void sunxi_mmc_init_priv_v4p5x(struct sunxi_mmc_host *host,
+			       struct platform_device *pdev, int phy_index)
+{
+	struct sunxi_mmc_ver_priv *ver_priv =
+	    devm_kzalloc(&pdev->dev, sizeof(struct sunxi_mmc_ver_priv),
+			 GFP_KERNEL);
+	host->version_priv_dat = ver_priv;
+
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].spm = SM0_DS26_SDR12;
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].mod_str = "DS26_SDR12";
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm_str[0] =
+	    "sdc_tm4_sm0_freq0";
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm_str[1] =
+	    "sdc_tm4_sm0_freq1";
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm[0] = 0;
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm[1] = 0;
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm_def[0] = 0;
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm_def[1] = 0;
+
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].spm = SM1_HSSDR52_SDR25;
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].mod_str = "HSSDR52_SDR25";
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm_str[0] =
+	    "sdc_tm4_sm1_freq0";
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm_str[1] =
+	    "sdc_tm4_sm1_freq1";
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm[0] = 0;
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm[1] = 0;
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm_def[0] = 0;
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm_def[1] = 0;
+
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].spm = SM2_HSDDR52_DDR50;
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].mod_str = "HSDDR52_DDR50";
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm_str[0] =
+	    "sdc_tm4_sm2_freq0";
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm_str[1] =
+	    "sdc_tm4_sm2_freq1";
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm[0] = 0;
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm[1] = 0;
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm_def[0] = 0;
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm_def[1] = 0;
+
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].spm = SM3_HS200_SDR104;
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].mod_str = "HS200_SDR104";
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm_str[0] =
+	    "sdc_tm4_sm3_freq0";
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm_str[1] =
+	    "sdc_tm4_sm3_freq1";
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm[0] = 0;
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm[1] = 0;
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm_def[0] = 0;
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm_def[1] = 0x00000405;
+
+	ver_priv->mmc_clk_dly[SM4_HS400].spm = SM4_HS400;
+	ver_priv->mmc_clk_dly[SM4_HS400].mod_str = "HS400";
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm_str[0] = "sdc_tm4_sm4_freq0";
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm_str[1] = "sdc_tm4_sm4_freq1";
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm[0] = 0;
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm[1] = 0x00000608;
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm_def[0] = 0;
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm_def[1] = 0x00000408;
+
+	ver_priv->mmc_clk_dly[SM4_HS400_CMD].spm = SM4_HS400_CMD;
+	ver_priv->mmc_clk_dly[SM4_HS400_CMD].mod_str = "HS400_cmd";
+	ver_priv->mmc_clk_dly[SM4_HS400_CMD].raw_tm_sm_str[0] = "sdc_tm4_sm4_freq0_cmd";
+	ver_priv->mmc_clk_dly[SM4_HS400_CMD].raw_tm_sm_str[1] = "sdc_tm4_sm4_freq1_cmd";
+	ver_priv->mmc_clk_dly[SM4_HS400_CMD].raw_tm_sm[0] = 0x0;
+	ver_priv->mmc_clk_dly[SM4_HS400_CMD].raw_tm_sm[1] = 0x0;
+	ver_priv->mmc_clk_dly[SM4_HS400_CMD].raw_tm_sm_def[0] = 0x2520ffff;
+	ver_priv->mmc_clk_dly[SM4_HS400_CMD].raw_tm_sm_def[1] = 0xffffff11;
+
+	host->sunxi_mmc_clk_set_rate = sunxi_mmc_clk_set_rate_for_sdmmc_v4p5x;
+	/*host->dma_tl = (0x2<<28)|(7<<16)|248; */
+	host->dma_tl = SUNXI_DMA_TL_SDMMC_V4P5X;
+	/*host->idma_des_size_bits = 15; */
+	host->idma_des_size_bits = SUNXI_DES_SIZE_SDMMC_V4P5X;
+	host->sunxi_mmc_thld_ctl = sunxi_mmc_thld_ctl_for_sdmmc_v4p5x;
+	host->sunxi_mmc_save_spec_reg = sunxi_mmc_save_spec_reg_v4p5x;
+	host->sunxi_mmc_restore_spec_reg = sunxi_mmc_restore_spec_reg_v4p5x;
+	sunxi_mmc_reg_ex_res_inter(host, phy_index);
+	host->sunxi_mmc_set_acmda = sunxi_mmc_set_a12a;
+	host->sunxi_mmc_dump_dly_table = sunxi_mmc_dump_dly2;
+	host->phy_index = phy_index;
+	host->sunxi_mmc_judge_retry = sunxi_mmc_judge_retry_v4p6x;
+	if (mmc_readl(host, REG_SMCV) == SMHC_VERSION_V4P5P1) {
+		host->sfc_dis = true;
+	}
+
+	host->sunxi_mmc_oclk_en = sunxi_mmc_oclk_onoff;
+}
+EXPORT_SYMBOL_GPL(sunxi_mmc_init_priv_v4p5x);
+
+void sunxi_mmc_init_priv_v4p6x(struct sunxi_mmc_host *host,
+			       struct platform_device *pdev, int phy_index)
+{
+	struct sunxi_mmc_ver_priv *ver_priv =
+	    devm_kzalloc(&pdev->dev, sizeof(struct sunxi_mmc_ver_priv),
+			 GFP_KERNEL);
+	host->version_priv_dat = ver_priv;
+
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].spm = SM0_DS26_SDR12;
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].mod_str = "DS26_SDR12";
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm_str[0] =
+	    "sdc_tm4_sm0_freq0";
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm_str[1] =
+	    "sdc_tm4_sm0_freq1";
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm[0] = 0;
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm[1] = 0;
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm_def[0] = 0;
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm_def[1] = 0;
+
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].spm = SM1_HSSDR52_SDR25;
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].mod_str = "HSSDR52_SDR25";
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm_str[0] =
+	    "sdc_tm4_sm1_freq0";
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm_str[1] =
+	    "sdc_tm4_sm1_freq1";
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm[0] = 0;
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm[1] = 0;
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm_def[0] = 0;
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm_def[1] = 0;
+
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].spm = SM2_HSDDR52_DDR50;
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].mod_str = "HSDDR52_DDR50";
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm_str[0] =
+	    "sdc_tm4_sm2_freq0";
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm_str[1] =
+	    "sdc_tm4_sm2_freq1";
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm[0] = 0;
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm[1] = 0;
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm_def[0] = 0;
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm_def[1] = 0;
+
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].spm = SM3_HS200_SDR104;
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].mod_str = "HS200_SDR104";
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm_str[0] =
+	    "sdc_tm4_sm3_freq0";
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm_str[1] =
+	    "sdc_tm4_sm3_freq1";
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm[0] = 0;
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm[1] = 0;
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm_def[0] = 0;
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm_def[1] = 0x00000405;
+
+	ver_priv->mmc_clk_dly[SM4_HS400].spm = SM4_HS400;
+	ver_priv->mmc_clk_dly[SM4_HS400].mod_str = "HS400";
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm_str[0] = "sdc_tm4_sm4_freq0";
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm_str[1] = "sdc_tm4_sm4_freq1";
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm[0] = 0;
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm[1] = 0x00000608;
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm_def[0] = 0;
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm_def[1] = 0x00000408;
+
+	ver_priv->mmc_clk_dly[SM4_HS400_CMD].spm = SM4_HS400_CMD;
+	ver_priv->mmc_clk_dly[SM4_HS400_CMD].mod_str = "HS400_cmd";
+	ver_priv->mmc_clk_dly[SM4_HS400_CMD].raw_tm_sm_str[0] = "sdc_tm4_sm4_freq0_cmd";
+	ver_priv->mmc_clk_dly[SM4_HS400_CMD].raw_tm_sm_str[1] = "sdc_tm4_sm4_freq1_cmd";
+	ver_priv->mmc_clk_dly[SM4_HS400_CMD].raw_tm_sm[0] = 0x0;
+	ver_priv->mmc_clk_dly[SM4_HS400_CMD].raw_tm_sm[1] = 0x0;
+	ver_priv->mmc_clk_dly[SM4_HS400_CMD].raw_tm_sm_def[0] = 0x2520ffff;
+	ver_priv->mmc_clk_dly[SM4_HS400_CMD].raw_tm_sm_def[1] = 0xffffff11;
+
+	host->sunxi_mmc_clk_set_rate = sunxi_mmc_clk_set_rate_for_sdmmc_v4p5x;
+	/*host->dma_tl = (0x2<<28)|(7<<16)|248; */
+	host->dma_tl = SUNXI_DMA_TL_SDMMC_V4P5X;
+	/*host->idma_des_size_bits = 15; */
+	host->idma_des_size_bits = SUNXI_DES_SIZE_SDMMC_V4P5X;
+	host->sunxi_mmc_thld_ctl = sunxi_mmc_thld_ctl_for_sdmmc_v4p5x;
+	host->sunxi_mmc_save_spec_reg = sunxi_mmc_save_spec_reg_v4p5x;
+	host->sunxi_mmc_restore_spec_reg = sunxi_mmc_restore_spec_reg_v4p5x;
+	sunxi_mmc_reg_ex_res_inter(host, phy_index);
+	host->sunxi_mmc_set_acmda = sunxi_mmc_set_a12a;
+	host->sunxi_mmc_dump_dly_table = sunxi_mmc_dump_dly2;
+	host->phy_index = phy_index;
+	host->sunxi_mmc_judge_retry = sunxi_mmc_judge_retry_v4p6x;
+	if (mmc_readl(host, REG_SMCV) >= SMHC_VERSION_V4P7)
+		host->sunxi_mmc_on_off_emce = sunxi_mmc_on_off_emce_v4p6x;
+	if (mmc_readl(host, REG_SMCV) >= SMHC_VERSION_V4P9) {
+		host->sunxi_mmc_opacmd23 = sunxi_mmc_opacmd23_v4p9;
+	}
+	if (mmc_readl(host, REG_SMCV) == SMHC_VERSION_V4P9) {
+		host->sfc_dis = true;
+	}
+	if (mmc_readl(host, REG_SMCV) == SMHC_VERSION_V4P5P2) {
+		host->des_addr_shift = 2;
+	}
+
+	if (mmc_readl(host, REG_SMCV) >= SMHC_VERSION_V5P3) {
+		host->des_addr_shift = 2;
+	}
+
+	host->sunxi_mmc_oclk_en = sunxi_mmc_oclk_onoff;
+}
+EXPORT_SYMBOL_GPL(sunxi_mmc_init_priv_v4p6x);
diff --git a/drivers/mmc/host/sunxi-mmc-v4p5x.h b/drivers/mmc/host/sunxi-mmc-v4p5x.h
new file mode 100644
index 000000000..7684058b5
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-v4p5x.h
@@ -0,0 +1,24 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#ifndef __SUNXI_MMC_V4P5X_H__
+#define __SUNXI_MMC_V4P5X_H__
+
+void sunxi_mmc_init_priv_v4p5x(struct sunxi_mmc_host *host,
+			       struct platform_device *pdev, int phy_index);
+void sunxi_mmc_init_priv_v4p6x(struct sunxi_mmc_host *host,
+			       struct platform_device *pdev, int phy_index);
+#endif
diff --git a/drivers/mmc/host/sunxi-mmc-v5p3x.c b/drivers/mmc/host/sunxi-mmc-v5p3x.c
new file mode 100644
index 000000000..abd4080a3
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-v5p3x.c
@@ -0,0 +1,803 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+
+#include <linux/clk.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/slot-gpio.h>
+
+#include "sunxi-mmc.h"
+#include "sunxi-mmc-v5p3x.h"
+#include "sunxi-mmc-export.h"
+
+#define SUNXI_RETRY_CNT_PER_PHA_V5P3X		3
+
+/*dma triger level setting*/
+#define SUNXI_DMA_TL_SDMMC_V5P3X	((0x2<<28)|(7<<16)|248)
+/*one dma des can transfer data size = 1<<SUNXI_DES_SIZE_SDMMC*/
+
+#define SUNXI_DES_SIZE_SDMMC_V5P3X	(12)
+
+/*reg*/
+/*SMHC eMMC4.5 DDR Start Bit Detection Control Register */
+/*SMHC CRC Status Detect Control Register */
+/*SMHC Card Threshold Control Register */
+/*SMHC Drive Delay Control Register */
+/*SMHC Sample Delay Control Register */
+/*SMHC Data Strobe Delay Control Register */
+/*SMHC NewTiming Set Register */
+/*SMHC Version Register */
+/*SMHC HS400 New Timing Delay Control Register*/
+#define SDXC_REG_EDSD		(0x010C)
+#define SDXC_REG_CSDC		(0x0054)
+#define SDXC_REG_THLD		(0x0100)
+#define SDXC_REG_DRV_DL		(0x0140)
+#define SDXC_REG_SAMP_DL	(0x0144)
+#define SDXC_REG_DS_DL		(0x0148)
+#define SDXC_REG_SD_NTSR	(0x005C)
+#define SDXC_REG_SMCV		(0x300)		/*SMHC Version Register */
+#define SDXC_REG_NTDL_HS400	(0x800)
+
+#define SDXC_SFC_BP					BIT(0)
+/*bit*/
+#define SDXC_HS400_MD_EN				(1U<<31)
+#define SDXC_CARD_WR_THLD_ENB		(1U<<2)
+#define SDXC_CARD_RD_THLD_ENB		(1U)
+
+#define SDXC_DAT_DRV_PH_SEL			(1U<<17)
+#define SDXC_CMD_DRV_PH_SEL			(1U<<16)
+#define SDXC_SAMP_DL_SW_EN			(1u<<7)
+#define SDXC_DS_DL_SW_EN			(1u<<7)
+
+#define	SDXC_2X_TIMING_MODE			(1U<<31)
+#define SDXC_HS400_NEW_SAMPLE_EN			(1U<<0)
+
+/*mask*/
+#define SDXC_CRC_DET_PARA_MASK		(0xf)
+#define SDXC_CARD_RD_THLD_MASK		(0x0FFF0000)
+#define SDXC_TX_TL_MASK				(0xff)
+#define SDXC_RX_TL_MASK				(0x00FF0000)
+
+#define SDXC_HS400_SAMP_DL_SW_MASK		(0x0000000F)
+#define SDXC_SAMP_DL_SW_MASK		(0x0000003F)
+#define SDXC_DS_DL_SW_MASK			(0x0000003F)
+
+#define SDXC_STIMING_CMD_PH_MASK		(0x00000030)
+#define SDXC_STIMING_DAT_PH_MASK		(0x00000300)
+
+/*value*/
+#define SDXC_CRC_DET_PARA_HS400		(6)
+#define SDXC_CRC_DET_PARA_OTHER		(3)
+#define SDXC_FIFO_DETH					(1024>>2)
+
+/*size*/
+#define SDXC_CARD_RD_THLD_SIZE		(0x00000FFF)
+
+/*shit*/
+#define SDXC_CARD_RD_THLD_SIZE_SHIFT		(16)
+
+#define SDXC_STIMING_CMD_PH_SHIFT			(4)
+#define SDXC_STIMING_DAT_PH_SHIFT			(8)
+
+/*Sunxi MMC Host Controller Version*/
+#define SMHC_VERSION_V5P3	0x50300
+
+
+enum sunxi_mmc_clk_mode {
+	mmc_clk_400k = 0,
+	mmc_clk_26M,
+	mmc_clk_52M,
+	mmc_clk_52M_DDR4,
+	mmc_clk_52M_DDR8,
+	mmc_clk_104M,
+	mmc_clk_208M,
+	mmc_clk_104M_DDR,
+	mmc_clk_208M_DDR,
+	mmc_clk_mod_num,
+};
+
+struct sunxi_mmc_clk_dly {
+	char *mod_str;
+	/*only used for 2X mode*/
+	enum sunxi_mmc_clk_mode cmod;
+	u32 cmd_drv_ph;
+	u32 dat_drv_ph;
+	u32 sam_dly;
+	u32 ds_dly;
+	u32 sam_ph_dat;
+	u32 sam_ph_cmd;
+};
+
+struct sunxi_mmc_spec_regs {
+	u32 drv_dl;		/*REG_DRV_DL */
+	u32 samp_dl;		/*REG_SAMP_DL */
+	u32 ds_dl;		/*REG_DS_DL */
+	u32 sd_ntsr;		/*REG_SD_NTSR */
+};
+
+struct sunxi_mmc_ver_priv {
+	struct sunxi_mmc_spec_regs bak_spec_regs;
+	struct sunxi_mmc_clk_dly mmc_clk_dly[mmc_clk_mod_num];
+};
+
+static void sunxi_mmc_set_clk_dly(struct sunxi_mmc_host *host, int clk,
+				  int bus_width, int timing)
+{
+	struct mmc_host *mhost = host->mmc;
+	u32 rval = 0;
+	enum sunxi_mmc_clk_mode cmod = mmc_clk_400k;
+	u32 in_clk_dly[6] = { 0 };
+	int ret = 0;
+	struct device_node *np = NULL;
+	struct sunxi_mmc_clk_dly *mmc_clk_dly =
+	    ((struct sunxi_mmc_ver_priv *)host->version_priv_dat)->mmc_clk_dly;
+
+	if (!mhost->parent || !mhost->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse clk dly,use default\n");
+		return;
+	}
+
+	np = mhost->parent->of_node;
+
+	if (clk <= 400 * 1000) {
+		cmod = mmc_clk_400k;
+	} else if (clk <= 26 * 1000 * 1000) {
+		cmod = mmc_clk_26M;
+	} else if (clk <= 52 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_4)
+		    && sunxi_mmc_ddr_timing(timing)) {
+			cmod = mmc_clk_52M_DDR4;
+		} else if ((bus_width == MMC_BUS_WIDTH_8)
+			   && (timing == MMC_TIMING_MMC_DDR52)) {
+			cmod = mmc_clk_52M_DDR8;
+		} else {
+			cmod = mmc_clk_52M;
+		}
+	} else if (clk <= 104 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_8)
+		    && (timing == MMC_TIMING_MMC_HS400)) {
+			cmod = mmc_clk_104M_DDR;
+		} else {
+			cmod = mmc_clk_104M;
+		}
+	} else if (clk <= 208 * 1000 * 1000) {
+		if ((bus_width == MMC_BUS_WIDTH_8)
+		    && (timing == MMC_TIMING_MMC_HS400)) {
+			cmod = mmc_clk_208M_DDR;
+		} else {
+			cmod = mmc_clk_208M;
+		}
+	} else {
+		dev_err(mmc_dev(mhost), "clk %d is out of range\n", clk);
+		return;
+	}
+
+	ret = of_property_read_u32_array(np, mmc_clk_dly[cmod].mod_str,
+					 in_clk_dly, ARRAY_SIZE(in_clk_dly));
+	if (ret) {
+		dev_dbg(mmc_dev(host->mmc), "failed to get %s used default\n",
+			mmc_clk_dly[cmod].mod_str);
+	} else {
+		mmc_clk_dly[cmod].cmd_drv_ph = in_clk_dly[0];
+		mmc_clk_dly[cmod].dat_drv_ph = in_clk_dly[1];
+		/*mmc_clk_dly[cmod].sam_dly             = in_clk_dly[2]; */
+		/*mmc_clk_dly[cmod].ds_dly              = in_clk_dly[3]; */
+		mmc_clk_dly[cmod].sam_ph_dat = in_clk_dly[4];
+		mmc_clk_dly[cmod].sam_ph_cmd = in_clk_dly[5];
+		dev_dbg(mmc_dev(host->mmc), "Get %s clk dly ok\n",
+			mmc_clk_dly[cmod].mod_str);
+
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "Try set %s clk dly	ok\n",
+		mmc_clk_dly[cmod].mod_str);
+	dev_dbg(mmc_dev(host->mmc), "cmd_drv_ph	%d\n",
+		mmc_clk_dly[cmod].cmd_drv_ph);
+	dev_dbg(mmc_dev(host->mmc), "dat_drv_ph	%d\n",
+		mmc_clk_dly[cmod].dat_drv_ph);
+	dev_dbg(mmc_dev(host->mmc), "sam_ph_dat	%d\n",
+		mmc_clk_dly[cmod].sam_ph_dat);
+	dev_dbg(mmc_dev(host->mmc), "sam_ph_cmd	%d\n",
+		mmc_clk_dly[cmod].sam_ph_cmd);
+
+	rval = mmc_readl(host, REG_DRV_DL);
+	if (mmc_clk_dly[cmod].cmd_drv_ph)
+		rval |= SDXC_CMD_DRV_PH_SEL;	/*180 phase */
+	else
+		rval &= ~SDXC_CMD_DRV_PH_SEL;	/*90 phase */
+
+	if (mmc_clk_dly[cmod].dat_drv_ph)
+		rval |= SDXC_DAT_DRV_PH_SEL;	/*180 phase */
+	else
+		rval &= ~SDXC_DAT_DRV_PH_SEL;	/*90 phase */
+
+	sunxi_r_op(host, mmc_writel(host, REG_DRV_DL, rval));
+
+/*
+*      rval = mmc_readl(host,REG_SAMP_DL);
+*      rval &= ~SDXC_SAMP_DL_SW_MASK;
+*      rval |= mmc_clk_dly[cmod].sam_dly & SDXC_SAMP_DL_SW_MASK;
+*      rval |= SDXC_SAMP_DL_SW_EN;
+*      mmc_writel(host,REG_SAMP_DL,rval);
+*
+*     rval = mmc_readl(host,REG_DS_DL);
+*     rval &= ~SDXC_DS_DL_SW_MASK;
+*     rval |= mmc_clk_dly[cmod].ds_dly & SDXC_DS_DL_SW_MASK;
+*     rval |= SDXC_DS_DL_SW_EN;
+*    mmc_writel(host,REG_DS_DL,rval);
+*/
+
+	rval = mmc_readl(host, REG_SD_NTSR);
+	rval &= ~SDXC_STIMING_DAT_PH_MASK;
+	rval |=
+	    (mmc_clk_dly[cmod].
+	     sam_ph_dat << SDXC_STIMING_DAT_PH_SHIFT) &
+	    SDXC_STIMING_DAT_PH_MASK;
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	rval = mmc_readl(host, REG_SD_NTSR);
+	rval &= ~SDXC_STIMING_CMD_PH_MASK;
+	rval |=
+	    (mmc_clk_dly[cmod].
+	     sam_ph_cmd << SDXC_STIMING_CMD_PH_SHIFT) &
+	    SDXC_STIMING_CMD_PH_MASK;
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), " REG_DRV_DL    %08x\n",
+		mmc_readl(host, REG_DRV_DL));
+	dev_dbg(mmc_dev(host->mmc), " REG_SAMP_DL  %08x\n",
+		mmc_readl(host, REG_SAMP_DL));
+	dev_dbg(mmc_dev(host->mmc), " REG_DS_DL      %08x\n",
+		mmc_readl(host, REG_DS_DL));
+	dev_dbg(mmc_dev(host->mmc), " REG_SD_NTSR      %08x\n",
+		mmc_readl(host, REG_SD_NTSR));
+
+}
+
+static int __sunxi_mmc_do_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en,
+				     u32 pwr_save, u32 ignore_dat0)
+{
+	unsigned long expire = jiffies + msecs_to_jiffies(250);
+	u32 rval;
+
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~(SDXC_CARD_CLOCK_ON | SDXC_LOW_POWER_ON | SDXC_MASK_DATA0);
+
+	if (oclk_en)
+		rval |= SDXC_CARD_CLOCK_ON;
+	if (pwr_save && host->voltage_switching == 0)
+		rval |= SDXC_LOW_POWER_ON;
+	if (ignore_dat0)
+		rval |= SDXC_MASK_DATA0;
+
+	mmc_writel(host, REG_CLKCR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), "%s REG_CLKCR:%x\n", __func__,
+		mmc_readl(host, REG_CLKCR));
+
+	if (host->voltage_switching == 1) {
+		rval = SDXC_START | SDXC_UPCLK_ONLY | SDXC_WAIT_PRE_OVER | SDXC_VOLTAGE_SWITCH;
+	} else {
+		rval = SDXC_START | SDXC_UPCLK_ONLY | SDXC_WAIT_PRE_OVER;
+	}
+	mmc_writel(host, REG_CMDR, rval);
+
+	do {
+		rval = mmc_readl(host, REG_CMDR);
+	} while (time_before(jiffies, expire) && (rval & SDXC_START));
+
+	/* clear irq status bits set by the command */
+	mmc_writel(host, REG_RINTR,
+		   mmc_readl(host, REG_RINTR) & ~SDXC_SDIO_INTERRUPT);
+
+	if (rval & SDXC_START) {
+		dev_err(mmc_dev(host->mmc), "fatal err update clk timeout\n");
+		return -EIO;
+	}
+
+	/*only use mask data0 when update clk,clear it when not update clk */
+	if (ignore_dat0)
+		mmc_writel(host, REG_CLKCR,
+			   mmc_readl(host, REG_CLKCR) & ~SDXC_MASK_DATA0);
+
+	return 0;
+}
+
+static int sunxi_mmc_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en)
+{
+	struct device_node *np = NULL;
+	struct mmc_host *mmc = host->mmc;
+	int pwr_save = 0;
+	int len = 0;
+
+	if (!mmc->parent || !mmc->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse power save mode\n");
+		return -EIO;
+	}
+
+	np = mmc->parent->of_node;
+	if (of_find_property(np, "sunxi-power-save-mode", &len))
+		pwr_save = 1;
+	return __sunxi_mmc_do_oclk_onoff(host, oclk_en, pwr_save, 1);
+}
+
+static void sunxi_mmc_2xmod_onoff(struct sunxi_mmc_host *host, u32 newmode_en)
+{
+	u32 rval = mmc_readl(host, REG_SD_NTSR);
+
+	if (newmode_en)
+		rval |= SDXC_2X_TIMING_MODE;
+	else
+		rval &= ~SDXC_2X_TIMING_MODE;
+
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	dev_dbg(mmc_dev(host->mmc), "REG_SD_NTSR: 0x%08x ,val %x\n",
+		mmc_readl(host, REG_SD_NTSR), rval);
+}
+
+static int sunxi_mmc_clk_set_rate_for_sdmmc_v5p3x(struct sunxi_mmc_host *host,
+						  struct mmc_ios *ios)
+{
+	u32 mod_clk = 0;
+	u32 src_clk = 0;
+	u32 rval = 0;
+	s32 err = 0;
+	u32 rate = 0;
+	char *sclk_name = NULL;
+	struct clk *mclk = host->clk_mmc;
+	struct clk *sclk = NULL;
+	struct device *dev = mmc_dev(host->mmc);
+	int div = 0;
+#ifdef MMC_FPGA
+	void __iomem *ctl_2x_en = ioremap(0x03000024, 0x4);
+#endif
+	if (ios->clock == 0) {
+		__sunxi_mmc_do_oclk_onoff(host, 0, 0, 1);
+		return 0;
+	}
+	if (sunxi_mmc_ddr_timing(ios->timing) || (ios->timing == MMC_TIMING_MMC_HS400)) {
+		mod_clk = ios->clock << 2;
+		div = 1;
+	} else {
+		mod_clk = ios->clock << 1;
+		div = 0;
+	}
+	sclk = clk_get(dev, "osc24m");
+	sclk_name = "osc24m";
+	if (IS_ERR(sclk)) {
+		dev_err(mmc_dev(host->mmc), "Error to get source clock %s\n",
+			sclk_name);
+		return -1;
+	}
+
+	src_clk = clk_get_rate(sclk);
+	if (mod_clk > src_clk) {
+		clk_put(sclk);
+		sclk = clk_get(dev, "pll_periph");
+		sclk_name = "pll_periph";
+	}
+	if (IS_ERR(sclk)) {
+		dev_err(mmc_dev(host->mmc), "Error to get source clock %s\n",
+			sclk_name);
+		return -1;
+	}
+
+	sunxi_mmc_oclk_onoff(host, 0);
+
+	err = clk_set_parent(mclk, sclk);
+	if (err) {
+		dev_err(mmc_dev(host->mmc), "set parent failed\n");
+		clk_put(sclk);
+		return -1;
+	}
+
+	rate = clk_round_rate(mclk, mod_clk);
+
+	dev_dbg(mmc_dev(host->mmc), "get round rate %d\n", rate);
+
+	clk_disable_unprepare(host->clk_mmc);
+
+	err = clk_set_rate(mclk, rate);
+	if (err) {
+		dev_err(mmc_dev(host->mmc), "set mclk rate error, rate %dHz\n",
+			rate);
+		clk_put(sclk);
+		return -1;
+	}
+
+	rval = clk_prepare_enable(host->clk_mmc);
+	if (rval) {
+		dev_err(mmc_dev(host->mmc), "Enable mmc clk err %d\n", rval);
+		return -1;
+	}
+
+	src_clk = clk_get_rate(sclk);
+	clk_put(sclk);
+
+	dev_dbg(mmc_dev(host->mmc), "set round clock %d, soure clk is %d\n",
+		rate, src_clk);
+
+#ifdef MMC_FPGA
+	if (sunxi_mmc_ddr_timing(ios->timing)) {
+		/* clear internal divider */
+		rval = mmc_readl(host, REG_CLKCR);
+		rval &= ~0xff;
+		rval |= 1;
+	}
+	mmc_writel(host, REG_CLKCR, rval);
+
+	rval = mmc_readl(host, REG_DRV_DL);
+	if (ios->clock > 400 * 1000) {
+		rval |= (1 << 7);
+		mmc_writel(host, REG_DRV_DL, rval);
+	} else {
+		if (sunxi_mmc_ddr_timing(ios->timing))
+			dev_info(mmc_dev(host->mmc), "Warning: is 400KHz DDR mode");
+		rval &= ~(1 << 7);
+		sunxi_r_op(host, mmc_writel(host, REG_DRV_DL, rval));
+	}
+	dev_info(mmc_dev(host->mmc), "FPGA REG_CLKCR: 0x%08x\n",
+		mmc_readl(host, REG_CLKCR));
+#else
+	/* clear internal divider */
+	rval = mmc_readl(host, REG_CLKCR);
+	rval &= ~0xff;
+	rval |= div;
+	mmc_writel(host, REG_CLKCR, rval);
+#endif
+#ifdef MMC_FPGA
+	/* Because V7 FPGA board only support 1xmode, use 0x03000024 Bit3 to control 1xmode or 2xmode ,*/
+	rval = readl(ctl_2x_en);
+	/*sunxi_of_parse_clk_dly(host); */
+	if (rval & (0x1 << 3))
+		sunxi_mmc_2xmod_onoff(host, 1);
+	else
+		sunxi_mmc_2xmod_onoff(host, 0);
+
+	iounmap(ctl_2x_en);
+#else
+	sunxi_mmc_2xmod_onoff(host, 1);
+#endif
+	if ((ios->bus_width == MMC_BUS_WIDTH_8)
+	    && (ios->timing == MMC_TIMING_MMC_HS400)
+	    ) {
+		rval = mmc_readl(host, REG_EDSD);
+		rval |= SDXC_HS400_MD_EN;
+		mmc_writel(host, REG_EDSD, rval);
+		rval = mmc_readl(host, REG_CSDC);
+		rval &= ~SDXC_CRC_DET_PARA_MASK;
+		rval |= SDXC_CRC_DET_PARA_HS400;
+		mmc_writel(host, REG_CSDC, rval);
+
+		rval = mmc_readl(host, REG_SD_NTSR);
+		rval |= SDXC_HS400_NEW_SAMPLE_EN;
+		mmc_writel(host, REG_SD_NTSR, rval);
+	} else {
+		rval = mmc_readl(host, REG_EDSD);
+		rval &= ~SDXC_HS400_MD_EN;
+		mmc_writel(host, REG_EDSD, rval);
+		rval = mmc_readl(host, REG_CSDC);
+		rval &= ~SDXC_CRC_DET_PARA_MASK;
+		rval |= SDXC_CRC_DET_PARA_OTHER;
+		mmc_writel(host, REG_CSDC, rval);
+	}
+	dev_dbg(mmc_dev(host->mmc), "SDXC_REG_EDSD: 0x%08x\n",
+		mmc_readl(host, REG_EDSD));
+	dev_dbg(mmc_dev(host->mmc), "SDXC_REG_CSDC: 0x%08x\n",
+		mmc_readl(host, REG_CSDC));
+
+	if (sunxi_mmc_ddr_timing(ios->timing) || (ios->timing == MMC_TIMING_MMC_HS400))
+		ios->clock = rate >> 2;
+	else
+		ios->clock = rate >> 1;
+
+	sunxi_mmc_set_clk_dly(host, ios->clock, ios->bus_width, ios->timing);
+
+	return sunxi_mmc_oclk_onoff(host, 1);
+}
+
+static void sunxi_mmc_thld_ctl_for_sdmmc_v5p3x(struct sunxi_mmc_host *host,
+					       struct mmc_ios *ios,
+					       struct mmc_data *data)
+{
+	u32 bsz = data->blksz;
+	/*unit:byte */
+	/*u32 tdtl = (host->dma_tl & SDXC_TX_TL_MASK)<<2;*/
+	/*unit:byte */
+	u32 rdtl = ((host->dma_tl & SDXC_RX_TL_MASK) >> 16) << 2;
+	u32 rval = 0;
+
+	if ((data->flags & MMC_DATA_READ)
+	    && (bsz <= SDXC_CARD_RD_THLD_SIZE)
+	    /*((SDXC_FIFO_DETH<<2)-bsz) >= (rdtl) */
+	    && ((SDXC_FIFO_DETH << 2) >= (rdtl + bsz))
+	    && ((ios->timing == MMC_TIMING_MMC_HS200)
+	       || (ios->timing == MMC_TIMING_UHS_SDR50)
+	       || (ios->timing == MMC_TIMING_UHS_SDR104))) {
+		rval = mmc_readl(host, REG_THLD);
+		rval &= ~SDXC_CARD_RD_THLD_MASK;
+		rval |= data->blksz << SDXC_CARD_RD_THLD_SIZE_SHIFT;
+		rval |= SDXC_CARD_RD_THLD_ENB;
+		mmc_writel(host, REG_THLD, rval);
+	} else {
+		rval = mmc_readl(host, REG_THLD);
+		rval &= ~SDXC_CARD_RD_THLD_ENB;
+		mmc_writel(host, REG_THLD, rval);
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "SDXC_REG_THLD: 0x%08x\n",
+		mmc_readl(host, REG_THLD));
+
+}
+
+static void sunxi_mmc_save_spec_reg_v5p3x(struct sunxi_mmc_host *host)
+{
+	struct sunxi_mmc_spec_regs *spec_regs =
+	    &((struct sunxi_mmc_ver_priv *)(host->version_priv_dat))->
+	    bak_spec_regs;
+	spec_regs->drv_dl = mmc_readl(host, REG_DRV_DL);
+	spec_regs->samp_dl = mmc_readl(host, REG_SAMP_DL);
+	spec_regs->ds_dl = mmc_readl(host, REG_DS_DL);
+	spec_regs->sd_ntsr = mmc_readl(host, REG_SD_NTSR);
+}
+
+static void sunxi_mmc_restore_spec_reg_v5p3x(struct sunxi_mmc_host *host)
+{
+	struct sunxi_mmc_spec_regs *spec_regs =
+	    &((struct sunxi_mmc_ver_priv *)(host->version_priv_dat))->
+	    bak_spec_regs;
+	sunxi_r_op(host, mmc_writel(host, REG_DRV_DL, spec_regs->drv_dl));
+	mmc_writel(host, REG_SAMP_DL, spec_regs->samp_dl);
+	mmc_writel(host, REG_DS_DL, spec_regs->ds_dl);
+	mmc_writel(host, REG_SD_NTSR, spec_regs->sd_ntsr);
+}
+
+static inline void sunxi_mmc_set_dly_raw(struct sunxi_mmc_host *host,
+					 s32 opha_cmd, s32 ipha_cmd,
+					 s32 opha_dat, s32 ipha_dat,
+					 s32 samp_dl)
+{
+	struct mmc_host *mmc = host->mmc;
+	u32 rval = mmc_readl(host, REG_DRV_DL);
+
+	if (opha_cmd > 0)
+		rval |= SDXC_CMD_DRV_PH_SEL;	/*180 phase */
+	else if (opha_cmd == 0)
+		rval &= ~SDXC_CMD_DRV_PH_SEL;	/*90 phase */
+
+	if (opha_dat > 0)
+		rval |= SDXC_DAT_DRV_PH_SEL;	/*180 phase */
+	else if (opha_dat == 0)
+		rval &= ~SDXC_DAT_DRV_PH_SEL;	/*90 phase */
+
+	sunxi_r_op(host, mmc_writel(host, REG_DRV_DL, rval));
+
+	rval = mmc_readl(host, REG_SD_NTSR);
+
+	if (ipha_cmd >= 0) {
+		rval &= ~SDXC_STIMING_CMD_PH_MASK;
+		rval |=
+		    (ipha_cmd << SDXC_STIMING_CMD_PH_SHIFT) &
+		    SDXC_STIMING_CMD_PH_MASK;
+	}
+
+	if (ipha_dat >= 0) {
+		rval &= ~SDXC_STIMING_DAT_PH_MASK;
+		rval |=
+		    (ipha_dat << SDXC_STIMING_DAT_PH_SHIFT) &
+		    SDXC_STIMING_DAT_PH_MASK;
+	}
+
+	rval &= ~SDXC_2X_TIMING_MODE;
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	/*select the 2x mode*/
+	rval |= SDXC_2X_TIMING_MODE;
+	mmc_writel(host, REG_SD_NTSR, rval);
+
+	/*only sdc2 with HS400 support the hs400 new sample enable on the 2x mode*/
+	if ((mmc->ios.timing == MMC_TIMING_MMC_HS400) && (rval & SDXC_HS400_NEW_SAMPLE_EN)) {
+		rval = mmc_readl(host, REG_NTDL_HS400);
+		rval &= ~SDXC_HS400_SAMP_DL_SW_MASK;
+		rval |= samp_dl;
+		rval |= SDXC_DS_DL_SW_EN;
+		mmc_writel(host, REG_NTDL_HS400, rval);
+	}
+
+	dev_info(mmc_dev(host->mmc), "REG_DRV_DL: 0x%08x\n",
+		 mmc_readl(host, REG_DRV_DL));
+	dev_info(mmc_dev(host->mmc), "REG_SD_NTSR: 0x%08x\n",
+		 mmc_readl(host, REG_SD_NTSR));
+	dev_info(mmc_dev(host->mmc), "REG_NTDL_HS400: 0x%08x\n",
+		 mmc_readl(host, REG_NTDL_HS400));
+}
+
+static int sunxi_mmc_judge_retry_v5p3x(struct sunxi_mmc_host *host,
+				       struct mmc_command *cmd, u32 rcnt,
+				       u32 errno, void *other)
+{
+	struct mmc_host *mmc = host->mmc;
+	/****-1 means use default value***/
+	/*
+	*We use {-1,-1} as first member,because we want to
+	*retry current delay first.
+	*Only If current delay failed,we try new delay
+	*/
+	const s32 sunxi_phase[][2] = { {-1, -1},
+		{1, 1}, {0, 0}, {1, 0}, {0, 1}, {1, 2}, {0, 2}, {1, 3}, {0, 3} };
+	u32 phase_num = ARRAY_SIZE(sunxi_phase);
+	/*
+	*only sdc2 with HS400 support the 0 degree phase
+	*and the HS400_NEW_TIMING_MODE_BY_2X
+	*/
+	u32 rcnt_max = (host->phy_index == 2 && mmc->ios.timing == MMC_TIMING_MMC_HS400)\
+			 ? (phase_num * 16) : (phase_num - 1);
+	u32 samp_unit = (rcnt_max + 1) / phase_num;
+
+	if (rcnt < (SUNXI_RETRY_CNT_PER_PHA_V5P3X * rcnt_max)) {
+		sunxi_mmc_set_dly_raw(host,
+				      sunxi_phase[rcnt /
+						  (SUNXI_RETRY_CNT_PER_PHA_V5P3X * samp_unit)]
+				      [0],
+				      sunxi_phase[rcnt /
+						  (SUNXI_RETRY_CNT_PER_PHA_V5P3X * samp_unit)]
+				      [1],
+				      sunxi_phase[rcnt /
+						  (SUNXI_RETRY_CNT_PER_PHA_V5P3X * samp_unit)]
+				      [0],
+				      sunxi_phase[rcnt /
+						  (SUNXI_RETRY_CNT_PER_PHA_V5P3X * samp_unit)]
+				      [1],
+				      rcnt % samp_unit);
+		return 0;
+	}
+
+	sunxi_mmc_set_dly_raw(host, sunxi_phase[0][0],
+			      sunxi_phase[0][1],
+			      sunxi_phase[0][0], sunxi_phase[0][1], 0);
+	dev_info(mmc_dev(host->mmc), "sunxi v5p3x retry give up\n");
+	return -1;
+}
+
+void sunxi_mmc_init_priv_v5p3x(struct sunxi_mmc_host *host,
+			       struct platform_device *pdev, int phy_index)
+{
+	struct sunxi_mmc_ver_priv *ver_priv =
+	    devm_kzalloc(&pdev->dev, sizeof(struct sunxi_mmc_ver_priv),
+			 GFP_KERNEL);
+	host->version_priv_dat = ver_priv;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].cmod = mmc_clk_400k;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].mod_str = "sunxi-dly-400k";
+	ver_priv->mmc_clk_dly[mmc_clk_400k].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].dat_drv_ph = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].sam_ph_dat = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_400k].sam_ph_cmd = 0;
+
+	ver_priv->mmc_clk_dly[mmc_clk_26M].cmod = mmc_clk_26M;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].mod_str = "sunxi-dly-26M";
+	ver_priv->mmc_clk_dly[mmc_clk_26M].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].dat_drv_ph = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].sam_ph_dat = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_26M].sam_ph_cmd = 0;
+
+	ver_priv->mmc_clk_dly[mmc_clk_52M].cmod = mmc_clk_52M,
+	    ver_priv->mmc_clk_dly[mmc_clk_52M].mod_str = "sunxi-dly-52M";
+	ver_priv->mmc_clk_dly[mmc_clk_52M].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M].dat_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_52M].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_52M].sam_ph_dat = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M].sam_ph_cmd = 1;
+
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].cmod = mmc_clk_52M_DDR4;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].mod_str = "sunxi-dly-52M-ddr4";
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].dat_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].sam_ph_dat = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR4].sam_ph_cmd = 1;
+
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].cmod = mmc_clk_52M_DDR8;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].mod_str = "sunxi-dly-52M-ddr8";
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].dat_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].sam_ph_dat = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_52M_DDR8].sam_ph_cmd = 1;
+
+	ver_priv->mmc_clk_dly[mmc_clk_104M].cmod = mmc_clk_104M;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].mod_str = "sunxi-dly-104M";
+	ver_priv->mmc_clk_dly[mmc_clk_104M].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].dat_drv_ph = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].sam_ph_dat = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_104M].sam_ph_cmd = 0;
+
+	ver_priv->mmc_clk_dly[mmc_clk_208M].cmod = mmc_clk_208M;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].mod_str = "sunxi-dly-208M";
+	ver_priv->mmc_clk_dly[mmc_clk_208M].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].dat_drv_ph = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].sam_ph_dat = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_208M].sam_ph_cmd = 0;
+
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].cmod = mmc_clk_104M_DDR;
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].mod_str = "sunxi-dly-104M-ddr";
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].dat_drv_ph = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].sam_ph_dat = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_104M_DDR].sam_ph_cmd = 0;
+
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].cmod = mmc_clk_208M_DDR;
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].mod_str = "sunxi-dly-208M-ddr";
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].cmd_drv_ph = 1;
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].dat_drv_ph = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].sam_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].ds_dly = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].sam_ph_dat = 0;
+	ver_priv->mmc_clk_dly[mmc_clk_208M_DDR].sam_ph_cmd = 0;
+
+	host->sunxi_mmc_clk_set_rate = sunxi_mmc_clk_set_rate_for_sdmmc_v5p3x;
+	host->dma_tl = SUNXI_DMA_TL_SDMMC_V5P3X;
+	host->idma_des_size_bits = SUNXI_DES_SIZE_SDMMC_V5P3X;
+	host->sunxi_mmc_thld_ctl = sunxi_mmc_thld_ctl_for_sdmmc_v5p3x;
+	host->sunxi_mmc_save_spec_reg = sunxi_mmc_save_spec_reg_v5p3x;
+	host->sunxi_mmc_restore_spec_reg = sunxi_mmc_restore_spec_reg_v5p3x;
+	sunxi_mmc_reg_ex_res_inter(host, phy_index);
+	host->sunxi_mmc_set_acmda = sunxi_mmc_set_a12a;
+	host->phy_index = phy_index;
+	host->sunxi_mmc_oclk_en = sunxi_mmc_oclk_onoff;
+	host->sunxi_mmc_judge_retry = sunxi_mmc_judge_retry_v5p3x;
+	/*sunxi_of_parse_clk_dly(host); */
+	if (mmc_readl(host, REG_SMCV) >= SMHC_VERSION_V5P3) {
+			host->des_addr_shift = 2;
+	}
+
+}
+
+EXPORT_SYMBOL_GPL(sunxi_mmc_init_priv_v5p3x);
diff --git a/drivers/mmc/host/sunxi-mmc-v5p3x.h b/drivers/mmc/host/sunxi-mmc-v5p3x.h
new file mode 100644
index 000000000..f6f13464c
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-v5p3x.h
@@ -0,0 +1,22 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#ifndef __SUNXI_MMC_V5P3X_H__
+#define __SUNXI_MMC_V5P3X_H__
+
+void sunxi_mmc_init_priv_v5p3x(struct sunxi_mmc_host *host,
+			       struct platform_device *pdev, int phy_index);
+#endif
diff --git a/drivers/mmc/host/sunxi-mmc-v5px.c b/drivers/mmc/host/sunxi-mmc-v5px.c
new file mode 100644
index 000000000..8711bcc9c
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-v5px.c
@@ -0,0 +1,608 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+
+#ifdef CONFIG_ARCH_SUN8IW10P1
+
+#include <linux/clk.h>
+#include <linux/clk-private.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/slot-gpio.h>
+
+#include "sunxi-smhc.h"
+#include "sunxi-mmc-v5px.h"
+
+#define SMHC_DS_DLY	(0x230)
+#define SMHC_THLD		(0x20c)
+
+#define SMHC_SAMP_DL_SW_MASK		(0x0000003F)
+#define SMHC_DS_DL_SW_MASK			(0x0000003F)
+#define SMHC_DS_DL_SW_EN			(1u<<7)
+
+#define SMHC_CARD_RD_TH_SZ		0x000007FF
+#define SMHC_CARD_RD_TH_MASK	0x000007FF
+#define SMHC_CARD_RD_TH_SHIFT	0x0
+
+#define SMHC_CARD_WR_TH_SZ		0x000007FF
+#define SMHC_CARD_WR_TH_MASK	(0x000007FF<<16)
+#define SMHC_CARD_WR_TH_SHIFT	16
+
+#define SMHC_DES_NUM_SHIFT_V5PX	(15)
+#define SMHC_DES_BUFFER_MAX_LEN_V5PX	(1U << SMHC_DES_NUM_SHIFT)
+
+enum sunxi_mmc_speed_mode {
+	SM0_DS26_SDR12 = 0,
+	SM1_HSSDR52_SDR25,
+	SM2_HSDDR52_DDR50,
+	SM3_HS200_SDR104,
+	SM4_HS400,
+	SM_NUM,
+};
+
+struct sunxi_mmc_clk_dly {
+	enum sunxi_mmc_speed_mode spm;
+	char *mod_str;
+	char *raw_tm_sm_str[2];
+	u32 raw_tm_sm[2];
+	u32 raw_tm_sm_def[2];
+};
+
+struct sunxi_mmc_ver_priv {
+	/*struct sunxi_mmc_spec_regs bak_spec_regs; */
+	struct sunxi_mmc_clk_dly mmc_clk_dly[SM_NUM];
+};
+
+static void sunxi_mmc_set_clk_dly(struct sunxi_mmc_host *host, int clk,
+				  int bus_width, int timing)
+{
+	struct mmc_host *mmc = host->mmc;
+	enum sunxi_mmc_speed_mode speed_mod = SM0_DS26_SDR12;
+	char *raw_sm_str = NULL;
+	char *m_str = NULL;
+	struct device_node *np = NULL;
+	u32 *raw_sm = 0;
+	u32 *raw_sm_def = 0;
+	u32 rval = 0;
+	int frq_index = 0;
+	u32 cmd_drv_ph = 1;
+	u32 dat_drv_ph = 0;
+	u32 sam_dly = 0;
+	u32 ds_dly = 0;
+	struct sunxi_mmc_clk_dly *mmc_clk_dly =
+	    ((struct sunxi_mmc_ver_priv *)host->version_priv_dat)->mmc_clk_dly;
+
+	if (!mmc->parent || !mmc->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse clk dly,use default\n");
+		return;
+	}
+
+	np = mmc->parent->of_node;
+
+	switch (timing) {
+	case MMC_TIMING_LEGACY:
+	case MMC_TIMING_UHS_SDR12:
+		speed_mod = SM0_DS26_SDR12;
+		break;
+	case MMC_TIMING_MMC_HS:
+	case MMC_TIMING_SD_HS:
+	case MMC_TIMING_UHS_SDR25:
+		speed_mod = SM1_HSSDR52_SDR25;
+		break;
+	case MMC_TIMING_UHS_DDR50:
+	case MMC_TIMING_MMC_DDR52:
+		speed_mod = SM2_HSDDR52_DDR50;
+		break;
+	case MMC_TIMING_UHS_SDR50:
+	case MMC_TIMING_UHS_SDR104:
+	case MMC_TIMING_MMC_HS200:
+		speed_mod = SM3_HS200_SDR104;
+		break;
+	case MMC_TIMING_MMC_HS400:
+		speed_mod = SM4_HS400;
+		break;
+	default:
+		dev_err(mmc_dev(mmc), "Wrong timing input\n");
+		return;
+	}
+
+	if (clk <= 400 * 1000) {
+		frq_index = 0;
+	} else if (clk <= 25 * 1000 * 1000) {
+		frq_index = 1;
+	} else if (clk <= 50 * 1000 * 1000) {
+		frq_index = 2;
+	} else if (clk <= 100 * 1000 * 1000) {
+		frq_index = 3;
+	} else if (clk <= 150 * 1000 * 1000) {
+		frq_index = 4;
+	} else if (clk <= 200 * 1000 * 1000) {
+		frq_index = 5;
+	} else if (clk <= 250 * 1000 * 1000) {
+		frq_index = 6;
+	} else if (clk <= 300 * 1000 * 1000) {
+		frq_index = 7;
+	} else {
+		dev_err(mmc_dev(mmc), "clk is over 300mhz\n");
+		return;
+	}
+
+	if (frq_index / 4 > 2) {
+		dev_err(mmc_dev(host->mmc), "err frq_index\n");
+		return;
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "freq %d frq index %d,frq/4 %x\n", clk,
+		frq_index, frq_index / 4);
+	raw_sm_str = mmc_clk_dly[speed_mod].raw_tm_sm_str[frq_index / 4];
+	raw_sm = &mmc_clk_dly[speed_mod].raw_tm_sm[frq_index / 4];
+	raw_sm_def = &mmc_clk_dly[speed_mod].raw_tm_sm_def[frq_index / 4];
+	m_str = mmc_clk_dly[speed_mod].mod_str;
+
+	rval = of_property_read_u32(np, raw_sm_str, raw_sm);
+	if (rval) {
+		dev_info(mmc_dev(host->mmc), "failed to get %s used default\n",
+			 m_str);
+	} else {
+		u32 sm_shift = (frq_index % 4) * 8;
+
+		rval = ((*raw_sm) >> sm_shift) & 0xff;
+		if (rval != 0xff) {
+			if (timing == MMC_TIMING_MMC_HS400) {
+				u32 raw_sm_hs200 = 0;
+
+				ds_dly = rval;
+				raw_sm_hs200 =
+				    mmc_clk_dly[SM3_HS200_SDR104].
+				    raw_tm_sm[frq_index / 4];
+				sam_dly = ((raw_sm_hs200) >> sm_shift) & 0xff;
+			} else {
+				sam_dly = rval;
+			}
+			dev_dbg(mmc_dev(host->mmc),
+				"Get speed mode %s clk dly %s ok\n", m_str,
+				raw_sm_str);
+		} else {
+			u32 sm_shift = (frq_index % 4) * 8;
+
+			dev_dbg(mmc_dev(host->mmc), "%s use default value\n",
+				m_str);
+			rval = ((*raw_sm_def) >> sm_shift) & 0xff;
+			if (timing == MMC_TIMING_MMC_HS400) {
+				u32 raw_sm_hs200 = 0;
+
+				ds_dly = rval;
+				raw_sm_hs200 =
+				    mmc_clk_dly[SM3_HS200_SDR104].
+				    raw_tm_sm_def[frq_index / 4];
+				sam_dly = ((raw_sm_hs200) >> sm_shift) & 0xff;
+			} else {
+				sam_dly = rval;
+			}
+		}
+
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "Try set %s clk dly	ok\n", m_str);
+	dev_dbg(mmc_dev(host->mmc), "cmd_drv_ph	%d\n", cmd_drv_ph);
+	dev_dbg(mmc_dev(host->mmc), "dat_drv_ph	%d\n", dat_drv_ph);
+	dev_dbg(mmc_dev(host->mmc), "sam_dly	%d\n", sam_dly);
+	dev_dbg(mmc_dev(host->mmc), "ds_dly		%d\n", ds_dly);
+
+	rval = smhc_readl(host, SMHC_DS_DLY);
+	rval &= ~SMHC_DS_DL_SW_MASK;
+	rval |= ds_dly & SMHC_DS_DL_SW_MASK;
+	rval |= SMHC_DS_DL_SW_EN;
+	smhc_writel(host, SMHC_DS_DLY, rval);
+	dev_dbg(mmc_dev(host->mmc), " SMHC_DS_DLY      %08x\n",
+		smhc_readl(host, SMHC_DS_DLY));
+}
+
+void sunxi_mmc_dump_dly2(struct sunxi_mmc_host *host)
+{
+	dev_dbg(mmc_dev(host->mmc), "no imple %s %d\n", __func__, __LINE__);
+}
+
+static int __sunxi_mmc_do_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en,
+				     u32 pwr_save, u32 ignore_dat0)
+{
+	u32 tmp = 0;
+
+	tmp = smhc_readl(host, SMHC_RST_CLK_CTRL);
+	if (oclk_en)
+		tmp |= SdclkEn;
+	else
+		tmp &= ~SdclkEn;
+
+	smhc_writel(host, SMHC_RST_CLK_CTRL, tmp);
+
+	tmp = smhc_readl(host, SMHC_CTRL3);
+	if (pwr_save)
+		tmp |= SdclkIdleCtrl;
+	else
+		tmp &= ~SdclkIdleCtrl;
+
+	smhc_writel(host, SMHC_CTRL3, tmp);
+
+	return 0;
+
+}
+
+int sunxi_mmc_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en)
+{
+	struct device_node *np = NULL;
+	struct mmc_host *mmc = host->mmc;
+	int pwr_save = 0;
+	int len = 0;
+
+	if (!mmc->parent || !mmc->parent->of_node) {
+		dev_err(mmc_dev(host->mmc),
+			"no dts to parse power save mode\n");
+		return -EIO;
+	}
+
+	np = mmc->parent->of_node;
+	if (of_find_property(np, "sunxi-power-save-mode", &len))
+		pwr_save = 1;
+	return __sunxi_mmc_do_oclk_onoff(host, oclk_en, pwr_save, 1);
+}
+int sunxi_mmc_clk_set_rate_v5px(struct sunxi_mmc_host *host,
+				struct mmc_ios *ios)
+{
+	u32 mod_clk = 0;
+	u32 src_clk = 0;
+	u32 rval = 0;
+	s32 err = 0;
+	u32 rate = 0;
+	char *sclk_name = NULL;
+	struct clk *mclk = host->clk_mmc;
+	struct clk *sclk = NULL;
+	struct device *dev = mmc_dev(host->mmc);
+
+	if (ios->clock == 0) {
+		__sunxi_mmc_do_oclk_onoff(host, 0, 0, 1);
+		return 0;
+	}
+
+	if (sunxi_mmc_ddr_timing(ios->timing))
+		mod_clk = ios->clock << 3;
+	else
+		mod_clk = ios->clock << 2;
+
+	if (ios->clock <= 400000) {
+		sclk = clk_get(dev, "osc24m");
+		sclk_name = "osc24m";
+	} else {
+		sclk = clk_get(dev, "pll_periph");
+		sclk_name = "pll_periph";
+	}
+	if (IS_ERR(sclk)) {
+		dev_err(mmc_dev(host->mmc), "Error to get source clock %s\n",
+			sclk_name);
+		return -1;
+	}
+
+	sunxi_mmc_oclk_onoff(host, 0);
+
+	err = clk_set_parent(mclk, sclk);
+	if (err) {
+		dev_err(mmc_dev(host->mmc), "set parent failed\n");
+		clk_put(sclk);
+		return -1;
+	}
+
+	rate = clk_round_rate(mclk, mod_clk);
+
+	dev_dbg(mmc_dev(host->mmc), "get round rate %d\n", rate);
+
+	clk_disable_unprepare(host->clk_mmc);
+
+	err = clk_set_rate(mclk, rate);
+	if (err) {
+		dev_err(mmc_dev(host->mmc), "set mclk rate error, rate %dHz\n",
+			rate);
+		clk_put(sclk);
+		return -1;
+	}
+
+	rval = clk_prepare_enable(host->clk_mmc);
+	if (rval) {
+		dev_err(mmc_dev(host->mmc), "Enable mmc clk err %d\n", rval);
+		return -1;
+	}
+
+	src_clk = clk_get_rate(sclk);
+	clk_put(sclk);
+
+	dev_dbg(mmc_dev(host->mmc), "set round clock %d, soure clk is %d\n",
+		rate, src_clk);
+
+	/*sunxi_of_parse_clk_dly(host); */
+	if (sunxi_mmc_ddr_timing(ios->timing))
+		ios->clock = rate >> 3;
+	else
+		ios->clock = rate >> 2;
+
+
+	sunxi_mmc_set_clk_dly(host, ios->clock, ios->bus_width, ios->timing);
+
+	return sunxi_mmc_oclk_onoff(host, 1);
+}
+
+void sunxi_mmc_thld_ctl_v5px(struct sunxi_mmc_host *host,
+			     struct mmc_ios *ios, struct mmc_data *data)
+{
+	u32 bsz = data->blksz;
+	u32 rval = 0;
+
+	if ((data->flags & MMC_DATA_WRITE)
+	    && (bsz <= SMHC_CARD_WR_TH_SZ)) {
+		rval = smhc_readl(host, SMHC_THLD);
+		rval &= ~SMHC_CARD_WR_TH_MASK;
+		rval |= data->blksz << SMHC_CARD_WR_TH_SHIFT;
+		/*rval |= SDXC_CARD_WR_THLD_ENB; */
+		smhc_writel(host, SMHC_THLD, rval);
+	} else {
+		/*
+		*   rval = mmc_readl(host, REG_THLD);
+		*   rval &= ~SDXC_CARD_WR_THLD_ENB;
+		 *  mmc_writel(host, REG_THLD, rval);
+		 */
+	}
+
+	if ((data->flags & MMC_DATA_READ)
+	    && (bsz <= SMHC_CARD_RD_TH_SZ)
+	    && ((ios->timing == MMC_TIMING_MMC_HS200)
+		|| (ios->timing == MMC_TIMING_MMC_HS400)
+		|| (ios->timing == MMC_TIMING_UHS_SDR50)
+		|| (ios->timing == MMC_TIMING_UHS_SDR104))) {
+		rval = smhc_readl(host, SMHC_THLD);
+		rval &= ~SMHC_CARD_RD_TH_MASK;
+		rval |= data->blksz << SMHC_CARD_RD_TH_SHIFT;
+		/*rval |= SDXC_CARD_RD_THLD_ENB; */
+		smhc_writel(host, SMHC_THLD, rval);
+	} else {
+		/*
+		*   rval = mmc_readl(host, REG_THLD);
+		*  rval &= ~SDXC_CARD_RD_THLD_ENB;
+		*  mmc_writel(host, REG_THLD, rval);
+		 */
+	}
+
+	dev_dbg(mmc_dev(host->mmc), "SDXC_REG_THLD: 0x%08x\n",
+		smhc_readl(host, SMHC_THLD));
+}
+
+void sunxi_mmc_save_spec_reg_v5px(struct sunxi_mmc_host *host)
+{
+	dev_dbg(mmc_dev(host->mmc), "no imple %s %d\n", __func__, __LINE__);
+
+}
+
+void sunxi_mmc_restore_spec_reg_v5px(struct sunxi_mmc_host *host)
+{
+	dev_dbg(mmc_dev(host->mmc), "no imple %s %d\n", __func__, __LINE__);
+
+}
+
+
+
+static int sunxi_mmc_can_poweroff_notify(const struct mmc_card *card)
+{
+	return card &&
+	    mmc_card_mmc(card) &&
+	    (card->ext_csd.power_off_notification == EXT_CSD_POWER_ON);
+}
+
+static int sunxi_mmc_poweroff_notify(struct mmc_card *card,
+				     unsigned int notify_type)
+{
+	unsigned int timeout = card->ext_csd.generic_cmd6_time;
+	int err;
+
+	/* Use EXT_CSD_POWER_OFF_SHORT as default notification type. */
+	if (notify_type == EXT_CSD_POWER_OFF_LONG)
+		timeout = card->ext_csd.power_off_longtime;
+
+	err = __mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
+			   EXT_CSD_POWER_OFF_NOTIFICATION,
+			   notify_type, timeout, true, false, false);
+	if (err)
+		pr_err("%s: Power Off Notification timed out, %u\n",
+		       mmc_hostname(card->host), timeout);
+
+	/* Disable the power off notification after the switch operation. */
+	card->ext_csd.power_off_notification = EXT_CSD_NO_POWER_NOTIFICATION;
+
+	return err;
+}
+
+static int sunxi_mmc_sleep(struct mmc_host *host)
+{
+	struct mmc_card *card = host->card;
+	int err = -1;
+
+	if (card && card->ext_csd.rev >= 3) {
+		err = mmc_card_sleepawake(host, 1);
+		if (err < 0)
+			pr_debug("%s: Error %d while putting card into sleep",
+				 mmc_hostname(host), err);
+	}
+
+	return err;
+}
+
+static int sunxi_mmc_suspend(struct mmc_host *host, bool is_suspend)
+{
+	int err = 0;
+	unsigned int notify_type = is_suspend ? EXT_CSD_POWER_OFF_SHORT :
+	    EXT_CSD_POWER_OFF_LONG;
+
+	if (!host) {
+		pr_err("Host should be null\n");
+		return -1;
+	}
+	if (!host->card) {
+		pr_err("Card should be null\n");
+		return -1;
+	}
+
+	mmc_claim_host(host);
+
+	/*
+	 *  if (mmc_card_suspended(host->card))
+	 *  goto out;
+	 */
+
+	if (mmc_card_doing_bkops(host->card)) {
+		err = mmc_stop_bkops(host->card);
+		if (err)
+			goto out;
+	}
+
+	err = mmc_flush_cache(host->card);
+
+	if (err)
+		goto out;
+
+	if (sunxi_mmc_can_poweroff_notify(host->card) &&
+	    ((host->caps2 & MMC_CAP2_POWEROFF_NOTIFY) || !is_suspend)) {
+		err = sunxi_mmc_poweroff_notify(host->card, notify_type);
+	} else if (mmc_card_can_sleep(host)) {
+		err = sunxi_mmc_sleep(host);
+	} else if (!mmc_host_is_spi(host)) {
+		err = mmc_deselect_cards(host);
+	}
+
+	if (!err) {
+		pr_info("%s: %s %d\n",
+			mmc_hostname(host), __func__, __LINE__);
+		mmc_power_off(host);
+/*		mmc_card_set_suspended(host->card);*/
+	}
+
+out:
+	mmc_release_host(host);
+	return err;
+}
+
+void sunxi_mmc_do_shutdown_v5px(struct platform_device *pdev)
+{
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	u32 shutdown_notify_type = 0;
+	u32 rval =
+	    of_property_read_u32(mmc->parent->of_node, "shutdown_notify_type",
+				 &shutdown_notify_type);
+	if (!rval)
+		sunxi_mmc_suspend(mmc, shutdown_notify_type);
+	else
+		sunxi_mmc_suspend(mmc, false);
+}
+
+void sunxi_mmc_init_priv_v5px(struct sunxi_mmc_host *host,
+			      struct platform_device *pdev, int phy_index)
+{
+	struct sunxi_mmc_ver_priv *ver_priv =
+	    devm_kzalloc(&pdev->dev, sizeof(struct sunxi_mmc_ver_priv),
+			 GFP_KERNEL);
+	host->version_priv_dat = ver_priv;
+
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].spm = SM0_DS26_SDR12;
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].mod_str = "DS26_SDR12";
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm_str[0] =
+	    "sdc_tm4_sm0_freq0";
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm_str[1] =
+	    "sdc_tm4_sm0_freq1";
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm[0] = 0;
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm[1] = 0;
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm_def[0] = 0;
+	ver_priv->mmc_clk_dly[SM0_DS26_SDR12].raw_tm_sm_def[1] = 0;
+
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].spm = SM1_HSSDR52_SDR25;
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].mod_str = "HSSDR52_SDR25";
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm_str[0] =
+	    "sdc_tm4_sm1_freq0";
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm_str[1] =
+	    "sdc_tm4_sm1_freq1";
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm[0] = 0;
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm[1] = 0;
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm_def[0] = 0;
+	ver_priv->mmc_clk_dly[SM1_HSSDR52_SDR25].raw_tm_sm_def[1] = 0;
+
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].spm = SM2_HSDDR52_DDR50;
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].mod_str = "HSDDR52_DDR50";
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm_str[0] =
+	    "sdc_tm4_sm2_freq0";
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm_str[1] =
+	    "sdc_tm4_sm2_freq1";
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm[0] = 0;
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm[1] = 0;
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm_def[0] = 0;
+	ver_priv->mmc_clk_dly[SM2_HSDDR52_DDR50].raw_tm_sm_def[1] = 0;
+
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].spm = SM3_HS200_SDR104;
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].mod_str = "HS200_SDR104";
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm_str[0] =
+	    "sdc_tm4_sm3_freq0";
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm_str[1] =
+	    "sdc_tm4_sm3_freq1";
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm[0] = 0;
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm[1] = 0;
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm_def[0] = 0;
+	ver_priv->mmc_clk_dly[SM3_HS200_SDR104].raw_tm_sm_def[1] = 0x00000405;
+
+	ver_priv->mmc_clk_dly[SM4_HS400].spm = SM4_HS400;
+	ver_priv->mmc_clk_dly[SM4_HS400].mod_str = "HS400";
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm_str[0] = "sdc_tm4_sm4_freq0";
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm_str[1] = "sdc_tm4_sm4_freq1";
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm[0] = 0;
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm[1] = 0x00000608;
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm_def[0] = 0;
+	ver_priv->mmc_clk_dly[SM4_HS400].raw_tm_sm_def[1] = 0x00000408;
+
+	host->sunxi_mmc_clk_set_rate = sunxi_mmc_clk_set_rate_v5px;
+	/*host->idma_des_size_bits = 15; */
+	host->idma_des_size_bits = SMHC_DES_NUM_SHIFT_V5PX;
+	host->sunxi_mmc_thld_ctl = sunxi_mmc_thld_ctl_v5px;
+	host->sunxi_mmc_save_spec_reg = sunxi_mmc_save_spec_reg_v5px;
+	host->sunxi_mmc_restore_spec_reg = sunxi_mmc_restore_spec_reg_v5px;
+	/*sunxi_mmc_reg_ex_res_inter(host, phy_index);
+	*  host->sunxi_mmc_set_acmda = sunxi_mmc_set_a12a;
+	 */
+	host->sunxi_mmc_dump_dly_table = sunxi_mmc_dump_dly2;
+	host->phy_index = phy_index;
+}
+
+#endif
diff --git a/drivers/mmc/host/sunxi-mmc-v5px.h b/drivers/mmc/host/sunxi-mmc-v5px.h
new file mode 100644
index 000000000..3423fc57f
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc-v5px.h
@@ -0,0 +1,33 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#ifdef CONFIG_ARCH_SUN8IW10P1
+
+#ifndef __SUNXI_MMC_SUN8IW10P1_2_H__
+#define __SUNXI_MMC_SUN8IW10P1_2_H__
+
+void sunxi_mmc_init_priv_v5px(struct sunxi_mmc_host *host,
+			      struct platform_device *pdev, int phy_index);
+int sunxi_mmc_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en);
+
+int mmc_card_sleep(struct mmc_host *host);
+int mmc_deselect_cards(struct mmc_host *host);
+void mmc_power_off(struct mmc_host *host);
+int mmc_card_sleepawake(struct mmc_host *host, int sleep);
+
+#endif
+
+#endif
diff --git a/drivers/mmc/host/sunxi-mmc.c b/drivers/mmc/host/sunxi-mmc.c
index d577a6b0c..e97a3b348 100644
--- a/drivers/mmc/host/sunxi-mmc.c
+++ b/drivers/mmc/host/sunxi-mmc.c
@@ -1,305 +1,323 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  * Driver for sunxi SD/MMC host controllers
  * (C) Copyright 2007-2011 Reuuimlla Technology Co., Ltd.
  * (C) Copyright 2007-2011 Aaron Maoye <leafy.myeh@reuuimllatech.com>
  * (C) Copyright 2013-2014 O2S GmbH <www.o2s.ch>
- * (C) Copyright 2013-2014 David Lanzendörfer <david.lanzendoerfer@o2s.ch>
+ * (C) Copyright 2013-2014 David Lanzend�rfer <david.lanzendoerfer@o2s.ch>
  * (C) Copyright 2013-2014 Hans de Goede <hdegoede@redhat.com>
- * (C) Copyright 2017 Sootech SA
+ * (C) Copyright 2014-2016 lixiang <lixiang@allwinnertech>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of
+ * the License, or (at your option) any later version.
  */
 
-#include <linux/clk.h>
-#include <linux/clk/sunxi-ng.h>
-#include <linux/delay.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/io.h>
 #include <linux/device.h>
-#include <linux/dma-mapping.h>
-#include <linux/err.h>
 #include <linux/interrupt.h>
-#include <linux/io.h>
-#include <linux/kernel.h>
-#include <linux/mmc/card.h>
-#include <linux/mmc/core.h>
+#include <linux/delay.h>
+#include <linux/err.h>
+
+#include <linux/clk.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+#include <linux/sunxi-gpio.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+#include <linux/regulator/consumer.h>
+
 #include <linux/mmc/host.h>
-#include <linux/mmc/mmc.h>
 #include <linux/mmc/sd.h>
 #include <linux/mmc/sdio.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/card.h>
 #include <linux/mmc/slot-gpio.h>
-#include <linux/module.h>
-#include <linux/of_address.h>
-#include <linux/of_platform.h>
-#include <linux/platform_device.h>
-#include <linux/pm_runtime.h>
-#include <linux/regulator/consumer.h>
-#include <linux/reset.h>
-#include <linux/scatterlist.h>
-#include <linux/slab.h>
-#include <linux/spinlock.h>
+#include "../core/card.h"
+//#include <linux/sunxi-sid.h>
+#include "sunxi-mmc.h"
+#include "sunxi-mmc-sun50iw1p1-2.h"
+#include "sunxi-mmc-sun50iw1p1-0.h"
+#include "sunxi-mmc-sun50iw1p1-1.h"
+#include "sunxi-mmc-v4p1x.h"
+#include "sunxi-mmc-v4p10x.h"
+#include "sunxi-mmc-v4p00x.h"
+#include "sunxi-mmc-v4p5x.h"
+#include "sunxi-mmc-v5p3x.h"
+
+
+#include "sunxi-mmc-debug.h"
+#include "sunxi-mmc-export.h"
+#include "sunxi-mmc-panic.h"
+
+/**default retry times ****/
+#define SUNXI_DEF_RETRY_TIMES		6
+/*default value 10 min = 600000 ms,warning,not less then 20**/
+#define SUNXI_DEF_MAX_R1B_TIMEOUT_MS (600000U)
+#define SUNXI_MIN_R1B_TIMEOUT_MS (20)
+#define SUNXI_TRANS_TIMEOUT  (5*HZ)
+
+/*judge encryption flag bit*/
+#define sunxi_crypt_flags(sg) (((sg->offset)	\
+	& (1 << ((sizeof(sg->offset) << 3) - 1))) ? 1 : 0)
+/*clear encryption flag bit*/
+#define sunxi_clear_crypt_flags(sg) ((sg->offset)	\
+	& ~(1 << ((sizeof(sg->offset) << 3) - 1)))
+
+/*Check host support busy check on r1b cmd*/
+#define sunxi_mmc_chk_hr1b_cap(host)	(!host->sunxi_mmc_hw_busy \
+		|| host->sunxi_mmc_hw_busy(host))
+/*judge data request if it need to check r1b */
+#define sunxi_mmc_dreq_r1b_chk_need(host, data) \
+		(data && (data->flags & MMC_DATA_WRITE) \
+			&& !(host->ctl_spec_cap & NO_WBUSY_WR_END)\
+			&& sunxi_mmc_chk_hr1b_cap(host))
+
+/*judge cmd request if it need to check r1b */
+#define sunxi_mmc_creq_r1b_chk_need(host, cmd) \
+		((cmd->flags & MMC_RSP_BUSY) \
+			&& !(host->ctl_spec_cap & NO_WBUSY_WR_END)\
+			&& sunxi_mmc_chk_hr1b_cap(host))
+
+#define sunxi_mmc_host_des_addr(host, soc_phy_address) \
+	((soc_phy_address) >> (host->des_addr_shift))
+
+#define sunxi_mmc_clean_retry_cnt(host) \
+	(host->retry_cnt = host->sunxi_ds_dl_cnt = host->sunxi_samp_dl_cnt = 0)
+
+static void sunxi_mmc_regs_save(struct sunxi_mmc_host *host);
+static void sunxi_mmc_regs_restore(struct sunxi_mmc_host *host);
+static int sunxi_mmc_bus_clk_en(struct sunxi_mmc_host *host, int enable);
+static void sunxi_mmc_parse_cmd(struct mmc_host *mmc, struct mmc_command *cmd,
+				u32 *cval, u32 *im, bool *wdma);
+static void sunxi_mmc_set_dat(struct sunxi_mmc_host *host, struct mmc_host *mmc,
+			      struct mmc_data *data);
+static void sunxi_mmc_exe_cmd(struct sunxi_mmc_host *host,
+			      struct mmc_command *cmd, u32 cmd_val, u32 imask);
+static irqreturn_t sunxi_mmc_handle_bottom_half(int irq, void *dev_id);
+static irqreturn_t sunxi_mmc_handle_do_bottom_half(void *dev_id);
+
+static void sunxi_timerout_handle(struct work_struct *work)
+{
+	struct sunxi_mmc_host *host;
+	unsigned long flags;
+	u32 rint = 0;
+	u32 idma_int = 0;
 
-/* register offset definitions */
-#define SDXC_REG_GCTRL	(0x00) /* SMC Global Control Register */
-#define SDXC_REG_CLKCR	(0x04) /* SMC Clock Control Register */
-#define SDXC_REG_TMOUT	(0x08) /* SMC Time Out Register */
-#define SDXC_REG_WIDTH	(0x0C) /* SMC Bus Width Register */
-#define SDXC_REG_BLKSZ	(0x10) /* SMC Block Size Register */
-#define SDXC_REG_BCNTR	(0x14) /* SMC Byte Count Register */
-#define SDXC_REG_CMDR	(0x18) /* SMC Command Register */
-#define SDXC_REG_CARG	(0x1C) /* SMC Argument Register */
-#define SDXC_REG_RESP0	(0x20) /* SMC Response Register 0 */
-#define SDXC_REG_RESP1	(0x24) /* SMC Response Register 1 */
-#define SDXC_REG_RESP2	(0x28) /* SMC Response Register 2 */
-#define SDXC_REG_RESP3	(0x2C) /* SMC Response Register 3 */
-#define SDXC_REG_IMASK	(0x30) /* SMC Interrupt Mask Register */
-#define SDXC_REG_MISTA	(0x34) /* SMC Masked Interrupt Status Register */
-#define SDXC_REG_RINTR	(0x38) /* SMC Raw Interrupt Status Register */
-#define SDXC_REG_STAS	(0x3C) /* SMC Status Register */
-#define SDXC_REG_FTRGL	(0x40) /* SMC FIFO Threshold Watermark Registe */
-#define SDXC_REG_FUNS	(0x44) /* SMC Function Select Register */
-#define SDXC_REG_CBCR	(0x48) /* SMC CIU Byte Count Register */
-#define SDXC_REG_BBCR	(0x4C) /* SMC BIU Byte Count Register */
-#define SDXC_REG_DBGC	(0x50) /* SMC Debug Enable Register */
-#define SDXC_REG_HWRST	(0x78) /* SMC Card Hardware Reset for Register */
-#define SDXC_REG_DMAC	(0x80) /* SMC IDMAC Control Register */
-#define SDXC_REG_DLBA	(0x84) /* SMC IDMAC Descriptor List Base Addre */
-#define SDXC_REG_IDST	(0x88) /* SMC IDMAC Status Register */
-#define SDXC_REG_IDIE	(0x8C) /* SMC IDMAC Interrupt Enable Register */
-#define SDXC_REG_CHDA	(0x90)
-#define SDXC_REG_CBDA	(0x94)
-
-/* New registers introduced in A64 */
-#define SDXC_REG_A12A		0x058 /* SMC Auto Command 12 Register */
-#define SDXC_REG_SD_NTSR	0x05C /* SMC New Timing Set Register */
-#define SDXC_REG_DRV_DL		0x140 /* Drive Delay Control Register */
-#define SDXC_REG_SAMP_DL_REG	0x144 /* SMC sample delay control */
-#define SDXC_REG_DS_DL_REG	0x148 /* SMC data strobe delay control */
-
-#define mmc_readl(host, reg) \
-	readl((host)->reg_base + SDXC_##reg)
-#define mmc_writel(host, reg, value) \
-	writel((value), (host)->reg_base + SDXC_##reg)
-
-/* global control register bits */
-#define SDXC_SOFT_RESET			BIT(0)
-#define SDXC_FIFO_RESET			BIT(1)
-#define SDXC_DMA_RESET			BIT(2)
-#define SDXC_INTERRUPT_ENABLE_BIT	BIT(4)
-#define SDXC_DMA_ENABLE_BIT		BIT(5)
-#define SDXC_DEBOUNCE_ENABLE_BIT	BIT(8)
-#define SDXC_POSEDGE_LATCH_DATA		BIT(9)
-#define SDXC_DDR_MODE			BIT(10)
-#define SDXC_MEMORY_ACCESS_DONE		BIT(29)
-#define SDXC_ACCESS_DONE_DIRECT		BIT(30)
-#define SDXC_ACCESS_BY_AHB		BIT(31)
-#define SDXC_ACCESS_BY_DMA		(0 << 31)
-#define SDXC_HARDWARE_RESET \
-	(SDXC_SOFT_RESET | SDXC_FIFO_RESET | SDXC_DMA_RESET)
-
-/* clock control bits */
-#define SDXC_MASK_DATA0			BIT(31)
-#define SDXC_CARD_CLOCK_ON		BIT(16)
-#define SDXC_LOW_POWER_ON		BIT(17)
-
-/* bus width */
-#define SDXC_WIDTH1			0
-#define SDXC_WIDTH4			1
-#define SDXC_WIDTH8			2
-
-/* smc command bits */
-#define SDXC_RESP_EXPIRE		BIT(6)
-#define SDXC_LONG_RESPONSE		BIT(7)
-#define SDXC_CHECK_RESPONSE_CRC		BIT(8)
-#define SDXC_DATA_EXPIRE		BIT(9)
-#define SDXC_WRITE			BIT(10)
-#define SDXC_SEQUENCE_MODE		BIT(11)
-#define SDXC_SEND_AUTO_STOP		BIT(12)
-#define SDXC_WAIT_PRE_OVER		BIT(13)
-#define SDXC_STOP_ABORT_CMD		BIT(14)
-#define SDXC_SEND_INIT_SEQUENCE		BIT(15)
-#define SDXC_UPCLK_ONLY			BIT(21)
-#define SDXC_READ_CEATA_DEV		BIT(22)
-#define SDXC_CCS_EXPIRE			BIT(23)
-#define SDXC_ENABLE_BIT_BOOT		BIT(24)
-#define SDXC_ALT_BOOT_OPTIONS		BIT(25)
-#define SDXC_BOOT_ACK_EXPIRE		BIT(26)
-#define SDXC_BOOT_ABORT			BIT(27)
-#define SDXC_VOLTAGE_SWITCH	        BIT(28)
-#define SDXC_USE_HOLD_REGISTER	        BIT(29)
-#define SDXC_START			BIT(31)
-
-/* interrupt bits */
-#define SDXC_RESP_ERROR			BIT(1)
-#define SDXC_COMMAND_DONE		BIT(2)
-#define SDXC_DATA_OVER			BIT(3)
-#define SDXC_TX_DATA_REQUEST		BIT(4)
-#define SDXC_RX_DATA_REQUEST		BIT(5)
-#define SDXC_RESP_CRC_ERROR		BIT(6)
-#define SDXC_DATA_CRC_ERROR		BIT(7)
-#define SDXC_RESP_TIMEOUT		BIT(8)
-#define SDXC_DATA_TIMEOUT		BIT(9)
-#define SDXC_VOLTAGE_CHANGE_DONE	BIT(10)
-#define SDXC_FIFO_RUN_ERROR		BIT(11)
-#define SDXC_HARD_WARE_LOCKED		BIT(12)
-#define SDXC_START_BIT_ERROR		BIT(13)
-#define SDXC_AUTO_COMMAND_DONE		BIT(14)
-#define SDXC_END_BIT_ERROR		BIT(15)
-#define SDXC_SDIO_INTERRUPT		BIT(16)
-#define SDXC_CARD_INSERT		BIT(30)
-#define SDXC_CARD_REMOVE		BIT(31)
-#define SDXC_INTERRUPT_ERROR_BIT \
-	(SDXC_RESP_ERROR | SDXC_RESP_CRC_ERROR | SDXC_DATA_CRC_ERROR | \
-	 SDXC_RESP_TIMEOUT | SDXC_DATA_TIMEOUT | SDXC_FIFO_RUN_ERROR | \
-	 SDXC_HARD_WARE_LOCKED | SDXC_START_BIT_ERROR | SDXC_END_BIT_ERROR)
-#define SDXC_INTERRUPT_DONE_BIT \
-	(SDXC_AUTO_COMMAND_DONE | SDXC_DATA_OVER | \
-	 SDXC_COMMAND_DONE | SDXC_VOLTAGE_CHANGE_DONE)
-
-/* status */
-#define SDXC_RXWL_FLAG			BIT(0)
-#define SDXC_TXWL_FLAG			BIT(1)
-#define SDXC_FIFO_EMPTY			BIT(2)
-#define SDXC_FIFO_FULL			BIT(3)
-#define SDXC_CARD_PRESENT		BIT(8)
-#define SDXC_CARD_DATA_BUSY		BIT(9)
-#define SDXC_DATA_FSM_BUSY		BIT(10)
-#define SDXC_DMA_REQUEST		BIT(31)
-#define SDXC_FIFO_SIZE			16
-
-/* Function select */
-#define SDXC_CEATA_ON			(0xceaa << 16)
-#define SDXC_SEND_IRQ_RESPONSE		BIT(0)
-#define SDXC_SDIO_READ_WAIT		BIT(1)
-#define SDXC_ABORT_READ_DATA		BIT(2)
-#define SDXC_SEND_CCSD			BIT(8)
-#define SDXC_SEND_AUTO_STOPCCSD		BIT(9)
-#define SDXC_CEATA_DEV_IRQ_ENABLE	BIT(10)
-
-/* IDMA controller bus mod bit field */
-#define SDXC_IDMAC_SOFT_RESET		BIT(0)
-#define SDXC_IDMAC_FIX_BURST		BIT(1)
-#define SDXC_IDMAC_IDMA_ON		BIT(7)
-#define SDXC_IDMAC_REFETCH_DES		BIT(31)
-
-/* IDMA status bit field */
-#define SDXC_IDMAC_TRANSMIT_INTERRUPT		BIT(0)
-#define SDXC_IDMAC_RECEIVE_INTERRUPT		BIT(1)
-#define SDXC_IDMAC_FATAL_BUS_ERROR		BIT(2)
-#define SDXC_IDMAC_DESTINATION_INVALID		BIT(4)
-#define SDXC_IDMAC_CARD_ERROR_SUM		BIT(5)
-#define SDXC_IDMAC_NORMAL_INTERRUPT_SUM		BIT(8)
-#define SDXC_IDMAC_ABNORMAL_INTERRUPT_SUM	BIT(9)
-#define SDXC_IDMAC_HOST_ABORT_INTERRUPT		BIT(10)
-#define SDXC_IDMAC_IDLE				(0 << 13)
-#define SDXC_IDMAC_SUSPEND			(1 << 13)
-#define SDXC_IDMAC_DESC_READ			(2 << 13)
-#define SDXC_IDMAC_DESC_CHECK			(3 << 13)
-#define SDXC_IDMAC_READ_REQUEST_WAIT		(4 << 13)
-#define SDXC_IDMAC_WRITE_REQUEST_WAIT		(5 << 13)
-#define SDXC_IDMAC_READ				(6 << 13)
-#define SDXC_IDMAC_WRITE			(7 << 13)
-#define SDXC_IDMAC_DESC_CLOSE			(8 << 13)
+	host = container_of(work, struct sunxi_mmc_host, sunxi_timerout_work.work);
+	spin_lock_irqsave(&host->lock, flags);
+	dev_err(mmc_dev(host->mmc), "timer timout\n");
+	queue_delayed_work(system_wq, \
+			&host->sunxi_timerout_work, \
+			SUNXI_TRANS_TIMEOUT);
+	if (host->mrq && !host->manual_stop_mrq && !host->mrq_busy && !host->mrq_retry) {
+		rint = mmc_readl(host, REG_RINTR);
+		idma_int = mmc_readl(host, REG_IDST);
+		if ((rint & (SDXC_INTERRUPT_DONE_BIT | SDXC_INTERRUPT_ERROR_BIT))\
+			|| (idma_int & (SDXC_IDMAC_TRANSMIT_INTERRUPT | SDXC_IDMAC_RECEIVE_INTERRUPT))) {
+			dev_info(mmc_dev(host->mmc), "transfering\n");
+			goto timeout_out;
+		}
+		dev_info(mmc_dev(host->mmc), "timeout retry\n");
+		mmc_writel(host, REG_IMASK, host->sdio_imask | host->dat3_imask);
+		host->mrq_retry = host->mrq;
+		spin_unlock_irqrestore(&host->lock, flags);
+		sunxi_mmc_handle_do_bottom_half(host);
+		return;
+	} else
+		dev_err(mmc_dev(host->mmc), "no request running\n");
+timeout_out:
+	spin_unlock_irqrestore(&host->lock, flags);
+}
 
-/*
-* If the idma-des-size-bits of property is ie 13, bufsize bits are:
-*  Bits  0-12: buf1 size
-*  Bits 13-25: buf2 size
-*  Bits 26-31: not used
-* Since we only ever set buf1 size, we can simply store it directly.
-*/
-#define SDXC_IDMAC_DES0_DIC	BIT(1)  /* disable interrupt on completion */
-#define SDXC_IDMAC_DES0_LD	BIT(2)  /* last descriptor */
-#define SDXC_IDMAC_DES0_FD	BIT(3)  /* first descriptor */
-#define SDXC_IDMAC_DES0_CH	BIT(4)  /* chain mode */
-#define SDXC_IDMAC_DES0_ER	BIT(5)  /* end of ring */
-#define SDXC_IDMAC_DES0_CES	BIT(30) /* card error summary */
-#define SDXC_IDMAC_DES0_OWN	BIT(31) /* 1-idma owns it, 0-host owns it */
-
-#define SDXC_CLK_400K		0
-#define SDXC_CLK_25M		1
-#define SDXC_CLK_50M		2
-#define SDXC_CLK_50M_DDR	3
-#define SDXC_CLK_50M_DDR_8BIT	4
-
-#define SDXC_2X_TIMING_MODE	BIT(31)
-
-#define SDXC_CAL_START		BIT(15)
-#define SDXC_CAL_DONE		BIT(14)
-#define SDXC_CAL_DL_SHIFT	8
-#define SDXC_CAL_DL_SW_EN	BIT(7)
-#define SDXC_CAL_DL_SW_SHIFT	0
-#define SDXC_CAL_DL_MASK	0x3f
-
-#define SDXC_CAL_TIMEOUT	3	/* in seconds, 3s is enough*/
-
-struct sunxi_mmc_clk_delay {
-	u32 output;
-	u32 sample;
-};
+static void sunxi_mmc_request_done(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	if (host->ctl_spec_cap & SUNXI_SC_EN_TIMEOUT_DETECT) {
+		cancel_delayed_work(&host->sunxi_timerout_work);
+	}
+	mmc_request_done(mmc, mrq);
+}
 
-struct sunxi_idma_des {
-	__le32 config;
-	__le32 buf_size;
-	__le32 buf_addr_ptr1;
-	__le32 buf_addr_ptr2;
-};
+#if IS_ENABLED(CONFIG_REGULATOR)
+/**
+ * mmc_vdd_to_ocrbitnum - Convert a voltage to the OCR bit number
+ * @vdd:	voltage (mV)
+ * @low_bits:	prefer low bits in boundary cases
+ *
+ * This function returns the OCR bit number according to the provided @vdd
+ * value. If conversion is not possible a negative errno value returned.
+ *
+ * Depending on the @low_bits flag the function prefers low or high OCR bits
+ * on boundary voltages. For example,
+ * with @low_bits = true, 3300 mV translates to ilog2(MMC_VDD_32_33);
+ * with @low_bits = false, 3300 mV translates to ilog2(MMC_VDD_33_34);
+ *
+ * Any value in the [1951:1999] range translates to the ilog2(MMC_VDD_20_21).
+ */
+static int mmc_vdd_to_ocrbitnum(int vdd, bool low_bits)
+{
+	const int max_bit = ilog2(MMC_VDD_35_36);
+	int bit;
 
-struct sunxi_mmc_cfg {
-	u32 idma_des_size_bits;
-	const struct sunxi_mmc_clk_delay *clk_delays;
+	if (vdd < 1650 || vdd > 3600)
+		return -EINVAL;
 
-	/* does the IP block support autocalibration? */
-	bool can_calibrate;
+	if (vdd >= 1650 && vdd <= 1950)
+		return ilog2(MMC_VDD_165_195);
 
-	/* Does DATA0 needs to be masked while the clock is updated */
-	bool mask_data0;
+	if (low_bits)
+		vdd -= 1;
 
-	/*
-	 * hardware only supports new timing mode, either due to lack of
-	 * a mode switch in the clock controller, or the mmc controller
-	 * is permanently configured in the new timing mode, without the
-	 * NTSR mode switch.
-	 */
-	bool needs_new_timings;
+	/* Base 2000 mV, step 100 mV, bit's base 8. */
+	bit = (vdd - 2000) / 100 + 8;
+	if (bit > max_bit)
+		return max_bit;
+	return bit;
+}
 
-	/* clock hardware can switch between old and new timing modes */
-	bool ccu_has_timings_switch;
-};
+/**
+ * mmc_vddrange_to_ocrmask - Convert a voltage range to the OCR mask
+ * @vdd_min:	minimum voltage value (mV)
+ * @vdd_max:	maximum voltage value (mV)
+ *
+ * This function returns the OCR mask bits according to the provided @vdd_min
+ * and @vdd_max values. If conversion is not possible the function returns 0.
+ *
+ * Notes wrt boundary cases:
+ * This function sets the OCR bits for all boundary voltages, for example
+ * [3300:3400] range is translated to MMC_VDD_32_33 | MMC_VDD_33_34 |
+ * MMC_VDD_34_35 mask.
+ */
+static u32 sunxi_mmc_vddrange_to_ocrmask(int vdd_min, int vdd_max)
+{
+	u32 mask = 0;
+
+	if (vdd_max < vdd_min)
+		return 0;
 
-struct sunxi_mmc_host {
-	struct device *dev;
-	struct mmc_host	*mmc;
-	struct reset_control *reset;
-	const struct sunxi_mmc_cfg *cfg;
+	/* Prefer high bits for the boundary vdd_max values. */
+	vdd_max = mmc_vdd_to_ocrbitnum(vdd_max, false);
+	if (vdd_max < 0)
+		return 0;
 
-	/* IO mapping base */
-	void __iomem	*reg_base;
+	/* Prefer low bits for the boundary vdd_min values. */
+	vdd_min = mmc_vdd_to_ocrbitnum(vdd_min, true);
+	if (vdd_min < 0)
+		return 0;
 
-	/* clock management */
-	struct clk	*clk_ahb;
-	struct clk	*clk_mmc;
-	struct clk	*clk_sample;
-	struct clk	*clk_output;
+	/* Fill the mask, from max bit to min bit. */
+	while (vdd_max >= vdd_min)
+		mask |= 1 << vdd_max--;
 
-	/* irq */
-	spinlock_t	lock;
-	int		irq;
-	u32		int_sum;
-	u32		sdio_imask;
+	return mask;
+}
+/**
+ * mmc_regulator_get_ocrmask - return mask of supported voltages
+ * @supply: regulator to use
+ *
+ * This returns either a negative errno, or a mask of voltages that
+ * can be provided to MMC/SD/SDIO devices using the specified voltage
+ * regulator.  This would normally be called before registering the
+ * MMC host adapter.
+ */
+static int mmc_regulator_get_ocrmask(struct regulator *supply)
+{
+	int			result = 0;
+	int			count;
+	int			i;
+	int			vdd_uV;
+	int			vdd_mV;
+
+	count = regulator_count_voltages(supply);
+	if (count < 0)
+		return count;
+
+	for (i = 0; i < count; i++) {
+		vdd_uV = regulator_list_voltage(supply, i);
+		if (vdd_uV <= 0)
+			continue;
+
+		vdd_mV = vdd_uV / 1000;
+		result |= sunxi_mmc_vddrange_to_ocrmask(vdd_mV, vdd_mV);
+	}
 
-	/* dma */
-	dma_addr_t	sg_dma;
-	void		*sg_cpu;
-	bool		wait_dma;
+	if (!result) {
+		vdd_uV = regulator_get_voltage(supply);
+		if (vdd_uV <= 0)
+			return vdd_uV;
 
-	struct mmc_request *mrq;
-	struct mmc_request *manual_stop_mrq;
-	int		ferror;
+		vdd_mV = vdd_uV / 1000;
+		result = sunxi_mmc_vddrange_to_ocrmask(vdd_mV, vdd_mV);
+	}
 
-	/* vqmmc */
-	bool		vqmmc_enabled;
+	return result;
+}
 
-	/* timings */
-	bool		use_new_timings;
-};
+/**
+ * mmc_regulator_set_ocr - set regulator to match host->ios voltage
+ * @mmc: the host to regulate
+ * @supply: regulator to use
+ * @vdd_bit: zero for power off, else a bit number (host->ios.vdd)
+ *
+ * Returns zero on success, else negative errno.
+ *
+ * MMC host drivers may use this to enable or disable a regulator using
+ * a particular supply voltage.  This would normally be called from the
+ * set_ios() method.
+ */
+int sunxi_mmc_regulator_set_ocr(struct mmc_host *mmc,
+			struct regulator *supply,
+			unsigned short vdd_bit)
+{
+	int			result = 0;
+	/*int			min_uV, max_uV;*/
+
+	if (vdd_bit) {
+		/*sunxi platform avoid set vcc voltage*/
+		/*mmc_ocrbitnum_to_vdd(vdd_bit, &min_uV, &max_uV);*/
+
+		/*result = regulator_set_voltage(supply, min_uV, max_uV);*/
+		if (result == 0 && !mmc->regulator_enabled) {
+			result = regulator_enable(supply);
+			if (!result)
+				mmc->regulator_enabled = true;
+		}
+	} else if (mmc->regulator_enabled) {
+		result = regulator_disable(supply);
+		if (result == 0)
+			mmc->regulator_enabled = false;
+	}
+
+	if (result)
+		dev_err(mmc_dev(mmc),
+			"could not set regulator OCR (%d)\n", result);
+	return result;
+}
+#else
+static inline int mmc_regulator_get_ocrmask(struct regulator *supply)
+{
+	return 0;
+}
+static inline int sunxi_mmc_regulator_set_ocr(struct mmc_host *mmc,
+			struct regulator *supply,
+			unsigned short vdd_bit)
+{
+	return 0;
+}
+#endif
 
 static int sunxi_mmc_reset_host(struct sunxi_mmc_host *host)
 {
@@ -309,7 +327,10 @@ static int sunxi_mmc_reset_host(struct sunxi_mmc_host *host)
 	mmc_writel(host, REG_GCTRL, SDXC_HARDWARE_RESET);
 	do {
 		rval = mmc_readl(host, REG_GCTRL);
-	} while (time_before(jiffies, expire) && (rval & SDXC_HARDWARE_RESET));
+		if (!(rval & SDXC_HARDWARE_RESET))
+			break;
+		cond_resched();
+	} while (time_before(jiffies, expire));
 
 	if (rval & SDXC_HARDWARE_RESET) {
 		dev_err(mmc_dev(host->mmc), "fatal err reset timeout\n");
@@ -319,38 +340,113 @@ static int sunxi_mmc_reset_host(struct sunxi_mmc_host *host)
 	return 0;
 }
 
-static int sunxi_mmc_init_host(struct sunxi_mmc_host *host)
+static int sunxi_mmc_reset_dmaif(struct sunxi_mmc_host *host)
+{
+	unsigned long expire = jiffies + msecs_to_jiffies(250);
+	u32 rval;
+
+	rval = mmc_readl(host, REG_GCTRL);
+	mmc_writel(host, REG_GCTRL, rval | SDXC_DMA_RESET);
+	do {
+		rval = mmc_readl(host, REG_GCTRL);
+		if (!(rval & SDXC_DMA_RESET))
+			break;
+		cond_resched();
+	} while (time_before(jiffies, expire));
+
+	if (rval & SDXC_DMA_RESET) {
+		dev_err(mmc_dev(host->mmc),
+			"fatal err reset dma interface timeout\n");
+		return -EIO;
+	}
+
+	return 0;
+}
+
+static int sunxi_mmc_reset_fifo(struct sunxi_mmc_host *host)
+{
+	unsigned long expire = jiffies + msecs_to_jiffies(250);
+	u32 rval;
+
+	rval = mmc_readl(host, REG_GCTRL);
+	mmc_writel(host, REG_GCTRL, rval | SDXC_FIFO_RESET);
+	do {
+		rval = mmc_readl(host, REG_GCTRL);
+		if (!(rval & SDXC_FIFO_RESET))
+			break;
+		cond_resched();
+	} while (time_before(jiffies, expire));
+
+	if (rval & SDXC_FIFO_RESET) {
+		dev_err(mmc_dev(host->mmc), "fatal err reset fifo timeout\n");
+		return -EIO;
+	}
+
+	return 0;
+}
+
+static int sunxi_mmc_reset_dmactl(struct sunxi_mmc_host *host)
+{
+	unsigned long expire = jiffies + msecs_to_jiffies(250);
+	u32 rval;
+
+	rval = mmc_readl(host, REG_DMAC);
+	mmc_writel(host, REG_DMAC, rval | SDXC_IDMAC_SOFT_RESET);
+	do {
+		rval = mmc_readl(host, REG_DMAC);
+		if (!(rval & SDXC_IDMAC_SOFT_RESET))
+			break;
+		cond_resched();
+	} while (time_before(jiffies, expire));
+
+	if (rval & SDXC_IDMAC_SOFT_RESET) {
+		dev_err(mmc_dev(host->mmc),
+			"fatal err reset dma contol timeout\n");
+		return -EIO;
+	}
+
+	return 0;
+}
+
+void sunxi_mmc_set_a12a(struct sunxi_mmc_host *host)
+{
+	mmc_writel(host, REG_A12A, 0);
+}
+EXPORT_SYMBOL_GPL(sunxi_mmc_set_a12a);
+
+static int sunxi_mmc_init_host(struct mmc_host *mmc)
 {
 	u32 rval;
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
 
 	if (sunxi_mmc_reset_host(host))
 		return -EIO;
 
-	/*
-	 * Burst 8 transfers, RX trigger level: 7, TX trigger level: 8
-	 *
-	 * TODO: sun9i has a larger FIFO and supports higher trigger values
-	 */
-	mmc_writel(host, REG_FTRGL, 0x20070008);
-	/* Maximum timeout value */
+	if (sunxi_mmc_reset_dmactl(host))
+		return -EIO;
+
+
+	mmc_writel(host, REG_FTRGL, host->dma_tl ? host->dma_tl : 0x20070008);
+	dev_dbg(mmc_dev(host->mmc), "REG_FTRGL %x\n",
+		mmc_readl(host, REG_FTRGL));
 	mmc_writel(host, REG_TMOUT, 0xffffffff);
-	/* Unmask SDIO interrupt if needed */
-	mmc_writel(host, REG_IMASK, host->sdio_imask);
-	/* Clear all pending interrupts */
+	mmc_writel(host, REG_IMASK, host->sdio_imask | host->dat3_imask);
 	mmc_writel(host, REG_RINTR, 0xffffffff);
-	/* Debug register? undocumented */
 	mmc_writel(host, REG_DBGC, 0xdeb);
-	/* Enable CEATA support */
-	mmc_writel(host, REG_FUNS, SDXC_CEATA_ON);
-	/* Set DMA descriptor list base address */
-	mmc_writel(host, REG_DLBA, host->sg_dma);
+	/*mmc_writel(host, REG_FUNS, SDXC_CEATA_ON);*/
+	mmc_writel(host, REG_DLBA, sunxi_mmc_host_des_addr(host, host->sg_dma));
 
 	rval = mmc_readl(host, REG_GCTRL);
 	rval |= SDXC_INTERRUPT_ENABLE_BIT;
-	/* Undocumented, but found in Allwinner code */
 	rval &= ~SDXC_ACCESS_DONE_DIRECT;
+	if (host->dat3_imask)
+		rval |= SDXC_DEBOUNCE_ENABLE_BIT;
+
 	mmc_writel(host, REG_GCTRL, rval);
 
+	if (host->sunxi_mmc_set_acmda)
+		host->sunxi_mmc_set_acmda(host);
+
 	return 0;
 }
 
@@ -358,51 +454,89 @@ static void sunxi_mmc_init_idma_des(struct sunxi_mmc_host *host,
 				    struct mmc_data *data)
 {
 	struct sunxi_idma_des *pdes = (struct sunxi_idma_des *)host->sg_cpu;
-	dma_addr_t next_desc = host->sg_dma;
-	int i, max_len = (1 << host->cfg->idma_des_size_bits);
+	struct sunxi_idma_des *pdes_pa = (struct sunxi_idma_des *)host->sg_dma;
+	struct mmc_host *mmc = host->mmc;
+	int i = 0, j = 0;
+	int count = 0;
+	int cycles_count = 0;
+	unsigned int remainder = 0;
 
 	for (i = 0; i < data->sg_len; i++) {
-		pdes[i].config = cpu_to_le32(SDXC_IDMAC_DES0_CH |
-					     SDXC_IDMAC_DES0_OWN |
-					     SDXC_IDMAC_DES0_DIC);
-
-		if (data->sg[i].length == max_len)
-			pdes[i].buf_size = 0; /* 0 == max_len */
-		else
-			pdes[i].buf_size = cpu_to_le32(data->sg[i].length);
+		cycles_count = (data->sg[i].length - 1) / mmc->max_seg_size + 1;
+		remainder = ((data->sg[i].length - 1) % (mmc->max_seg_size)) + 1;
+		for (j = 0; j < cycles_count; j++) {
+			pdes[i + count].config = SDXC_IDMAC_DES0_CH | SDXC_IDMAC_DES0_OWN |
+			    SDXC_IDMAC_DES0_DIC;
+			pdes[i + count].buf_size = (j != (cycles_count - 1)) ? (mmc->max_seg_size):(remainder);
+			pdes[i + count].buf_addr_ptr1 = sunxi_mmc_host_des_addr(host,
+								sg_dma_address(&data->sg[i]) + j * mmc->max_seg_size);
+			/*We use size_t only to avoid compile waring */
+			/*pdes[i].buf_addr_ptr2 = (u32) (size_t) &pdes_pa[i + 1];*/
+			pdes[i + count].buf_addr_ptr2 = (u32)sunxi_mmc_host_des_addr(host, (size_t)&pdes_pa[i + count + 1]);
+			count++;
+		}
+		count--;
+	}
 
-		next_desc += sizeof(struct sunxi_idma_des);
-		pdes[i].buf_addr_ptr1 =
-			cpu_to_le32(sg_dma_address(&data->sg[i]));
-		pdes[i].buf_addr_ptr2 = cpu_to_le32((u32)next_desc);
+	if ((i + count) > mmc->max_segs) {
+		dev_err(mmc_dev(mmc), "sg_len greater than max_segs\n");
 	}
 
-	pdes[0].config |= cpu_to_le32(SDXC_IDMAC_DES0_FD);
-	pdes[i - 1].config |= cpu_to_le32(SDXC_IDMAC_DES0_LD |
-					  SDXC_IDMAC_DES0_ER);
-	pdes[i - 1].config &= cpu_to_le32(~SDXC_IDMAC_DES0_DIC);
-	pdes[i - 1].buf_addr_ptr2 = 0;
+	pdes[0].config |= SDXC_IDMAC_DES0_FD;
+	pdes[i + count - 1].config |= SDXC_IDMAC_DES0_LD;
+	pdes[i + count - 1].config &= ~SDXC_IDMAC_DES0_DIC;
 
 	/*
-	 * Avoid the io-store starting the idmac hitting io-mem before the
+	 * **Avoid the io-store starting the idmac hitting io-mem before the
 	 * descriptors hit the main-mem.
 	 */
 	wmb();
 }
 
-static int sunxi_mmc_map_dma(struct sunxi_mmc_host *host,
-			     struct mmc_data *data)
+static enum dma_data_direction sunxi_mmc_get_dma_dir(struct mmc_data *data)
 {
-	u32 i, dma_len;
-	struct scatterlist *sg;
+	if (data->flags & MMC_DATA_WRITE)
+		return DMA_TO_DEVICE;
+	else
+		return DMA_FROM_DEVICE;
+}
+
+static int sunxi_mmc_map_dma(struct sunxi_mmc_host *host, struct mmc_data *data,
+			     int cookie)
+{
+	u32 i = 0, dma_len;
+	struct scatterlist *sg = NULL;
+	int max_len = (1 << host->idma_des_size_bits);
+
+	if (data->host_cookie == COOKIE_PRE_MAPPED)
+		return 0;
 
 	dma_len = dma_map_sg(mmc_dev(host->mmc), data->sg, data->sg_len,
-			     mmc_get_dma_dir(data));
+			     sunxi_mmc_get_dma_dir(data));
 	if (dma_len == 0) {
 		dev_err(mmc_dev(host->mmc), "dma_map_sg failed\n");
 		return -ENOMEM;
 	}
 
+	/*
+	 *Acorrding DMA-API.txt,dma_len should not be
+	 *always equal to data->sg_len.
+	 *Because The dma_map_sg implementation is free
+	 *to merge several consecutive sglist entries into one
+	 *But according to dma_map_sg implement in fact,
+	 *dma_len is always equal to data->sg_len.
+	 *So we don't change the code,only add a warning on it only for safe
+	 */
+	if (dma_len != data->sg_len) {
+		dev_err(mmc_dev(host->mmc), "*******dma_len != data->sg_len*******\n");
+		return -1;
+	}
+
+	if (dma_len > host->mmc->max_segs) {
+		dev_err(mmc_dev(host->mmc), "*******dma_len > host->mmc->max_segs*******\n");
+		return -1;
+	}
+
 	for_each_sg(data->sg, sg, data->sg_len, i) {
 		if (sg->offset & 3 || sg->length & 3) {
 			dev_err(mmc_dev(host->mmc),
@@ -410,8 +544,15 @@ static int sunxi_mmc_map_dma(struct sunxi_mmc_host *host,
 				sg->offset, sg->length);
 			return -EINVAL;
 		}
+		if (data->sg_len > max_len) {
+			dev_err(mmc_dev(host->mmc),
+				"******sg len is over one dma des transfer len******\n");
+			return -1;
+		}
 	}
 
+	data->host_cookie = cookie;
+
 	return 0;
 }
 
@@ -422,19 +563,18 @@ static void sunxi_mmc_start_dma(struct sunxi_mmc_host *host,
 
 	sunxi_mmc_init_idma_des(host, data);
 
+	sunxi_mmc_reset_fifo(host);
+	sunxi_mmc_reset_dmaif(host);
+	sunxi_mmc_reset_dmactl(host);
+
 	rval = mmc_readl(host, REG_GCTRL);
 	rval |= SDXC_DMA_ENABLE_BIT;
 	mmc_writel(host, REG_GCTRL, rval);
-	rval |= SDXC_DMA_RESET;
-	mmc_writel(host, REG_GCTRL, rval);
-
-	mmc_writel(host, REG_DMAC, SDXC_IDMAC_SOFT_RESET);
 
 	if (!(data->flags & MMC_DATA_WRITE))
 		mmc_writel(host, REG_IDIE, SDXC_IDMAC_RECEIVE_INTERRUPT);
 
-	mmc_writel(host, REG_DMAC,
-		   SDXC_IDMAC_FIX_BURST | SDXC_IDMAC_IDMA_ON);
+	mmc_writel(host, REG_DMAC, SDXC_IDMAC_FIX_BURST | SDXC_IDMAC_IDMA_ON);
 }
 
 static void sunxi_mmc_send_manual_stop(struct sunxi_mmc_host *host,
@@ -443,19 +583,21 @@ static void sunxi_mmc_send_manual_stop(struct sunxi_mmc_host *host,
 	u32 arg, cmd_val, ri;
 	unsigned long expire = jiffies + msecs_to_jiffies(1000);
 
-	cmd_val = SDXC_START | SDXC_RESP_EXPIRE |
-		  SDXC_STOP_ABORT_CMD | SDXC_CHECK_RESPONSE_CRC;
+	cmd_val = SDXC_START | SDXC_RESP_EXPECT |
+	    SDXC_STOP_ABORT_CMD | SDXC_CHECK_RESPONSE_CRC;
 
 	if (req->cmd->opcode == SD_IO_RW_EXTENDED) {
 		cmd_val |= SD_IO_RW_DIRECT;
-		arg = (1 << 31) | (0 << 28) | (SDIO_CCCR_ABORT << 9) |
-		      ((req->cmd->arg >> 28) & 0x7);
+		arg = (1U << 31) | (0 << 28) | (SDIO_CCCR_ABORT << 9) |
+		    ((req->cmd->arg >> 28) & 0x7);
 	} else {
 		cmd_val |= MMC_STOP_TRANSMISSION;
 		arg = 0;
 	}
 
 	mmc_writel(host, REG_CARG, arg);
+	/**cmd shuld be sent before arg**/
+	wmb();
 	mmc_writel(host, REG_CMDR, cmd_val);
 
 	do {
@@ -464,12 +606,14 @@ static void sunxi_mmc_send_manual_stop(struct sunxi_mmc_host *host,
 		 time_before(jiffies, expire));
 
 	if (!(ri & SDXC_COMMAND_DONE) || (ri & SDXC_INTERRUPT_ERROR_BIT)) {
-		dev_err(mmc_dev(host->mmc), "send stop command failed\n");
+		dev_err(mmc_dev(host->mmc),
+			"send  manual stop command failed %x\n", (unsigned int)(ri & SDXC_INTERRUPT_ERROR_BIT));
 		if (req->stop)
 			req->stop->resp[0] = -ETIMEDOUT;
 	} else {
 		if (req->stop)
 			req->stop->resp[0] = mmc_readl(host, REG_RESP0);
+		dev_dbg(mmc_dev(host->mmc), "send manual stop command ok\n");
 	}
 
 	mmc_writel(host, REG_RINTR, 0xffff);
@@ -481,64 +625,136 @@ static void sunxi_mmc_dump_errinfo(struct sunxi_mmc_host *host)
 	struct mmc_data *data = host->mrq->data;
 
 	/* For some cmds timeout is normal with sd/mmc cards */
-	if ((host->int_sum & SDXC_INTERRUPT_ERROR_BIT) ==
-		SDXC_RESP_TIMEOUT && (cmd->opcode == SD_IO_SEND_OP_COND ||
-				      cmd->opcode == SD_IO_RW_DIRECT))
-		return;
+	/*
+	 *  if ((host->int_sum & SDXC_INTERRUPT_ERROR_BIT) ==
+	 *  SDXC_RESP_TIMEOUT &&
+	 *(cmd->opcode == SD_IO_SEND_OP_COND || cmd->opcode == SD_IO_RW_DIRECT))
+	 *  return;
+	 */
 
-	dev_dbg(mmc_dev(host->mmc),
-		"smc %d err, cmd %d,%s%s%s%s%s%s%s%s%s%s !!\n",
-		host->mmc->index, cmd->opcode,
+	dev_err(mmc_dev(host->mmc),
+		"smc %d p%d err, cmd %d,%s%s%s%s%s%s%s%s%s%s !!\n",
+		host->mmc->index, host->phy_index, cmd->opcode,
 		data ? (data->flags & MMC_DATA_WRITE ? " WR" : " RD") : "",
-		host->int_sum & SDXC_RESP_ERROR     ? " RE"     : "",
-		host->int_sum & SDXC_RESP_CRC_ERROR  ? " RCE"    : "",
-		host->int_sum & SDXC_DATA_CRC_ERROR  ? " DCE"    : "",
-		host->int_sum & SDXC_RESP_TIMEOUT ? " RTO"    : "",
-		host->int_sum & SDXC_DATA_TIMEOUT ? " DTO"    : "",
-		host->int_sum & SDXC_FIFO_RUN_ERROR  ? " FE"     : "",
-		host->int_sum & SDXC_HARD_WARE_LOCKED ? " HL"     : "",
-		host->int_sum & SDXC_START_BIT_ERROR ? " SBE"    : "",
-		host->int_sum & SDXC_END_BIT_ERROR   ? " EBE"    : ""
-		);
+		host->int_sum & SDXC_RESP_ERROR ? " RE" : "",
+		host->int_sum & SDXC_RESP_CRC_ERROR ? " RCE" : "",
+		host->int_sum & SDXC_DATA_CRC_ERROR ? " DCE" : "",
+		host->int_sum & SDXC_RESP_TIMEOUT ? " RTO" : "",
+		host->int_sum & SDXC_DATA_TIMEOUT ? " DTO" : "",
+		host->int_sum & SDXC_FIFO_RUN_ERROR ? " FE" : "",
+		host->int_sum & SDXC_HARD_WARE_LOCKED ? " HL" : "",
+		host->int_sum & SDXC_START_BIT_ERROR ? " SBE" : "",
+		host->int_sum & SDXC_END_BIT_ERROR ? " EBE" : "");
+	/*sunxi_mmc_dumphex32(host,"sunxi mmc",host->reg_base,0x180); */
+	/*sunxi_mmc_dump_des(host,host->sg_cpu,PAGE_SIZE); */
 }
 
+#define SUNXI_FINAL_CONT	1
+#define SUNXI_FINAL_END		2
+#define SUNXI_FINAL_BHALF	3
+#define SUNXI_FINAL_NONE	0
+
+
+
 /* Called in interrupt context! */
-static irqreturn_t sunxi_mmc_finalize_request(struct sunxi_mmc_host *host)
+static int sunxi_mmc_finalize_request(struct sunxi_mmc_host *host)
 {
 	struct mmc_request *mrq = host->mrq;
 	struct mmc_data *data = mrq->data;
+	struct mmc_command *sbc = mrq->sbc;
+	struct mmc_command *cmd = mrq->cmd;
+	const struct mmc_host_ops *ops = host->mmc->ops;
+	u32 imask = 0;
+	u32 cmd_val = 0;
 	u32 rval;
-
-	mmc_writel(host, REG_IMASK, host->sdio_imask);
-	mmc_writel(host, REG_IDIE, 0);
+	bool wait_dma = false;
+	bool cont_dat_cmd = false;
 
 	if (host->int_sum & SDXC_INTERRUPT_ERROR_BIT) {
 		sunxi_mmc_dump_errinfo(host);
-		mrq->cmd->error = -ETIMEDOUT;
+		if (((host->ctl_spec_cap & SUNXI_SC_EN_RETRY) && data)\
+			|| ((host->ctl_spec_cap & SUNXI_SC_EN_RETRY_CMD) && !data)) {
+			host->mrq_retry = mrq;
+			host->errno_retry =
+			    host->int_sum & SDXC_INTERRUPT_ERROR_BIT;
+		} else {
+			mrq->cmd->error = -ETIMEDOUT;
 
-		if (data) {
-			data->error = -ETIMEDOUT;
-			host->manual_stop_mrq = mrq;
-		}
+			if (data) {
+				data->error = -ETIMEDOUT;
+				host->manual_stop_mrq = mrq;
+			}
 
-		if (mrq->stop)
-			mrq->stop->error = -ETIMEDOUT;
+			if (mrq->stop)
+				mrq->stop->error = -ETIMEDOUT;
+		}
 	} else {
-		if (mrq->cmd->flags & MMC_RSP_136) {
-			mrq->cmd->resp[0] = mmc_readl(host, REG_RESP3);
-			mrq->cmd->resp[1] = mmc_readl(host, REG_RESP2);
-			mrq->cmd->resp[2] = mmc_readl(host, REG_RESP1);
-			mrq->cmd->resp[3] = mmc_readl(host, REG_RESP0);
+		/*if (!sbc || (sbc && host->sunxi_mmc_opacmd23)) {*/
+		if (!sbc || (host->sunxi_mmc_opacmd23)) {
+
+			if (cmd->flags & MMC_RSP_136) {
+				cmd->resp[0] = mmc_readl(host, REG_RESP3);
+				cmd->resp[1] = mmc_readl(host, REG_RESP2);
+				cmd->resp[2] = mmc_readl(host, REG_RESP1);
+				cmd->resp[3] = mmc_readl(host, REG_RESP0);
+			} else {
+				cmd->resp[0] = mmc_readl(host, REG_RESP0);
+			}
+
+			if (data) {
+				data->bytes_xfered = data->blocks * data->blksz;
+				if (sbc && host->sunxi_mmc_opacmd23)
+					host->sunxi_mmc_opacmd23(host, false, 0, sbc->resp);
+			}
+
+			/*
+			*To avoid that "wait busy" and "maual stop"
+			*occur at the same time,
+			*We wait busy only on not error occur.
+			*/
+			if (sunxi_mmc_creq_r1b_chk_need(host, cmd)
+				|| sunxi_mmc_dreq_r1b_chk_need(host, data)) {
+				if ((ops->card_busy) && (ops->card_busy(host->mmc))) {
+				host->mrq_busy = host->mrq;
+				dev_dbg(mmc_dev(host->mmc),
+					"cmd%d,wb\n", cmd->opcode);
+				}
+			}
+			/**clear retry count if retry ok*/
+			if (host->retry_cnt)
+				printk("%d,end\n", host->retry_cnt);
+			sunxi_mmc_clean_retry_cnt(host);
 		} else {
-			mrq->cmd->resp[0] = mmc_readl(host, REG_RESP0);
-		}
 
-		if (data)
-			data->bytes_xfered = data->blocks * data->blksz;
+			if (host->int_sum & SDXC_COMMAND_DONE) {
+				sbc->resp[0] = mmc_readl(host, REG_RESP0);
+				cont_dat_cmd = true;
+				goto out;
+			} else if (host->int_sum & SDXC_INTERRUPT_DDONE_BIT) {
+				cmd->resp[0] = mmc_readl(host, REG_RESP0);
+				data->bytes_xfered = data->blocks * data->blksz;
+
+				/*
+				*To avoid that "wait busy" and "maual stop"
+				*occur at the same time,
+				*We wait busy only on not error occur.
+				*/
+				if (sunxi_mmc_dreq_r1b_chk_need(host, data)) {
+					if ((ops->card_busy) && (ops->card_busy(host->mmc))) {
+					host->mrq_busy = host->mrq;
+					dev_dbg(mmc_dev(host->mmc),
+						"cmd%d,wb\n", cmd->opcode);
+					}
+				}
+				/**clear retry count if retry ok*/
+				sunxi_mmc_clean_retry_cnt(host);
+			}
+		}
 	}
 
 	if (data) {
 		mmc_writel(host, REG_IDST, 0x337);
+		mmc_writel(host, REG_IDIE, 0);
 		mmc_writel(host, REG_DMAC, 0);
 		rval = mmc_readl(host, REG_GCTRL);
 		rval |= SDXC_DMA_RESET;
@@ -548,16 +764,48 @@ static irqreturn_t sunxi_mmc_finalize_request(struct sunxi_mmc_host *host)
 		rval |= SDXC_FIFO_RESET;
 		mmc_writel(host, REG_GCTRL, rval);
 		dma_unmap_sg(mmc_dev(host->mmc), data->sg, data->sg_len,
-			     mmc_get_dma_dir(data));
+			     sunxi_mmc_get_dma_dir(data));
+		data->host_cookie = COOKIE_UNMAPPED;
+		sunxi_mmc_uperf_stat(host, data, host->mrq_busy, false);
+		if (host->sunxi_mmc_on_off_emce && data->sg) {
+			if (host->crypt_flag) {
+			dev_dbg(mmc_dev(host->mmc), "emce is disable\n");
+			host->sunxi_mmc_on_off_emce(host, 0, 0, 0,
+						    data->bytes_xfered, 1, 0);
+			}
+		}
+		host->crypt_flag = 0;
 	}
 
+out:
+	mmc_writel(host, REG_IMASK, host->sdio_imask | host->dat3_imask);
 	mmc_writel(host, REG_RINTR, 0xffff);
 
+	if (host->dat3_imask) {
+		rval = mmc_readl(host, REG_GCTRL);
+		mmc_writel(host, REG_GCTRL, rval | SDXC_DEBOUNCE_ENABLE_BIT);
+	}
+
 	host->mrq = NULL;
 	host->int_sum = 0;
 	host->wait_dma = false;
 
-	return host->manual_stop_mrq ? IRQ_WAKE_THREAD : IRQ_HANDLED;
+
+	if (cont_dat_cmd) {
+		sunxi_mmc_parse_cmd(host->mmc,
+							cmd,
+							&cmd_val,
+							&imask,
+							&wait_dma);
+		host->mrq = mrq;
+		host->wait_dma = wait_dma;
+		sunxi_mmc_exe_cmd(host, cmd, cmd_val, imask);
+		return SUNXI_FINAL_CONT;
+	}
+
+	return (host->manual_stop_mrq
+		|| host->mrq_busy
+		|| host->mrq_retry) ? SUNXI_FINAL_BHALF : SUNXI_FINAL_END;
 }
 
 static irqreturn_t sunxi_mmc_irq(int irq, void *dev_id)
@@ -567,16 +815,30 @@ static irqreturn_t sunxi_mmc_irq(int irq, void *dev_id)
 	u32 msk_int, idma_int;
 	bool finalize = false;
 	bool sdio_int = false;
+	int final_ret = 0;
 	irqreturn_t ret = IRQ_HANDLED;
 
 	spin_lock(&host->lock);
 
-	idma_int  = mmc_readl(host, REG_IDST);
-	msk_int   = mmc_readl(host, REG_MISTA);
+	idma_int = mmc_readl(host, REG_IDST);
+	msk_int = mmc_readl(host, REG_MISTA);
 
 	dev_dbg(mmc_dev(host->mmc), "irq: rq %p mi %08x idi %08x\n",
 		host->mrq, msk_int, idma_int);
 
+	if (host->dat3_imask) {
+		if (msk_int & SDXC_CARD_INSERT) {
+			mmc_writel(host, REG_RINTR, SDXC_CARD_INSERT);
+			mmc_detect_change(host->mmc, msecs_to_jiffies(500));
+			goto out;
+		}
+		if (msk_int & SDXC_CARD_REMOVE) {
+			mmc_writel(host, REG_RINTR, SDXC_CARD_REMOVE);
+			mmc_detect_change(host->mmc, msecs_to_jiffies(50));
+			goto out;
+		}
+	}
+
 	mrq = host->mrq;
 	if (mrq) {
 		if (idma_int & SDXC_IDMAC_RECEIVE_INTERRUPT)
@@ -586,14 +848,15 @@ static irqreturn_t sunxi_mmc_irq(int irq, void *dev_id)
 
 		/* Wait for COMMAND_DONE on RESPONSE_TIMEOUT before finalize */
 		if ((host->int_sum & SDXC_RESP_TIMEOUT) &&
-				!(host->int_sum & SDXC_COMMAND_DONE))
+		    !(host->int_sum & SDXC_COMMAND_DONE))
 			mmc_writel(host, REG_IMASK,
-				   host->sdio_imask | SDXC_COMMAND_DONE);
+				   host->sdio_imask | host->
+				   dat3_imask | SDXC_COMMAND_DONE);
 		/* Don't wait for dma on error */
 		else if (host->int_sum & SDXC_INTERRUPT_ERROR_BIT)
 			finalize = true;
 		else if ((host->int_sum & SDXC_INTERRUPT_DONE_BIT) &&
-				!host->wait_dma)
+			 !host->wait_dma)
 			finalize = true;
 	}
 
@@ -604,362 +867,707 @@ static irqreturn_t sunxi_mmc_irq(int irq, void *dev_id)
 	mmc_writel(host, REG_IDST, idma_int);
 
 	if (finalize)
-		ret = sunxi_mmc_finalize_request(host);
-
+		final_ret = sunxi_mmc_finalize_request(host);
+out:
+/******************************************************/
+	smp_wmb();
 	spin_unlock(&host->lock);
 
-	if (finalize && ret == IRQ_HANDLED)
-		mmc_request_done(host->mmc, mrq);
+	if (finalize && (final_ret == SUNXI_FINAL_END))
+		sunxi_mmc_request_done(host->mmc, mrq);
 
 	if (sdio_int)
 		mmc_signal_sdio_irq(host->mmc);
 
+	if (final_ret == SUNXI_FINAL_BHALF)
+		ret = IRQ_WAKE_THREAD;
+
 	return ret;
 }
 
-static irqreturn_t sunxi_mmc_handle_manual_stop(int irq, void *dev_id)
+int sunxi_check_r1_ready(struct sunxi_mmc_host *smc_host, unsigned ms)
 {
-	struct sunxi_mmc_host *host = dev_id;
-	struct mmc_request *mrq;
-	unsigned long iflags;
-
-	spin_lock_irqsave(&host->lock, iflags);
-	mrq = host->manual_stop_mrq;
-	spin_unlock_irqrestore(&host->lock, iflags);
+	unsigned long expire = jiffies + msecs_to_jiffies(ms);
+	const struct mmc_host_ops *ops = smc_host->mmc->ops;
 
-	if (!mrq) {
-		dev_err(mmc_dev(host->mmc), "no request for manual stop\n");
-		return IRQ_HANDLED;
+	dev_info(mmc_dev(smc_host->mmc), "wrd\n");
+	do {
+		if ((ops->card_busy) && (!(ops->card_busy(smc_host->mmc))))
+			break;
+	} while (time_before(jiffies, expire));
+
+	if ((ops->card_busy) && ((ops->card_busy(smc_host->mmc)))) {
+		dev_err(mmc_dev(smc_host->mmc), "wait r1 rdy %d ms timeout\n",
+			ms);
+		return -1;
+	} else {
+		return 0;
 	}
+}
 
-	dev_err(mmc_dev(host->mmc), "data error, sending stop command\n");
-
+int sunxi_check_r1_ready_may_sleep(struct sunxi_mmc_host *smc_host)
+{
+	unsigned int cnt = 0;
 	/*
-	 * We will never have more than one outstanding request,
-	 * and we do not complete the request until after
-	 * we've cleared host->manual_stop_mrq so we do not need to
-	 * spin lock this function.
-	 * Additionally we have wait states within this function
-	 * so having it in a lock is a very bad idea.
-	 */
-	sunxi_mmc_send_manual_stop(host, mrq);
+	*SUNXI_DEF_MAX_R1B_TIMEOUT-10ms(dead wait)-(10)
+	*(wait interval 10us,all wait 10*1000 us=10ms)**
+	*/
+	unsigned int delay_max_cnt[2] = {0};
+	int i = 0;
+	unsigned long expire = jiffies + msecs_to_jiffies(10);
+	const struct mmc_host_ops *ops = smc_host->mmc->ops;
+
+	delay_max_cnt[0] = 1000; /*wait interval 10us */
+	/*wait interval 1ms */
+	delay_max_cnt[1] = smc_host->mmc->max_busy_timeout-10-10;
+
+	/*****dead wait******/
+	do {
+		if ((ops->card_busy) && (!(ops->card_busy(smc_host->mmc))))
+			break;
+		cond_resched();
+	} while (time_before(jiffies, expire));
 
-	spin_lock_irqsave(&host->lock, iflags);
-	host->manual_stop_mrq = NULL;
-	spin_unlock_irqrestore(&host->lock, iflags);
+	if ((ops->card_busy) && (!(ops->card_busy(smc_host->mmc)))) {
+		dev_dbg(mmc_dev(smc_host->mmc), "dead Wait r1 rdy ok\n");
+		return 0;
+	}
 
-	mmc_request_done(host->mmc, mrq);
+	/*****no dead wait*****/
+	for (i = 0; i < 2; i++, cnt = 0) {
+		do {
+			if ((ops->card_busy) && (!(ops->card_busy(smc_host->mmc)))) {
+				dev_dbg(mmc_dev(smc_host->mmc),
+					"cmd%d Wait r1 rdy ok c%d i%d\n",
+					mmc_readl(smc_host, REG_CMDR) & 0x3F,
+					cnt, i);
+				return 0;
+			}
 
-	return IRQ_HANDLED;
+			/* wait data0 busy... */
+			if (i == 0) {
+				if (((cnt % 500000) == 0) && cnt) {
+					dev_info(mmc_dev(smc_host->mmc),
+						 "cmd%d Has wait r1 rdy c%d i%d\n",
+						 mmc_readl(smc_host,
+							   REG_CMDR) & 0x3F,
+						 cnt, i);
+				}
+				usleep_range(10, 20);
+			} else {
+				if (((cnt % 5000) == 0) && cnt) {
+					dev_info(mmc_dev(smc_host->mmc),
+						 "cmd%d Has wait r1 rdy c%d i%d\n",
+						 mmc_readl(smc_host,
+							   REG_CMDR) & 0x3F,
+						 cnt, i);
+				}
+				usleep_range(1000, 1200);
+			}
+		} while ((cnt++) < delay_max_cnt[i]);
+	}
+	dev_err(mmc_dev(smc_host->mmc), "cmd%d Wait r1 rdy timeout\n",
+		mmc_readl(smc_host, REG_CMDR) & 0x3F);
+	return -1;
 }
 
-static int sunxi_mmc_oclk_onoff(struct sunxi_mmc_host *host, u32 oclk_en)
+static irqreturn_t sunxi_mmc_handle_bottom_half(int irq, void *dev_id)
 {
-	unsigned long expire = jiffies + msecs_to_jiffies(750);
-	u32 rval;
-
-	dev_dbg(mmc_dev(host->mmc), "%sabling the clock\n",
-		oclk_en ? "en" : "dis");
+	return sunxi_mmc_handle_do_bottom_half(dev_id);
+}
 
-	rval = mmc_readl(host, REG_CLKCR);
-	rval &= ~(SDXC_CARD_CLOCK_ON | SDXC_LOW_POWER_ON | SDXC_MASK_DATA0);
+static irqreturn_t sunxi_mmc_handle_do_bottom_half(void *dev_id)
+{
+	struct sunxi_mmc_host *host = dev_id;
+	struct mmc_request *mrq_stop;
+	struct mmc_request *mrq_busy = NULL;
+	struct mmc_request *mrq_retry = NULL;
+	struct mmc_host *mmc = host->mmc;
+	int rval = 0;
+	unsigned long iflags;
 
-	if (oclk_en)
-		rval |= SDXC_CARD_CLOCK_ON;
-	if (host->cfg->mask_data0)
-		rval |= SDXC_MASK_DATA0;
+	spin_lock_irqsave(&host->lock, iflags);
+	mrq_stop = host->manual_stop_mrq;
+	mrq_busy = host->mrq_busy;
+	mrq_retry = host->mrq_retry;
+	spin_unlock_irqrestore(&host->lock, iflags);
 
-	mmc_writel(host, REG_CLKCR, rval);
+	if (mrq_busy) {
+		/*
+		 *Here,we don't use the timeout value in mrq_busy->busy_timeout
+		 *Because this value may not right for example when useing TRIM
+		 *So we use 10min wait time max and print time value every
+		 *5 second
+		 */
+		rval = sunxi_check_r1_ready_may_sleep(host);
+		spin_lock_irqsave(&host->lock, iflags);
+		if (rval) {
+			mrq_busy->cmd->error = -ETIMEDOUT;
+			if (mrq_busy->data)
+				mrq_busy->data->error = -ETIMEDOUT;
+			if (mrq_busy->stop)
+				mrq_busy->stop->error = -ETIMEDOUT;
+		}
+		host->mrq_busy = NULL;
+/******************************************************/
+		sunxi_mmc_uperf_stat(host, mrq_busy->data, mrq_busy, true);
+		smp_wmb();
+		spin_unlock_irqrestore(&host->lock, iflags);
+		sunxi_mmc_request_done(mmc, mrq_busy);
+		return IRQ_HANDLED;
+	}
+	dev_dbg(mmc_dev(mmc), "no request for busy\n");
 
-	rval = SDXC_START | SDXC_UPCLK_ONLY | SDXC_WAIT_PRE_OVER;
-	mmc_writel(host, REG_CMDR, rval);
+	if (mrq_stop) {
+		dev_err(mmc_dev(mmc), "data error, sending stop command\n");
+		/***reset host***/
+		spin_lock_irqsave(&host->lock, iflags);
+		sunxi_mmc_regs_save(host);
+		spin_unlock_irqrestore(&host->lock, iflags);
+		/**if gating/reset protect itself,so no lock use host->lock**/
+		sunxi_mmc_bus_clk_en(host, 0);
+		sunxi_mmc_bus_clk_en(host, 1);
+		sunxi_mmc_regs_restore(host);
+		dev_dbg(mmc_dev(host->mmc),
+			"no device retry:host reset and reg recover ok\n");
+
+		/***use sunxi_mmc_oclk_en  to update clk***/
+		rval = host->sunxi_mmc_oclk_en(host, 1);
+		dev_err(mmc_dev(host->mmc),
+		"stop:recover\n");
+		if (rval) {
+			dev_err(mmc_dev(mmc), "retry:update clk failed %s %d\n",
+					__func__, __LINE__);
+		}
 
-	do {
-		rval = mmc_readl(host, REG_CMDR);
-	} while (time_before(jiffies, expire) && (rval & SDXC_START));
+		/*
+		 * We will never have more than one outstanding request,
+		 * and we do not complete the request until after
+		 * we've cleared host->manual_stop_mrq so we do not need to
+		 * spin lock this function.
+		 * Additionally we have wait states within this function
+		 * so having it in a lock is a very bad idea.
+		 */
+		sunxi_mmc_send_manual_stop(host, mrq_stop);
+		if (gpio_is_valid(host->card_pwr_gpio))
+			gpio_set_value(host->card_pwr_gpio,
+				       (host->
+					ctl_spec_cap &
+					CARD_PWR_GPIO_HIGH_ACTIVE) ? 0 : 1);
+
+		/***reset host***/
+		sunxi_mmc_regs_save(host);
+		sunxi_mmc_bus_clk_en(host, 0);
+		sunxi_mmc_bus_clk_en(host, 1);
+		sunxi_mmc_regs_restore(host);
+		dev_info(mmc_dev(host->mmc),
+			 "reset:host reset and recover finish\n");
+		/***update clk***/
+		rval = host->sunxi_mmc_oclk_en(host, 1);
+		if (rval) {
+			dev_err(mmc_dev(mmc), "reset:update clk failed %s %d\n",
+				__func__, __LINE__);
+		}
 
-	/* clear irq status bits set by the command */
-	mmc_writel(host, REG_RINTR,
-		   mmc_readl(host, REG_RINTR) & ~SDXC_SDIO_INTERRUPT);
+		spin_lock_irqsave(&host->lock, iflags);
+		host->manual_stop_mrq = NULL;
+/******************************************************/
+		smp_wmb();
+		spin_unlock_irqrestore(&host->lock, iflags);
 
-	if (rval & SDXC_START) {
-		dev_err(mmc_dev(host->mmc), "fatal err update clk timeout\n");
-		return -EIO;
+		sunxi_mmc_request_done(mmc, mrq_stop);
+		return IRQ_HANDLED;
 	}
+	dev_dbg(mmc_dev(mmc), "no request for manual stop\n");
 
-	if (host->cfg->mask_data0) {
-		rval = mmc_readl(host, REG_CLKCR);
-		mmc_writel(host, REG_CLKCR, rval & ~SDXC_MASK_DATA0);
-	}
+	if (mrq_retry) {
+		bool wait_dma = false;
+		u32 imask = 0;
+		u32 cmd_val = 0;
+		struct mmc_command *cmd = NULL;
+		struct mmc_data *data = mrq_retry->data;
+		cmd = (mrq_retry->sbc && !host->sunxi_mmc_opacmd23) ? mrq_retry->sbc : mrq_retry->cmd;
 
-	return 0;
-}
+		dev_info(mmc_dev(host->mmc), "retry:start\n");
 
-static int sunxi_mmc_calibrate(struct sunxi_mmc_host *host, int reg_off)
-{
-	if (!host->cfg->can_calibrate)
-		return 0;
+		/***Recover device state and stop host state machine****/
+		if (data) {
+			dev_err(mmc_dev(mmc), "retry:stop\n");
+			/***reset host***/
+			spin_lock_irqsave(&host->lock, iflags);
+			sunxi_mmc_regs_save(host);
+			spin_unlock_irqrestore(&host->lock, iflags);
+			/**if gating/reset protect itself,so no lock use host->lock**/
+			sunxi_mmc_bus_clk_en(host, 0);
+			sunxi_mmc_bus_clk_en(host, 1);
+			sunxi_mmc_regs_restore(host);
+			dev_dbg(mmc_dev(host->mmc),
+			"no device retry:host reset and reg recover ok\n");
+
+			/***use sunxi_mmc_oclk_en  to update clk***/
+			rval = host->sunxi_mmc_oclk_en(host, 1);
+			dev_err(mmc_dev(host->mmc),
+			"retry:stop recover\n");
+			if (rval) {
+				dev_err(mmc_dev(mmc), "retry:update clk failed %s %d\n",
+					__func__, __LINE__);
+			}
 
-	/*
-	 * FIXME:
-	 * This is not clear how the calibration is supposed to work
-	 * yet. The best rate have been obtained by simply setting the
-	 * delay to 0, as Allwinner does in its BSP.
-	 *
-	 * The only mode that doesn't have such a delay is HS400, that
-	 * is in itself a TODO.
-	 */
-	writel(SDXC_CAL_DL_SW_EN, host->reg_base + reg_off);
+			sunxi_mmc_send_manual_stop(host, mrq_retry);
+		}
 
-	return 0;
-}
+		/*****If device not exit,no need to retry*****/
+		/**to do:how to deal with data3 detect better here**/
+		if (!mmc_gpio_get_cd(mmc)) {
+			dev_err(mmc_dev(mmc), "retry:no device\n");
+			/***reset host***/
+			spin_lock_irqsave(&host->lock, iflags);
+			sunxi_mmc_regs_save(host);
+			spin_unlock_irqrestore(&host->lock, iflags);
+			/**if gating/reset protect itself,so no lock use host->lock**/
+			sunxi_mmc_bus_clk_en(host, 0);
+			sunxi_mmc_bus_clk_en(host, 1);
+			sunxi_mmc_regs_restore(host);
+			dev_dbg(mmc_dev(host->mmc),
+			"no device retry:host reset and reg recover ok\n");
+
+			/***use sunxi_mmc_oclk_en  to update clk***/
+			rval = host->sunxi_mmc_oclk_en(host, 1);
+			dev_err(mmc_dev(host->mmc),
+			"no device retry:recover ck\n");
+			if (rval) {
+				dev_err(mmc_dev(mmc), "retry:update clk failed %s %d\n",
+					__func__, __LINE__);
+			}
 
-static int sunxi_mmc_clk_set_phase(struct sunxi_mmc_host *host,
-				   struct mmc_ios *ios, u32 rate)
-{
-	int index;
+			goto retry_giveup;
+		}
 
-	/* clk controller delays not used under new timings mode */
-	if (host->use_new_timings)
-		return 0;
+		/***wait device busy over***/
+		rval = sunxi_mmc_check_r1_ready(mmc, 1000);
+		if (rval) {
+			dev_err(mmc_dev(host->mmc), "retry:busy timeout\n");
+			//goto retry_giveup;
+		}
 
-	/* some old controllers don't support delays */
-	if (!host->cfg->clk_delays)
-		return 0;
+		/***reset host***/
+		spin_lock_irqsave(&host->lock, iflags);
+		sunxi_mmc_regs_save(host);
+		spin_unlock_irqrestore(&host->lock, iflags);
+		/**if gating/reset protect itself,so no lock use host->lock**/
+		sunxi_mmc_bus_clk_en(host, 0);
+		sunxi_mmc_bus_clk_en(host, 1);
+		sunxi_mmc_regs_restore(host);
+		dev_dbg(mmc_dev(host->mmc),
+			"retry:host reset and reg recover ok\n");
+
+		/***set phase/delay not lock***/
+		if (host->sunxi_mmc_judge_retry) {
+			rval =
+			    host->sunxi_mmc_judge_retry(host, NULL,
+							host->retry_cnt,
+							host->errno_retry,
+							NULL);
+			if (rval) {
+				dev_err(mmc_dev(mmc),
+					"retry:set phase failed or over retry times\n");
+				goto reupdate_clk;
+			}
+		} else if (host->retry_cnt > SUNXI_DEF_RETRY_TIMES) {
+			dev_err(mmc_dev(mmc),
+				"retry:over default retry times\n");
+			goto reupdate_clk;
+		}
 
-	/* determine delays */
-	if (rate <= 400000) {
-		index = SDXC_CLK_400K;
-	} else if (rate <= 25000000) {
-		index = SDXC_CLK_25M;
-	} else if (rate <= 52000000) {
-		if (ios->timing != MMC_TIMING_UHS_DDR50 &&
-		    ios->timing != MMC_TIMING_MMC_DDR52) {
-			index = SDXC_CLK_50M;
-		} else if (ios->bus_width == MMC_BUS_WIDTH_8) {
-			index = SDXC_CLK_50M_DDR_8BIT;
-		} else {
-			index = SDXC_CLK_50M_DDR;
+		/***use sunxi_mmc_oclk_en  to update clk***/
+		rval = host->sunxi_mmc_oclk_en(host, 1);
+		if (rval) {
+			dev_err(mmc_dev(mmc), "retry:update clk failed %s %d\n",
+				__func__, __LINE__);
+			goto retry_giveup;
 		}
-	} else {
-		dev_dbg(mmc_dev(host->mmc), "Invalid clock... returning\n");
-		return -EINVAL;
+
+		if (data) {
+			rval = sunxi_mmc_map_dma(host, data, COOKIE_MAPPED);
+			if (rval < 0) {
+				dev_err(mmc_dev(mmc), "map DMA failed\n");
+				goto retry_giveup;
+			}
+		}
+
+		sunxi_mmc_parse_cmd(mmc, cmd, &cmd_val, &imask, &wait_dma);
+		if (data)
+			sunxi_mmc_set_dat(host, mmc, data);
+		spin_lock_irqsave(&host->lock, iflags);
+		host->mrq = mrq_retry;
+		host->mrq_retry = NULL;
+		host->wait_dma = wait_dma;
+		host->retry_cnt++;
+		host->errno_retry = 0;
+		sunxi_mmc_exe_cmd(host, cmd, cmd_val, imask);
+		dev_info(mmc_dev(host->mmc), "*****retry:re-send cmd*****\n");
+/******************************************************/
+		smp_wmb();
+		spin_unlock_irqrestore(&host->lock, iflags);
+		return IRQ_HANDLED;
+reupdate_clk:
+		/**update clk for other cmd from upper layer to be sent****/
+		rval = host->sunxi_mmc_oclk_en(host, 1);
+		if (rval)
+			dev_err(mmc_dev(mmc), "retry:update clk failed %s %d\n",
+				__func__, __LINE__);
+retry_giveup:
+		dev_err(mmc_dev(host->mmc), "retry:give up\n");
+		spin_lock_irqsave(&host->lock, iflags);
+		host->mrq_retry = NULL;
+		host->mrq = NULL;
+		host->int_sum = 0;
+		host->wait_dma = false;
+		host->errno_retry = 0;
+		sunxi_mmc_clean_retry_cnt(host);
+		/**clear retry count if retry giveup*/
+		cmd->error = -ETIMEDOUT;
+		if (mrq_retry->sbc)
+			mrq_retry->cmd->error = -ETIMEDOUT;
+		if (data)
+			data->error = -ETIMEDOUT;
+		if (mrq_retry->stop)
+			mrq_retry->stop->error = -ETIMEDOUT;
+/******************************************************/
+		smp_wmb();
+		spin_unlock_irqrestore(&host->lock, iflags);
+		sunxi_mmc_request_done(host->mmc, mrq_retry);
+		return IRQ_HANDLED;
+
 	}
+	dev_dbg(mmc_dev(host->mmc), "no request for data retry\n");
 
-	clk_set_phase(host->clk_sample, host->cfg->clk_delays[index].sample);
-	clk_set_phase(host->clk_output, host->cfg->clk_delays[index].output);
+	dev_err(mmc_dev(host->mmc), "no request in bottom halfhalf\n");
 
-	return 0;
+	return IRQ_HANDLED;
 }
 
-static int sunxi_mmc_clk_set_rate(struct sunxi_mmc_host *host,
-				  struct mmc_ios *ios)
+s32 sunxi_mmc_update_clk(struct sunxi_mmc_host *host)
 {
-	struct mmc_host *mmc = host->mmc;
-	long rate;
-	u32 rval, clock = ios->clock, div = 1;
-	int ret;
-
-	ret = sunxi_mmc_oclk_onoff(host, 0);
-	if (ret)
-		return ret;
-
-	/* Our clock is gated now */
-	mmc->actual_clock = 0;
+	u32 rval;
+	/*1000ms timeout*/
+	unsigned long expire = jiffies + msecs_to_jiffies(1000);
+	s32 ret = 0;
 
-	if (!ios->clock)
-		return 0;
+	/* mask data0 when update clock */
+	mmc_writel(host, REG_CLKCR,
+		   mmc_readl(host, REG_CLKCR) | SDXC_MASK_DATA0);
 
+	rval = SDXC_START | SDXC_UPCLK_ONLY | SDXC_WAIT_PRE_OVER;
 	/*
-	 * Under the old timing mode, 8 bit DDR requires the module
-	 * clock to be double the card clock. Under the new timing
-	 * mode, all DDR modes require a doubled module clock.
-	 *
-	 * We currently only support the standard MMC DDR52 mode.
-	 * This block should be updated once support for other DDR
-	 * modes is added.
+	 *  if (smc_host->voltage_switching)
+	 * rval |= SDXC_VolSwitch;
 	 */
-	if (ios->timing == MMC_TIMING_MMC_DDR52 &&
-	    (host->use_new_timings ||
-	     ios->bus_width == MMC_BUS_WIDTH_8)) {
-		div = 2;
-		clock <<= 1;
+	mmc_writel(host, REG_CMDR, rval);
+
+	do {
+		rval = mmc_readl(host, REG_CMDR);
+	} while (time_before(jiffies, expire) && (rval & SDXC_START));
+
+	if (rval & SDXC_START) {
+		dev_err(mmc_dev(host->mmc),
+			"update clock timeout, fatal error!!!\n");
+		ret = -EIO;
 	}
 
-	if (host->use_new_timings && host->cfg->ccu_has_timings_switch) {
-		ret = sunxi_ccu_set_mmc_timing_mode(host->clk_mmc, true);
-		if (ret) {
-			dev_err(mmc_dev(mmc),
-				"error setting new timing mode\n");
-			return ret;
+	/* release data0 after update clock */
+	mmc_writel(host, REG_CLKCR,
+		   mmc_readl(host, REG_CLKCR) & (~SDXC_MASK_DATA0));
+
+	return ret;
+}
+
+static int sunxi_mmc_bus_clk_en(struct sunxi_mmc_host *host, int enable)
+{
+	int rval = 0;
+	struct mmc_host *mmc = host->mmc;
+
+	if (enable) {
+		if (!IS_ERR(host->clk_rst)) {
+			rval = reset_control_deassert(host->clk_rst);
+			if (rval) {
+				dev_err(mmc_dev(mmc), "reset err %d\n", rval);
+				return -1;
+			}
 		}
-	}
 
-	rate = clk_round_rate(host->clk_mmc, clock);
-	if (rate < 0) {
-		dev_err(mmc_dev(mmc), "error rounding clk to %d: %ld\n",
-			clock, rate);
-		return rate;
+		rval = clk_prepare_enable(host->clk_ahb);
+		if (rval) {
+			dev_err(mmc_dev(mmc), "Enable ahb clk err %d\n", rval);
+			return -1;
+		}
+		rval = clk_prepare_enable(host->clk_mmc);
+		if (rval) {
+			dev_err(mmc_dev(mmc), "Enable mmc clk err %d\n", rval);
+			return -1;
+		}
+	} else {
+		clk_disable_unprepare(host->clk_mmc);
+		clk_disable_unprepare(host->clk_ahb);
+		if (!IS_ERR(host->clk_rst))
+			reset_control_assert(host->clk_rst);
 	}
-	dev_dbg(mmc_dev(mmc), "setting clk to %d, rounded %ld\n",
-		clock, rate);
+	return 0;
+}
 
-	/* setting clock rate */
-	ret = clk_set_rate(host->clk_mmc, rate);
-	if (ret) {
-		dev_err(mmc_dev(mmc), "error setting clk to %ld: %d\n",
-			rate, ret);
-		return ret;
-	}
+static void sunxi_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	u32 rval;
+	static const char * const bus_mode[] = { "", "OD", "PP" };
+	static const char * const pwr_mode[] = { "OFF", "UP", "ON", "udef" };
+	static const char * const timing[] = {
+		"LEGACY(SDR12)", "MMC-HS(SDR20)", "SD-HS(SDR25)", "UHS-SDR12",
+		"UHS-SDR25",
+		"UHS-SDR50", "UHS-SDR104", "UHS-DDR50", "MMC-DDR52",
+		    "MMC-HS200", "MMC-HS400"
+	};
+	static const char * const drv_type[] = { "B", "A", "C", "D" };
+
+	WARN_ON(ios->bus_mode >= ARRAY_SIZE(bus_mode));
+	WARN_ON(ios->power_mode >= ARRAY_SIZE(pwr_mode));
+	WARN_ON(ios->timing >= ARRAY_SIZE(timing));
+	dev_info(mmc_dev(mmc),
+		 "sdc set ios:clk %dHz bm %s pm %s vdd %d width %d timing %s dt %s\n",
+		 ios->clock, bus_mode[ios->bus_mode],
+		 pwr_mode[ios->power_mode], ios->vdd,
+		 1 << ios->bus_width, timing[ios->timing],
+		 drv_type[ios->drv_type]);
+
+	/* Set the power state */
+	switch (ios->power_mode) {
+	case MMC_POWER_ON:
+		break;
 
-	/* set internal divider */
-	rval = mmc_readl(host, REG_CLKCR);
-	rval &= ~0xff;
-	rval |= div - 1;
-	mmc_writel(host, REG_CLKCR, rval);
+	case MMC_POWER_UP:
+		if (host->power_on)
+			break;
 
-	/* update card clock rate to account for internal divider */
-	rate /= div;
+		if (!IS_ERR(mmc->supply.vmmc)) {
+			rval =
+			    sunxi_mmc_regulator_set_ocr(mmc, mmc->supply.vmmc,
+						  ios->vdd);
+			if (rval)
+				return;
+		}
+		if (!IS_ERR(mmc->supply.vqmmc)) {
+			rval = regulator_enable(mmc->supply.vqmmc);
+			if (rval < 0) {
+				dev_err(mmc_dev(mmc),
+					"failed to enable vqmmc regulator\n");
+				return;
+			}
+		}
 
-	/*
-	 * Configure the controller to use the new timing mode if needed.
-	 * On controllers that only support the new timing mode, such as
-	 * the eMMC controller on the A64, this register does not exist,
-	 * and any writes to it are ignored.
-	 */
-	if (host->use_new_timings) {
-		/* Don't touch the delay bits */
-		rval = mmc_readl(host, REG_SD_NTSR);
-		rval |= SDXC_2X_TIMING_MODE;
-		mmc_writel(host, REG_SD_NTSR, rval);
-	}
+		if (!IS_ERR(host->supply.vqmmc33sw)) {
+			rval = regulator_enable(host->supply.vqmmc33sw);
+			if (rval < 0) {
+				dev_err(mmc_dev(mmc),
+					"failed to enable vqmmc33sw regulator\n");
+				return;
+			}
+		}
+		if (!IS_ERR(host->supply.vqmmc18sw)) {
+			rval = regulator_enable(host->supply.vqmmc18sw);
+			if (rval < 0) {
+				dev_err(mmc_dev(mmc),
+					"failed to enable vqmmc18sw regulator\n");
+				return;
+			}
+		}
 
-	/* sunxi_mmc_clk_set_phase expects the actual card clock rate */
-	ret = sunxi_mmc_clk_set_phase(host, ios, rate);
-	if (ret)
-		return ret;
+		if (gpio_is_valid(host->card_pwr_gpio)) {
+			if (!IS_ERR(host->pins_sleep)) {
+				rval = pinctrl_select_state(host->pinctrl,
+							 host->pins_sleep);
+				if (rval) {
+					dev_err(mmc_dev(mmc),
+						"could not set sleep pins\n");
+					return;
+				}
+			}
+			gpio_set_value(host->card_pwr_gpio,
+				       (host->
+					ctl_spec_cap &
+					CARD_PWR_GPIO_HIGH_ACTIVE) ? 0 : 1);
+			msleep(host->time_pwroff_ms);
+			gpio_set_value(host->card_pwr_gpio,
+				       (host->
+					ctl_spec_cap &
+					CARD_PWR_GPIO_HIGH_ACTIVE) ? 1 : 0);
+			/*delay to ensure voltage stability*/
+			msleep(1);
+		}
 
-	ret = sunxi_mmc_calibrate(host, SDXC_REG_SAMP_DL_REG);
-	if (ret)
-		return ret;
+		if (!IS_ERR(host->pins_default)) {
+			rval =
+			    pinctrl_select_state(host->pinctrl,
+						 host->pins_default);
+			if (rval) {
+				dev_err(mmc_dev(mmc),
+					"could not set default pins\n");
+				return;
+			}
+		}
 
-	/*
-	 * FIXME:
-	 *
-	 * In HS400 we'll also need to calibrate the data strobe
-	 * signal. This should only happen on the MMC2 controller (at
-	 * least on the A64).
-	 */
+		if (!IS_ERR(host->clk_rst)) {
+			rval = reset_control_deassert(host->clk_rst);
+			if (rval) {
+				dev_err(mmc_dev(mmc), "reset err %d\n", rval);
+				return;
+			}
+		}
 
-	ret = sunxi_mmc_oclk_onoff(host, 1);
-	if (ret)
-		return ret;
+		rval = clk_prepare_enable(host->clk_ahb);
+		if (rval) {
+			dev_err(mmc_dev(mmc), "Enable ahb clk err %d\n", rval);
+			return;
+		}
+		rval = clk_prepare_enable(host->clk_mmc);
+		if (rval) {
+			dev_err(mmc_dev(mmc), "Enable mmc clk err %d\n", rval);
+			return;
+		}
 
-	/* And we just enabled our clock back */
-	mmc->actual_clock = rate;
+		host->ferror = sunxi_mmc_init_host(mmc);
+		if (host->ferror)
+			return;
 
-	return 0;
-}
+		enable_irq(host->irq);
 
-static void sunxi_mmc_set_bus_width(struct sunxi_mmc_host *host,
-				   unsigned char width)
-{
-	switch (width) {
-	case MMC_BUS_WIDTH_1:
-		mmc_writel(host, REG_WIDTH, SDXC_WIDTH1);
-		break;
-	case MMC_BUS_WIDTH_4:
-		mmc_writel(host, REG_WIDTH, SDXC_WIDTH4);
+		host->power_on = 1;
+		dev_dbg(mmc_dev(mmc), "power on!\n");
 		break;
-	case MMC_BUS_WIDTH_8:
-		mmc_writel(host, REG_WIDTH, SDXC_WIDTH8);
-		break;
-	}
-}
 
-static void sunxi_mmc_set_clk(struct sunxi_mmc_host *host, struct mmc_ios *ios)
-{
-	u32 rval;
+	case MMC_POWER_OFF:
+		if (!host->power_on || host->dat3_imask)
+			break;
 
-	/* set ddr mode */
-	rval = mmc_readl(host, REG_GCTRL);
-	if (ios->timing == MMC_TIMING_UHS_DDR50 ||
-	    ios->timing == MMC_TIMING_MMC_DDR52)
-		rval |= SDXC_DDR_MODE;
-	else
-		rval &= ~SDXC_DDR_MODE;
-	mmc_writel(host, REG_GCTRL, rval);
+		disable_irq(host->irq);
+		sunxi_mmc_reset_host(host);
 
-	host->ferror = sunxi_mmc_clk_set_rate(host, ios);
-	/* Android code had a usleep_range(50000, 55000); here */
-}
+		clk_disable_unprepare(host->clk_mmc);
+		clk_disable_unprepare(host->clk_ahb);
 
-static void sunxi_mmc_card_power(struct sunxi_mmc_host *host,
-				 struct mmc_ios *ios)
-{
-	struct mmc_host *mmc = host->mmc;
+		if (!IS_ERR(host->clk_rst))
+			reset_control_assert(host->clk_rst);
 
-	switch (ios->power_mode) {
-	case MMC_POWER_UP:
-		dev_dbg(mmc_dev(mmc), "Powering card up\n");
+		if (!IS_ERR(host->pins_sleep)) {
+			rval =
+			    pinctrl_select_state(host->pinctrl,
+						 host->pins_sleep);
+			if (rval) {
+				dev_err(mmc_dev(mmc),
+					"could not set sleep pins\n");
+				return;
+			}
+		}
 
-		if (!IS_ERR(mmc->supply.vmmc)) {
-			host->ferror = mmc_regulator_set_ocr(mmc,
-							     mmc->supply.vmmc,
-							     ios->vdd);
-			if (host->ferror)
+		if (gpio_is_valid(host->card_pwr_gpio)) {
+			gpio_set_value(host->card_pwr_gpio,
+				       (host->
+					ctl_spec_cap &
+					CARD_PWR_GPIO_HIGH_ACTIVE) ? 0 : 1);
+			msleep(host->time_pwroff_ms);
+		}
+
+		if (!IS_ERR(host->pins_uart_jtag)) {
+			rval =
+			    pinctrl_select_state(host->pinctrl,
+						 host->pins_uart_jtag);
+			if (rval) {
+				dev_err(mmc_dev(mmc),
+					"could not set uart_jtag pins\n");
 				return;
+			}
 		}
 
-		if (!IS_ERR(mmc->supply.vqmmc)) {
-			host->ferror = regulator_enable(mmc->supply.vqmmc);
-			if (host->ferror) {
+
+		if (!IS_ERR(host->supply.vqmmc18sw)) {
+			rval = regulator_disable(host->supply.vqmmc18sw);
+			if (rval) {
 				dev_err(mmc_dev(mmc),
-					"failed to enable vqmmc\n");
+					"Could not disable vqmmc18sw\n");
 				return;
 			}
-			host->vqmmc_enabled = true;
 		}
-		break;
 
-	case MMC_POWER_OFF:
-		dev_dbg(mmc_dev(mmc), "Powering card off\n");
+		/*SD PMU control*/
+		if (!IS_ERR(host->supply.vqmmc33sw)) {
+			rval = regulator_disable(host->supply.vqmmc33sw);
+			if (rval) {
+				dev_err(mmc_dev(mmc),
+					"Could not disable vqmmc33sw\n");
+				return;
+			}
+		}
 
-		if (!IS_ERR(mmc->supply.vmmc))
-			mmc_regulator_set_ocr(mmc, mmc->supply.vmmc, 0);
+		if (!IS_ERR(mmc->supply.vqmmc)) {
+			rval = regulator_disable(mmc->supply.vqmmc);
+			if (rval) {
+				dev_err(mmc_dev(mmc),
+					"Could not disable vqmmc\n");
+				return;
+			}
+		}
 
-		if (!IS_ERR(mmc->supply.vqmmc) && host->vqmmc_enabled)
-			regulator_disable(mmc->supply.vqmmc);
+		if (!IS_ERR(mmc->supply.vmmc)) {
+			rval = sunxi_mmc_regulator_set_ocr(mmc, mmc->supply.vmmc, 0);
+			if (rval)
+				return;
+		}
 
-		host->vqmmc_enabled = false;
+		host->power_on = 0;
+		dev_dbg(mmc_dev(mmc), "power off!\n");
 		break;
+	}
 
-	default:
-		dev_dbg(mmc_dev(mmc), "Ignoring unknown card power state\n");
+	/* set bus width */
+	switch (ios->bus_width) {
+	case MMC_BUS_WIDTH_1:
+		mmc_writel(host, REG_WIDTH, SDXC_WIDTH1);
+		break;
+	case MMC_BUS_WIDTH_4:
+		mmc_writel(host, REG_WIDTH, SDXC_WIDTH4);
+		break;
+	case MMC_BUS_WIDTH_8:
+		mmc_writel(host, REG_WIDTH, SDXC_WIDTH8);
 		break;
 	}
-}
-
-static void sunxi_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
-{
-	struct sunxi_mmc_host *host = mmc_priv(mmc);
-
-	sunxi_mmc_card_power(host, ios);
-	sunxi_mmc_set_bus_width(host, ios->bus_width);
-	sunxi_mmc_set_clk(host, ios);
-}
 
-static int sunxi_mmc_volt_switch(struct mmc_host *mmc, struct mmc_ios *ios)
-{
-	/* vqmmc regulator is available */
-	if (!IS_ERR(mmc->supply.vqmmc))
-		return mmc_regulator_set_vqmmc(mmc, ios);
+	dev_dbg(mmc_dev(host->mmc), "REG_WIDTH: 0x%08x\n",
+		mmc_readl(host, REG_WIDTH));
 
-	/* no vqmmc regulator, assume fixed regulator at 3/3.3V */
-	if (mmc->ios.signal_voltage == MMC_SIGNAL_VOLTAGE_330)
-		return 0;
+	/* set ddr mode */
+	if (host->power_on
+		&& ios->clock) {
+		/**If we set ddr mode,we should disable mclk first**/
+	clk_disable_unprepare(host->clk_mmc);
+	rval = mmc_readl(host, REG_GCTRL);
+	if (sunxi_mmc_ddr_timing(ios->timing))
+		rval |= SDXC_DDR_MODE;
+	else
+		rval &= ~SDXC_DDR_MODE;
+	mmc_writel(host, REG_GCTRL, rval);
+	dev_dbg(mmc_dev(host->mmc), "REG_GCTRL: 0x%08x\n",
+			mmc_readl(host, REG_GCTRL));
+		rval = clk_prepare_enable(host->clk_mmc);
+		if (rval) {
+			dev_err(mmc_dev(mmc), "Enable mmc clk err %d\n", rval);
+			return;
+		}
 
-	return -EINVAL;
+	}
+	/* set up clock */
+	if (ios->power_mode && host->sunxi_mmc_clk_set_rate) {
+		host->ferror = host->sunxi_mmc_clk_set_rate(host, ios);
+		/* Android code had a usleep_range(50000, 55000); here */
+	}
 }
 
 static void sunxi_mmc_enable_sdio_irq(struct mmc_host *mmc, int enable)
@@ -968,9 +1576,6 @@ static void sunxi_mmc_enable_sdio_irq(struct mmc_host *mmc, int enable)
 	unsigned long flags;
 	u32 imask;
 
-	if (enable)
-		pm_runtime_get_noresume(host->dev);
-
 	spin_lock_irqsave(&host->lock, flags);
 
 	imask = mmc_readl(host, REG_IMASK);
@@ -983,9 +1588,6 @@ static void sunxi_mmc_enable_sdio_irq(struct mmc_host *mmc, int enable)
 	}
 	mmc_writel(host, REG_IMASK, imask);
 	spin_unlock_irqrestore(&host->lock, flags);
-
-	if (!enable)
-		pm_runtime_put_noidle(host->mmc->parent);
 }
 
 static void sunxi_mmc_hw_reset(struct mmc_host *mmc)
@@ -997,51 +1599,208 @@ static void sunxi_mmc_hw_reset(struct mmc_host *mmc)
 	udelay(300);
 }
 
-static void sunxi_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
+static int sunxi_mmc_signal_voltage_switch(struct mmc_host *mmc,
+					   struct mmc_ios *ios)
 {
+	int ret = 0;
+	struct regulator *vqmmc = mmc->supply.vqmmc;
+	struct device_node *np = NULL;
+	bool disable_vol_switch = false;
+	bool vol_switch_without_pmu = false;
 	struct sunxi_mmc_host *host = mmc_priv(mmc);
-	struct mmc_command *cmd = mrq->cmd;
-	struct mmc_data *data = mrq->data;
-	unsigned long iflags;
-	u32 imask = SDXC_INTERRUPT_ERROR_BIT;
-	u32 cmd_val = SDXC_START | (cmd->opcode & 0x3f);
-	bool wait_dma = host->wait_dma;
-	int ret;
 
-	/* Check for set_ios errors (should never happen) */
-	if (host->ferror) {
-		mrq->cmd->error = host->ferror;
-		mmc_request_done(mmc, mrq);
-		return;
+	if (!mmc->parent || !mmc->parent->of_node) {
+		dev_err(mmc_dev(mmc),
+			"no dts to parse signal switch fun,use default\n");
+		return 0;
 	}
 
-	if (data) {
-		ret = sunxi_mmc_map_dma(host, data);
-		if (ret < 0) {
-			dev_err(mmc_dev(mmc), "map DMA failed\n");
-			cmd->error = ret;
-			data->error = ret;
-			mmc_request_done(mmc, mrq);
-			return;
+	np = mmc->parent->of_node;
+	disable_vol_switch =
+	    of_property_read_bool(np, "sunxi-dis-signal-vol-sw");
+
+#if IS_ENABLED(CONFIG_REGULATOR)
+	vol_switch_without_pmu = true;
+#else
+	vol_switch_without_pmu =
+	    of_property_read_bool(np, "sunxi-signal-vol-sw-without-pmu");
+#endif
+	/*For some emmc,io voltage will be fixed at 1.8v or other voltage,
+	 *so we can not switch io voltage
+	 */
+	 /*Because mmc core will change the io voltage to 3.3v when power up,
+	 *so will must disable voltage switch
+	 */
+
+	if (disable_vol_switch || (!vol_switch_without_pmu)) {
+		dev_dbg(mmc_dev(mmc), "disable signal voltage-switch\n");
+		return 0;
+	}
+
+	switch (ios->signal_voltage) {
+	case MMC_SIGNAL_VOLTAGE_330:
+		if (!IS_ERR(vqmmc)) {
+			ret = regulator_set_voltage(vqmmc, 3300000, 3300000);
+			if (ret) {
+				dev_err(mmc_dev(mmc),
+					"Switching to 3.3V signalling voltage failed\n");
+				return -EIO;
+			} else
+				dev_info(mmc_dev(mmc),
+					"Switching to 3.3V signalling voltage ok\n");
+		} else {
+			dev_info(mmc_dev(mmc),
+				 "no vqmmc,Check if there is regulator\n");
+		}
+
+		if (!IS_ERR(host->pins_default)) {
+			ret = pinctrl_select_state(host->pinctrl, host->pins_default);
+			if (ret)
+				dev_warn(mmc_dev(mmc), "Cannot select 3.3v pio mode\n");
+		}
+
+		return 0;
+	case MMC_SIGNAL_VOLTAGE_180:
+		if (!IS_ERR(vqmmc)) {
+			ret = regulator_set_voltage(vqmmc, 1800000, 1800000);
+			if (ret) {
+				dev_err(mmc_dev(mmc),
+					"Switching to 1.8V signalling voltage failed\n");
+				return -EIO;
+			} else
+				dev_info(mmc_dev(mmc),
+					"Switching to 1.8V signalling voltage ok\n");
+		} else {
+			dev_info(mmc_dev(mmc),
+				 "no vqmmc,Check if there is regulator\n");
+		}
+
+		if (!IS_ERR(host->pins_bias_1v8)) {
+			ret = pinctrl_select_state(host->pinctrl, host->pins_bias_1v8);
+			if (ret)
+				dev_warn(mmc_dev(mmc), "Cannot select 1.8v pio mode\n");
 		}
+
+		return 0;
+	case MMC_SIGNAL_VOLTAGE_120:
+		if (!IS_ERR(vqmmc)) {
+			ret = regulator_set_voltage(vqmmc, 1200000, 1200000);
+			if (ret) {
+				dev_err(mmc_dev(mmc),
+					"Switching to 1.2V signalling voltage failed\n");
+				return -EIO;
+			}
+		} else {
+			dev_info(mmc_dev(mmc),
+				 "no vqmmc,Check if there is regulator\n");
+			return 0;
+		}
+
+		dev_err(mmc_dev(mmc), "*************Cannot support 1.2v now*************\n");
+
+		return 0;
+	default:
+		/* No signal voltage switch required */
+		dev_err(mmc_dev(mmc),
+			"unknown signal voltage switch request %x\n",
+			ios->signal_voltage);
+		return -1;
 	}
+}
+
+static int __sunxi_mmc_card_busy(struct mmc_host *mmc)
+{
+	u32 data_down;
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	unsigned long expire = jiffies + msecs_to_jiffies(10);
+	u32 rval;
+	u32 ret;
+
+	if (host->voltage_switching == 0) {
+		ret = mmc_readl(host, REG_STAS) & SDXC_CARD_DATA_BUSY;
+	} else {
+		/*only cmd11 switch voltage process come here*/
+		data_down = mmc_readl(host, REG_STAS);
+		/* check whether data[3:0]*/
+		if ((data_down & SDXC_CARD_PRESENT)) {
+			/*wait switch voltage done*/
+			do {
+				rval = mmc_readl(host, REG_RINTR);
+				dev_dbg(mmc_dev(mmc), "now is present\n");
+			} while (time_before(jiffies, expire) && ((rval & SDXC_SWITCH_DDONE_BIT) != (SDXC_SWITCH_DDONE_BIT)));
+
+			host->voltage_switching = 0;
+			mmc_writel(host, REG_RINTR, SDXC_SWITCH_DDONE_BIT);
+			ret = ((rval & SDXC_SWITCH_DDONE_BIT) == SDXC_SWITCH_DDONE_BIT) ? 0 : 1;
+		} else {
+			dev_dbg(mmc_dev(mmc), "card is not presenting\n");
+			ret = (!(data_down & SDXC_CARD_PRESENT));
+		}
+	}
+
+	return ret;
+}
+
+static int sunxi_mmc_card_busy(struct mmc_host *mmc)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	if (!host->sunxi_mmc_dat0_busy) {
+		/*host control support busy detect*/
+		return __sunxi_mmc_card_busy(mmc);
+	} else {
+		/*host control donnt support busy detect;
+		 *used on v4p10x version driver
+		 * */
+		return host->sunxi_mmc_dat0_busy(host);
+	}
+}
+
+static void sunxi_mmc_parse_cmd(struct mmc_host *mmc, struct mmc_command *cmd,
+				u32 *cval, u32 *im, bool *wdma)
+{
+	bool wait_dma = false;
+	u32 imask = SDXC_INTERRUPT_ERROR_BIT;
+	u32 cmd_val = SDXC_START | (cmd->opcode & 0x3f);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
 
 	if (cmd->opcode == MMC_GO_IDLE_STATE) {
 		cmd_val |= SDXC_SEND_INIT_SEQUENCE;
 		imask |= SDXC_COMMAND_DONE;
 	}
 
+	if (cmd->opcode == SD_SWITCH_VOLTAGE) {
+		cmd_val |= SDXC_VOLTAGE_SWITCH;
+		imask |= SDXC_VOLTAGE_CHANGE_DONE;
+		host->voltage_switching = 1;
+		/* switch controller to high power mode */
+		if (host->sunxi_mmc_oclk_en) {
+			host->sunxi_mmc_oclk_en(host, 1);
+		} else {
+			/*if the definition of sunxi_mmc_oclk_en is missing,
+			 *cat not execute cmd11-process,because, it should switch controller to high power mode
+			 * before cmd11-process.
+			 * */
+			dev_err(mmc_dev(mmc), "the definition of sunxi_mmc_oclk_en is missing\n");
+		}
+	}
+
 	if (cmd->flags & MMC_RSP_PRESENT) {
-		cmd_val |= SDXC_RESP_EXPIRE;
+		cmd_val |= SDXC_RESP_EXPECT;
 		if (cmd->flags & MMC_RSP_136)
 			cmd_val |= SDXC_LONG_RESPONSE;
 		if (cmd->flags & MMC_RSP_CRC)
 			cmd_val |= SDXC_CHECK_RESPONSE_CRC;
 
 		if ((cmd->flags & MMC_CMD_MASK) == MMC_CMD_ADTC) {
-			cmd_val |= SDXC_DATA_EXPIRE | SDXC_WAIT_PRE_OVER;
+			cmd_val |= SDXC_DATA_EXPECT | SDXC_WAIT_PRE_OVER;
+			if (cmd->data->flags & MMC_DATA_STREAM) {
+				imask |= SDXC_AUTO_COMMAND_DONE;
+				cmd_val |= SDXC_SEQUENCE_MODE |
+				    SDXC_SEND_AUTO_STOP;
+			}
 
-			if (cmd->data->stop) {
+			if ((cmd->mrq->sbc == NULL) && cmd->data->stop) {
 				imask |= SDXC_AUTO_COMMAND_DONE;
 				cmd_val |= SDXC_SEND_AUTO_STOP;
 			} else {
@@ -1050,14 +1809,137 @@ static void sunxi_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 
 			if (cmd->data->flags & MMC_DATA_WRITE)
 				cmd_val |= SDXC_WRITE;
-			else
+			else if (cmd->data->flags & MMC_DATA_READ)
 				wait_dma = true;
+			else
+				dev_err(mmc_dev(mmc),
+					"!!!!!!!Not support cmd->data->flags %x !!!!!!!\n",
+					cmd->data->flags);
 		} else {
 			imask |= SDXC_COMMAND_DONE;
 		}
 	} else {
 		imask |= SDXC_COMMAND_DONE;
 	}
+	*im = imask;
+	*cval = cmd_val;
+	*wdma = wait_dma;
+}
+
+static void sunxi_mmc_set_dat(struct sunxi_mmc_host *host, struct mmc_host *mmc,
+			      struct mmc_data *data)
+{
+	struct mmc_command *sbc = data->mrq->sbc;
+	mmc_writel(host, REG_BLKSZ, data->blksz);
+	mmc_writel(host, REG_BCNTR, data->blksz * data->blocks);
+	if (host->sunxi_mmc_thld_ctl)
+		host->sunxi_mmc_thld_ctl(host, &mmc->ios, data);
+	sunxi_mmc_start_dma(host, data);
+	if (host->sunxi_mmc_opacmd23 && sbc)
+		host->sunxi_mmc_opacmd23(host, true, sbc->arg, NULL);
+}
+
+static void sunxi_mmc_exe_cmd(struct sunxi_mmc_host *host,
+			      struct mmc_command *cmd, u32 cmd_val, u32 imask)
+{
+	u32 rval = 0;
+
+	if (host->dat3_imask) {
+		rval = mmc_readl(host, REG_GCTRL);
+		rval &= ~SDXC_DEBOUNCE_ENABLE_BIT;
+		mmc_writel(host, REG_GCTRL, rval);
+	}
+	mmc_writel(host, REG_IMASK,
+		   host->sdio_imask | host->dat3_imask | imask);
+	mmc_writel(host, REG_CARG, cmd->arg);
+/*********************************************************/
+	wmb();
+	mmc_writel(host, REG_CMDR, cmd_val);
+}
+
+static void sunxi_mmc_post_req(struct mmc_host *mmc, struct mmc_request *mrq,
+				int err)
+{
+	struct mmc_data *data = mrq->data;
+
+	if (data->host_cookie != COOKIE_UNMAPPED) {
+		dma_unmap_sg(mmc_dev(mmc), data->sg, data->sg_len,
+			     sunxi_mmc_get_dma_dir(data));
+		data->host_cookie = COOKIE_UNMAPPED;
+	}
+}
+
+static void sunxi_mmc_pre_req(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	struct mmc_data *data = mrq->data;
+
+	data->host_cookie = COOKIE_UNMAPPED;
+
+	sunxi_mmc_map_dma(host, data, COOKIE_PRE_MAPPED);
+}
+
+static void sunxi_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	struct mmc_command *cmd = (mrq->sbc && !host->sunxi_mmc_opacmd23) ? mrq->sbc : mrq->cmd;
+	struct mmc_data *data = mrq->data;
+	unsigned long iflags;
+	bool wait_dma = false;
+	u32 imask = 0;
+	u32 cmd_val = 0;
+	u32 arg_pwr_off = ((MMC_SWITCH_MODE_WRITE_BYTE << 24) |
+				(EXT_CSD_POWER_OFF_NOTIFICATION << 16) |
+				(EXT_CSD_POWER_ON << 8) |
+				(EXT_CSD_CMD_SET_NORMAL << 0));
+	int crypt_flags = 0;
+	struct scatterlist *sg = NULL;
+	int ret;
+
+	/* Check for set_ios errors (should never happen) */
+	if (host->ferror) {
+		mrq->cmd->error = host->ferror;
+		sunxi_mmc_request_done(mmc, mrq);
+		return;
+	}
+
+	/*avoid mmc switch to power_off_notification:0x01;
+	 *which Can't accept sudden power failure
+	 */
+	if ((cmd->opcode == MMC_SWITCH) && (cmd->arg == arg_pwr_off)) {
+		dev_err(mmc_dev(mmc), "avoid to switch power_off_notification to POWERED_ON(0x01)\n");
+		mrq->cmd->error = -EBADMSG;
+		sunxi_mmc_request_done(mmc, mrq);
+		return ;
+	}
+
+	if (host->sunxi_mmc_on_off_emce) {
+		if (data && data->sg) {
+			sg = data->sg;
+			crypt_flags = sunxi_crypt_flags(sg);
+			if (crypt_flags)
+				sg->offset = sunxi_clear_crypt_flags(sg);
+		}
+	}
+
+	if (data) {
+		ret = sunxi_mmc_map_dma(host, data, COOKIE_MAPPED);
+		if (ret < 0) {
+			dev_err(mmc_dev(mmc), "map DMA failed\n");
+			cmd->error = ret;
+			data->error = ret;
+			sunxi_mmc_request_done(mmc, mrq);
+			return;
+		}
+	}
+
+
+	sunxi_mmc_parse_cmd(mmc, cmd, &cmd_val, &imask, &wait_dma);
+
+/*
+ *if (host->ctl_spec_cap & SUNXI_SC_EN_TIMEOUT_DETECT)
+ *	cancel_delayed_work_sync(&host->sunxi_timerout_work);
+*/
 
 	dev_dbg(mmc_dev(mmc), "cmd %d(%08x) arg %x ie 0x%08x len %d\n",
 		cmd_val & 0x3f, cmd_val, cmd->arg, imask,
@@ -1065,283 +1947,899 @@ static void sunxi_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 
 	spin_lock_irqsave(&host->lock, iflags);
 
-	if (host->mrq || host->manual_stop_mrq) {
+	if (host->mrq || host->manual_stop_mrq
+	    || host->mrq_busy || host->mrq_retry) {
 		spin_unlock_irqrestore(&host->lock, iflags);
 
-		if (data)
+		if (data) {
 			dma_unmap_sg(mmc_dev(mmc), data->sg, data->sg_len,
-				     mmc_get_dma_dir(data));
+				     sunxi_mmc_get_dma_dir(data));
+			data->host_cookie = COOKIE_UNMAPPED;
+		}
 
-		dev_err(mmc_dev(mmc), "request already pending\n");
+		dev_err(mmc_dev(mmc), "request already pending,%px,%px,%px %px\n", host->mrq,
+			host->manual_stop_mrq, host->mrq_busy,
+			host->mrq_retry);
+		dump_stack();
 		mrq->cmd->error = -EBUSY;
-		mmc_request_done(mmc, mrq);
+		sunxi_mmc_request_done(mmc, mrq);
 		return;
 	}
 
-	if (data) {
-		mmc_writel(host, REG_BLKSZ, data->blksz);
-		mmc_writel(host, REG_BCNTR, data->blksz * data->blocks);
-		sunxi_mmc_start_dma(host, data);
+	if (host->sunxi_mmc_updata_pha) {
+		spin_unlock_irqrestore(&host->lock, iflags);
+		host->sunxi_mmc_updata_pha(host, cmd, data);
+		spin_lock_irqsave(&host->lock, iflags);
+	}
+
+	if (host->sunxi_mmc_on_off_emce) {
+		if (data && (mmc->card) && crypt_flags) {
+			dev_dbg(mmc_dev(mmc), "emce is enable\n");
+			host->sunxi_mmc_on_off_emce(host, 1,
+					!mmc_card_blockaddr(mmc->card), 1,
+					data->blksz * data->blocks, 0, 1);
+			host->crypt_flag = crypt_flags;
+		}
+	}
+
+	if (data) {
+		if (host->perf_enable && cmd->data)
+			host->perf.start = ktime_get();
+		spin_unlock_irqrestore(&host->lock, iflags);
+		sunxi_mmc_set_dat(host, mmc, data);
+		spin_lock_irqsave(&host->lock, iflags);
+	}
+
+	host->mrq = mrq;
+	host->wait_dma = wait_dma;
+	if (host->ctl_spec_cap & SUNXI_SC_EN_TIMEOUT_DETECT)
+		queue_delayed_work(system_wq, \
+				&host->sunxi_timerout_work, \
+				SUNXI_TRANS_TIMEOUT);
+	sunxi_mmc_exe_cmd(host, cmd, cmd_val, imask);
+/******************************************************/
+	smp_wmb();
+	spin_unlock_irqrestore(&host->lock, iflags);
+}
+
+/*we use our own mmc_regulator_get_supply because
+ *our platform regulator not support supply name,
+ */
+/*only support regulator ID,
+ *but linux mmc' own mmc_regulator_get_supply use supply name
+ */
+static int sunxi_mmc_regulator_get_supply(struct mmc_host *mmc)
+{
+	struct device *dev = mmc_dev(mmc);
+	int ret = 0;
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	mmc->supply.vmmc = regulator_get_optional(dev, "vmmc");
+	mmc->supply.vqmmc = regulator_get_optional(dev, "vqmmc");
+	host->supply.vdmmc = regulator_get_optional(dev, "vdmmc");
+	host->supply.vdmmc33sw = regulator_get_optional(dev, "vdmmc33sw");
+	host->supply.vdmmc18sw = regulator_get_optional(dev, "vdmmc18sw");
+	host->supply.vqmmc33sw = regulator_get_optional(dev, "vqmmc33sw");
+	host->supply.vqmmc18sw = regulator_get_optional(dev, "vqmmc18sw");
+
+	if (IS_ERR(mmc->supply.vmmc)) {
+		dev_info(dev, "No vmmc regulator found\n");
+	} else {
+		ret = mmc_regulator_get_ocrmask(mmc->supply.vmmc);
+		if (ret > 0)
+			mmc->ocr_avail = ret;
+		else
+			dev_warn(dev, "Failed getting OCR mask: %d\n", ret);
+	}
+
+	if (IS_ERR(mmc->supply.vqmmc))
+		dev_info(dev, "No vqmmc regulator found\n");
+
+	if (IS_ERR(host->supply.vdmmc))
+		dev_info(dev, "No vdmmc regulator found\n");
+
+	if (IS_ERR(host->supply.vdmmc33sw))
+		dev_info(dev, "No vd33sw regulator found\n");
+
+	if (IS_ERR(host->supply.vdmmc18sw))
+		dev_info(dev, "No vd18sw regulator found\n");
+
+	if (IS_ERR(host->supply.vqmmc33sw))
+		dev_info(dev, "No vq33sw regulator found\n");
+
+	if (IS_ERR(host->supply.vqmmc18sw))
+		dev_info(dev, "No vq18sw regulator found\n");
+
+	return 0;
+}
+
+/*Because our regulator driver does not support binding to device tree,
+* so we can not binding it to our dev
+*(for example regulator_get(dev, reg_str[0])
+* or devm_regulator_get(dev, reg_str[0]) )
+*/
+/*so we must release it manully*/
+static void sunxi_mmc_regulator_release_supply(struct mmc_host *mmc)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	if (!IS_ERR(host->supply.vdmmc18sw))
+		regulator_put(host->supply.vdmmc18sw);
+
+	if (!IS_ERR(host->supply.vdmmc33sw))
+		regulator_put(host->supply.vdmmc33sw);
+
+	if (!IS_ERR(host->supply.vdmmc))
+		regulator_put(host->supply.vdmmc);
+
+	if (!IS_ERR(host->supply.vqmmc18sw))
+		regulator_put(host->supply.vqmmc18sw);
+
+	if (!IS_ERR(host->supply.vqmmc33sw))
+		regulator_put(host->supply.vqmmc33sw);
+
+	if (!IS_ERR(mmc->supply.vqmmc))
+		regulator_put(mmc->supply.vqmmc);
+
+	if (!IS_ERR(mmc->supply.vmmc))
+		regulator_put(mmc->supply.vmmc);
+
+}
+
+
+static int sunxi_mmc_gpio_get_cd(struct mmc_host *mmc)
+{
+	u32 present = 0;
+	int i = 0;
+	int gpio_val = 0;
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	if (!(mmc->caps & MMC_CAP_NEEDS_POLL)
+		|| ((mmc->caps & MMC_CAP_NEEDS_POLL)
+			&& !(host->ctl_spec_cap & SUNXI_DIS_KER_NAT_CD)))
+		return mmc_gpio_get_cd(mmc);
+
+	for (i = 0; i < 5; i++) {
+		gpio_val += mmc_gpio_get_cd(mmc);
+		usleep_range(1000, 1500);
+	}
+
+	if (gpio_val == 5)
+		present = 1;
+	else if (gpio_val == 0)
+		present = 0;
+
+	pr_debug("*%s %s %d %d*\n", mmc_hostname(mmc),
+				__func__, __LINE__, present);
+	/*only cd pin change we wil return true*/
+	if (host->present ^ present) {
+		host->present = present;
+		pr_debug("*%s %s %d h%d*\n", mmc_hostname(mmc),
+			__func__, __LINE__, host->present);
+		return 1;
+	}
+
+	return 0;
+}
+
+
+
+static const struct of_device_id sunxi_mmc_of_match[] = {
+	{.compatible = "allwinner,sun4i-a10-mmc",},
+	{.compatible = "allwinner,sun5i-a13-mmc",},
+	{.compatible = "allwinner,sun8iw10p1-sdmmc3",},
+	{.compatible = "allwinner,sun8iw10p1-sdmmc1",},
+	{.compatible = "allwinner,sun8iw10p1-sdmmc0",},
+	{.compatible = "allwinner,sun50i-sdmmc2",},
+	{.compatible = "allwinner,sun50i-sdmmc1",},
+	{.compatible = "allwinner,sun50i-sdmmc0",},
+	{.compatible = "allwinner,sunxi-mmc-v4p1x",},
+	{.compatible = "allwinner,sunxi-mmc-v4p10x",},
+	{.compatible = "allwinner,sunxi-mmc-v4p00x",},
+	{.compatible = "allwinner,sunxi-mmc-v4p5x",},
+	{.compatible = "allwinner,sunxi-mmc-v4p6x",},
+	{.compatible = "allwinner,sunxi-mmc-v5p3x",},
+	{ /* sentinel */ }
+};
+
+MODULE_DEVICE_TABLE(of, sunxi_mmc_of_match);
+
+static struct mmc_host_ops sunxi_mmc_ops = {
+	.post_req = sunxi_mmc_post_req,
+	.pre_req = sunxi_mmc_pre_req,
+	.request = sunxi_mmc_request,
+	.set_ios = sunxi_mmc_set_ios,
+	.get_ro = mmc_gpio_get_ro,
+	.get_cd = sunxi_mmc_gpio_get_cd,
+	.enable_sdio_irq = sunxi_mmc_enable_sdio_irq,
+	.hw_reset = sunxi_mmc_hw_reset,
+	.start_signal_voltage_switch = sunxi_mmc_signal_voltage_switch,
+	.card_busy = sunxi_mmc_card_busy,
+};
+
+#if defined(MMC_FPGA) && defined(CONFIG_ARCH_SUN8IW10P1)
+void disable_card2_dat_det(void)
+{
+	void __iomem *card2_int_sg_en =
+	    ioremap(0x1c0f000 + 0x1000 * 2 + 0x38, 0x100);
+	writel(0, card2_int_sg_en);
+	iounmap(card2_int_sg_en);
+}
+
+void enable_card3(void)
+{
+	void __iomem *card3_en = ioremap(0x1c20800 + 0xB4, 0x100);
+	/*void __iomem *card3_en =  ioremap(0x1c20800 + 0x48, 0x100);*/
+	writel(0x55555555, card3_en);
+	writel(0x55555555, card3_en + 4);
+	writel(0x55555555, card3_en + 8);
+	writel(0x55555555, card3_en + 12);
+	iounmap(card3_en);
+}
+
+#endif
+
+#if 0
+/*The following shutdown only use for sdmmc2 to be compatible with a20*/
+
+void sunxi_mmc_do_shutdown_com(struct platform_device *pdev)
+{
+	u32 ocr = 0;
+	u32 err = 0;
+	struct mmc_host *mmc = NULL;
+	struct sunxi_mmc_host *host = NULL;
+	u32 status = 0;
+
+	mmc = platform_get_drvdata(pdev);
+	if (mmc == NULL) {
+		dev_err(&pdev->dev, "%s: mmc is NULL\n", __func__);
+		goto out;
+	}
+
+	host = mmc_priv(mmc);
+	if (host == NULL) {
+		dev_err(&pdev->dev, "%s: host is NULL\n", __func__);
+		goto out;
+	}
+
+	dev_info(mmc_dev(mmc), "try to disable cache\n");
+	mmc_claim_host(mmc);
+	err = mmc_flush_cache(mmc->card);
+	mmc_release_host(mmc);
+	if (err) {
+		dev_err(mmc_dev(mmc), "disable cache failed\n");
+/*not release host to not allow android to read/write after shutdown */
+		mmc_claim_host(mmc);
+		goto out;
+	}
+	/*claim host to not allow androd read/write during shutdown*/
+	dev_dbg(mmc_dev(mmc), "%s: claim host\n", __func__);
+	mmc_claim_host(mmc);
+
+	do {
+		if (mmc_send_status(mmc->card, &status) != 0) {
+			dev_err(mmc_dev(mmc), "%s: send status failed\n",
+				__func__);
+	/*
+	*err_out;
+	*not release host to not allow android to read/write after shutdown
+	*/
+				goto out;
+		}
+	} while (status != 0x00000900);
+
+	/*mmc_card_set_ddr_mode(card);*/
+	mmc_set_timing(mmc, MMC_TIMING_LEGACY);
+	mmc_set_bus_width(mmc, MMC_BUS_WIDTH_1);
+	mmc_set_clock(mmc, 400000);
+	err = mmc_go_idle(mmc);
+	if (err) {
+		dev_err(mmc_dev(mmc), "%s: mmc_go_idle err\n", __func__);
+	/*
+	*err_out;
+	//not release host to not allow android to read/write after shutdown
+	*/
+			goto out;
+	}
+/*sd can support cmd1,so not send cmd1 */
+	if (mmc->card->type != MMC_TYPE_MMC)
+	/*not release host to not allow android to read/write after shutdown */
+		goto out;
+
+
+	err = mmc_send_op_cond(mmc, 0, &ocr);
+	if (err) {
+		dev_err(mmc_dev(mmc), "%s: first mmc_send_op_cond err\n",
+			__func__);
+	/*
+	*err_out;
+	*not release host to not allow android to read/write after shutdown
+	*/
+			goto out;
+	}
+
+	err = mmc_send_op_cond(mmc, ocr | (1 << 30), &ocr);
+	if (err) {
+		dev_err(mmc_dev(mmc), "%s: mmc_send_op_cond err\n",
+			__func__);
+	/*err_out;
+	*not release host to not allow android to read/write after shutdown
+	*/
+			goto out;
+	}
+	/*
+	 *do not release host to not allow
+	 *android to read/write after shutdown
+	 */
+	goto out;
+
+out:
+	dev_info(mmc_dev(mmc), "%s: mmc shutdown exit..ok\n", __func__);
+}
+#endif
+
+static int sunxi_mmc_resource_request(struct sunxi_mmc_host *host,
+				      struct platform_device *pdev)
+{
+	struct device_node *np = pdev->dev.of_node;
+	int ret;
+	u32 caps_val = 0;
+	struct gpio_config flags;
+	struct device_node *apk_np = of_find_node_by_name(NULL, "auto_print");
+	const char *apk_sta = NULL;
+
+	ret = of_property_read_u32(np, "ctl-spec-caps", &caps_val);
+	if (!ret) {
+		host->ctl_spec_cap |= caps_val;
+		dev_info(&pdev->dev, "***ctl-spec-caps*** %x\n",
+			 host->ctl_spec_cap);
+	}
+#ifdef SUNXI_SDMMC3
+	if (of_device_is_compatible(np, "allwinner,sun8iw10p1-sdmmc3")) {
+		host->sunxi_mmc_clk_set_rate =
+		    sunxi_mmc_clk_set_rate_for_sdmmc3;
+		/*host->dma_tl = (0x3<<28)|(15<<16)|240;*/
+		host->dma_tl = SUNXI_DMA_TL_SDMMC3;
+		/*host->idma_des_size_bits = 12;*/
+		host->idma_des_size_bits = SUNXI_DES_SIZE_SDMMC3;
+		host->sunxi_mmc_thld_ctl = sunxi_mmc_thld_ctl_for_sdmmc3;
+		host->sunxi_mmc_save_spec_reg = sunxi_mmc_save_spec_reg3;
+		host->sunxi_mmc_restore_spec_reg = sunxi_mmc_restore_spec_reg3;
+		host->sunxi_mmc_dump_dly_table = sunxi_mmc_dump_dly3;
+		sunxi_mmc_reg_ex_res_inter(host, 3);
+		host->sunxi_mmc_set_acmda = sunxi_mmc_set_a12a;
+		host->phy_index = 3;	/*2; */
+	}
+#if defined(MMC_FPGA) && defined(CONFIG_ARCH_SUN8IW10P1)
+	enable_card3();
+#endif	/*defined(MMC_FPGA) && defined(CONFIG_ARCH_SUN8IW10P1) */
+
+#endif
+
+#ifdef SUNXI_SDMMC2
+	if (of_device_is_compatible(np, "allwinner,sun50i-sdmmc2")) {
+		host->sunxi_mmc_clk_set_rate =
+		    sunxi_mmc_clk_set_rate_for_sdmmc2;
+		/*host->dma_tl = (0x3<<28)|(15<<16)|240;*/
+		host->dma_tl = SUNXI_DMA_TL_SDMMC2;
+		/*host->idma_des_size_bits = 12;*/
+		host->idma_des_size_bits = SUNXI_DES_SIZE_SDMMC2;
+		host->sunxi_mmc_thld_ctl = sunxi_mmc_thld_ctl_for_sdmmc2;
+		host->sunxi_mmc_save_spec_reg = sunxi_mmc_save_spec_reg2;
+		host->sunxi_mmc_restore_spec_reg = sunxi_mmc_restore_spec_reg2;
+		host->sunxi_mmc_dump_dly_table = sunxi_mmc_dump_dly2;
+		sunxi_mmc_reg_ex_res_inter(host, 2);
+		host->sunxi_mmc_set_acmda = sunxi_mmc_set_a12a;
+		host->phy_index = 2;
+		host->sunxi_mmc_oclk_en = sunxi_mmc_oclk_onoff_sdmmc2;
+	}
+#endif
+
+#ifdef SUNXI_SDMMC0
+	if (of_device_is_compatible(np, "allwinner,sun50i-sdmmc0")
+	    || of_device_is_compatible(np, "allwinner,sun8iw10p1-sdmmc0")) {
+		host->sunxi_mmc_clk_set_rate =
+		    sunxi_mmc_clk_set_rate_for_sdmmc0;
+		/*host->dma_tl = (0x2<<28)|(7<<16)|248;*/
+		host->dma_tl = SUNXI_DMA_TL_SDMMC0;
+		/*host->idma_des_size_bits = 15;*/
+		host->idma_des_size_bits = SUNXI_DES_SIZE_SDMMC0;
+		host->sunxi_mmc_thld_ctl = sunxi_mmc_thld_ctl_for_sdmmc0;
+		host->sunxi_mmc_save_spec_reg = sunxi_mmc_save_spec_reg0;
+		host->sunxi_mmc_restore_spec_reg = sunxi_mmc_restore_spec_reg0;
+		sunxi_mmc_reg_ex_res_inter(host, 0);
+		host->sunxi_mmc_set_acmda = sunxi_mmc_set_a12a;
+		host->phy_index = 0;
+		host->sunxi_mmc_oclk_en = sunxi_mmc_oclk_onoff_sdmmc0;
+	}
+#endif
+
+#ifdef SUNXI_SDMMC1
+	if (of_device_is_compatible(np, "allwinner,sun50i-sdmmc1")
+	    || of_device_is_compatible(np, "allwinner,sun8iw10p1-sdmmc1")) {
+		host->sunxi_mmc_clk_set_rate =
+		    sunxi_mmc_clk_set_rate_for_sdmmc1;
+		/*host->dma_tl = (0x3<<28)|(15<<16)|240;*/
+		host->dma_tl = SUNXI_DMA_TL_SDMMC1;
+		/*host->idma_des_size_bits = 15;*/
+		host->idma_des_size_bits = SUNXI_DES_SIZE_SDMMC1;
+		host->sunxi_mmc_thld_ctl = sunxi_mmc_thld_ctl_for_sdmmc1;
+		host->sunxi_mmc_save_spec_reg = sunxi_mmc_save_spec_reg1;
+		host->sunxi_mmc_restore_spec_reg = sunxi_mmc_restore_spec_reg1;
+		sunxi_mmc_reg_ex_res_inter(host, 1);
+		host->sunxi_mmc_set_acmda = sunxi_mmc_set_a12a;
+		host->phy_index = 1;
+		host->sunxi_mmc_oclk_en = sunxi_mmc_oclk_onoff_sdmmc1;
+	}
+#endif
+
+#if IS_ENABLED(CONFIG_MMC_SUNXI_V4P1X)
+	if (of_device_is_compatible(np, "allwinner,sunxi-mmc-v4p1x")) {
+		int phy_index = 0;
+
+		if (of_property_match_string(np, "device_type", "sdc0") == 0) {
+			phy_index = 0;
+		} else if (of_property_match_string(np, "device_type", "sdc1")
+			   == 0) {
+			phy_index = 1;
+		} else if (of_property_match_string(np, "device_type", "sdc2")
+			   == 0) {
+			phy_index = 2;
+		} else if (of_property_match_string(np, "device_type", "sdc3")
+			   == 0) {
+			phy_index = 3;
+		} else {
+			dev_err(&pdev->dev, "No sdmmc device,check dts\n");
+		}
+		sunxi_mmc_init_priv_v4p1x(host, pdev, phy_index);
+	}
+#endif
+
+#if IS_ENABLED(CONFIG_MMC_SUNXI_V4P00X)
+	if ((of_device_is_compatible(np,
+					"allwinner,sunxi-mmc-v4p00x")) ||
+		of_device_is_compatible(np,
+					"allwinner,sun3iw1p1-sdmmc1") ||
+		of_device_is_compatible(np,
+					"allwinner,sun3iw1p1-sdmmc0"))	{
+		int phy_index = 0;
+
+		if (of_property_match_string(np,
+					"device_type", "sdc0") == 0)
+			phy_index = 0;
+		 else if (of_property_match_string(np,
+					"device_type", "sdc1") == 0)
+			phy_index = 1;
+		 else if (of_property_match_string(np,
+					"device_type", "sdc2") == 0)
+			phy_index = 2;
+		 else if (of_property_match_string(np,
+					"device_type", "sdc3") == 0)
+			phy_index = 3;
+		 else
+			dev_err(&pdev->dev, "No sdmmc device,check dts\n");
+
+		sunxi_mmc_init_priv_v4p00x(host, pdev, phy_index);
 	}
+#endif
 
-	host->mrq = mrq;
-	host->wait_dma = wait_dma;
-	mmc_writel(host, REG_IMASK, host->sdio_imask | imask);
-	mmc_writel(host, REG_CARG, cmd->arg);
-	mmc_writel(host, REG_CMDR, cmd_val);
+#if IS_ENABLED(CONFIG_MMC_SUNXI_V4P10X)
+	if (of_device_is_compatible(np, "allwinner,sunxi-mmc-v4p10x")) {
+		int phy_index = 0;
+
+		if (of_property_match_string(np,
+					"device_type", "sdc0") == 0)
+			phy_index = 0;
+		 else if (of_property_match_string(np,
+					"device_type", "sdc1") == 0)
+			phy_index = 1;
+		 else if (of_property_match_string(np,
+					"device_type", "sdc2") == 0)
+			phy_index = 2;
+		 else if (of_property_match_string(np,
+					"device_type", "sdc3") == 0)
+			phy_index = 3;
+		 else
+			dev_err(&pdev->dev, "No sdmmc device,check dts\n");
+
+		sunxi_mmc_init_priv_v4p10x(host, pdev, phy_index);
+	}
+#endif
 
-	spin_unlock_irqrestore(&host->lock, iflags);
-}
+#if IS_ENABLED(CONFIG_MMC_SUNXI_V4P5X)
+	if (of_device_is_compatible(np, "allwinner,sunxi-mmc-v4p5x"))	{
+		int phy_index = 0;
+		if (of_property_match_string(np, "device_type", "sdc0") == 0) {
+			phy_index = 0;
+		} else if (of_property_match_string(np, "device_type", "sdc1")
+			   == 0) {
+			phy_index = 1;
+		} else if (of_property_match_string(np, "device_type", "sdc2")
+			   == 0) {
+			phy_index = 2;
+		} else if (of_property_match_string(np, "device_type", "sdc3")
+			   == 0) {
+			phy_index = 3;
+		} else {
+			dev_err(&pdev->dev, "No sdmmc device,check dts\n");
+		}
+		sunxi_mmc_init_priv_v4p5x(host, pdev, phy_index);
+	}
+#endif
 
-static int sunxi_mmc_card_busy(struct mmc_host *mmc)
-{
-	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	/*ret = mmc_regulator_get_supply(host->mmc);*/
+	ret = sunxi_mmc_regulator_get_supply(host->mmc);
+	if (ret) {
+		return ret;
+	}
+	/*Maybe in some platform,no regulator,so we set ocr_avail manully */
+	if (!host->mmc->ocr_avail)
+		host->mmc->ocr_avail =
+		    MMC_VDD_28_29 | MMC_VDD_29_30 | MMC_VDD_30_31 |
+		    MMC_VDD_31_32 | MMC_VDD_32_33 | MMC_VDD_33_34;
+
+	/*enable card detect pin power*/
+	if (!IS_ERR(host->supply.vdmmc)) {
+		ret = regulator_enable(host->supply.vdmmc);
+		if (ret < 0) {
+			dev_err(mmc_dev(host->mmc),
+				"failed to enable vdmmc regulator\n");
+			return ret;
+		}
+	}
 
-	return !!(mmc_readl(host, REG_STAS) & SDXC_CARD_DATA_BUSY);
-}
+	/*enable card detect pin power with SD PMU*/
+	if (!IS_ERR(host->supply.vdmmc33sw)) {
+		ret = regulator_enable(host->supply.vdmmc33sw);
+		if (ret < 0) {
+			dev_err(mmc_dev(host->mmc),
+				"failed to enable vdmmc33sw regulator\n");
+			return ret;
+		}
+	}
 
-static const struct mmc_host_ops sunxi_mmc_ops = {
-	.request	 = sunxi_mmc_request,
-	.set_ios	 = sunxi_mmc_set_ios,
-	.get_ro		 = mmc_gpio_get_ro,
-	.get_cd		 = mmc_gpio_get_cd,
-	.enable_sdio_irq = sunxi_mmc_enable_sdio_irq,
-	.start_signal_voltage_switch = sunxi_mmc_volt_switch,
-	.hw_reset	 = sunxi_mmc_hw_reset,
-	.card_busy	 = sunxi_mmc_card_busy,
-};
+	if (!IS_ERR(host->supply.vdmmc18sw)) {
+		ret = regulator_enable(host->supply.vdmmc18sw);
+		if (ret < 0) {
+			dev_err(mmc_dev(host->mmc),
+				"failed to enable vdmmc18sw regulator\n");
+			return ret;
+		}
+	}
 
-static const struct sunxi_mmc_clk_delay sunxi_mmc_clk_delays[] = {
-	[SDXC_CLK_400K]		= { .output = 180, .sample = 180 },
-	[SDXC_CLK_25M]		= { .output = 180, .sample =  75 },
-	[SDXC_CLK_50M]		= { .output =  90, .sample = 120 },
-	[SDXC_CLK_50M_DDR]	= { .output =  60, .sample = 120 },
-	/* Value from A83T "new timing mode". Works but might not be right. */
-	[SDXC_CLK_50M_DDR_8BIT]	= { .output =  90, .sample = 180 },
-};
 
-static const struct sunxi_mmc_clk_delay sun9i_mmc_clk_delays[] = {
-	[SDXC_CLK_400K]		= { .output = 180, .sample = 180 },
-	[SDXC_CLK_25M]		= { .output = 180, .sample =  75 },
-	[SDXC_CLK_50M]		= { .output = 150, .sample = 120 },
-	[SDXC_CLK_50M_DDR]	= { .output =  54, .sample =  36 },
-	[SDXC_CLK_50M_DDR_8BIT]	= { .output =  72, .sample =  72 },
-};
+	host->card_pwr_gpio =
+	    of_get_named_gpio_flags(np, "card-pwr-gpios", 0,
+				    (enum of_gpio_flags *)&flags);
+	if (gpio_is_valid(host->card_pwr_gpio)) {
+		ret =
+		    devm_gpio_request_one(&pdev->dev, host->card_pwr_gpio,
+					  GPIOF_DIR_OUT, "card-pwr-gpios");
+		if (ret < 0)
+			dev_err(&pdev->dev,
+				"could not get  card-pwr-gpios gpio\n");
+	}
 
-static const struct sunxi_mmc_cfg sun4i_a10_cfg = {
-	.idma_des_size_bits = 13,
-	.clk_delays = NULL,
-	.can_calibrate = false,
-};
+	host->pinctrl = devm_pinctrl_get(&pdev->dev);
+	if (IS_ERR(host->pinctrl)) {
+		dev_warn(&pdev->dev,
+			 "Could not get pinctrl,check if pin is needed\n");
+	}
 
-static const struct sunxi_mmc_cfg sun5i_a13_cfg = {
-	.idma_des_size_bits = 16,
-	.clk_delays = NULL,
-	.can_calibrate = false,
-};
+	host->pins_default = pinctrl_lookup_state(host->pinctrl,
+						  PINCTRL_STATE_DEFAULT);
+	if (IS_ERR(host->pins_default)) {
+		dev_warn(&pdev->dev,
+			 "could not get default pinstate,check if pin is needed\n");
+	}
 
-static const struct sunxi_mmc_cfg sun7i_a20_cfg = {
-	.idma_des_size_bits = 16,
-	.clk_delays = sunxi_mmc_clk_delays,
-	.can_calibrate = false,
-};
+	if (apk_np
+		&& !of_property_read_string(apk_np, "status", &apk_sta)
+		&& !strcmp(apk_sta, "okay")) {
+		host->pins_uart_jtag = pinctrl_lookup_state(host->pinctrl,
+						"uart_jtag");
+		if (IS_ERR(host->pins_uart_jtag))
+			dev_warn(&pdev->dev, "Cann't get uart0 pinstate,check if needed\n");
+	} else {
+		host->pins_uart_jtag = ERR_PTR(-ENODEV);
+	}
 
-static const struct sunxi_mmc_cfg sun8i_a83t_emmc_cfg = {
-	.idma_des_size_bits = 16,
-	.clk_delays = sunxi_mmc_clk_delays,
-	.can_calibrate = false,
-	.ccu_has_timings_switch = true,
-};
+	host->pins_sleep = pinctrl_lookup_state(host->pinctrl,
+				PINCTRL_STATE_SLEEP);
+	if (IS_ERR(host->pins_sleep))
+		dev_warn(&pdev->dev, "Cann't get sleep pinstate,check if needed\n");
 
-static const struct sunxi_mmc_cfg sun9i_a80_cfg = {
-	.idma_des_size_bits = 16,
-	.clk_delays = sun9i_mmc_clk_delays,
-	.can_calibrate = false,
-};
+	host->pins_bias_1v8 = pinctrl_lookup_state(host->pinctrl,
+				"mmc_1v8");
+	if (IS_ERR(host->pins_bias_1v8))
+		dev_warn(&pdev->dev, "Cann't get pin bias hs pinstate,check if needed\n");
 
-static const struct sunxi_mmc_cfg sun50i_a64_cfg = {
-	.idma_des_size_bits = 16,
-	.clk_delays = NULL,
-	.can_calibrate = true,
-	.mask_data0 = true,
-	.needs_new_timings = true,
-};
+	host->reg_base = devm_ioremap_resource(&pdev->dev,
+					       platform_get_resource(pdev,
+							     IORESOURCE_MEM,
+								     0));
+	if (IS_ERR(host->reg_base)) {
+		ret = PTR_ERR(host->reg_base);
+		goto error_disable_regulator;
+	}
 
-static const struct sunxi_mmc_cfg sun50i_a64_emmc_cfg = {
-	.idma_des_size_bits = 13,
-	.clk_delays = NULL,
-	.can_calibrate = true,
-	.needs_new_timings = true,
-};
+	host->clk_ahb = devm_clk_get(&pdev->dev, "ahb");
+	if (IS_ERR(host->clk_ahb)) {
+		dev_err(&pdev->dev, "Could not get ahb clock\n");
+		ret = PTR_ERR(host->clk_ahb);
+		goto error_disable_regulator;
+	}
 
-static const struct of_device_id sunxi_mmc_of_match[] = {
-	{ .compatible = "allwinner,sun4i-a10-mmc", .data = &sun4i_a10_cfg },
-	{ .compatible = "allwinner,sun5i-a13-mmc", .data = &sun5i_a13_cfg },
-	{ .compatible = "allwinner,sun7i-a20-mmc", .data = &sun7i_a20_cfg },
-	{ .compatible = "allwinner,sun8i-a83t-emmc", .data = &sun8i_a83t_emmc_cfg },
-	{ .compatible = "allwinner,sun9i-a80-mmc", .data = &sun9i_a80_cfg },
-	{ .compatible = "allwinner,sun50i-a64-mmc", .data = &sun50i_a64_cfg },
-	{ .compatible = "allwinner,sun50i-a64-emmc", .data = &sun50i_a64_emmc_cfg },
-	{ /* sentinel */ }
-};
-MODULE_DEVICE_TABLE(of, sunxi_mmc_of_match);
+	host->clk_mmc = devm_clk_get(&pdev->dev, "mmc");
+	if (IS_ERR(host->clk_mmc)) {
+		dev_err(&pdev->dev, "Could not get mmc clock\n");
+		ret = PTR_ERR(host->clk_mmc);
+		goto error_disable_regulator;
+	}
 
-static int sunxi_mmc_enable(struct sunxi_mmc_host *host)
-{
-	int ret;
+	host->clk_rst = devm_reset_control_get(&pdev->dev, "rst");
+	if (IS_ERR(host->clk_rst))
+		dev_warn(&pdev->dev, "Could not get mmc rst\n");
 
-	if (!IS_ERR(host->reset)) {
-		ret = reset_control_reset(host->reset);
+	if (!IS_ERR(host->clk_rst)) {
+		ret = reset_control_deassert(host->clk_rst);
 		if (ret) {
-			dev_err(host->dev, "Couldn't reset the MMC controller (%d)\n",
-				ret);
-			return ret;
+			dev_err(&pdev->dev, "reset err %d\n", ret);
+			goto error_disable_regulator;
 		}
 	}
 
 	ret = clk_prepare_enable(host->clk_ahb);
 	if (ret) {
-		dev_err(host->dev, "Couldn't enable the bus clocks (%d)\n", ret);
+		dev_err(&pdev->dev, "Enable ahb clk err %d\n", ret);
 		goto error_assert_reset;
 	}
 
 	ret = clk_prepare_enable(host->clk_mmc);
 	if (ret) {
-		dev_err(host->dev, "Enable mmc clk err %d\n", ret);
+		dev_err(&pdev->dev, "Enable mmc clk err %d\n", ret);
 		goto error_disable_clk_ahb;
 	}
-
-	ret = clk_prepare_enable(host->clk_output);
-	if (ret) {
-		dev_err(host->dev, "Enable output clk err %d\n", ret);
-		goto error_disable_clk_mmc;
-	}
-
-	ret = clk_prepare_enable(host->clk_sample);
-	if (ret) {
-		dev_err(host->dev, "Enable sample clk err %d\n", ret);
-		goto error_disable_clk_output;
-	}
-
+#if defined(MMC_FPGA) && defined(CONFIG_ARCH_SUN8IW10P1)
+	disable_card2_dat_det();
+#endif
 	/*
 	 * Sometimes the controller asserts the irq on boot for some reason,
 	 * make sure the controller is in a sane state before enabling irqs.
 	 */
 	ret = sunxi_mmc_reset_host(host);
 	if (ret)
-		goto error_disable_clk_sample;
+		goto error_disable_clk_mmc;
 
-	return 0;
+#ifdef CONFIG_MMC_SUNXI_V4P5X
+	if (of_device_is_compatible(np, "allwinner,sunxi-mmc-v4p6x"))	{
+		int phy_index = 0;
+
+		if (of_property_match_string(np, "device_type", "sdc0") == 0)
+			phy_index = 0;
+		else if (of_property_match_string(np, "device_type", "sdc1") == 0)
+			phy_index = 1;
+		else if (of_property_match_string(np, "device_type", "sdc2") == 0)
+			phy_index = 2;
+		else if (of_property_match_string(np, "device_type", "sdc3") == 0)
+			phy_index = 3;
+		else
+			dev_err(&pdev->dev, "No sdmmc device,check dts\n");
+		sunxi_mmc_init_priv_v4p6x(host, pdev, phy_index);
+	}
+#endif
+
+#ifdef CONFIG_MMC_SUNXI_V5P3X
+	if (of_device_is_compatible(np, "allwinner,sunxi-mmc-v5p3x")) {
+		int phy_index = 0;
+		if (of_property_match_string(np, "device_type", "sdc0") == 0) {
+			phy_index = 0;
+		} else if (of_property_match_string(np, "device_type", "sdc1")
+			   == 0) {
+			phy_index = 1;
+		} else if (of_property_match_string(np, "device_type", "sdc2")
+			   == 0) {
+			phy_index = 2;
+		} else if (of_property_match_string(np, "device_type", "sdc3")
+			   == 0) {
+			phy_index = 3;
+		} else {
+			dev_err(&pdev->dev, "No sdmmc device,check dts\n");
+		}
+		sunxi_mmc_init_priv_v5p3x(host, pdev, phy_index);
+	}
+#endif
+
+	host->irq = platform_get_irq(pdev, 0);
+	snprintf(host->name, sizeof(host->name), "mmc%d",
+		 host->phy_index);
+	ret = devm_request_threaded_irq(&pdev->dev, host->irq, sunxi_mmc_irq,
+					sunxi_mmc_handle_bottom_half, 0,
+					host->name, host);
+	if (ret) {
+		dev_err(&pdev->dev, "failed to request irq %d\n", ret);
+		goto error_disable_clk_mmc;
+	}
+
+	if (host->ctl_spec_cap & SUNXI_SC_EN_TIMEOUT_DETECT)
+				INIT_DELAYED_WORK(&host->sunxi_timerout_work, sunxi_timerout_handle);
+
+	disable_irq(host->irq);
+
+	clk_disable_unprepare(host->clk_mmc);
+	clk_disable_unprepare(host->clk_ahb);
+
+	if (!IS_ERR(host->clk_rst))
+		reset_control_assert(host->clk_rst);
+
+	return ret;
 
-error_disable_clk_sample:
-	clk_disable_unprepare(host->clk_sample);
-error_disable_clk_output:
-	clk_disable_unprepare(host->clk_output);
 error_disable_clk_mmc:
 	clk_disable_unprepare(host->clk_mmc);
 error_disable_clk_ahb:
 	clk_disable_unprepare(host->clk_ahb);
 error_assert_reset:
+#if 0
 	if (!IS_ERR(host->reset))
 		reset_control_assert(host->reset);
+#else
+	if (!IS_ERR(host->clk_rst))
+		reset_control_assert(host->clk_rst);
+#endif
+error_disable_regulator:
+	if (!IS_ERR(host->supply.vdmmc18sw))  /*SD PMU control*/
+		regulator_disable(host->supply.vdmmc18sw);
+	if (!IS_ERR(host->supply.vdmmc33sw))  /*SD PMU control*/
+		regulator_disable(host->supply.vdmmc33sw);
+	if (!IS_ERR(host->supply.vdmmc))
+		regulator_disable(host->supply.vdmmc);
+	sunxi_mmc_regulator_release_supply(host->mmc);
+
 	return ret;
 }
 
-static void sunxi_mmc_disable(struct sunxi_mmc_host *host)
+static void sunxi_show_det_mode(struct mmc_host *mmc)
 {
-	sunxi_mmc_reset_host(host);
-
-	clk_disable_unprepare(host->clk_sample);
-	clk_disable_unprepare(host->clk_output);
-	clk_disable_unprepare(host->clk_mmc);
-	clk_disable_unprepare(host->clk_ahb);
-
-	if (!IS_ERR(host->reset))
-		reset_control_assert(host->reset);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	if (host->sunxi_caps3 & MMC_SUNXI_CAP3_DAT3_DET)
+		dev_info(mmc_dev(mmc), "detmode:data3\n");
+	else if (mmc->caps & MMC_CAP_NEEDS_POLL)
+		dev_info(mmc_dev(mmc), "detmode:gpio polling\n");
+	else if (mmc->caps & MMC_CAP_NONREMOVABLE)
+		dev_info(mmc_dev(mmc), "detmode:alway in(non removable)\n");
+	else if (mmc->slot.cd_irq >= 0)
+		dev_info(mmc_dev(mmc), "detmode:gpio irq\n");
+	else
+		dev_info(mmc_dev(mmc), "detmode:manually by software\n");
 }
-
-static int sunxi_mmc_resource_request(struct sunxi_mmc_host *host,
-				      struct platform_device *pdev)
+static int sunxi_mmc_extra_of_parse(struct mmc_host *mmc)
 {
-	int ret;
-
-	host->cfg = of_device_get_match_data(&pdev->dev);
-	if (!host->cfg)
-		return -EINVAL;
-
-	ret = mmc_regulator_get_supply(host->mmc);
-	if (ret)
-		return ret;
-
-	host->reg_base = devm_ioremap_resource(&pdev->dev,
-			      platform_get_resource(pdev, IORESOURCE_MEM, 0));
-	if (IS_ERR(host->reg_base))
-		return PTR_ERR(host->reg_base);
-
-	host->clk_ahb = devm_clk_get(&pdev->dev, "ahb");
-	if (IS_ERR(host->clk_ahb)) {
-		dev_err(&pdev->dev, "Could not get ahb clock\n");
-		return PTR_ERR(host->clk_ahb);
-	}
+	struct device_node *np;
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	int perf_enable = 0;
+	if (!mmc->parent || !mmc->parent->of_node)
+		return 0;
 
-	host->clk_mmc = devm_clk_get(&pdev->dev, "mmc");
-	if (IS_ERR(host->clk_mmc)) {
-		dev_err(&pdev->dev, "Could not get mmc clock\n");
-		return PTR_ERR(host->clk_mmc);
+	np = mmc->parent->of_node;
+
+	if (of_property_read_bool(np, "cap-erase"))
+		mmc->caps |= MMC_CAP_ERASE;
+	if (of_property_read_bool(np, "mmc-high-capacity-erase-size"))
+		mmc->caps2 |= MMC_CAP2_HC_ERASE_SZ;
+	if (sunxi_mmc_chk_hr1b_cap(host)
+			&& of_property_read_bool(np, "cap-wait-while-busy")) {
+		int max_busy_timeout = 0;
+		mmc->caps |= MMC_CAP_WAIT_WHILE_BUSY;
+		if (of_property_read_u32(np,
+				"max-busy-timeout", &max_busy_timeout) < 0) {
+			dev_dbg(mmc->parent,
+				"max-busy-timeout is missing, use default %d ms.\n",
+				SUNXI_DEF_MAX_R1B_TIMEOUT_MS);
+			mmc->max_busy_timeout = SUNXI_DEF_MAX_R1B_TIMEOUT_MS;
+		} else {
+			if (max_busy_timeout < SUNXI_MIN_R1B_TIMEOUT_MS)
+				max_busy_timeout = SUNXI_MIN_R1B_TIMEOUT_MS;
+			mmc->max_busy_timeout = max_busy_timeout;
+			dev_dbg(mmc->parent, "max-busy-timeout is %d ms\n",
+					max_busy_timeout);
+		}
 	}
 
-	if (host->cfg->clk_delays) {
-		host->clk_output = devm_clk_get(&pdev->dev, "output");
-		if (IS_ERR(host->clk_output)) {
-			dev_err(&pdev->dev, "Could not get output clock\n");
-			return PTR_ERR(host->clk_output);
+	if (of_property_read_bool(np, "ignore-pm-notify"))
+		mmc->pm_flags |= MMC_PM_IGNORE_PM_NOTIFY;
+	if (of_property_read_bool(np, "cap-cmd23"))
+		mmc->caps |= MMC_CAP_CMD23;
+	if (of_property_read_bool(np, "ignore-pm-notify"))
+		mmc->pm_flags |= MMC_PM_IGNORE_PM_NOTIFY;
+	if (of_property_read_bool(np, "cap-pack-write"))
+		mmc->caps2 |= MMC_CAP2_PACKED_WR;
+	if (of_property_read_bool(np, "mmc-cache-ctrl"))
+		mmc->caps2 |= MMC_CAP2_CACHE_CTRL;
+	if (of_property_read_bool(np, "mmc-bootpart-noacc"))
+		mmc->caps2 |= MMC_CAP2_BOOTPART_NOACC;
+
+#ifdef CONFIG_ARCH_SUN8IW16P1
+	if (sunxi_get_soc_ver() ==  SUN8IW16P1_REV_A) {
+		if (host->phy_index == 0) {
+		mmc->caps &= ~(MMC_CAP_UHS_SDR12|MMC_CAP_UHS_SDR25|
+				MMC_CAP_UHS_SDR50|MMC_CAP_UHS_SDR104|
+				MMC_CAP_UHS_DDR50);
 		}
+	}
+#endif
+	if (of_property_read_bool(np, "cd-used-24M"))
+		host->sunxi_caps3 |= MMC_SUNXI_CAP3_CD_USED_24M;
+	if (of_property_read_bool(np, "data3-detect"))
+		host->sunxi_caps3 |= MMC_SUNXI_CAP3_DAT3_DET;
+
+	if (of_property_read_u32(np,
+			"filter_speed", &(host->filter_speed)) < 0) {
+		dev_dbg(mmc->parent,
+			"filter speed is missing, function is no used\n");
+	} else {
+		dev_info(mmc->parent, "filter speed is %d B/s\n", host->filter_speed);
+	}
 
-		host->clk_sample = devm_clk_get(&pdev->dev, "sample");
-		if (IS_ERR(host->clk_sample)) {
-			dev_err(&pdev->dev, "Could not get sample clock\n");
-			return PTR_ERR(host->clk_sample);
-		}
+	if (of_property_read_u32(np,
+			"filter_sector", &(host->filter_sector)) < 0) {
+		dev_dbg(mmc->parent,
+			"filter sector is missing, function is no used\n");
+	} else {
+		dev_info(mmc->parent, "filter sector is %d sector\n", host->filter_sector);
 	}
 
-	host->reset = devm_reset_control_get_optional_exclusive(&pdev->dev,
-								"ahb");
-	if (PTR_ERR(host->reset) == -EPROBE_DEFER)
-		return PTR_ERR(host->reset);
+	if (of_property_read_u32(np,
+			"perf_enable", &perf_enable) < 0) {
+		dev_dbg(mmc->parent,
+			"perf_enable is missing, function is no used\n");
+	} else {
+		dev_info(mmc->parent, "Perf function is enable\n");
+		host->perf_enable = true;
+	}
 
-	ret = sunxi_mmc_enable(host);
-	if (ret)
-		return ret;
+	if (of_property_read_u32(np,
+			"min-frequency", &mmc->f_min) < 0) {
+		dev_dbg(mmc->parent,
+			"min-frequency used default:%d\n", mmc->f_min);
+	} else {
+		dev_info(mmc->parent, "min-frequency:%d\n", mmc->f_min);
+	}
 
-	host->irq = platform_get_irq(pdev, 0);
-	if (host->irq <= 0) {
-		ret = -EINVAL;
-		goto error_disable_mmc;
+	/* delay time:pwr-gpio control poweroff->powerup */
+	if (of_property_read_u32(np, "time_pwroff_ms", &host->time_pwroff_ms) < 0) {
+		host->time_pwroff_ms = 200;
+		dev_dbg(mmc->parent,
+			"powerctrl default delay time:%dms\n", host->time_pwroff_ms);
 	}
 
-	return devm_request_threaded_irq(&pdev->dev, host->irq, sunxi_mmc_irq,
-			sunxi_mmc_handle_manual_stop, 0, "sunxi-mmc", host);
+	if (of_property_read_u32(np,
+			"req-page-count", &host->req_page_count) < 0) {
+		host->req_page_count = 4;
+		dev_dbg(mmc->parent,
+			"req-page-count used default:%d\n", host->req_page_count);
+	} else {
+		dev_dbg(mmc->parent,
+			"req-page-count used value:%d\n", host->req_page_count);
+	}
 
-error_disable_mmc:
-	sunxi_mmc_disable(host);
-	return ret;
+	return 0;
 }
 
 static int sunxi_mmc_probe(struct platform_device *pdev)
 {
 	struct sunxi_mmc_host *host;
 	struct mmc_host *mmc;
+	struct mmc_gpio *ctx;
 	int ret;
 
+	dev_info(&pdev->dev, "%s\n", DRIVER_VERSION);
+
 	mmc = mmc_alloc_host(sizeof(struct sunxi_mmc_host), &pdev->dev);
 	if (!mmc) {
 		dev_err(&pdev->dev, "mmc alloc host failed\n");
 		return -ENOMEM;
 	}
-	platform_set_drvdata(pdev, mmc);
 
 	host = mmc_priv(mmc);
-	host->dev = &pdev->dev;
 	host->mmc = mmc;
 	spin_lock_init(&host->lock);
 
@@ -1349,7 +2847,32 @@ static int sunxi_mmc_probe(struct platform_device *pdev)
 	if (ret)
 		goto error_free_host;
 
-	host->sg_cpu = dma_alloc_coherent(&pdev->dev, PAGE_SIZE,
+	/* 400kHz ~ 50MHz */
+	mmc->f_min = 400000;
+	mmc->f_max = 50000000;
+
+	if (sunxi_mmc_chk_hr1b_cap(host)) {
+		mmc->max_busy_timeout = SUNXI_DEF_MAX_R1B_TIMEOUT_MS;
+		mmc->caps |= MMC_CAP_WAIT_WHILE_BUSY;
+		dev_dbg(&pdev->dev, "set host busy\n");
+	} else
+		dev_err(&pdev->dev, "non-existent host busy\n");
+
+#if !IS_ENABLED(CONFIG_REGULATOR)
+	/*Because fpga has no regulator,so we add it manully*/
+	mmc->ocr_avail =
+	    MMC_VDD_28_29 | MMC_VDD_29_30 | MMC_VDD_30_31 | MMC_VDD_31_32 |
+	    MMC_VDD_32_33 | MMC_VDD_33_34;
+	dev_info(&pdev->dev, "***set host ocr***\n");
+#endif
+
+	mmc_of_parse(mmc);
+	sunxi_mmc_extra_of_parse(mmc);
+
+	host->dma_mask = DMA_BIT_MASK(64);
+	pdev->dev.coherent_dma_mask = DMA_BIT_MASK(64);
+	pdev->dev.dma_mask = &host->dma_mask;
+	host->sg_cpu = dma_alloc_coherent(&pdev->dev, PAGE_SIZE * host->req_page_count,
 					  &host->sg_dma, GFP_KERNEL);
 	if (!host->sg_cpu) {
 		dev_err(&pdev->dev, "Failed to allocate DMA descriptor mem\n");
@@ -1357,94 +2880,47 @@ static int sunxi_mmc_probe(struct platform_device *pdev)
 		goto error_free_host;
 	}
 
-	if (host->cfg->ccu_has_timings_switch) {
-		/*
-		 * Supports both old and new timing modes.
-		 * Try setting the clk to new timing mode.
-		 */
-		sunxi_ccu_set_mmc_timing_mode(host->clk_mmc, true);
-
-		/* And check the result */
-		ret = sunxi_ccu_get_mmc_timing_mode(host->clk_mmc);
-		if (ret < 0) {
-			/*
-			 * For whatever reason we were not able to get
-			 * the current active mode. Default to old mode.
-			 */
-			dev_warn(&pdev->dev, "MMC clk timing mode unknown\n");
-			host->use_new_timings = false;
-		} else {
-			host->use_new_timings = !!ret;
+	mmc->ops = &sunxi_mmc_ops;
+	mmc->max_blk_count = 8192;
+	mmc->max_blk_size = 4096;
+	mmc->max_segs = PAGE_SIZE * host->req_page_count / sizeof(struct sunxi_idma_des);
+	mmc->max_seg_size = (1 << host->idma_des_size_bits);
+	mmc->max_req_size = mmc->max_seg_size * mmc->max_segs;
+	if (host->sunxi_caps3 & MMC_SUNXI_CAP3_DAT3_DET)
+		host->dat3_imask = SDXC_CARD_INSERT | SDXC_CARD_REMOVE;
+	if (host->sunxi_caps3 & MMC_SUNXI_CAP3_CD_USED_24M) {
+		ctx = (struct mmc_gpio *)mmc->slot.handler_priv;
+		if (ctx  && ctx->cd_gpio) {
+			ret = gpiod_set_debounce(ctx->cd_gpio, 1);
+			if (ret < 0) {
+				dev_info(&pdev->dev, "set cd-gpios as 24M fail\n");
+			}
 		}
-	} else if (host->cfg->needs_new_timings) {
-		/* Supports new timing mode only */
-		host->use_new_timings = true;
-	}
-
-	mmc->ops		= &sunxi_mmc_ops;
-	mmc->max_blk_count	= 8192;
-	mmc->max_blk_size	= 4096;
-	mmc->max_segs		= PAGE_SIZE / sizeof(struct sunxi_idma_des);
-	mmc->max_seg_size	= (1 << host->cfg->idma_des_size_bits);
-	mmc->max_req_size	= mmc->max_seg_size * mmc->max_segs;
-	/* 400kHz ~ 52MHz */
-	mmc->f_min		=   400000;
-	mmc->f_max		= 52000000;
-	mmc->caps	       |= MMC_CAP_MMC_HIGHSPEED | MMC_CAP_SD_HIGHSPEED |
-				  MMC_CAP_ERASE | MMC_CAP_SDIO_IRQ;
-
-	/*
-	 * Some H5 devices do not have signal traces precise enough to
-	 * use HS DDR mode for their eMMC chips.
-	 *
-	 * We still enable HS DDR modes for all the other controller
-	 * variants that support them.
-	 */
-	if ((host->cfg->clk_delays || host->use_new_timings) &&
-	    !of_device_is_compatible(pdev->dev.of_node,
-				     "allwinner,sun50i-h5-emmc"))
-		mmc->caps      |= MMC_CAP_1_8V_DDR | MMC_CAP_3_3V_DDR;
-
-	ret = mmc_of_parse(mmc);
-	if (ret)
-		goto error_free_dma;
-
-	/*
-	 * If we don't support delay chains in the SoC, we can't use any
-	 * of the higher speed modes. Mask them out in case the device
-	 * tree specifies the properties for them, which gets added to
-	 * the caps by mmc_of_parse() above.
-	 */
-	if (!(host->cfg->clk_delays || host->use_new_timings)) {
-		mmc->caps &= ~(MMC_CAP_3_3V_DDR | MMC_CAP_1_8V_DDR |
-			       MMC_CAP_1_2V_DDR | MMC_CAP_UHS);
-		mmc->caps2 &= ~MMC_CAP2_HS200;
 	}
 
-	/* TODO: This driver doesn't support HS400 mode yet */
-	mmc->caps2 &= ~MMC_CAP2_HS400;
+	dev_dbg(&pdev->dev, "base:0x%p irq:%u\n", host->reg_base, host->irq);
+	platform_set_drvdata(pdev, mmc);
 
-	ret = sunxi_mmc_init_host(host);
+	ret = mmc_add_host(mmc);
 	if (ret)
 		goto error_free_dma;
 
-	pm_runtime_set_active(&pdev->dev);
-	pm_runtime_set_autosuspend_delay(&pdev->dev, 50);
-	pm_runtime_use_autosuspend(&pdev->dev);
-	pm_runtime_enable(&pdev->dev);
-
-	ret = mmc_add_host(mmc);
-	if (ret)
+	/*fix Unbalanced pm_runtime_enable when async occured.*/
+	dev_pm_set_driver_flags(&mmc->class_dev, DPM_FLAG_NEVER_SKIP);
+	sunxi_show_det_mode(mmc);
+	ret = mmc_create_sys_fs(host, pdev);
+	if (ret) {
+		dev_err(&pdev->dev, "create sys fs failed\n");
 		goto error_free_dma;
+	}
 
-	dev_info(&pdev->dev, "initialized, max. request size: %u KB%s\n",
-		 mmc->max_req_size >> 10,
-		 host->use_new_timings ? ", uses new timings mode" : "");
+	sunxi_mmc_panic_init_ps(NULL);
 
 	return 0;
 
 error_free_dma:
-	dma_free_coherent(&pdev->dev, PAGE_SIZE, host->sg_cpu, host->sg_dma);
+	dma_free_coherent(&pdev->dev, PAGE_SIZE * host->req_page_count, host->sg_cpu,
+			  host->sg_dma);
 error_free_host:
 	mmc_free_host(mmc);
 	return ret;
@@ -1452,74 +2928,333 @@ static int sunxi_mmc_probe(struct platform_device *pdev)
 
 static int sunxi_mmc_remove(struct platform_device *pdev)
 {
-	struct mmc_host	*mmc = platform_get_drvdata(pdev);
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
 	struct sunxi_mmc_host *host = mmc_priv(mmc);
 
 	mmc_remove_host(mmc);
-	pm_runtime_force_suspend(&pdev->dev);
+	if (host->ctl_spec_cap & SUNXI_SC_EN_TIMEOUT_DETECT)
+		cancel_delayed_work_sync(&host->sunxi_timerout_work);
 	disable_irq(host->irq);
-	sunxi_mmc_disable(host);
-	dma_free_coherent(&pdev->dev, PAGE_SIZE, host->sg_cpu, host->sg_dma);
+	sunxi_mmc_reset_host(host);
+
+	mmc_remove_sys_fs(host, pdev);
+
+	if (!IS_ERR(host->supply.vdmmc18sw))   /*SD PMU control*/
+		regulator_disable(host->supply.vdmmc18sw);
+	if (!IS_ERR(host->supply.vdmmc33sw))   /*SD PMU control*/
+		regulator_disable(host->supply.vdmmc33sw);
+	if (!IS_ERR(host->supply.vdmmc))
+		regulator_disable(host->supply.vdmmc);
+	sunxi_mmc_regulator_release_supply(mmc);
+
+	dma_free_coherent(&pdev->dev, PAGE_SIZE * host->req_page_count, host->sg_cpu,
+			  host->sg_dma);
 	mmc_free_host(mmc);
 
 	return 0;
 }
 
-#ifdef CONFIG_PM
-static int sunxi_mmc_runtime_resume(struct device *dev)
+static void sunxi_mmc_regs_save(struct sunxi_mmc_host *host)
+{
+	struct sunxi_mmc_ctrl_regs *bak_regs = &host->bak_regs;
+
+	/*save public register */
+	bak_regs->gctrl = mmc_readl(host, REG_GCTRL);
+	bak_regs->clkc = mmc_readl(host, REG_CLKCR);
+	bak_regs->timeout = mmc_readl(host, REG_TMOUT);
+	bak_regs->buswid = mmc_readl(host, REG_WIDTH);
+	bak_regs->waterlvl = mmc_readl(host, REG_FTRGL);
+	bak_regs->funcsel = mmc_readl(host, REG_FUNS);
+	bak_regs->debugc = mmc_readl(host, REG_DBGC);
+	bak_regs->idmacc = mmc_readl(host, REG_DMAC);
+	bak_regs->dlba = mmc_readl(host, REG_DLBA);
+	bak_regs->imask = mmc_readl(host, REG_IMASK);
+
+	if (host->sunxi_mmc_save_spec_reg)
+		host->sunxi_mmc_save_spec_reg(host);
+	 else
+		dev_warn(mmc_dev(host->mmc), "no spec reg save\n");
+}
+
+static void sunxi_mmc_regs_restore(struct sunxi_mmc_host *host)
+{
+	struct sunxi_mmc_ctrl_regs *bak_regs = &host->bak_regs;
+
+	/*restore public register */
+	mmc_writel(host, REG_GCTRL, bak_regs->gctrl);
+	mmc_writel(host, REG_CLKCR, bak_regs->clkc);
+	mmc_writel(host, REG_TMOUT, bak_regs->timeout);
+	mmc_writel(host, REG_WIDTH, bak_regs->buswid);
+	mmc_writel(host, REG_FTRGL, bak_regs->waterlvl);
+	mmc_writel(host, REG_FUNS, bak_regs->funcsel);
+	mmc_writel(host, REG_DBGC, bak_regs->debugc);
+	mmc_writel(host, REG_DMAC, bak_regs->idmacc);
+	mmc_writel(host, REG_DLBA, bak_regs->dlba);
+	mmc_writel(host, REG_IMASK, bak_regs->imask);
+
+	if (host->sunxi_mmc_restore_spec_reg)
+		host->sunxi_mmc_restore_spec_reg(host);
+	else
+		dev_warn(mmc_dev(host->mmc), "no spec reg restore\n");
+	if (host->sunxi_mmc_set_acmda)
+		host->sunxi_mmc_set_acmda(host);
+}
+
+#if IS_ENABLED(CONFIG_PM)
+
+static int sunxi_mmc_suspend(struct device *dev)
 {
-	struct mmc_host	*mmc = dev_get_drvdata(dev);
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
 	struct sunxi_mmc_host *host = mmc_priv(mmc);
-	int ret;
+	int ret = 0;
+
+	if (mmc) {
+		/*ret = mmc_suspend_host(mmc);*/
+		if (!ret) {
+			if (!IS_ERR(host->supply.vdmmc18sw)) {
+				ret = regulator_disable(host->supply.vdmmc18sw);
+				if (ret) {
+					dev_err(mmc_dev(mmc),
+						"disable vdmmc18sw failed in suspend\n");
+					return ret;
+				}
+			}
 
-	ret = sunxi_mmc_enable(host);
-	if (ret)
-		return ret;
+			/*SD  PMU control*/
+			if (!IS_ERR(host->supply.vdmmc33sw)) {
+				ret = regulator_disable(host->supply.vdmmc33sw);
+				if (ret) {
+					dev_err(mmc_dev(mmc),
+						"disable vdmmc33sw failed in suspend\n");
+					return ret;
+				}
+			}
 
-	sunxi_mmc_init_host(host);
-	sunxi_mmc_set_bus_width(host, mmc->ios.bus_width);
-	sunxi_mmc_set_clk(host, &mmc->ios);
-	enable_irq(host->irq);
+			if (!IS_ERR(host->supply.vdmmc)) {
+				ret = regulator_disable(host->supply.vdmmc);
+				if (ret) {
+					dev_err(mmc_dev(mmc),
+						"disable vdmmc failed in suspend\n");
+					return ret;
+				}
+			}
 
-	return 0;
+
+			if (mmc_card_keep_power(mmc) || host->dat3_imask) {
+				disable_irq(host->irq);
+				sunxi_mmc_regs_save(host);
+
+				clk_disable_unprepare(host->clk_mmc);
+				clk_disable_unprepare(host->clk_ahb);
+
+				if (!IS_ERR(host->clk_rst))
+					reset_control_assert(host->clk_rst);
+
+				if (!IS_ERR(host->pins_sleep)) {
+					ret =
+					    pinctrl_select_state(host->pinctrl,
+								 host->
+								 pins_sleep);
+					if (ret) {
+						dev_err(mmc_dev(mmc),
+							"could not set sleep pins in suspend\n");
+						return ret;
+					}
+				}
+				if (!IS_ERR(host->supply.vqmmc18sw))
+					regulator_disable(host->supply.vqmmc18sw);
+				if (!IS_ERR(host->supply.vqmmc33sw))
+					regulator_disable(host->supply.vqmmc33sw);
+				if (!IS_ERR(mmc->supply.vqmmc))
+					regulator_disable(mmc->supply.vqmmc);
+
+
+				if (!IS_ERR(mmc->supply.vmmc)) {
+					ret =
+					    sunxi_mmc_regulator_set_ocr(mmc,
+								  mmc->supply.
+								  vmmc, 0);
+					return ret;
+				}
+				dev_dbg(mmc_dev(mmc), "dat3_imask %x\n",
+					host->dat3_imask);
+				/*dump_reg(host); */
+			}
+			/*sunxi_mmc_gpio_suspend_cd(mmc);*/
+			/*sunxi_dump_reg(mmc); */
+		}
+	}
+
+	return ret;
 }
 
-static int sunxi_mmc_runtime_suspend(struct device *dev)
+static int sunxi_mmc_resume(struct device *dev)
 {
-	struct mmc_host	*mmc = dev_get_drvdata(dev);
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
 	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	int ret = 0;
+
+	if (mmc) {
+		/*sunxi_mmc_gpio_resume_cd(mmc);*/
+		if (mmc_card_keep_power(mmc) || host->dat3_imask) {
+			if (!IS_ERR(mmc->supply.vmmc)) {
+				ret =
+				    sunxi_mmc_regulator_set_ocr(mmc, mmc->supply.vmmc,
+							  mmc->ios.vdd);
+				if (ret)
+					return ret;
+			}
 
-	/*
-	 * When clocks are off, it's possible receiving
-	 * fake interrupts, which will stall the system.
-	 * Disabling the irq  will prevent this.
-	 */
-	disable_irq(host->irq);
-	sunxi_mmc_reset_host(host);
-	sunxi_mmc_disable(host);
+			if (!IS_ERR(mmc->supply.vqmmc)) {
+				ret = regulator_enable(mmc->supply.vqmmc);
+				if (ret < 0) {
+					dev_err(mmc_dev(mmc),
+						"failed to enable vqmmc regulator\n");
+					return ret;
+				}
+			}
+			/*SD PMU control*/
+			if (!IS_ERR(host->supply.vqmmc33sw)) {
+				ret = regulator_enable(host->supply.vqmmc33sw);
+				if (ret < 0) {
+					dev_err(mmc_dev(mmc),
+						"failed to enable vqmmc33sw regulator\n");
+					return ret;
+				}
+			}
+			/*SD PMU control*/
+			if (!IS_ERR(host->supply.vqmmc18sw)) {
+				ret = regulator_enable(host->supply.vqmmc18sw);
+				if (ret < 0) {
+					dev_err(mmc_dev(mmc),
+						"failed to enable vq18sw regulator\n");
+					return ret;
+				}
+			}
 
-	return 0;
+			if (!IS_ERR(host->pins_default)) {
+				ret =
+				    pinctrl_select_state(host->pinctrl,
+							 host->pins_default);
+				if (ret) {
+					dev_err(mmc_dev(mmc),
+						"could not set default pins in resume\n");
+					return ret;
+				}
+			}
+
+			if (!IS_ERR(host->clk_rst)) {
+				ret = reset_control_deassert(host->clk_rst);
+				if (ret) {
+					dev_err(mmc_dev(mmc), "reset err %d\n",
+						ret);
+					return ret;
+				}
+			}
+
+			ret = clk_prepare_enable(host->clk_ahb);
+			if (ret) {
+				dev_err(mmc_dev(mmc), "Enable ahb clk err %d\n",
+					ret);
+				return ret;
+			}
+			ret = clk_prepare_enable(host->clk_mmc);
+			if (ret) {
+				dev_err(mmc_dev(mmc), "Enable mmc clk err %d\n",
+					ret);
+				return ret;
+			}
+
+			host->ferror = sunxi_mmc_init_host(mmc);
+			if (host->ferror)
+				return -1;
+
+			sunxi_mmc_regs_restore(host);
+			host->ferror = sunxi_mmc_update_clk(host);
+			if (host->ferror)
+				return -1;
+
+			enable_irq(host->irq);
+			dev_info(mmc_dev(mmc), "dat3_imask %x\n",
+				 host->dat3_imask);
+			/*dump_reg(host); */
+		}
+		/*enable card detect pin power*/
+		if (!IS_ERR(host->supply.vdmmc)) {
+			ret = regulator_enable(host->supply.vdmmc);
+			if (ret < 0) {
+				dev_err(mmc_dev(mmc),
+					"failed to enable vdmmc regulator\n");
+				return ret;
+			}
+		}
+		/*SD PMU control*/
+		if (!IS_ERR(host->supply.vdmmc33sw)) {
+			ret = regulator_enable(host->supply.vdmmc33sw);
+			if (ret < 0) {
+				dev_err(mmc_dev(mmc),
+					"failed to enable vdmmc33sw regulator\n");
+				return ret;
+			}
+		}
+		/*SD PMU control*/
+		if (!IS_ERR(host->supply.vdmmc18sw)) {
+			ret = regulator_enable(host->supply.vdmmc18sw);
+			if (ret < 0) {
+				dev_err(mmc_dev(mmc),
+					"failed to enable vdmmc18sw regulator\n");
+				return ret;
+			}
+		}
+
+
+		/*sunxi_dump_reg(mmc); */
+		/*ret = mmc_resume_host(mmc);*/
+	}
+
+	return ret;
 }
-#endif
 
-static const struct dev_pm_ops sunxi_mmc_pm_ops = {
-	SET_RUNTIME_PM_OPS(sunxi_mmc_runtime_suspend,
-			   sunxi_mmc_runtime_resume,
-			   NULL)
+static const struct dev_pm_ops sunxi_mmc_pm = {
+	.suspend = sunxi_mmc_suspend,
+	.resume = sunxi_mmc_resume,
 };
 
+#define sunxi_mmc_pm_ops (&sunxi_mmc_pm)
+
+#else				/* CONFIG_PM */
+
+#define sunxi_mmc_pm_ops NULL
+
+#endif				/* CONFIG_PM */
+
+void sunxi_shutdown_mmc(struct platform_device *pdev)
+{
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	if (host->sunxi_mmc_shutdown)
+		host->sunxi_mmc_shutdown(pdev);
+}
+
 static struct platform_driver sunxi_mmc_driver = {
 	.driver = {
-		.name	= "sunxi-mmc",
-		.of_match_table = of_match_ptr(sunxi_mmc_of_match),
-		.pm = &sunxi_mmc_pm_ops,
-	},
-	.probe		= sunxi_mmc_probe,
-	.remove		= sunxi_mmc_remove,
+		   .name = "sunxi-mmc",
+		   .of_match_table = of_match_ptr(sunxi_mmc_of_match),
+		   .pm = sunxi_mmc_pm_ops,
+		   },
+	.probe = sunxi_mmc_probe,
+	.remove = sunxi_mmc_remove,
+	.shutdown = sunxi_shutdown_mmc,
 };
+
 module_platform_driver(sunxi_mmc_driver);
 
 MODULE_DESCRIPTION("Allwinner's SD/MMC Card Controller Driver");
 MODULE_LICENSE("GPL v2");
-MODULE_AUTHOR("David Lanzendörfer <david.lanzendoerfer@o2s.ch>");
+MODULE_AUTHOR("David Lanzend�rfer <david.lanzendoerfer@o2s.ch>");
 MODULE_ALIAS("platform:sunxi-mmc");
+
+
diff --git a/drivers/mmc/host/sunxi-mmc.h b/drivers/mmc/host/sunxi-mmc.h
new file mode 100644
index 000000000..126944e3b
--- /dev/null
+++ b/drivers/mmc/host/sunxi-mmc.h
@@ -0,0 +1,507 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+
+#include <linux/clk.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/pinctrl/pinctrl-sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/slot-gpio.h>
+
+#include "../core/core.h"
+
+#ifndef __SUNXI_MMC_H__
+#define __SUNXI_MMC_H__
+
+#define DRIVER_NAME "sunxi-mmc"
+#define DRIVER_RIVISION "v4.21 2021-11-18 10:02"
+#define DRIVER_VERSION "SD/MMC/SDIO Host Controller Driver(" DRIVER_RIVISION ")"
+
+#if defined CONFIG_FPGA_V4_PLATFORM || defined CONFIG_FPGA_V7_PLATFORM
+#define MMC_FPGA
+#endif
+
+
+/* register offset definitions */
+#define SDXC_REG_GCTRL	(0x00)	/* SMC Global Control Register */
+#define SDXC_REG_CLKCR	(0x04)	/* SMC Clock Control Register */
+#define SDXC_REG_TMOUT	(0x08)	/* SMC Time Out Register */
+#define SDXC_REG_WIDTH	(0x0C)	/* SMC Bus Width Register */
+#define SDXC_REG_BLKSZ	(0x10)	/* SMC Block Size Register */
+#define SDXC_REG_BCNTR	(0x14)	/* SMC Byte Count Register */
+#define SDXC_REG_CMDR	(0x18)	/* SMC Command Register */
+#define SDXC_REG_CARG	(0x1C)	/* SMC Argument Register */
+#define SDXC_REG_RESP0	(0x20)	/* SMC Response Register 0 */
+#define SDXC_REG_RESP1	(0x24)	/* SMC Response Register 1 */
+#define SDXC_REG_RESP2	(0x28)	/* SMC Response Register 2 */
+#define SDXC_REG_RESP3	(0x2C)	/* SMC Response Register 3 */
+#define SDXC_REG_IMASK	(0x30)	/* SMC Interrupt Mask Register */
+#define SDXC_REG_MISTA	(0x34)	/* SMC Masked Interrupt Status Register */
+#define SDXC_REG_RINTR	(0x38)	/* SMC Raw Interrupt Status Register */
+#define SDXC_REG_STAS	(0x3C)	/* SMC Status Register */
+#define SDXC_REG_FTRGL	(0x40)	/* SMC FIFO Threshold Watermark Registe */
+#define SDXC_REG_FUNS	(0x44)	/* SMC Function Select Register */
+#define SDXC_REG_CBCR	(0x48)	/* SMC CIU Byte Count Register */
+#define SDXC_REG_BBCR	(0x4C)	/* SMC BIU Byte Count Register */
+#define SDXC_REG_DBGC	(0x50)	/* SMC Debug Enable Register */
+#define SDXC_REG_A12A	(0x58)	/*auto cmd12 arg*/
+#define SDXC_REG_HWRST	(0x78)	/* SMC Card Hardware Reset for Register */
+#define SDXC_REG_DMAC	(0x80)	/* SMC IDMAC Control Register */
+#define SDXC_REG_DLBA	(0x84)	/* SMC IDMAC Descriptor List Base Addre */
+#define SDXC_REG_IDST	(0x88)	/* SMC IDMAC Status Register */
+#define SDXC_REG_IDIE	(0x8C)	/* SMC IDMAC Interrupt Enable Register */
+#define SDXC_REG_CHDA	(0x90)
+#define SDXC_REG_CBDA	(0x94)
+
+
+#define SDXC_REG_FIFO	(0x200)
+
+#define mmc_readl(host, reg) \
+	readl((host)->reg_base + SDXC_##reg)
+#define mmc_writel(host, reg, value) \
+	writel((value), (host)->reg_base + SDXC_##reg)
+
+/* global control register bits */
+#define SDXC_SOFT_RESET			BIT(0)
+#define SDXC_FIFO_RESET			BIT(1)
+#define SDXC_DMA_RESET			BIT(2)
+#define SDXC_INTERRUPT_ENABLE_BIT	BIT(4)
+#define SDXC_DMA_ENABLE_BIT		BIT(5)
+#define SDXC_DEBOUNCE_ENABLE_BIT	BIT(8)
+#define SDXC_POSEDGE_LATCH_DATA		BIT(9)
+#define SDXC_DDR_MODE			BIT(10)
+#define SDXC_MEMORY_ACCESS_DONE		BIT(29)
+#define SDXC_ACCESS_DONE_DIRECT		BIT(30)
+#define SDXC_ACCESS_BY_AHB		BIT(31)
+#define SDXC_ACCESS_BY_DMA		(0 << 31)
+#define SDXC_HARDWARE_RESET \
+	(SDXC_SOFT_RESET | SDXC_FIFO_RESET | SDXC_DMA_RESET)
+
+/* clock control bits */
+#define SDXC_CARD_CLOCK_ON		BIT(16)
+#define SDXC_LOW_POWER_ON		BIT(17)
+#define SDXC_MASK_DATA0			BIT(31)
+
+/* bus width */
+#define SDXC_WIDTH1			0
+#define SDXC_WIDTH4			1
+#define SDXC_WIDTH8			2
+
+/* smc command bits */
+#define SDXC_RESP_EXPECT		BIT(6)
+#define SDXC_LONG_RESPONSE		BIT(7)
+#define SDXC_CHECK_RESPONSE_CRC		BIT(8)
+#define SDXC_DATA_EXPECT		BIT(9)
+#define SDXC_WRITE			BIT(10)
+#define SDXC_SEQUENCE_MODE		BIT(11)
+#define SDXC_SEND_AUTO_STOP		BIT(12)
+#define SDXC_WAIT_PRE_OVER		BIT(13)
+#define SDXC_STOP_ABORT_CMD		BIT(14)
+#define SDXC_SEND_INIT_SEQUENCE		BIT(15)
+#define SDXC_UPCLK_ONLY			BIT(21)
+#define SDXC_READ_CEATA_DEV		BIT(22)
+#define SDXC_CCS_EXPECT			BIT(23)
+#define SDXC_ENABLE_BIT_BOOT		BIT(24)
+#define SDXC_ALT_BOOT_OPTIONS		BIT(25)
+#define SDXC_BOOT_ACK_EXPECT		BIT(26)
+#define SDXC_BOOT_ABORT			BIT(27)
+#define SDXC_VOLTAGE_SWITCH	        BIT(28)
+#define SDXC_USE_HOLD_REGISTER	        BIT(29)
+#define SDXC_START			BIT(31)
+
+/* interrupt bits */
+#define SDXC_RESP_ERROR			BIT(1)
+#define SDXC_COMMAND_DONE		BIT(2)
+#define SDXC_DATA_OVER			BIT(3)
+#define SDXC_TX_DATA_REQUEST		BIT(4)
+#define SDXC_RX_DATA_REQUEST		BIT(5)
+#define SDXC_RESP_CRC_ERROR		BIT(6)
+#define SDXC_DATA_CRC_ERROR		BIT(7)
+#define SDXC_RESP_TIMEOUT		BIT(8)
+#define SDXC_DATA_TIMEOUT		BIT(9)
+#define SDXC_VOLTAGE_CHANGE_DONE	BIT(10)
+#define SDXC_FIFO_RUN_ERROR		BIT(11)
+#define SDXC_HARD_WARE_LOCKED		BIT(12)
+#define SDXC_START_BIT_ERROR		BIT(13)
+#define SDXC_AUTO_COMMAND_DONE		BIT(14)
+#define SDXC_END_BIT_ERROR		BIT(15)
+#define SDXC_SDIO_INTERRUPT		BIT(16)
+#define SDXC_CARD_INSERT		BIT(30)
+#define SDXC_CARD_REMOVE		BIT(31)
+#define SDXC_INTERRUPT_ERROR_BIT \
+	(SDXC_RESP_ERROR | SDXC_RESP_CRC_ERROR | SDXC_DATA_CRC_ERROR | \
+	 SDXC_RESP_TIMEOUT | SDXC_DATA_TIMEOUT | SDXC_FIFO_RUN_ERROR | \
+	 SDXC_HARD_WARE_LOCKED | SDXC_START_BIT_ERROR | SDXC_END_BIT_ERROR)
+#define SDXC_INTERRUPT_CMD_ERROR_BIT \
+	(SDXC_RESP_ERROR | SDXC_RESP_CRC_ERROR | SDXC_RESP_TIMEOUT)
+#define SDXC_INTERRUPT_DONE_BIT \
+	(SDXC_AUTO_COMMAND_DONE | SDXC_DATA_OVER | \
+	 SDXC_COMMAND_DONE | SDXC_VOLTAGE_CHANGE_DONE)
+#define SDXC_INTERRUPT_DDONE_BIT \
+	(SDXC_AUTO_COMMAND_DONE | SDXC_DATA_OVER)
+#define SDXC_SWITCH_DDONE_BIT \
+	(SDXC_VOLTAGE_CHANGE_DONE | SDXC_COMMAND_DONE)
+
+
+/* status */
+#define SDXC_RXWL_FLAG			BIT(0)
+#define SDXC_TXWL_FLAG			BIT(1)
+#define SDXC_FIFO_EMPTY			BIT(2)
+#define SDXC_FIFO_FULL			BIT(3)
+#define SDXC_CARD_PRESENT		BIT(8)
+#define SDXC_CARD_DATA_BUSY		BIT(9)
+#define SDXC_DATA_FSM_BUSY		BIT(10)
+#define SDXC_DMA_REQUEST		BIT(31)
+#define SDXC_FIFO_SIZE			16
+
+/* Function select */
+#define SDXC_CEATA_ON			(0xceaa << 16)
+#define SDXC_SEND_IRQ_RESPONSE		BIT(0)
+#define SDXC_SDIO_READ_WAIT		BIT(1)
+#define SDXC_ABORT_READ_DATA		BIT(2)
+#define SDXC_SEND_CCSD			BIT(8)
+#define SDXC_SEND_AUTO_STOPCCSD		BIT(9)
+#define SDXC_CEATA_DEV_IRQ_ENABLE	BIT(10)
+
+/* IDMA controller bus mod bit field */
+#define SDXC_IDMAC_SOFT_RESET		BIT(0)
+#define SDXC_IDMAC_FIX_BURST		BIT(1)
+#define SDXC_IDMAC_IDMA_ON		BIT(7)
+#define SDXC_IDMAC_REFETCH_DES		BIT(31)
+
+/* IDMA status bit field */
+#define SDXC_IDMAC_TRANSMIT_INTERRUPT		BIT(0)
+#define SDXC_IDMAC_RECEIVE_INTERRUPT		BIT(1)
+#define SDXC_IDMAC_FATAL_BUS_ERROR		BIT(2)
+#define SDXC_IDMAC_DESTINATION_INVALID		BIT(4)
+#define SDXC_IDMAC_CARD_ERROR_SUM		BIT(5)
+#define SDXC_IDMAC_NORMAL_INTERRUPT_SUM		BIT(8)
+#define SDXC_IDMAC_ABNORMAL_INTERRUPT_SUM	BIT(9)
+#define SDXC_IDMAC_HOST_ABORT_INTERRUPT		BIT(10)
+#define SDXC_IDMAC_IDLE				(0 << 13)
+#define SDXC_IDMAC_SUSPEND			(1 << 13)
+#define SDXC_IDMAC_DESC_READ			(2 << 13)
+#define SDXC_IDMAC_DESC_CHECK			(3 << 13)
+#define SDXC_IDMAC_READ_REQUEST_WAIT		(4 << 13)
+#define SDXC_IDMAC_WRITE_REQUEST_WAIT		(5 << 13)
+#define SDXC_IDMAC_READ				(6 << 13)
+#define SDXC_IDMAC_WRITE			(7 << 13)
+#define SDXC_IDMAC_DESC_CLOSE			(8 << 13)
+
+/*
+* If the idma-des-size-bits of property is ie 13, bufsize bits are:
+*  Bits  0-12: buf1 size
+*  Bits 13-25: buf2 size
+*  Bits 26-31: not used
+* Since we only ever set buf1 size, we can simply store it directly.
+*/
+#define SDXC_IDMAC_DES0_DIC	BIT(1)	/* disable interrupt on completion */
+#define SDXC_IDMAC_DES0_LD	BIT(2)	/* last descriptor */
+#define SDXC_IDMAC_DES0_FD	BIT(3)	/* first descriptor */
+#define SDXC_IDMAC_DES0_CH	BIT(4)	/* chain mode */
+#define SDXC_IDMAC_DES0_ER	BIT(5)	/* end of ring */
+#define SDXC_IDMAC_DES0_CES	BIT(30)	/* card error summary */
+#define SDXC_IDMAC_DES0_OWN	BIT(31)	/* 1-idma owns it, 0-host owns it */
+
+void sunxi_dump_reg(struct mmc_host *mmc);
+
+#if 0
+#define sunxi_r_op(host, op) (\
+{\
+	int __ret_val = 0;\
+	struct mmc_host	*mmc = host->mmc;\
+	clk_disable_unprepare(host->clk_mmc);\
+	dev_dbg(mmc_dev(mmc), "%s, %d\n", __FUNCTION__, __LINE__);\
+	sunxi_dump_reg(mmc);\
+	op;\
+	__ret_val = clk_prepare_enable(host->clk_mmc);\
+	if (__ret_val) {\
+		dev_err(mmc_dev(mmc), "Enable mmc clk err %d\n", __ret_val);\
+	} \
+	__ret_val;\
+} \
+)
+#else
+#define sunxi_r_op(__h, __op) (\
+{\
+	int __ret_val = 0;\
+	struct mmc_host	*mmc = (__h)->mmc;\
+	clk_disable_unprepare((__h)->clk_mmc);\
+	dev_dbg(mmc_dev(mmc), "%s, %d\n", __FUNCTION__, __LINE__);\
+	__op;\
+	__ret_val  = clk_prepare_enable((__h)->clk_mmc);\
+	if (__ret_val) {\
+		dev_err(mmc_dev(mmc), "Enable mmc clk err %d\n", __ret_val);\
+	} \
+	__ret_val;\
+} \
+)
+#endif
+
+enum sunxi_cookie {
+	COOKIE_UNMAPPED,
+	COOKIE_PRE_MAPPED,	/* mapped by sunxi_mmc_pre_req() */
+	COOKIE_MAPPED,		/* mapped by sunxi_mmc_request() or retry*/
+};
+
+struct sunxi_idma_des {
+	u32 config;
+	u32 buf_size;
+	u32 buf_addr_ptr1;
+	u32 buf_addr_ptr2;
+};
+
+struct sunxi_mmc_ctrl_regs {
+	u32 gctrl;
+	u32 clkc;
+	u32 timeout;
+	u32 buswid;
+	u32 waterlvl;
+	u32 funcsel;
+	u32 debugc;
+	u32 idmacc;
+	u32 dlba;
+	u32 imask;
+};
+
+struct sunxi_mmc_host_perf{
+	ktime_t start;
+	int64_t rbytes;
+	int64_t wbytes;
+	ktime_t rtime;
+	ktime_t wtime;
+
+	/***use to compute the time no include busy***/
+	int64_t wbytestran;
+	ktime_t wtimetran;
+};
+
+struct sunxi_mmc_supply {
+	struct regulator *vmmc;		/* Card power supply */
+	struct regulator *vqmmc;	/* Optional Vccq supply */
+	struct regulator *vdmmc;	/*Optional card detect pin supply*/
+	struct regulator *vdmmc33sw;	/* SD card PMU control*/
+	struct regulator *vdmmc18sw;
+	struct regulator *vqmmc33sw;	/* SD card PMU control*/
+	struct regulator *vqmmc18sw;
+};
+
+struct sunxi_mmc_host {
+	struct mmc_host *mmc;
+	struct reset_control *reset;
+
+	/* IO mapping base */
+	void __iomem *reg_base;
+
+	/* clock management */
+	struct clk *clk_ahb;
+	struct clk *clk_mmc;
+	struct reset_control *clk_rst;
+
+	int (*sunxi_mmc_clk_set_rate)(struct sunxi_mmc_host *host,
+				struct mmc_ios *ios);
+	int crypt_flag;
+
+	/* irq */
+	spinlock_t lock;
+	int irq;
+	u32 int_sum;
+	u32 sdio_imask;
+
+	/* dma */
+	u32 req_page_count;
+	u32 idma_des_size_bits;
+	dma_addr_t sg_dma;
+	void *sg_cpu;
+	bool wait_dma;
+	u32 dma_tl;
+	u64 dma_mask;
+
+	void (*sunxi_mmc_thld_ctl)(struct sunxi_mmc_host *host,
+				 struct mmc_ios *ios,
+				    struct mmc_data *data);
+
+	struct mmc_request *mrq;
+	struct mmc_request *mrq_busy;
+	struct mmc_request *mrq_retry;
+	struct mmc_request *manual_stop_mrq;
+	int ferror;
+
+	u32 power_on;
+	u32 time_pwroff_ms;
+
+	/* pinctrl handles */
+	struct pinctrl *pinctrl;
+	struct pinctrl_state *pins_default;
+	struct pinctrl_state *pins_bias_1v8;
+	struct pinctrl_state *pins_sleep;
+	struct pinctrl_state *pins_uart_jtag;
+
+	/*sys node */
+	struct device_attribute maual_insert;
+	struct device_attribute *dump_register;
+	struct device_attribute dump_clk_dly;
+	struct device_attribute host_sample_dly;
+	struct device_attribute host_ds_dly;
+	struct device_attribute host_send_status;
+	void (*sunxi_mmc_dump_dly_table)(struct sunxi_mmc_host *host);
+
+	/* backup register structrue */
+	struct sunxi_mmc_ctrl_regs bak_regs;
+	void (*sunxi_mmc_save_spec_reg)(struct sunxi_mmc_host *host);
+	void (*sunxi_mmc_restore_spec_reg)(struct sunxi_mmc_host *host);
+	void (*sunxi_mmc_set_acmda)(struct sunxi_mmc_host *host);
+	void (*sunxi_mmc_shutdown)(struct platform_device *pdev);
+	int (*sunxi_mmc_oclk_en)(struct sunxi_mmc_host *host, u32 oclk_en);
+	int (*sunxi_mmc_updata_pha)(struct sunxi_mmc_host *host,
+			struct mmc_command *cmd, struct mmc_data *data);
+	void (*sunxi_mmc_on_off_emce)(struct sunxi_mmc_host *host,
+			u32 en_crypt, u32 ac_mode, u32 en_emce, int data_len,
+			int bypass, int task_load);
+	bool (*sunxi_mmc_hw_busy)(struct sunxi_mmc_host *host);
+	int (*sunxi_mmc_dat0_busy)(struct sunxi_mmc_host *host);
+
+	/*really controller id,no logic id */
+	int phy_index;
+
+	u32 dat3_imask;
+
+	/*no wait busy if wrtie end, only for customer need */
+#define NO_WBUSY_WR_END  0x1
+#define NO_REINIT_SHUTDOWN			   0x2
+#define CARD_PWR_GPIO_HIGH_ACTIVE	   0x4
+#define SUNXI_SC_EN_RETRY					0x8
+	/**If set this bit,when use sunxi_check_r1_ready_may_sleep,
+	*we will wait 0xFFFFFFFF ms, for debug use
+	*it is no meant on linux4.4
+	*/
+#define SUNXI_R1B_WAIT_MAX					0x10
+
+/*#define SUNXI_MANUAL_READ_DATA_TIMEOUT      0x20*/
+/*
+*Disable linux kernel native broken cd function,use host  defined.
+*Host defined cd function only report true when it detect cd pin change.
+*If not detect cd pin change,it return false.
+*We use it to deal with some bad card which cannot init at all
+*But host defined cd function has a disadvantage that it may not detect card
+*If card is inserted too often.
+*/
+#define SUNXI_DIS_KER_NAT_CD			0x40
+
+/*#define SUNXI_NO_ERASE				0x80*/
+#define SUNXI_SC_EN_RETRY_CMD			0x100
+#define SUNXI_SC_EN_TIMEOUT_DETECT		0x200
+/*control specal function control,for customer need*/
+	u32 ctl_spec_cap;
+
+#define MMC_SUNXI_CAP3_DAT3_DET	(1 << 0)
+#define MMC_SUNXI_CAP3_CD_USED_24M	(1 << 1)
+	u32 sunxi_caps3;
+
+	struct sunxi_mmc_supply supply;
+	int card_pwr_gpio;
+
+	u32 retry_cnt;
+	u32 errno_retry;
+	int (*sunxi_mmc_judge_retry)(struct sunxi_mmc_host *host,
+				      struct mmc_command *cmd, u32 rcnt,
+				      u32 errno, void *other);
+	int sunxi_samp_dl;
+	int sunxi_ds_dl;
+
+	u32 sunxi_ds_dl_cnt;
+	u32 sunxi_samp_dl_cnt;
+	/*only use for MMC_CAP_NEEDS_POLL and SUNXI_DIS_KER_NAT_CD is on*/
+	u32 present;
+	u32 voltage_switching;
+
+	bool perf_enable;
+	struct device_attribute host_perf;
+	struct sunxi_mmc_host_perf perf;
+	struct device_attribute filter_sector_perf;
+	struct device_attribute filter_speed_perf;
+	unsigned int filter_sector;
+	unsigned int filter_speed;
+	struct device_attribute host_mwr;
+
+	void *version_priv_dat;
+
+	/*auto command 23 operate*/
+	/*set auto cmd 23 val and enable bit,or get respose*/
+	bool (*sunxi_mmc_opacmd23)(struct sunxi_mmc_host *host, bool set, u32 arg, u32 *rep);
+	/*sample fifo contral */
+	bool sfc_dis;
+
+	/*des phy address shift,use for over 4G phy ddrest*/
+	size_t des_addr_shift;
+	char name[32];
+	struct delayed_work sunxi_timerout_work;
+};
+
+/*the struct as the the kernel version changes,which copy form core/slot-gpio.c*/
+struct mmc_gpio {
+	struct gpio_desc *ro_gpio;
+	struct gpio_desc *cd_gpio;
+	bool override_ro_active_level;
+	bool override_cd_active_level;
+	irqreturn_t (*cd_gpio_isr)(int irq, void *dev_id);
+	char *ro_label;
+	char cd_label[0];
+};
+
+/*use to check ddr mode,not include hs400*/
+#define sunxi_mmc_ddr_timing(it)	\
+	(((it) == MMC_TIMING_UHS_DDR50) || ((it) == MMC_TIMING_MMC_DDR52))
+
+
+/*Transfer core definition here*/
+/*core.h*/
+#define MMC_DATA_STREAM			BIT(10)
+/*host.h cap2*/
+#define MMC_CAP2_CACHE_CTRL	(1 << 1)	/* Allow cache control */
+#define MMC_CAP2_PACKED_RD	(1 << 12)	/* Allow packed read */
+#define MMC_CAP2_PACKED_WR	(1 << 13)	/* Allow packed write */
+#define MMC_CAP2_PACKED_CMD	(MMC_CAP2_PACKED_RD | \
+						 MMC_CAP2_PACKED_WR)
+#define MMC_CAP2_HC_ERASE_SZ	(1 << 9)	/* High-capacity erase size */
+
+void sunxi_mmc_set_a12a(struct sunxi_mmc_host *host);
+void sunxi_mmc_do_shutdown_com(struct platform_device *pdev);
+extern int mmc_send_status(struct mmc_card *card, u32 *status);
+extern void mmc_set_bus_width(struct mmc_host *host, unsigned int width);
+extern int mmc_flush_cache(struct mmc_card *);
+extern int sunxi_sel_pio_mode(struct pinctrl *pinctrl, u32 pm_sel);
+
+#endif
diff --git a/drivers/mmc/host/sunxi-smhc.c b/drivers/mmc/host/sunxi-smhc.c
new file mode 100644
index 000000000..24ab013a3
--- /dev/null
+++ b/drivers/mmc/host/sunxi-smhc.c
@@ -0,0 +1,1794 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#ifdef CONFIG_ARCH_SUN8IW10P1
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/io.h>
+#include <linux/device.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/err.h>
+
+#include <linux/clk.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+#include <linux/regulator/consumer.h>
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/slot-gpio.h>
+
+#include "sunxi-smhc.h"
+#include "sunxi-mmc-v5px.h"
+#include "sunxi-mmc-debug.h"
+#include "sunxi-mmc-export.h"
+
+#ifdef CONFIG_REGULATOR
+/**
+ * mmc_regulator_get_ocrmask - return mask of supported voltages
+ * @supply: regulator to use
+ *
+ * This returns either a negative errno, or a mask of voltages that
+ * can be provided to MMC/SD/SDIO devices using the specified voltage
+ * regulator.  This would normally be called before registering the
+ * MMC host adapter.
+ */
+static int mmc_regulator_get_ocrmask(struct regulator *supply)
+{
+	int			result = 0;
+	int			count;
+	int			i;
+	int			vdd_uV;
+	int			vdd_mV;
+
+	count = regulator_count_voltages(supply);
+	if (count < 0)
+		return count;
+
+	for (i = 0; i < count; i++) {
+		vdd_uV = regulator_list_voltage(supply, i);
+		if (vdd_uV <= 0)
+			continue;
+
+		vdd_mV = vdd_uV / 1000;
+		result |= mmc_vddrange_to_ocrmask(vdd_mV, vdd_mV);
+	}
+
+	if (!result) {
+		vdd_uV = regulator_get_voltage(supply);
+		if (vdd_uV <= 0)
+			return vdd_uV;
+
+		vdd_mV = vdd_uV / 1000;
+		result = mmc_vddrange_to_ocrmask(vdd_mV, vdd_mV);
+	}
+
+	return result;
+}
+
+/**
+ * mmc_regulator_set_ocr - set regulator to match host->ios voltage
+ * @mmc: the host to regulate
+ * @supply: regulator to use
+ * @vdd_bit: zero for power off, else a bit number (host->ios.vdd)
+ *
+ * Returns zero on success, else negative errno.
+ *
+ * MMC host drivers may use this to enable or disable a regulator using
+ * a particular supply voltage.  This would normally be called from the
+ * set_ios() method.
+ */
+int sunxi_mmc_regulator_set_ocr(struct mmc_host *mmc,
+			struct regulator *supply,
+			unsigned short vdd_bit)
+{
+	int			result = 0;
+	/*int			min_uV, max_uV;*/
+
+	if (vdd_bit) {
+		/*sunxi platform avoid set vcc voltage*/
+		/*mmc_ocrbitnum_to_vdd(vdd_bit, &min_uV, &max_uV);*/
+
+		/*result = regulator_set_voltage(supply, min_uV, max_uV);*/
+		if (result == 0 && !mmc->regulator_enabled) {
+			result = regulator_enable(supply);
+			if (!result)
+				mmc->regulator_enabled = true;
+		}
+	} else if (mmc->regulator_enabled) {
+		result = regulator_disable(supply);
+		if (result == 0)
+			mmc->regulator_enabled = false;
+	}
+
+	if (result)
+		dev_err(mmc_dev(mmc),
+			"could not set regulator OCR (%d)\n", result);
+	return result;
+}
+#else
+static inline int mmc_regulator_get_ocrmask(struct regulator *supply)
+{
+	return 0;
+}
+static inline int sunxi_mmc_regulator_set_ocr(struct mmc_host *mmc,
+			struct regulator *supply,
+	i		unsigned short vdd_bit)
+{
+	return 0;
+}
+#endif
+
+static int sunxi_wait_bit_clr(struct sunxi_mmc_host *smc_host, u32 reg_add,
+			      u32 bit_map, s8 *reg_add_str, s8 *bit_map_str,
+			      u32 timeout_ms)
+{
+	unsigned long expire = 0;
+	u32 tmp = 0;
+	s32 ret = 0;
+
+	expire = jiffies + msecs_to_jiffies(timeout_ms);	/* 1ms timeout*/
+	do {
+		/*SMC_DBG(smc_host,"Wait reg %s(%x),bit %s(%x)\n",
+		 *reg_add_str,reg_add,bit_map_str,bit_map);
+		 */
+		tmp = smhc_readl(smc_host, reg_add);
+	} while (time_before(jiffies, expire) && (tmp & bit_map));
+
+	tmp = smhc_readl(smc_host, reg_add);
+	if (tmp & bit_map) {
+		dev_err(mmc_dev(smc_host->mmc),
+			"Wait reg %s(%x),bit %s(%x) %d ms timeout\n",
+			reg_add_str, reg_add, bit_map_str, bit_map, timeout_ms);
+		ret = 1;
+	} else {
+		ret = 0;
+	}
+
+	return ret;
+}
+
+static int sunxi_mmc_init_host(struct mmc_host *mmc)
+{
+	u32 tmp;
+	struct sunxi_mmc_host *smc_host = mmc_priv(mmc);
+
+	dev_dbg(mmc_dev(mmc), "MMC Driver init host p%d\n",
+		smc_host->phy_index);
+
+	/*reset control*/
+	tmp = smhc_readl(smc_host, SMHC_RST_CLK_CTRL);
+	smhc_writel(smc_host, SMHC_RST_CLK_CTRL, tmp | ResetAll);
+	/*wait reset done*/
+	if (sunxi_wait_bit_clr(smc_host,
+			       SMHC_RST_CLK_CTRL, ResetAll,
+			       "SMHC_RST_CLK_CTRL", "ResetAll", 1)) {
+		return -1;
+	}
+
+	smhc_writel(smc_host, SMHC_INT_STA_EN, 0xffffffff);
+	smhc_writel(smc_host, SMHC_INT_STA, 0xffffffff);
+	dev_dbg(mmc_dev(mmc), "int sta %x\n",
+		smhc_readl(smc_host, SMHC_INT_STA));
+
+	/*Set Data & Response Timeout Value*/
+#define  SMC_DATA_TIMEOUT	  0xffffffU
+#define  SMC_RESP_TIMEOUT	  0xff
+	smhc_writel(smc_host, SMHC_TO_CTRL2,
+		    (SMC_DATA_TIMEOUT << 8) | SMC_RESP_TIMEOUT);
+
+	/*stop clock at block gap, bit8*/
+	tmp = smhc_readl(smc_host, SMHC_CTRL3);
+	smhc_writel(smc_host, SMHC_CTRL3, tmp | StopReadClkAtBlkGap);
+
+	/*disable dat3 int*/
+	if (smc_host->dat3_imask) {
+		/*enable data3 detect*/
+		smhc_clr_bit(smc_host, SMHC_CTRL3, SWDebounceMode);
+		smhc_set_bit(smc_host, SMHC_CTRL3, CdDat3En);
+
+		/*enable data3 detect int*/
+		smhc_set_bit(smc_host, SMHC_INT_STA_EN,
+			     CardRemoveInt | CardInsertInt);
+		smhc_set_bit(smc_host, SMHC_INT_SIG_EN,
+			     CardRemoveInt | CardInsertInt);
+	} else {
+		smhc_clr_bit(smc_host, SMHC_INT_STA_EN,
+			     CardRemoveInt | CardInsertInt);
+		smhc_clr_bit(smc_host, SMHC_INT_SIG_EN,
+			     CardRemoveInt | CardInsertInt);
+	}
+
+/*
+*dumphex32(smc_host, "mmc",
+			IOMEM(IO_ADDRESS(SMHC_BASE_ADDR)), 0x100);
+*/
+/*dumphex32(smc_host, "gpio", IO_ADDRESS(SUNXI_PIO_BASE), 0x120);
+*/
+	return 0;
+
+}
+
+static void sunxi_mmc_init_idma_des(struct sunxi_mmc_host *smc_host,
+				    struct mmc_data *data)
+{
+	struct sdhc_idma_des *pdes = (struct sdhc_idma_des *)smc_host->sg_cpu;
+/*    struct sdhc_idma_des* pdes_pa =
+	*(struct sdhc_idma_des*)smc_host->sg_dma;
+	*/
+	struct scatterlist *sg = NULL;
+	u32 i = 0;
+
+	for_each_sg(data->sg, sg, data->sg_len, i) {
+		memset((void *)(&pdes[i]), 0, sizeof(struct sdhc_idma_des));
+		pdes[i].valid = 1;
+		pdes[i].end = 0;
+		pdes[i].int_en = 0;
+		pdes[i].act = ACT_TRANS;
+		pdes[i].length = sg->length;
+		pdes[i].addr = sg_dma_address(sg);
+	}
+
+	pdes[i - 1].end = 1;
+	pdes[i - 1].int_en = 1;
+/******************************************************/
+	smp_wmb();
+	dev_dbg(mmc_dev(smc_host->mmc), "sg len %d end des index %d\n",
+		data->sg_len, i - 1);
+
+	for_each_sg(data->sg, sg, data->sg_len, i) {
+		dev_dbg(mmc_dev(smc_host->mmc),
+			"sg %d, des[%d](%08x): [0] = %08x, [1] = %08x\n", i, i,
+			(u32) &pdes[i], (u32) ((u32 *) &pdes[i])[0],
+			(u32) ((u32 *) &pdes[i])[1]);
+	}
+}
+
+static enum dma_data_direction sunxi_mmc_get_dma_dir(struct mmc_data *data)
+{
+	if (data->flags & MMC_DATA_WRITE)
+		return DMA_TO_DEVICE;
+	else
+		return DMA_FROM_DEVICE;
+}
+
+static int sunxi_mmc_map_dma(struct sunxi_mmc_host *host, struct mmc_data *data)
+{
+	u32 i, dma_len;
+	struct scatterlist *sg;
+
+	dma_len = dma_map_sg(mmc_dev(host->mmc), data->sg, data->sg_len,
+			     sunxi_mmc_get_dma_dir(data));
+	if (dma_len == 0) {
+		dev_err(mmc_dev(host->mmc), "dma_map_sg failed\n");
+		return -ENOMEM;
+	}
+
+	WARN_ON(dma_len != data->sg_len);
+	WARN_ON(dma_len > host->mmc->max_segs);
+
+	for_each_sg(data->sg, sg, data->sg_len, i) {
+		if (sg->offset & 3 || sg->length & 3) {
+			dev_err(mmc_dev(host->mmc),
+				"unaligned scatterlist: os %x length %d\n",
+				sg->offset, sg->length);
+			return -EINVAL;
+		}
+	}
+
+	return 0;
+}
+
+static void sunxi_mmc_start_dma(struct sunxi_mmc_host *smc_host,
+				struct mmc_data *data)
+{
+	u32 tmp = 0;
+
+	sunxi_mmc_init_idma_des(smc_host, data);
+	/*dma access*/
+	tmp = smhc_readl(smc_host, SMHC_CTRL3);
+	tmp &= ~CPUAcessBuffEn;
+	smhc_writel(smc_host, SMHC_CTRL3, tmp);
+
+	/*dma select*/
+	tmp = smhc_readl(smc_host, SMHC_CTRL1);
+	tmp &= ~DmaSel;
+	tmp |= Dma32BitSel;
+	smhc_writel(smc_host, SMHC_CTRL1, tmp);
+	smhc_writel(smc_host, SMHC_ADMA_ADDR, smc_host->sg_dma);
+
+}
+
+static void sunxi_mmc_send_manual_stop(struct sunxi_mmc_host *host,
+				       struct mmc_request *req)
+{
+/*
+*	u32 arg, cmd_val, ri;
+*	unsigned long expire = jiffies + msecs_to_jiffies(1000);
+*
+*	cmd_val = SDXC_START | SDXC_RESP_EXPECT |
+*		  SDXC_STOP_ABORT_CMD | SDXC_CHECK_RESPONSE_CRC;
+*
+*	if (req->cmd->opcode == SD_IO_RW_EXTENDED) {
+*		cmd_val |= SD_IO_RW_DIRECT;
+*		arg = (1 << 31) | (0 << 28) | (SDIO_CCCR_ABORT << 9) |
+*		      ((req->cmd->arg >> 28) & 0x7);
+*	} else {
+*		cmd_val |= MMC_STOP_TRANSMISSION;
+*		arg = 0;
+*	}
+*
+*	mmc_writel(host, REG_CARG, arg);
+*	mmc_writel(host, REG_CMDR, cmd_val);
+*
+*	do {
+*		ri = mmc_readl(host, REG_RINTR);
+*	} while (!(ri & (SDXC_COMMAND_DONE | SDXC_INTERRUPT_ERROR_BIT)) &&
+*		 time_before(jiffies, expire));
+*
+*	if (!(ri & SDXC_COMMAND_DONE) || (ri & SDXC_INTERRUPT_ERROR_BIT)) {
+*		dev_err(mmc_dev(host->mmc), "send stop command failed\n");
+*		if (req->stop)
+*			req->stop->resp[0] = -ETIMEDOUT;
+*	} else {
+*		if (req->stop)
+*			req->stop->resp[0] = mmc_readl(host, REG_RESP0);
+*	}
+*
+*	mmc_writel(host, REG_RINTR, 0xffff);
+*/
+	dev_info(mmc_dev(host->mmc), "no imple %s %d\n", __func__,
+		 __LINE__);
+}
+
+static void sunxi_mmc_dump_errinfo(struct sunxi_mmc_host *host)
+{
+
+	/* For some cmds timeout is normal with sd/mmc cards */
+/*
+*      if ((host->int_sum & SDXC_INTERRUPT_ERROR_BIT) ==
+*		SDXC_RESP_TIMEOUT && (cmd->opcode == SD_IO_SEND_OP_COND ||
+*				cmd->opcode == SD_IO_RW_DIRECT))
+*		 return;
+*/
+	dev_err(mmc_dev(host->mmc),
+		"smc p%d err, cmd %d, %s%s%s%s%s%s%s%s%s%s !!\n",
+		host->phy_index, host->mrq->cmd ? host->mrq->cmd->opcode : -1,
+		host->int_sum & DSFOInt ? "SBE " : "",
+		host->int_sum & DmaErrInt ? "DME " : "",
+		host->int_sum & AcmdErrInt ? "ATE " : "",
+		host->int_sum & DatEndBitErrInt ? "DEBE " : "",
+		host->int_sum & DatCRCErrInt ? "DCE " : "",
+		host->int_sum & DatTimeoutErrInt ? "DTO " : "",
+		host->int_sum & CmdIdxErrInt ? "RIE " : "",
+		host->int_sum & CmdEndBitErrInt ? "REBE " : "",
+		host->int_sum & CmdCRCErrInt ? "RCE " : "",
+		host->int_sum & CmdTimeoutErrInt ? "RTO " : "");
+
+	/*sunxi_mmc_dumphex32(host,"sunxi mmc",host->reg_base,0x180);*/
+	/*sunxi_mmc_dump_des(host,host->sg_cpu,PAGE_SIZE);*/
+}
+
+/* Called in interrupt context! */
+static irqreturn_t sunxi_mmc_finalize_request(struct sunxi_mmc_host *smc_host)
+{
+	struct mmc_request *mrq = smc_host->mrq;
+	struct mmc_data *data = mrq->data;
+	u32 tmp = 0;
+
+/*
+*	mmc_writel(host, REG_IMASK, host->sdio_imask | host->dat3_imask);
+*	mmc_writel(host, REG_IDIE, 0);
+*	clear  int signal enable
+*	tmp = smhc_readl(smc_host,SMHC_INT_SIG_EN);
+*	tmp &= (CardInt|CardRemoveInt|CardInsertInt);
+*	smhc_writel(smc_host,SMHC_INT_SIG_EN,tmp);
+*/
+	if (smc_host->int_sum & ErrIntBit) {
+		sunxi_mmc_dump_errinfo(smc_host);
+		mrq->cmd->error = -ETIMEDOUT;
+
+		if (data) {
+			data->error = -ETIMEDOUT;
+			smc_host->manual_stop_mrq = mrq;
+		}
+
+		if (mrq->stop)
+			mrq->stop->error = -ETIMEDOUT;
+	} else {
+		if (mrq->cmd->flags & MMC_RSP_136) {
+			mrq->cmd->resp[0] =
+			    (smhc_readl(smc_host, SMHC_RESP3) & 0xffffff) << 8;
+			mrq->cmd->resp[0] |=
+			    (smhc_readl(smc_host, SMHC_RESP2) >> 24) & 0xff;
+			mrq->cmd->resp[1] =
+			    (smhc_readl(smc_host, SMHC_RESP2) & 0xffffff) << 8;
+			mrq->cmd->resp[1] |=
+			    (smhc_readl(smc_host, SMHC_RESP1) >> 24) & 0xff;
+			mrq->cmd->resp[2] =
+			    (smhc_readl(smc_host, SMHC_RESP1) & 0xffffff) << 8;
+			mrq->cmd->resp[2] |=
+			    (smhc_readl(smc_host, SMHC_RESP0) >> 24) & 0xff;
+			mrq->cmd->resp[3] =
+			    (smhc_readl(smc_host, SMHC_RESP0) & 0xffffff) << 8;
+		} else {
+			mrq->cmd->resp[0] = smhc_readl(smc_host, SMHC_RESP0);
+		}
+
+		if (data)
+			data->bytes_xfered = data->blocks * data->blksz;
+/*
+*		To avoid that "wait busy" and "maual stop" occur
+*		at the same time,
+*		We wait busy only on not error occur.
+*		if(mrq->cmd->flags & MMC_RSP_BUSY){
+*		      host->mrq_busy = host->mrq;
+*		}
+*/
+	}
+
+	if (data) {
+		struct mmc_data *data = mrq->data;
+		/*recover to cpu access*/
+		/*
+*		   tmp = smhc_readl(smc_host, SMHC_CTRL3);
+*		   tmp |= CPUAcessBuffEn;
+*		   smhc_writel(smc_host, SMHC_CTRL3, tmp);
+		 */
+
+		/* recover dma select*/
+		tmp = smhc_readl(smc_host, SMHC_CTRL1);
+		tmp &= ~DmaSel;
+		smhc_writel(smc_host, SMHC_CTRL1, tmp);
+
+		dma_unmap_sg(mmc_dev(smc_host->mmc), data->sg, data->sg_len,
+			     sunxi_mmc_get_dma_dir(data));
+	}
+	/*clear int status*/
+	smhc_writel(smc_host, SMHC_INT_STA,
+		    0xffffffff & ~(CardInt | CardRemoveInt | CardInsertInt));
+	/*clear  int signal enable*/
+	tmp = smhc_readl(smc_host, SMHC_INT_SIG_EN);
+	tmp &= (CardInt | CardRemoveInt | CardInsertInt);
+	smhc_writel(smc_host, SMHC_INT_SIG_EN, tmp);
+
+	dev_dbg(mmc_dev(smc_host->mmc), "final sta %x\n",
+		smhc_readl(smc_host, SMHC_INT_STA));
+
+	dev_dbg(mmc_dev(smc_host->mmc),
+		"smc p%d done, resp %08x %08x %08x %08x\n", smc_host->phy_index,
+		mrq->cmd->resp[0], mrq->cmd->resp[1], mrq->cmd->resp[2],
+		mrq->cmd->resp[3]);
+
+/*
+*	//if(host->dat3_imask){
+*	//      rval = mmc_readl(host,REG_GCTRL);
+*	//      mmc_writel(host, REG_GCTRL, rval|SDXC_DEBOUNCE_ENABLE_BIT);
+*	//}
+*/
+
+	smc_host->mrq = NULL;
+	smc_host->int_sum = 0;
+	smc_host->wait_dma = false;
+
+	return (smc_host->manual_stop_mrq
+		|| smc_host->mrq_busy) ? IRQ_WAKE_THREAD : IRQ_HANDLED;
+}
+
+static irqreturn_t sunxi_mmc_irq(int irq, void *dev_id)
+{
+	struct sunxi_mmc_host *host = dev_id;
+	struct mmc_request *mrq;
+	u32 msk_int = 0;
+	bool finalize = false;
+	bool sdio_int = false;
+	irqreturn_t ret = IRQ_HANDLED;
+	u32 int_sta = 0;
+	u32 int_sig_en = 0;
+	u32 int_sta_en = 0;
+
+	spin_lock(&host->lock);
+
+	int_sta = smhc_readl(host, SMHC_INT_STA);
+	int_sig_en = smhc_readl(host, SMHC_INT_SIG_EN);
+	int_sta_en = smhc_readl(host, SMHC_INT_STA_EN);
+	msk_int = int_sta & int_sig_en;
+
+	dev_dbg(mmc_dev(host->mmc),
+		"smc p%d irq, sta %08x(%08x) sta_en %08x sig_en %08x,msk_int %x\n",
+		host->phy_index, int_sta, host->int_sum, int_sta_en, int_sig_en,
+		msk_int);
+
+	/*
+	*   if(host->dat3_imask){
+	*   if(msk_int & SDXC_CARD_INSERT){
+	*   mmc_writel(host, REG_RINTR, SDXC_CARD_INSERT);
+	*   mmc_detect_change(host->mmc,msecs_to_jiffies(500));
+	*   goto out;
+	*   }
+	*   if(msk_int & SDXC_CARD_REMOVE){
+	*   mmc_writel(host, REG_RINTR, SDXC_CARD_REMOVE)
+	*   mmc_detect_change(host->mmc,msecs_to_jiffies(50));
+	*   goto out;
+	*   }
+	*   }
+	 */
+	/*
+	*   if(host->dat3_imask){
+	*   if(msk_int & CardInsertInt){
+	*   smhc_writel(smc_host,SMHC_INT_STA,CardInsertInt);
+	*   mmc_detect_change(host->mmc,msecs_to_jiffies(500));
+	*   goto out;
+	*   }
+	*   if(msk_int  & CardRemoveInt){
+	*   smhc_writel(smc_host,SMHC_INT_STA,CardRemoveInt);
+	*   mmc_detect_change(host->mmc,msecs_to_jiffies(50));
+	*   goto out;
+	*   }
+	*   }
+	 */
+
+	mrq = host->mrq;
+	if (mrq) {
+		if (msk_int & DmaInt)
+			host->wait_dma = false;
+
+		host->int_sum |= msk_int;
+
+		/* Don't wait for dma on error */
+		if (host->int_sum & ErrIntBit)
+			finalize = true;
+		else if ((host->int_sum & DoneIntBit) && !host->wait_dma)
+			finalize = true;
+	}
+
+	if (msk_int & CardInt)
+		sdio_int = true;
+
+	smhc_writel(host, SMHC_INT_STA, msk_int);
+
+	if (finalize)
+		ret = sunxi_mmc_finalize_request(host);
+/*out:*/
+	spin_unlock(&host->lock);
+
+	if (finalize && ret == IRQ_HANDLED)
+		mmc_request_done(host->mmc, mrq);
+
+	if (sdio_int)
+		mmc_signal_sdio_irq(host->mmc);
+
+	return ret;
+}
+
+/*
+*static int sunxi_check_r1_ready(struct sunxi_mmc_host *smc_host, unsigned ms)
+*{
+*	//struct sunxi_mmc_host *smc_host = mmc_priv(mmc);
+*dev_info(mmc_dev(smc_host->mmc),"no imple %s %d\n",
+		__func__,__LINE__);
+*	return 1;
+*}
+*/
+
+static int sunxi_check_r1_ready_may_sleep(struct sunxi_mmc_host *smc_host,
+					  unsigned ms)
+{
+	dev_info(mmc_dev(smc_host->mmc), "no imple %s %d\n", __func__,
+		 __LINE__);
+	return 1;
+}
+
+static irqreturn_t sunxi_mmc_handle_bottom_half(int irq, void *dev_id)
+{
+	struct sunxi_mmc_host *host = dev_id;
+	struct mmc_request *mrq;
+	struct mmc_request *mrq_busy = NULL;
+	unsigned long iflags;
+
+	spin_lock_irqsave(&host->lock, iflags);
+	mrq = host->manual_stop_mrq;
+	mrq_busy = host->mrq_busy;
+	spin_unlock_irqrestore(&host->lock, iflags);
+		/*
+		*Here,we don't use the timeout value in mrq_busy->busy_timeout
+		*Because this value may not right for example when useing TRIM
+		*So we use max wait time and print time value every 1 second
+		*/
+	if (mrq_busy) {
+		sunxi_check_r1_ready_may_sleep(host, 0x7ffffff);
+		spin_lock_irqsave(&host->lock, iflags);
+		host->mrq_busy = NULL;
+		spin_unlock_irqrestore(&host->lock, iflags);
+		mmc_request_done(host->mmc, mrq_busy);
+		return IRQ_HANDLED;
+
+	} else
+		dev_dbg(mmc_dev(host->mmc), "no request for busy\n");
+
+	if (!mrq) {
+		dev_err(mmc_dev(host->mmc), "no request for manual stop\n");
+		return IRQ_HANDLED;
+	}
+
+	dev_err(mmc_dev(host->mmc), "data error, sending stop command\n");
+
+	/*
+	 * We will never have more than one outstanding request,
+	 * and we do not complete the request until after
+	 * we've cleared host->manual_stop_mrq so we do not need to
+	 * spin lock this function.
+	 * Additionally we have wait states within this function
+	 * so having it in a lock is a very bad idea.
+	 */
+	sunxi_mmc_send_manual_stop(host, mrq);
+
+	spin_lock_irqsave(&host->lock, iflags);
+	host->manual_stop_mrq = NULL;
+	spin_unlock_irqrestore(&host->lock, iflags);
+
+	mmc_request_done(host->mmc, mrq);
+
+	return IRQ_HANDLED;
+}
+
+static void sunxi_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	u32 rval;
+	u32 tmp = 0;
+	static const char * const bus_mode[] = { "", "OD", "PP" };
+	static const char * const pwr_mode[] = { "OFF", "UP", "ON" };
+	static const char * const timing[] = { "LEGACY(SDR12)",
+		"MMC-HS(SDR20)",
+		"SD-HS(SDR25)", "UHS-SDR12",
+		"UHS-SDR25",
+		"UHS-SDR50", "UHS-SDR104", "UHS-DDR50", "MMC-HS200", "MMC-HS400"
+	};
+	static const char * const drv_type[] = { "B", "A", "C", "D" };
+
+WARN_ON(ios->bus_mode >= ARRAY_SIZE(bus_mode) / ARRAY_SIZE(bus_mode[0]));
+WARN_ON(ios->power_mode >= ARRAY_SIZE(pwr_mode) / ARRAY_SIZE(pwr_mode[0]));
+WARN_ON(ios->timing >= ARRAY_SIZE(timing) / ARRAY_SIZE(timing[0]));
+dev_info(mmc_dev(mmc), "sdc set ios: ",
+		 "clk %dHz bm %s pm %s vdd %d width %d timing %s dt %s\n",
+		 ios->clock, bus_mode[ios->bus_mode],
+		 pwr_mode[ios->power_mode], ios->vdd,
+		 1 << ios->bus_width, timing[ios->timing],
+		 drv_type[ios->drv_type]);
+
+	/* Set the power state */
+	switch (ios->power_mode) {
+	case MMC_POWER_ON:
+		break;
+
+	case MMC_POWER_UP:
+		if (host->power_on)
+			break;
+		if (!IS_ERR(mmc->supply.vmmc)) {
+			rval =
+			    sunxi_mmc_regulator_set_ocr(mmc, mmc->supply.vmmc,
+						  ios->vdd);
+			if (rval)
+				return;
+		}
+		if (!IS_ERR(mmc->supply.vqmmc)) {
+			rval = regulator_enable(mmc->supply.vqmmc);
+			if (rval < 0) {
+				dev_err(mmc_dev(mmc),
+					"failed to enable vqmmc regulator\n");
+				return;
+			}
+		}
+
+		rval = pinctrl_select_state(host->pinctrl, host->pins_default);
+		if (rval) {
+			dev_err(mmc_dev(mmc), "could not set default pins\n");
+			return;
+		}
+
+		if (!IS_ERR(host->clk_rst)) {
+			rval = clk_prepare_enable(host->clk_rst);
+			if (rval) {
+				dev_err(mmc_dev(mmc), "reset err %d\n", rval);
+				return;
+			}
+		}
+
+		rval = clk_prepare_enable(host->clk_ahb);
+		if (rval) {
+			dev_err(mmc_dev(mmc), "Enable ahb clk err %d\n", rval);
+			return;
+		}
+		rval = clk_prepare_enable(host->clk_mmc);
+		if (rval) {
+			dev_err(mmc_dev(mmc), "Enable mmc clk err %d\n", rval);
+			return;
+		}
+
+		host->ferror = sunxi_mmc_init_host(mmc);
+		if (host->ferror)
+			return;
+
+		enable_irq(host->irq);
+
+		host->power_on = 1;
+		dev_dbg(mmc_dev(mmc), "power on!\n");
+		break;
+
+	case MMC_POWER_OFF:
+		if (!host->power_on || host->dat3_imask)
+			break;
+
+		disable_irq(host->irq);
+		/*sunxi_mmc_reset_host(host);*/
+
+		clk_disable_unprepare(host->clk_mmc);
+		clk_disable_unprepare(host->clk_ahb);
+
+		if (!IS_ERR(host->clk_rst))
+			clk_disable_unprepare(host->clk_rst);
+
+		rval = pinctrl_select_state(host->pinctrl, host->pins_sleep);
+		if (rval) {
+			dev_err(mmc_dev(mmc), "could not set sleep pins\n");
+			return;
+		}
+		if (!IS_ERR(mmc->supply.vqmmc)) {
+			rval = regulator_disable(mmc->supply.vqmmc);
+			if (rval) {
+				dev_err(mmc_dev(mmc),
+					"Could not disable vqmmc\n");
+				return;
+			}
+		}
+
+		if (!IS_ERR(mmc->supply.vmmc)) {
+			rval = sunxi_mmc_regulator_set_ocr(mmc, mmc->supply.vmmc, 0);
+			if (rval)
+				return;
+		}
+
+		host->power_on = 0;
+		dev_dbg(mmc_dev(mmc), "power off!\n");
+		break;
+	}
+
+	/* set bus width */
+	switch (ios->bus_width) {
+	case MMC_BUS_WIDTH_1:
+		tmp = smhc_readl(host, SMHC_CTRL1);
+		tmp &= ~(BusWidth | ExtBusWidth);
+		smhc_writel(host, SMHC_CTRL1, tmp);
+		break;
+	case MMC_BUS_WIDTH_4:
+		tmp = smhc_readl(host, SMHC_CTRL1);
+		tmp &= ~(BusWidth | ExtBusWidth);
+		tmp |= BusWidth;	/*4bit bus*/
+		smhc_writel(host, SMHC_CTRL1, tmp);
+		break;
+	case MMC_BUS_WIDTH_8:
+		tmp = smhc_readl(host, SMHC_CTRL1);
+		tmp &= ~(BusWidth | ExtBusWidth);
+		tmp |= ExtBusWidth;	/*8bit bus*/
+		smhc_writel(host, SMHC_CTRL1, tmp);
+		break;
+	}
+
+	/*if set ddr mode in SMHC_ACMD_ERR_CTRL2,
+	 *we  reset SD Clock Enable before changing this field to
+	 *avoid generating clock glitch
+	 */
+	sunxi_mmc_oclk_onoff(host, 0);
+	/* set ddr mode */
+	if (sunxi_mmc_ddr_timing(ios->timing)) {
+		dev_dbg(mmc_dev(mmc), "fun %s,line %d val%x\n", __func__,
+			__LINE__, smhc_readl(host, SMHC_ACMD_ERR_CTRL2));
+		tmp = smhc_readl(host, SMHC_ACMD_ERR_CTRL2);
+		tmp &= ~DdrType;
+		tmp |= (0x4 << DDR_SHIFT);
+		smhc_writel(host, SMHC_ACMD_ERR_CTRL2, tmp);
+
+		smhc_writel(host, SMHC_ATC, 0x50310000);
+
+/*
+*smhc_writel(smc_host, SMHC_RTC,   (1U<<3)|(0));
+*smhc_writel(smc_host, SMHC_DITC0,
+*(((1U<<3)|0)<<24) | (((1U<<3)|0)<<16) | (((1U<<3)|0)<<8) | (((1U<<3)|0)<<0) );
+*smhc_writel(smc_host, SMHC_DITC1,
+*(((1U<<3)|0)<<24) | (((1U<<3)|0)<<16) | (((1U<<3)|0)<<8) | (((1U<<3)|0)<<0) );
+*/
+		dev_dbg(mmc_dev(mmc), "fun %s,line %d val%x %x\n", __func__,
+			__LINE__, smhc_readl(host, SMHC_ACMD_ERR_CTRL2),
+			smhc_readl(host, SMHC_ATC));
+	} else if (ios->timing == MMC_TIMING_MMC_HS400) {
+		tmp = smhc_readl(host, SMHC_ACMD_ERR_CTRL2);
+		tmp &= ~DdrType;
+		tmp |= (0x5 << DDR_SHIFT);
+		smhc_writel(host, SMHC_ACMD_ERR_CTRL2, tmp);
+
+		smhc_writel(host, SMHC_ATC, 0x30330000);
+
+/*
+*   smhc_writel(smc_host, SMHC_RTC,   (1U<<3)|(3));
+*   smhc_writel(smc_host, SMHC_DITC0,
+*(((1U<<3)|3)<<24) | (((1U<<3)|3)<<16) | (((1U<<3)|3)<<8) | (((1U<<3)|3)<<0) );
+*   smhc_writel(smc_host, SMHC_DITC1,
+*(((1U<<3)|3)<<24) | (((1U<<3)|3)<<16) | (((1U<<3)|3)<<8) | (((1U<<3)|3)<<0) );
+ */
+
+		dev_dbg(mmc_dev(mmc), "fun %s,line %d val%x %x\n", __func__,
+			__LINE__, smhc_readl(host, SMHC_ACMD_ERR_CTRL2),
+			smhc_readl(host, SMHC_ATC));
+	} else {
+		tmp = smhc_readl(host, SMHC_ACMD_ERR_CTRL2);
+		tmp &= ~DdrType;
+		smhc_writel(host, SMHC_ACMD_ERR_CTRL2, tmp);
+
+		smhc_writel(host, SMHC_ATC, 0x30330000);
+
+/*
+*   smhc_writel(smc_host, SMHC_RTC,   (1U<<3)|(3));
+*   smhc_writel(smc_host, SMHC_DITC0,
+(((1U<<3)|3)<<24) | (((1U<<3)|3)<<16) | (((1U<<3)|3)<<8) | (((1U<<3)|3)<<0) );
+*   smhc_writel(smc_host, SMHC_DITC1,
+(((1U<<3)|3)<<24) | (((1U<<3)|3)<<16) | (((1U<<3)|3)<<8) | (((1U<<3)|3)<<0) );
+ */
+
+		dev_dbg(mmc_dev(mmc), "fun %s,line %d val%x %x\n", __func__,
+			__LINE__, smhc_readl(host, SMHC_ACMD_ERR_CTRL2),
+			smhc_readl(host, SMHC_ATC));
+	}
+	sunxi_mmc_oclk_onoff(host, 1);
+
+	/* set up clock */
+	if (ios->power_mode && host->sunxi_mmc_clk_set_rate) {
+		host->ferror = host->sunxi_mmc_clk_set_rate(host, ios);
+		/* Android code had a usleep_range(50000, 55000); here */
+	}
+}
+
+static void sunxi_mmc_enable_sdio_irq(struct mmc_host *mmc, int enable)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	unsigned long flags;
+	u32 int_sig_en = 0;
+	u32 int_sta_en = 0;
+
+	spin_lock_irqsave(&host->lock, flags);
+	int_sig_en = smhc_readl(host, SMHC_INT_SIG_EN);
+	int_sta_en = smhc_readl(host, SMHC_INT_STA_EN);
+
+	if (enable) {
+		host->sdio_imask = CardInt;
+		int_sta_en |= CardInt;
+		int_sig_en |= CardInt;
+		/*
+		*smhc_writel(host,SMHC_INT_STA_EN,int_sta_en|CardInt);
+		*smhc_writel(host,SMHC_INT_SIG_EN,int_sig_en|CardInt);
+		*/
+	} else {
+		host->sdio_imask = 0;
+		int_sta_en &= (~CardInt);
+		int_sig_en &= (~CardInt);
+		/*
+		*smhc_writel(smc_host,SMHC_INT_STA_EN,int_sta_en & (~CardInt));
+		*smhc_writel(smc_host,SMHC_INT_SIG_EN,int_sig_en & (~CardInt));
+		*/
+	}
+	smhc_writel(host, SMHC_INT_STA_EN, int_sta_en);
+	smhc_writel(host, SMHC_INT_SIG_EN, int_sig_en);
+
+	spin_unlock_irqrestore(&host->lock, flags);
+}
+
+static void sunxi_mmc_hw_reset(struct mmc_host *mmc)
+{
+	dev_info(mmc_dev(mmc), "no imple %s %d\n", __func__, __LINE__);
+}
+
+static int sunxi_mmc_signal_voltage_switch(struct mmc_host *mmc,
+					   struct mmc_ios *ios)
+{
+#ifdef CONFIG_REGULATOR
+	int ret = 0;
+	struct regulator *vqmmc = mmc->supply.vqmmc;
+	struct device_node *np = NULL;
+	bool disable_vol_switch = false;
+
+	if (!mmc->parent || !mmc->parent->of_node) {
+		dev_err(mmc_dev(mmc),
+			"no dts to parse signal switch fun,use default\n");
+		return 0;
+	}
+
+	np = mmc->parent->of_node;
+	disable_vol_switch =
+	    of_property_read_bool(np, "sunxi-dis-signal-vol-sw");
+
+	/*For some emmc,io voltage will be fixed at 1.8v or other voltage,
+	*so we can not switch io voltage
+	*/
+	/*Because mmc core will change the io voltage to 3.3v when power up,
+	*so will must disable voltage switch
+	*/
+	if (disable_vol_switch) {
+		dev_dbg(mmc_dev(mmc), "disable signal voltage-switch\n");
+		return 0;
+	}
+
+	switch (ios->signal_voltage) {
+	case MMC_SIGNAL_VOLTAGE_330:
+		if (!IS_ERR(vqmmc)) {
+			ret = regulator_set_voltage(vqmmc, 2700000, 3600000);
+			if (ret) {
+				dev_err(mmc_dev(mmc),
+					"Switching to 3.3V signalling voltage ",
+					" failed\n");
+				return -EIO;
+			}
+		} else {
+			dev_info(mmc_dev(mmc),
+				 "no vqmmc,Check if there is regulator\n");
+			return 0;
+		}
+		/* Wait for 5ms */
+		/*usleep_range(5000, 5500);*/
+		return 0;
+	case MMC_SIGNAL_VOLTAGE_180:
+		if (!IS_ERR(vqmmc)) {
+			ret = regulator_set_voltage(vqmmc, 1700000, 1950000);
+			if (ret) {
+				dev_err(mmc_dev(mmc),
+					"Switching to 1.8V signalling voltage ",
+					" failed\n");
+				return -EIO;
+			}
+		} else {
+			dev_info(mmc_dev(mmc),
+				 "no vqmmc,Check if there is regulator\n");
+			return 0;
+		}
+
+		/* Wait for 5ms */
+		/*usleep_range(5000, 5500);*/
+		return 0;
+	case MMC_SIGNAL_VOLTAGE_120:
+		if (!IS_ERR(vqmmc)) {
+			ret = regulator_set_voltage(vqmmc, 1100000, 1300000);
+			if (ret) {
+				dev_err(mmc_dev(mmc),
+					"Switching to 1.2V signalling voltage ",
+					" failed\n");
+				return -EIO;
+			}
+		} else {
+			dev_info(mmc_dev(mmc),
+				 "no vqmmc,Check if there is regulator\n");
+			return 0;
+		}
+
+		return 0;
+	default:
+		/* No signal voltage switch required */
+		dev_err(mmc_dev(mmc),
+			"unknown signal voltage switch request %x\n",
+			ios->signal_voltage);
+		return -1;
+	}
+#else
+	return 0;
+#endif
+}
+
+static int sunxi_mmc_card_busy(struct mmc_host *mmc)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	return !(smhc_readl(host, SMHC_STA) & Dat0LineSta);
+}
+
+static void sunxi_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	struct mmc_command *cmd = mrq->cmd;
+	struct mmc_data *data = mrq->data;
+	unsigned long iflags;
+	bool wait_dma = host->wait_dma;
+	int ret;
+	u32 cmd_val = 0;
+	u32 int_sg_en = 0;
+	u32 int_st_en = 0;
+	u32 cmd_attr = 0;
+	u32 tmp = 0;
+
+	/* Check for set_ios errors (should never happen) */
+	if (host->ferror) {
+		mrq->cmd->error = host->ferror;
+		mmc_request_done(mmc, mrq);
+		return;
+	}
+	/*Wait for cmd line free*/
+	/*
+	*   if(sunxi_wait_bit_clr(host,                  \
+	*   SMHC_STA,CmdInhibitCmd, \
+	*   "SMHC_STA","CmdInhibitCmd",1)){
+	*   dev_err(mmc_dev(mmc),"Wait cmd free timeout\n");
+	*   mrq->cmd->error = -EINVAL;
+	*   mmc_request_done(mmc, mrq);
+	*   return;
+	*   }
+	 */
+
+	/*************cmd val ***************/
+	/*response*/
+	if (cmd->flags & MMC_RSP_PRESENT) {
+		if (cmd->flags & MMC_RSP_136)
+			cmd_val |= Rsp136;
+		else if (cmd->flags & MMC_RSP_BUSY)
+			cmd_val |= Rsp48b;
+		else
+			cmd_val |= Rsp48;
+
+		if (cmd->flags & MMC_RSP_CRC)
+			cmd_val |= CheckRspCRC;
+		if (cmd->flags & MMC_RSP_OPCODE)
+			cmd_val |= CheckRspIdx;
+	}
+	/*data*/
+	if ((cmd->flags & MMC_CMD_MASK) == MMC_CMD_ADTC) {
+		cmd_val |= DataExp;
+		if (cmd->data->blocks > 1)
+			cmd_val |= MultiBlkTrans | BlkCntEn;
+
+		if (cmd->data->flags & MMC_DATA_READ)
+			cmd_val |= Read;
+
+/*if sbc is set,use cmd23 instead of cmd12 ,
+ *regardless if stop is set
+ */
+		if (cmd->mrq->sbc != NULL)
+			cmd_val |= AutoCmd23;
+		else if (cmd->mrq->stop != NULL)
+			cmd_val |= AutoCmd12;
+		cmd_val |= DMAEn;
+	}
+	/*opcode*/
+	cmd_val |= (cmd->opcode & 0x3f) << 24;
+
+	/******************cmd attr val******************/
+	if (cmd->opcode == MMC_GO_IDLE_STATE)
+		cmd_attr |= SendInitSeq;
+	else
+		cmd_attr &= ~SendInitSeq;
+
+	if (data) {
+		/*Wait for data line free */
+		/*
+		*   if(sunxi_wait_bit_clr(host,          \
+		*   SMHC_STA,CmdInhibitDat, \
+		*   "SMHC_STA","CmdInhibitDat",1)){
+		*   dev_err(mmc_dev(mmc),"Wait data free timeout\n");
+		*   mrq->cmd->error = -EINVAL;
+		*   mmc_request_done(mmc, mrq);
+		*   return;
+		*   }
+		 */
+		/*prepare dma */
+		ret = sunxi_mmc_map_dma(host, data);
+		if (ret < 0) {
+			dev_err(mmc_dev(mmc), "map DMA failed\n");
+			cmd->error = ret;
+			data->error = ret;
+			mmc_request_done(mmc, mrq);
+			return;
+		}
+	}
+
+	/***************irq setting and the wait in irq *********************/
+	if ((cmd->flags & MMC_CMD_MASK) == MMC_CMD_ADTC) {
+		int_sg_en = TransOverInt;
+		if (cmd->data->flags & MMC_DATA_READ) {
+			wait_dma = true;
+			int_sg_en |= DmaInt;
+		}
+	} else {
+		if (cmd->flags & MMC_RSP_BUSY)
+			int_sg_en = TransOverInt;
+		else
+			int_sg_en = CmdOverInt;
+	}
+
+	spin_lock_irqsave(&host->lock, iflags);
+	if (host->mrq || host->manual_stop_mrq || host->mrq_busy) {
+		spin_unlock_irqrestore(&host->lock, iflags);
+
+		if (data)
+			dma_unmap_sg(mmc_dev(mmc), data->sg, data->sg_len,
+				     sunxi_mmc_get_dma_dir(data));
+
+		dev_err(mmc_dev(mmc), "request already pending\n");
+		mrq->cmd->error = -EBUSY;
+		mmc_request_done(mmc, mrq);
+		return;
+	}
+
+	host->mrq = mrq;
+
+	/**************irq setting*******************/
+	/*enble all int state*/
+	smhc_writel(host, SMHC_INT_STA_EN, 0xffffffff);
+	int_st_en = smhc_readl(host, SMHC_INT_STA_EN);
+	int_sg_en |= ErrIntBit;
+	int_sg_en |= (smhc_readl(host, SMHC_INT_SIG_EN))
+	    & (CardInt | CardRemoveInt | CardInsertInt);
+	smhc_writel(host, SMHC_INT_SIG_EN, int_sg_en);
+	host->wait_dma = wait_dma;
+
+	if (data) {
+	/**************DMA setting*******************/
+		sunxi_mmc_start_dma(host, data);
+	/**************blk size/blk cnt*******************/
+		smhc_writel(host, SMHC_BLK_CFG,
+			    (data->
+			     blksz & 0xFFF) | ((data->blocks & 0xFFFF) << 16));
+		host->sunxi_mmc_thld_ctl(host, &mmc->ios, data);
+	}
+
+	/**************arg*******************/
+	smhc_writel(host, SMHC_CMD_ARG1, cmd->arg);
+	dev_dbg(mmc_dev(mmc), "stop %x,sbc %x\n", (u32) (cmd->mrq->stop),
+		(u32) (cmd->mrq->sbc));
+	/*if sbc is set,use cmd23 instead of cmd12 ,regardless if stop is set*/
+	if (cmd->mrq->sbc)
+		smhc_writel(host, SMHC_CMD_ARG2, cmd->mrq->sbc->arg);
+	else if (cmd->mrq->stop)
+		smhc_writel(host, SMHC_CMD_ARG2, cmd->mrq->stop->arg);
+
+	/**************cmd attr*******************/
+	tmp = smhc_readl(host, SMHC_CMD_ATTR);
+	tmp &= ~SendInitSeq;	/*clear Initialization first*/
+	smhc_writel(host, SMHC_CMD_ATTR, cmd_attr | tmp);
+
+	dev_dbg(mmc_dev(mmc),
+		"smc p%d cmd %d(%08x) cmd_val %x in_sg_en 0x%08x int_st_en 0x%08x len %d\n",
+		host->phy_index, cmd->opcode & 0x3f, cmd->arg, cmd_val,
+		int_sg_en, int_st_en,
+		host->mrq->data ? host->mrq->data->blksz *
+		host->mrq->data->blocks : 0);
+
+	if (host->dat3_imask) {
+		dev_info(mmc_dev(host->mmc), "no imple %s %d\n", __func__,
+			 __LINE__);
+	}
+
+	/******************exe cmd******************/
+	smhc_writel(host, SMHC_CMD, cmd_val);
+
+	spin_unlock_irqrestore(&host->lock, iflags);
+}
+
+/*we use our own mmc_regulator_get_supply
+*because our platform regulator not support supply name,
+*/
+/*only support regulator ID,
+*but linux mmc' own mmc_regulator_get_supply use supply name
+*/
+static int sunxi_mmc_regulator_get_supply(struct mmc_host *mmc)
+{
+	struct device *dev = mmc_dev(mmc);
+	int ret = 0;
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	mmc->supply.vmmc = regulator_get_optional(dev, "vmmc");
+	mmc->supply.vqmmc = regulator_get_optional(dev, "vqmmc");
+	host->supply.vdmmc = regulator_get_optional(dev, "vdmmc");
+
+	if (IS_ERR(mmc->supply.vmmc)) {
+		dev_info(dev, "No vmmc regulator found\n");
+	} else {
+		ret = mmc_regulator_get_ocrmask(mmc->supply.vmmc);
+		if (ret > 0)
+			mmc->ocr_avail = ret;
+		else
+			dev_warn(dev, "Failed getting OCR mask: %d\n", ret);
+	}
+
+	if (IS_ERR(mmc->supply.vqmmc))
+		dev_info(dev, "No vqmmc regulator found\n");
+
+	if (IS_ERR(host->supply.vdmmc))
+		dev_info(dev, "No vdmmc regulator found\n");
+
+	return 0;
+}
+
+/*
+*Because our regulator driver does not support binding to device tree,
+*so we can not binding it to our dev(for example
+*regulator_get(dev, reg_str[0]) or devm_regulator_get(dev, reg_str[0]) )
+*/
+/*so we must release it manully*/
+static void sunxi_mmc_regulator_release_supply(struct mmc_host *mmc)
+{
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	if (!IS_ERR(host->supply.vdmmc))
+		regulator_put(host->supply.vdmmc);
+
+	if (!IS_ERR(mmc->supply.vqmmc))
+		regulator_put(mmc->supply.vqmmc);
+
+	if (!IS_ERR(mmc->supply.vmmc))
+		regulator_put(mmc->supply.vmmc);
+}
+
+static const struct of_device_id sunxi_mmc_of_match[] = {
+	{.compatible = "allwinner,sunxi-mmc-v5px",},
+	{ /* sentinel */ }
+};
+
+MODULE_DEVICE_TABLE(of, sunxi_mmc_of_match);
+
+static struct mmc_host_ops sunxi_mmc_ops = {
+	.request = sunxi_mmc_request,
+	.set_ios = sunxi_mmc_set_ios,
+	.get_ro = mmc_gpio_get_ro,
+	.get_cd = mmc_gpio_get_cd,
+	.enable_sdio_irq = sunxi_mmc_enable_sdio_irq,
+	.hw_reset = sunxi_mmc_hw_reset,
+	.start_signal_voltage_switch = sunxi_mmc_signal_voltage_switch,
+	.card_busy = sunxi_mmc_card_busy,
+};
+
+static int sunxi_mmc_resource_request(struct sunxi_mmc_host *host,
+				      struct platform_device *pdev)
+{
+	struct device_node *np = pdev->dev.of_node;
+	int ret;
+
+	if (of_device_is_compatible(np, "allwinner,sunxi-mmc-v5px")) {
+		int phy_index = 0;
+
+		if (of_property_match_string(np, "device_type", "sdc0") == 0) {
+			phy_index = 0;
+		} else if (of_property_match_string(np, "device_type", "sdc1")
+			   == 0) {
+			phy_index = 1;
+		} else if (of_property_match_string(np, "device_type", "sdc2")
+			   == 0) {
+			phy_index = 2;
+		} else if (of_property_match_string(np, "device_type", "sdc3")
+			   == 0) {
+			phy_index = 3;
+		} else {
+			dev_err(&pdev->dev, "No sdmmc device,check dts\n");
+		}
+		sunxi_mmc_init_priv_v5px(host, pdev, phy_index);
+	}
+	/*ret = mmc_regulator_get_supply(host->mmc);*/
+	ret = sunxi_mmc_regulator_get_supply(host->mmc);
+	if (ret)
+		return ret;
+	/*Maybe in some platform,no regulator,so we set ocr_avail manully */
+	if (!host->mmc->ocr_avail)
+		host->mmc->ocr_avail =
+		    MMC_VDD_28_29 | MMC_VDD_29_30 | MMC_VDD_30_31 |
+		    MMC_VDD_31_32 | MMC_VDD_32_33 | MMC_VDD_33_34;
+
+	/*enable card detect pin power*/
+	if (!IS_ERR(host->supply.vdmmc)) {
+		ret = regulator_enable(host->supply.vdmmc);
+		if (ret < 0)
+			dev_err(mmc_dev(host->mmc),
+				"failed to enable vdmmc regulator\n");
+			return ret;
+	}
+
+	host->pinctrl = devm_pinctrl_get(&pdev->dev);
+	if (IS_ERR(host->pinctrl)) {
+		ret = PTR_ERR(host->pinctrl);
+		goto error_disable_regulator;
+	}
+
+	host->pins_default = pinctrl_lookup_state(host->pinctrl,
+						  PINCTRL_STATE_DEFAULT);
+	if (IS_ERR(host->pins_default)) {
+		dev_err(&pdev->dev, "could not get default pinstate\n");
+		ret = PTR_ERR(host->pins_default);
+		goto error_disable_regulator;
+	}
+
+	host->pins_sleep = pinctrl_lookup_state(host->pinctrl,
+						PINCTRL_STATE_SLEEP);
+	if (IS_ERR(host->pins_sleep)) {
+		dev_err(&pdev->dev, "could not get sleep pinstate\n");
+		ret = PTR_ERR(host->pins_sleep);
+		goto error_disable_regulator;
+	}
+
+	host->reg_base = devm_ioremap_resource(&pdev->dev,
+					       platform_get_resource(pdev,
+					       IORESOURCE_MEM,
+								     0));
+	if (IS_ERR(host->reg_base)) {
+		ret = PTR_ERR(host->reg_base);
+		goto error_disable_regulator;
+	}
+
+	host->clk_ahb = devm_clk_get(&pdev->dev, "ahb");
+	if (IS_ERR(host->clk_ahb)) {
+		dev_err(&pdev->dev, "Could not get ahb clock\n");
+		ret = PTR_ERR(host->clk_ahb);
+		goto error_disable_regulator;
+	}
+
+	host->clk_mmc = devm_clk_get(&pdev->dev, "mmc");
+	if (IS_ERR(host->clk_mmc)) {
+		dev_err(&pdev->dev, "Could not get mmc clock\n");
+		ret = PTR_ERR(host->clk_mmc);
+		goto error_disable_regulator;
+	}
+
+	host->clk_rst = devm_clk_get(&pdev->dev, "rst");
+	if (IS_ERR(host->clk_rst))
+		dev_warn(&pdev->dev, "Could not get mmc rst\n");
+
+	if (!IS_ERR(host->clk_rst)) {
+		ret = clk_prepare_enable(host->clk_rst);
+		if (ret) {
+			dev_err(&pdev->dev, "reset err %d\n", ret);
+			goto error_disable_regulator;
+		}
+	}
+
+	ret = clk_prepare_enable(host->clk_ahb);
+	if (ret) {
+		dev_err(&pdev->dev, "Enable ahb clk err %d\n", ret);
+		goto error_assert_reset;
+	}
+
+	ret = clk_prepare_enable(host->clk_mmc);
+	if (ret) {
+		dev_err(&pdev->dev, "Enable mmc clk err %d\n", ret);
+		goto error_disable_clk_ahb;
+	}
+
+	/*
+	 * Sometimes the controller asserts the irq on boot for some reason,
+	 * make sure the controller is in a sane state before enabling irqs.
+	 */
+	/*ret = sunxi_mmc_reset_host(host);*/
+	ret = sunxi_mmc_init_host(host->mmc);
+	if (ret)
+		goto error_disable_clk_mmc;
+
+	host->irq = platform_get_irq(pdev, 0);
+	ret = devm_request_threaded_irq(&pdev->dev, host->irq, sunxi_mmc_irq,
+					sunxi_mmc_handle_bottom_half, 0,
+					"sunxi-mmc", host);
+	if (ret) {
+		dev_err(&pdev->dev, "failed to request irq %d\n", ret);
+		goto error_disable_clk_mmc;
+	}
+
+	disable_irq(host->irq);
+
+	clk_disable_unprepare(host->clk_mmc);
+	clk_disable_unprepare(host->clk_ahb);
+#if 0
+	if (!IS_ERR(host->reset))
+		reset_control_assert(host->reset);
+#else
+	if (!IS_ERR(host->clk_rst))
+		clk_disable_unprepare(host->clk_rst);
+#endif
+/**
+ *	ret = mmc_create_sys_fs(host,pdev);
+ *	if(ret)
+ *	      goto error_disable_regulator;
+ */
+
+	return ret;
+
+error_disable_clk_mmc:
+	clk_disable_unprepare(host->clk_mmc);
+error_disable_clk_ahb:
+	clk_disable_unprepare(host->clk_ahb);
+error_assert_reset:
+#if 0
+	if (!IS_ERR(host->reset))
+		reset_control_assert(host->reset);
+#else
+	if (!IS_ERR(host->clk_rst))
+		clk_disable_unprepare(host->clk_rst);
+#endif
+error_disable_regulator:
+	if (!IS_ERR(host->supply.vdmmc))
+		regulator_disable(host->supply.vdmmc);
+	sunxi_mmc_regulator_release_supply(host->mmc);
+
+	return ret;
+}
+
+static int sunxi_mmc_probe(struct platform_device *pdev)
+{
+	struct sunxi_mmc_host *host;
+	struct mmc_host *mmc;
+	int ret;
+
+	dev_info(&pdev->dev, "%s\n", DRIVER_VERSION);
+
+	mmc = mmc_alloc_host(sizeof(struct sunxi_mmc_host), &pdev->dev);
+	if (!mmc) {
+		dev_err(&pdev->dev, "mmc alloc host failed\n");
+		return -ENOMEM;
+	}
+
+	host = mmc_priv(mmc);
+	host->mmc = mmc;
+	spin_lock_init(&host->lock);
+
+	ret = sunxi_mmc_resource_request(host, pdev);
+	if (ret)
+		goto error_free_host;
+
+	host->dma_mask = DMA_BIT_MASK(32);
+	pdev->dev.dma_mask = &host->dma_mask;
+	pdev->dev.coherent_dma_mask = DMA_BIT_MASK(32);
+	host->sg_cpu = dma_alloc_coherent(&pdev->dev, SUNXI_REQ_PAGE_SIZE,
+					  &host->sg_dma, GFP_KERNEL);
+	if (!host->sg_cpu) {
+		dev_err(&pdev->dev, "Failed to allocate DMA descriptor mem\n");
+		ret = -ENOMEM;
+		goto error_free_host;
+	}
+
+	mmc->ops = &sunxi_mmc_ops;
+	mmc->max_blk_count = MAX_BLK_COUNT;
+	mmc->max_blk_size = MAX_BLK_SIZE;
+	mmc->max_segs = SUNXI_REQ_PAGE_SIZE / sizeof(struct sdhc_idma_des);
+	mmc->max_seg_size = 1 << host->idma_des_size_bits;
+	mmc->max_req_size = mmc->max_blk_size * mmc->max_blk_count;
+	/* 400kHz ~ 50MHz */
+	mmc->f_min = 400000;
+	mmc->f_max = 50000000;
+	/*
+	 *  mmc->caps|= MMC_CAP_MMC_HIGHSPEED | MMC_CAP_SD_HIGHSPEED \
+	 *  | MMC_CAP_ERASE | MMC_CAP_WAIT_WHILE_BUSY;
+	 */
+	mmc->caps |=
+	    MMC_CAP_MMC_HIGHSPEED | MMC_CAP_SD_HIGHSPEED | MMC_CAP_ERASE;
+	/*mmc->caps2      |= MMC_CAP2_HS400_1_8V;*/
+
+#ifndef CONFIG_REGULATOR
+	/*Because fpga has no regulator,so we add it manully*/
+	mmc->ocr_avail =
+	    MMC_VDD_28_29 | MMC_VDD_29_30 | MMC_VDD_30_31 | MMC_VDD_31_32 |
+	    MMC_VDD_32_33 | MMC_VDD_33_34;
+	dev_info(&pdev->dev,
+		 "*******************set host ocr**************************\n");
+
+#endif
+
+	mmc_of_parse(mmc);
+	if (mmc->sunxi_caps3 & MMC_SUNXI_CAP3_DAT3_DET) {
+		/*host->dat3_imask = SDXC_CARD_INSERT|SDXC_CARD_REMOVE;*/
+		dev_info(mmc_dev(host->mmc), "no imple %s %d\n", __func__,
+			 __LINE__);
+	}
+
+	ret = mmc_add_host(mmc);
+	if (ret)
+		goto error_free_dma;
+
+	ret = mmc_create_sys_fs(host, pdev);
+	if (ret) {
+		dev_err(&pdev->dev, "create sys fs failed\n");
+		goto error_free_dma;
+	}
+
+	dev_info(&pdev->dev, "base:0x%p irq:%u\n", host->reg_base, host->irq);
+	platform_set_drvdata(pdev, mmc);
+	return 0;
+
+error_free_dma:
+	dma_free_coherent(&pdev->dev, SUNXI_REQ_PAGE_SIZE, host->sg_cpu,
+			  host->sg_dma);
+error_free_host:
+	mmc_free_host(mmc);
+	return ret;
+}
+
+static int sunxi_mmc_remove(struct platform_device *pdev)
+{
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	mmc_remove_host(mmc);
+	disable_irq(host->irq);
+/*      sunxi_mmc_reset_host(host);*/
+
+	mmc_remove_sys_fs(host, pdev);
+
+	if (!IS_ERR(host->supply.vdmmc))
+		regulator_disable(host->supply.vdmmc);
+
+	sunxi_mmc_regulator_release_supply(mmc);
+
+	dma_free_coherent(&pdev->dev, SUNXI_REQ_PAGE_SIZE, host->sg_cpu,
+			  host->sg_dma);
+	mmc_free_host(mmc);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+
+static void sunxi_mmc_regs_save(struct sunxi_mmc_host *host)
+{
+	struct sunxi_mmc_ctrl_regs *bak_regs = &host->bak_regs;
+
+/*save public register */
+/*dev_info(mmc_dev(host->mmc),"no imple %s %d\n",__func__,__LINE__);*/
+	bak_regs->rst_clk_ctrl = smhc_readl(host, SMHC_RST_CLK_CTRL);
+	bak_regs->int_sta_en = smhc_readl(host, SMHC_INT_STA_EN);
+	bak_regs->to = smhc_readl(host, SMHC_TO_CTRL2);
+	bak_regs->ctrl3 = smhc_readl(host, SMHC_CTRL3);
+	bak_regs->int_sig_en = smhc_readl(host, SMHC_INT_SIG_EN);
+	bak_regs->ctrl1 = smhc_readl(host, SMHC_CTRL1);
+	bak_regs->acmd_err_ctrl2 = smhc_readl(host, SMHC_ACMD_ERR_CTRL2);
+	bak_regs->atc = smhc_readl(host, SMHC_ATC);
+
+	if (host->sunxi_mmc_save_spec_reg)
+		host->sunxi_mmc_save_spec_reg(host);
+	else
+		dev_warn(mmc_dev(host->mmc), "no spec reg save\n");
+}
+
+static void sunxi_mmc_regs_restore(struct sunxi_mmc_host *host)
+{
+	struct sunxi_mmc_ctrl_regs *bak_regs = &host->bak_regs;
+
+/*restore public register */
+/*dev_info(mmc_dev(host->mmc),"no imple %s %d\n",__func__,__LINE__);*/
+	smhc_writel(host, SMHC_RST_CLK_CTRL, bak_regs->rst_clk_ctrl);
+	smhc_writel(host, SMHC_INT_STA_EN, bak_regs->rst_clk_ctrl);
+	smhc_writel(host, SMHC_TO_CTRL2, bak_regs->rst_clk_ctrl);
+	smhc_writel(host, SMHC_CTRL3, bak_regs->rst_clk_ctrl);
+	smhc_writel(host, SMHC_INT_SIG_EN, bak_regs->rst_clk_ctrl);
+	smhc_writel(host, SMHC_CTRL1, bak_regs->rst_clk_ctrl);
+	smhc_writel(host, SMHC_ACMD_ERR_CTRL2, bak_regs->rst_clk_ctrl);
+	smhc_writel(host, SMHC_ATC, bak_regs->rst_clk_ctrl);
+
+	if (host->sunxi_mmc_restore_spec_reg)
+		host->sunxi_mmc_restore_spec_reg(host);
+	else
+		dev_warn(mmc_dev(host->mmc), "no spec reg restore\n");
+
+}
+
+static int sunxi_mmc_suspend(struct device *dev)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	int ret = 0;
+
+	dev_info(mmc_dev(host->mmc), "suspend start%s %d\n", __func__,
+		 __LINE__);
+	if (mmc) {
+		ret = mmc_suspend_host(mmc);
+		if (!ret) {
+			if (!IS_ERR(host->supply.vdmmc)) {
+				ret = regulator_disable(host->supply.vdmmc);
+				if (ret) {
+					dev_err(mmc_dev(mmc),
+						"disable vdmmc failed in suspend\n");
+					return ret;
+				}
+			}
+
+			if (mmc_card_keep_power(mmc) || host->dat3_imask) {
+				disable_irq(host->irq);
+				sunxi_mmc_regs_save(host);
+
+				clk_disable_unprepare(host->clk_mmc);
+				clk_disable_unprepare(host->clk_ahb);
+
+				if (!IS_ERR(host->clk_rst))
+					clk_disable_unprepare(host->clk_rst);
+
+				ret =
+				    pinctrl_select_state(host->pinctrl,
+							 host->pins_sleep);
+				if (ret) {
+					dev_err(mmc_dev(mmc),
+						"could not set sleep pins in suspend\n");
+					return ret;
+				}
+				if (!IS_ERR(mmc->supply.vqmmc))
+					regulator_disable(mmc->supply.vqmmc);
+
+				if (!IS_ERR(mmc->supply.vmmc)) {
+					ret =
+					    sunxi_mmc_regulator_set_ocr(mmc,
+								  mmc->supply.
+								  vmmc, 0);
+					return ret;
+				}
+				dev_info(mmc_dev(mmc), "dat3_imask %x\n",
+					 host->dat3_imask);
+				/*dump_reg(host);  */
+			}
+		}
+	}
+
+	dev_info(mmc_dev(host->mmc), "suspend end %s %d\n", __func__,
+		 __LINE__);
+	return ret;
+}
+
+static int sunxi_mmc_resume(struct device *dev)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+	int ret = 0;
+
+	dev_info(mmc_dev(host->mmc), "resume start%s %d\n", __func__,
+		 __LINE__);
+	if (mmc) {
+		if (mmc_card_keep_power(mmc) || host->dat3_imask) {
+			if (!IS_ERR(mmc->supply.vmmc)) {
+				ret =
+				    sunxi_mmc_regulator_set_ocr(mmc, mmc->supply.vmmc,
+							  mmc->ios.vdd);
+				if (ret)
+					return ret;
+			}
+
+			if (!IS_ERR(mmc->supply.vqmmc)) {
+				ret = regulator_enable(mmc->supply.vqmmc);
+				if (ret < 0) {
+					dev_err(mmc_dev(mmc),
+						"failed to enable vqmmc regulator\n");
+					return ret;
+				}
+			}
+
+			ret =
+			    pinctrl_select_state(host->pinctrl,
+						 host->pins_default);
+			if (ret) {
+				dev_err(mmc_dev(mmc),
+					"could not set default pins in resume\n");
+				return ret;
+			}
+
+			if (!IS_ERR(host->clk_rst)) {
+				ret = clk_prepare_enable(host->clk_rst);
+				if (ret) {
+					dev_err(mmc_dev(mmc), "reset err %d\n",
+						ret);
+					return ret;
+				}
+			}
+
+			ret = clk_prepare_enable(host->clk_ahb);
+			if (ret) {
+				dev_err(mmc_dev(mmc), "Enable ahb clk err %d\n",
+					ret);
+				return ret;
+			}
+			ret = clk_prepare_enable(host->clk_mmc);
+			if (ret) {
+				dev_err(mmc_dev(mmc), "Enable mmc clk err %d\n",
+					ret);
+				return ret;
+			}
+
+			host->ferror = sunxi_mmc_init_host(mmc);
+			if (host->ferror)
+				return -1;
+
+			sunxi_mmc_regs_restore(host);
+
+			/*
+			 * host->ferror = sunxi_mmc_update_clk(host);
+			 * if (host->ferror)
+			 *	return -1;
+			 */
+			enable_irq(host->irq);
+			dev_info(mmc_dev(mmc), "dat3_imask %x\n",
+				 host->dat3_imask);
+			/*dump_reg(host);*/
+		}
+		/*enable card detect pin power*/
+		if (!IS_ERR(host->supply.vdmmc)) {
+			ret = regulator_enable(host->supply.vdmmc);
+			if (ret < 0) {
+				dev_err(mmc_dev(mmc),
+					"failed to enable vdmmc regulator\n");
+				return ret;
+			}
+		}
+		ret = mmc_resume_host(mmc);
+	}
+
+	dev_info(mmc_dev(host->mmc), "resume end %s %d\n", __func__,
+		 __LINE__);
+	return ret;
+}
+
+static const struct dev_pm_ops sunxi_mmc_pm = {
+	.suspend = sunxi_mmc_suspend,
+	.resume = sunxi_mmc_resume,
+};
+
+#define sunxi_mmc_pm_ops (&sunxi_mmc_pm)
+
+#else				/* CONFIG_PM */
+
+#define sunxi_mmc_pm_ops NULL
+
+#endif				/* CONFIG_PM */
+
+static void sunxi_shutdown_mmc(struct platform_device *pdev)
+{
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	struct sunxi_mmc_host *host = mmc_priv(mmc);
+
+	if (host->sunxi_mmc_shutdown)
+		host->sunxi_mmc_shutdown(pdev);
+}
+
+static struct platform_driver sunxi_mmc_driver = {
+	.driver = {
+		   .name = "sunxi-smhc",
+		   .of_match_table = of_match_ptr(sunxi_mmc_of_match),
+		   .pm = sunxi_mmc_pm_ops,
+		   },
+	.probe = sunxi_mmc_probe,
+	.remove = sunxi_mmc_remove,
+	.shutdown = sunxi_shutdown_mmc,
+};
+
+module_platform_driver(sunxi_mmc_driver);
+
+MODULE_DESCRIPTION("Allwinner's SD/MMC Card Controller Driver");
+MODULE_LICENSE("GPL v2");
+MODULE_AUTHOR("David Lanzend�rfer <david.lanzendoerfer@o2s.ch>");
+MODULE_ALIAS("platform:sunxi-mmc");
+
+#endif
diff --git a/drivers/mmc/host/sunxi-smhc.h b/drivers/mmc/host/sunxi-smhc.h
new file mode 100644
index 000000000..74f020410
--- /dev/null
+++ b/drivers/mmc/host/sunxi-smhc.h
@@ -0,0 +1,362 @@
+/*
+* Sunxi SD/MMC host driver
+*
+* Copyright (C) 2015 AllWinnertech Ltd.
+* Author: lixiang <lixiang@allwinnertech>
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+* This program is distributed "as is" WITHOUT ANY WARRANTY of any
+* kind, whether express or implied; without even the implied warranty
+* of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+
+#include <linux/clk.h>
+#include <linux/clk/sunxi.h>
+
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/reset.h>
+
+#include <linux/of_address.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/slot-gpio.h>
+
+#ifndef __SUNXI_MMC_H__
+#define __SUNXI_MMC_H__
+
+#define DRIVER_NAME "sunxi-smhc"
+#define DRIVER_RIVISION "v0.6 2016-4-29 16:53"
+#define DRIVER_VERSION "SD/MMC/SDIO Host Controller Driver(" DRIVER_RIVISION ")"
+
+#if defined CONFIG_FPGA_V4_PLATFORM || defined CONFIG_FPGA_V7_PLATFORM
+#define MMC_FPGA
+#endif
+
+
+#define SMHC_DEVICE_ID			(2)	/*number of id in multi device*/
+/*max blk count and size is limited by the SMHC_BLK_CFG register's max value*/
+#define MAX_BLK_COUNT		(0xFFFF)
+#define MAX_BLK_SIZE		(0x800)
+/*#define MAX_DES_SIZE          PAGE_SIZE*/
+#define SUNXI_REQ_PAGE_SIZE			(PAGE_SIZE*4)
+
+/*---------------------------------------------*/
+/* registers define */
+/*---------------------------------------------*/
+#define SMHC_CMD_ARG2          (0x00)
+#define SMHC_BLK_CFG           (0x04)
+#define SMHC_CMD_ARG1          (0x08)
+#define SMHC_CMD               (0x0C)
+#define SMHC_RESP0             (0x10)
+#define SMHC_RESP1             (0x14)
+#define SMHC_RESP2             (0x18)
+#define SMHC_RESP3             (0x1C)
+#define SMHC_BUFF              (0x20)
+#define SMHC_STA               (0x24)
+#define SMHC_CTRL1             (0x28)
+#define SMHC_RST_CLK_CTRL      (0x2C)
+#define SMHC_INT_STA           (0x30)
+#define SMHC_INT_STA_EN        (0x34)
+#define SMHC_INT_SIG_EN        (0x38)
+#define SMHC_ACMD_ERR_CTRL2    (0x3C)
+#define SMHC_SET_ERR           (0x50)
+#define SMHC_ADMA_ERR          (0x54)
+#define SMHC_ADMA_ADDR         (0x58)
+
+#define SMHC_CTRL3             (0x200)
+#define SMHC_CMD_ATTR          (0x204)
+#define SMHC_TO_CTRL2          (0x208)
+#define SMHC_ATC               (0x210)
+#define SMHC_RTC               (0x214)
+#define SMHC_DITC0             (0x218)
+#define SMHC_DITC1             (0x21C)
+#define SMHC_TP0               (0x220)
+#define SMHC_TP1               (0x224)
+
+#define SMHC_CRC_STA           (0x240)
+#define SMHC_TBC0              (0x244)
+#define SMHC_TBC1              (0x248)
+#define SMHC_BL                (0x24C)
+#define SMHC_CEDBN             (0x250)
+/*----------------------------------------*/
+
+#define smhc_readl(host, reg) \
+	__raw_readl((host)->reg_base + reg)
+#define smhc_writel(host, reg, value) \
+	__raw_writel((value), (host)->reg_base + reg)
+#define smhc_readw(host, reg) \
+	__raw_readw((host)->reg_base + reg)
+#define smhc_writew(host, reg, value) \
+	__raw_writew((value), (host)->reg_base + reg)
+#define smhc_clr_bit(host, reg, bitmap) \
+	do {							\
+		u32 tmp = smhc_readl(host, reg);	\
+		tmp &= ~(bitmap);				\
+		smhc_writel(host, reg, tmp);		\
+	} while (0)
+
+#define smhc_set_bit(host, reg, bitmap) \
+	do {								\
+		u32 tmp = smhc_readl(host, reg); \
+		tmp |= (bitmap);				\
+		smhc_writel(host, reg, tmp);		\
+	} while (0)
+
+	/* control register bit field */
+	/*0x2c */
+#define ResetAll            (0x1U<<24)
+#define ResetCmd            (0x1U<<25)
+#define ResetDat            (0x1U<<26)
+#define SdclkEn	            (0x1U<<2)
+
+	/*0x200 */
+#define CPUAcessBuffEn      (0x1U<<31)
+#define StopReadClkAtBlkGap (0x1U<<8)
+#define SWDebounceMode      (0x1U<<5)
+#define DebounceEnb         (0x1U<<4)
+#define CdDat3En            (0x1U<<3)
+#define SdclkIdleCtrl       (0x1U<<2)
+
+	/* Struct for SMC Commands */
+	/*0x18 */
+#define CMDType         (0x3U<<22)
+#define DataExp         (0x1U<<21)
+#define CheckRspIdx     (0x1U<<20)
+#define CheckRspCRC     (0x1U<<19)
+#define NoRsp           (0x0U<<16)
+#define Rsp136          (0x1U<<16)
+#define Rsp48           (0x2U<<16)
+#define Rsp48b          (0x3U<<16)
+#define SingleBlkTrans  (0x0U<<5)
+#define MultiBlkTrans   (0x1U<<5)
+#define Read            (0x1U<<4)
+#define Write           (0x0U<<4)
+#define AutoCmd12       (0x1U<<2)
+#define AutoCmd23       (0x2U<<2)
+#define BlkCntEn        (0x1U<<1)
+#define DMAEn           (0x1U<<0)
+
+	/*0x204 */
+#define SendInitSeq     (0x1U<<4)
+#define DisableBoot     (0x1U<<3)
+#define BootACKExp      (0x1U<<2)
+#define AltBootMode     (0x2U<<0)
+#define MandBootMode    (0x1U<<0)
+
+	/*0x03C */
+#define Switch3v3To1v8  (0x1U<<19)
+#define DdrType         (0x7<<16)
+#define DDR_SHIFT       (16)
+
+	/*0x24 */
+#define CmdLineSta      (0x1U<<24)
+#define Dat3LineSta     (0x1U<<23)
+#define Dat2LineSta     (0x1U<<22)
+#define Dat1LineSta     (0x1U<<21)
+#define Dat0LineSta     (0x1U<<20)
+#define WpPinSta        (0x1U<<19)
+#define CdPinInvSta     (0x1U<<18)
+#define CardStable      (0x1U<<17)
+#define CardInsert      (0x1U<<16)
+#define BuffRDEn        (0x1U<<11)
+#define BuffWREn        (0x1U<<10)
+#define RDTransActive   (0x1U<<9)
+#define WRTransActive   (0x1U<<8)
+#define DatLineActive   (0x1U<<2)
+#define CmdInhibitDat   (0x1U<<1)
+#define CmdInhibitCmd   (0x1U<<0)
+
+#define BootDataStart     (0x1U<<29)
+#define BootAckRcv        (0x1U<<28)
+#define DSFOInt		        (0x1U<<30)
+#define DmaErrInt         (0x1U<<25)
+#define AcmdErrInt        (0x1U<<24)
+#define DatEndBitErrInt   (0x1U<<22)
+#define DatCRCErrInt      (0x1U<<21)
+#define DatTimeoutErrInt  (0x1U<<20)
+#define CmdIdxErrInt      (0x1U<<19)
+#define CmdEndBitErrInt   (0x1U<<18)
+#define CmdCRCErrInt      (0x1U<<17)
+#define CmdTimeoutErrInt  (0x1U<<16)
+#define ErrInt            (0x1U<<15)
+#define CardInt           (0x1U<<8)
+#define CardRemoveInt     (0x1U<<7)
+#define CardInsertInt     (0x1U<<6)
+#define BuffRDRdyInt      (0x1U<<5)
+#define BuffWRRdyInt      (0x1U<<4)
+#define DmaInt            (0x1U<<3)
+	/*#define BlkGapEvtInt          (0x1U<<2)*/
+#define TransOverInt      (0x1U<<1)
+#define CmdOverInt        (0x1U<<0)
+#define TxDatIntBit       (DmaInt | TransOverInt | DmaErrInt | ErrInt)
+#define RxDatIntBit       (DmaInt | TransOverInt | DmaErrInt | ErrInt)
+#define DmaIntBit         (DmaInt | DmaErrInt)
+#define ErrIntBit         (0x437F0000)	/*(0x1ff<<16)*/
+#define DoneIntBit		  (TransOverInt|CmdOverInt)
+
+	/*0x28 SMHC_CTRL1 bit field*/
+#define Dma32BitSel       (0x3<<3)
+#define DmaSel            (0x3<<3)
+#define BusWidth          (0x1<<1)
+#define ExtBusWidth       (0x1<<5)
+
+	/*0x3C Auto CMD Error Status */
+#define NoAcmd12          (0x1U<<7)
+#define AcmdIdxErr        (0x1U<<4)
+#define AcmdEndBitErr     (0x1U<<3)
+#define AcmdCRCErr        (0x1U<<2)
+#define AcmdTimeoutErr    (0x1U<<1)
+#define NotIssueAcmd      (0x0<<0)
+
+enum {
+	ACT_NOP = 0,
+	ACT_RSV,
+	ACT_TRANS,
+	ACT_LINK,
+};
+
+enum {
+	MAN_BOOT_MD = 0,
+	ALT_BOOT_MD,
+};
+
+struct sdhc_idma_des {
+/*=1: indicates this line of descriptor is effective.
+ *=0: generate ADMA Error interrupt and stop ADMA to prevent runaway.
+ */
+	u32 valid:1,
+/*=1: indicates end of descriptor.
+ *The Transfer Complete Interrupt is generated
+ *when the operation of the descriptor line is completed.
+ */
+		end:1,
+/*
+ *=1: generates DMA Interrupt
+ *when the operation of the descriptor line is completed.
+ */
+			int_en:1,
+		: 1,
+/*00b: Nop, No Operation, Do not execute current line and go to next line.*/
+act:2,
+/*01b: rsv, reserved, (Same as Nop. Do not execute current line
+ *and go to next line.)
+ */
+/*10b: Tran, transfer data, Transfer data of one descriptor
+ *line Transfer data of one descriptor line
+ */
+/*11b: Link, Link Descriptor, Link to another descriptor*/
+		: 10,
+	length:16;
+	u32 addr;
+};
+
+struct sunxi_mmc_ctrl_regs {
+	u32 rst_clk_ctrl;
+	u32 int_sta_en;
+	u32 to;
+	u32 ctrl3;
+	u32 int_sig_en;
+	u32 ctrl1;
+	u32 acmd_err_ctrl2;
+	u32 atc;
+};
+
+struct sunxi_mmc_host {
+	struct mmc_host *mmc;
+	struct reset_control *reset;
+
+	/* IO mapping base */
+	void __iomem *reg_base;
+
+	/* clock management */
+	struct clk *clk_ahb;
+	struct clk *clk_mmc;
+	struct clk *clk_rst;
+
+	int (*sunxi_mmc_clk_set_rate)(struct sunxi_mmc_host *host,
+				       struct mmc_ios *ios);
+
+	/* irq */
+	spinlock_t lock;
+	int irq;
+	u32 int_sum;
+	u32 sdio_imask;
+
+	/* dma */
+	u32 idma_des_size_bits;
+	dma_addr_t sg_dma;
+	void *sg_cpu;
+	bool wait_dma;
+	u32 dma_tl;
+	u64 dma_mask;
+
+	void (*sunxi_mmc_thld_ctl)(struct sunxi_mmc_host *host,
+				    struct mmc_ios *ios,
+				    struct mmc_data *data);
+
+	struct mmc_request *mrq;
+	struct mmc_request *mrq_busy;
+	struct mmc_request *manual_stop_mrq;
+	int ferror;
+
+	u32 power_on;
+
+	/* pinctrl handles */
+	struct pinctrl *pinctrl;
+	struct pinctrl_state *pins_default;
+	struct pinctrl_state *pins_sleep;
+
+	/*sys node */
+	struct device_attribute maual_insert;
+	struct device_attribute *dump_register;
+	struct device_attribute dump_clk_dly;
+	void (*sunxi_mmc_dump_dly_table)(struct sunxi_mmc_host *host);
+
+	/* backup register structrue */
+	struct sunxi_mmc_ctrl_regs bak_regs;
+	void (*sunxi_mmc_save_spec_reg)(struct sunxi_mmc_host *host);
+	void (*sunxi_mmc_restore_spec_reg)(struct sunxi_mmc_host *host);
+
+	void (*sunxi_mmc_set_acmda)(struct sunxi_mmc_host *host);
+
+	void (*sunxi_mmc_shutdown)(struct platform_device *pdev);
+
+	/*really controller id,no logic id */
+	int phy_index;
+
+	u32 dat3_imask;
+
+	/*no wait busy if wrtie end, only for customer need */
+#define NO_MANUAL_WAIT_BUSY_WRITE_END  0x1
+#define NO_REINIT_SHUTDOWN			   0x2
+#define CARD_PWR_GPIO_HIGH_ACTIVE	   0x4
+	/*control specal function control,for customer need */
+	u32 ctl_spec_cap;
+
+	int card_pwr_gpio;
+
+	void *version_priv_dat;
+};
+
+/*use to check ddr mode,not include hs400*/
+#define sunxi_mmc_ddr_timing(it)	\
+	(((it) == MMC_TIMING_UHS_DDR50) || ((it) == MMC_TIMING_MMC_DDR52))
+
+#endif
-- 
2.17.1

